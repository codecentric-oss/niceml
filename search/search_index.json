{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to niceML","text":"<p>niceML is a tool to help you set up your machine learning projects faster.  It provides pipelines for a variety of ML tasks, like</p> <ul> <li>Object Detection,</li> <li>Semantic Segmentation,</li> <li>Regression,</li> <li>Classification</li> <li>and others.</li> </ul> <p>All you have to do is configure your pipeline, and you're ready to go!</p> <p>You can also add your own components to the built-in dashboard,  where you can compair the results and performance of your ML models.</p> <p>The documentation of niceML is separated into four paths:</p> <ol> <li>Tutorials</li> <li>How-To Guides</li> <li>Concepts</li> <li>References</li> </ol> <p>Quickly find what you're looking for depending on your use case by looking at the provided pages.</p>"},{"location":"#installation","title":"Installation","text":"<pre><code>poetry add niceml\n</code></pre> <p>For a detailed installation guide, have a look at the Getting Started Tutorial.</p>"},{"location":"CODE_OF_CONDUCT/","title":"\ud83e\udd1d Code of Conduct for niceML \ud83c\udf66","text":"<p>As contributors and maintainers of this open source project, we are committed to providing a welcoming and inclusive environment for everyone involved. We value the participation of all individuals, regardless of their background, experience level, gender, gender identity and expression, sexual orientation, disability, personal appearance, race, ethnicity, age, religion, or nationality. Therefore, we have established the following code of conduct, which applies to all project participants, including maintainers, contributors, and users. By participating in this project, you agree to abide by this code of conduct.</p>"},{"location":"CODE_OF_CONDUCT/#1-be-respectful-and-inclusive","title":"1. \ud83d\udc50 Be Respectful and Inclusive","text":"<p>Treat all individuals with respect and kindness. Be considerate of differing viewpoints and experiences. Refrain from using derogatory, offensive, or exclusionary language or behavior. Foster a positive and inclusive atmosphere where everyone feels valued and heard.</p>"},{"location":"CODE_OF_CONDUCT/#2-embrace-diversity","title":"2. \ud83c\udf08 Embrace Diversity","text":"<p>We welcome and encourage participation from people of all backgrounds. Embrace and celebrate diversity in all its forms. We believe that a diverse community leads to richer discussions and better outcomes.</p>"},{"location":"CODE_OF_CONDUCT/#3-open-communication","title":"3. \ud83d\udde3\ufe0f Open Communication","text":"<p>Maintain open and constructive communication. Listen attentively to others and be open to feedback and criticism. Communicate in a clear, concise, and respectful manner. Disagreements may arise, but they should always be handled with civility.</p>"},{"location":"CODE_OF_CONDUCT/#4-collaboration-and-cooperation","title":"4. \ud83e\udd1d Collaboration and Cooperation","text":"<p>Encourage a collaborative and cooperative environment. Support and uplift fellow contributors. Offer assistance and guidance to those who seek it. Together, we can achieve great things through teamwork.</p>"},{"location":"CODE_OF_CONDUCT/#5-be-mindful-of-others","title":"5. \ud83d\ude4c Be Mindful of Others","text":"<p>Be aware of the impact your words and actions may have on others. Be mindful of cultural differences and varying perspectives. Strive to create an environment where everyone feels safe and comfortable to participate.</p>"},{"location":"CODE_OF_CONDUCT/#6-respect-project-guidelines","title":"6. \u2705 Respect Project Guidelines","text":"<p>Adhere to the project's guidelines, including coding standards, documentation requirements, and contribution processes. Respect the decisions made by project maintainers and follow their guidance.</p>"},{"location":"CODE_OF_CONDUCT/#7-reporting-violations","title":"7. \ud83d\udea8 Reporting Violations","text":"<p>If you witness or experience any behavior that violates this code of conduct, promptly report it to one of the project maintainers at contact-niceml@codecentric.de. All reports will be reviewed and handled confidentially. We are dedicated to addressing any concerns and ensuring a positive project environment for all.</p> <p>Remember that this code of conduct applies to all project spaces, including GitHub repositories, issue trackers, communication channels, and project events.</p> <p>Let's work together to build a welcoming and inclusive community where everyone can contribute and grow.</p> <p>Note: This code of conduct was adapted from the Contributor Covenant (https://www.contributor-covenant.org/version/2/0/code_of_conduct.html).</p>"},{"location":"CODING_STANDARDS/","title":"Coding Guidelines for niceML \ud83c\udf66","text":"<p>Welcome to the coding guidelines for niceML! To ensure consistency and maintainability across the codebase, please follow these guidelines when contributing to the project. \ud83d\udea7\ud83d\udcbb</p>"},{"location":"CODING_STANDARDS/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Style Guide</li> <li>Naming Conventions</li> <li>Documentation</li> <li>Testing</li> <li>Code Organization</li> <li>Dependencies</li> <li>Security</li> </ul>"},{"location":"CODING_STANDARDS/#style-guide","title":"Style Guide","text":"<p>We follow the PEP 8 style guide for Python code. Please run a linter before submitting your code changes.</p>"},{"location":"CODING_STANDARDS/#naming-conventions","title":"Naming Conventions","text":"<ul> <li>Use descriptive and meaningful variable and function names.</li> <li>Follow the snake_case convention for variable and function names.</li> <li>Class names should follow the CamelCase convention.</li> </ul> <pre><code># Good\ndef calculate_average(numbers_list):\n    pass\n\n\nclass DataProcessor:\n    pass\n\n\n# Avoid\ndef calc_avg(nums):\n    pass\n\n\nclass data_processor:\n    pass\n</code></pre>"},{"location":"CODING_STANDARDS/#pre-commit-hooks","title":"Pre-Commit Hooks","text":"<p>We use of pre-commit hooks to maintain code quality and consistency throughout the project. Pre-commit hooks automate checks and formatting tasks before each commit, preventing issues from being introduced into the repository. This ensures that all contributors follow the established coding standards and  contribute to a cleaner and more consistent codebase. Make sure to run pre-commit checks before each commit to avoid common issues and keep the development process smooth. \ud83e\uddf9\ud83d\udc69\u200d\ud83d\udcbb\ud83d\udc68\u200d\ud83d\udcbb</p> <p>To set up pre-commit hooks:</p> <p>Install Pre-Commit: <pre><code>poetry run pre-commit install\n</code></pre></p> <p>Run Pre-Commit on Existing Code: (Optional) <pre><code>poetry run pre-commit run --all-files\n</code></pre></p> <p>Run Pre-Commit on your staged Code Changes: (Required for each Commit) <pre><code>poetry run pre-commit run\n</code></pre></p>"},{"location":"CODING_STANDARDS/#documentation","title":"Documentation","text":"<ul> <li>Include docstrings for all modules, classes, and functions using   the Google Style Docstrings.</li> <li>Provide clear and concise comments for complex or non-obvious code sections.</li> </ul>"},{"location":"CODING_STANDARDS/#testing","title":"Testing","text":"<ul> <li>Write unit tests for new features and bug fixes.</li> <li>Ensure existing tests pass before submitting a pull request.</li> <li>Strive for high test coverage to catch potential issues early.</li> <li>Make sure all tests ran successfully, before a Merge.</li> </ul>"},{"location":"CODING_STANDARDS/#code-organization","title":"Code Organization","text":"<ul> <li>Keep each module focused on a specific functionality.</li> <li>Group related functions and classes together.</li> <li>Generalize where it is reasonable and possible.</li> <li>Avoid overly long functions; consider breaking them into smaller, more modular   functions.</li> </ul>"},{"location":"CODING_STANDARDS/#dependencies","title":"Dependencies","text":"<ul> <li>Use Poetry for managing project dependencies.</li> <li>Document dependencies in the <code>pyproject.toml</code> file.</li> <li>Pin versions to ensure consistent behavior across environments.</li> </ul> <pre><code>poetry add &lt;new-package&gt;\n</code></pre>"},{"location":"CODING_STANDARDS/#security","title":"Security","text":"<ul> <li>Be mindful of potential security vulnerabilities in your code.</li> <li>If you discover a security issue, please report it responsibly by contacting the   maintainers privately via our Email contact-niceml@codecentric.de.</li> </ul> <p>These guidelines are designed to ensure a clean and maintainable codebase. Thank you for your commitment to writing high-quality code for niceML! \ud83c\udf08\ud83d\udc69\u200d\ud83d\udcbb\ud83d\udc68\u200d\ud83d\udcbb</p>"},{"location":"COMMIT_GUIDELINES/","title":"Commit Guidelines for niceML \ud83c\udf66","text":""},{"location":"COMMIT_GUIDELINES/#overview","title":"Overview","text":"<p>\ud83d\udc4b Welcome to the commit guidelines for niceML! We follow the Conventional Commits specification, a lightweight convention on top of commit messages. The commit messages play a crucial role in determining the project version for a new release and are used to generate the CHANGELOG. Let's dive into the details of how to structure your commits.</p>"},{"location":"COMMIT_GUIDELINES/#commit-message-structure","title":"Commit Message Structure","text":"<p>A commit message consists of a header, an optional body, and an optional footer. The header has a special format that includes a type, an optional scope, and a short description:</p> <pre><code>&lt;type&gt;(&lt;scope&gt;): &lt;description&gt;\n</code></pre>"},{"location":"COMMIT_GUIDELINES/#type","title":"Type","text":"<p>The type must be one of the following:</p> <ul> <li>build: Changes related to the build system or external dependencies.</li> <li>chore: Routine tasks, maintenance, or refactors.</li> <li>ci: Changes to the project's CI/CD configuration.</li> <li>docs: Documentation changes.</li> <li>feat: A new feature for the user.</li> <li>fix: A bug fix.</li> <li>perf: Performance-related improvements.</li> <li>style: Code style changes (formatting).</li> <li>refactor: Code refactoring without changing external behavior.</li> <li>test: Adding or modifying tests.</li> </ul>"},{"location":"COMMIT_GUIDELINES/#scope-optional","title":"Scope (Optional)","text":"<p>The scope provides additional context about the location of the change. It can be omitted if the change is general or affects multiple components.</p>"},{"location":"COMMIT_GUIDELINES/#description","title":"Description","text":"<p>The description is a concise, present-tense summary of the change. It should be clear and easy to understand.</p>"},{"location":"COMMIT_GUIDELINES/#examples","title":"Examples","text":"<p>Here are some examples of well-formed commit messages:</p> <ul> <li>feat(user-auth): add social media login options</li> <li>fix(api): resolve issue with incorrect response format</li> <li>chore: update dependencies to latest versions</li> <li>docs(readme): improve project setup instructions</li> <li>style: format code using black</li> <li>test(unit): add test coverage for module X</li> <li>ci: configure GitHub Actions for continuous integration</li> </ul>"},{"location":"COMMIT_GUIDELINES/#committing-changes","title":"Committing Changes","text":"<p>When making changes, please follow these guidelines:</p> <ol> <li> <p>Separate Changes: If a commit includes multiple changes, try to group them logically and make separate commits.</p> </li> <li> <p>Be Clear and Concise: Write clear and concise commit messages. Avoid unnecessary details in the header.</p> </li> <li> <p>Use Imperative Mood: Write the description in the imperative mood, e.g., \"fix bug\" instead of \"fixed bug.\"</p> </li> <li> <p>Avoid WIP commits: To have a clean GIT history, please avoid WIP commits or other commits that are not conventional commits.     If the Git history contains commits that are not conventional commits, your code contribution will be squashed when the pull request is merged.</p> </li> </ol>"},{"location":"COMMIT_GUIDELINES/#versioning-and-changelog","title":"Versioning and Changelog","text":"<p>The version number for a new release is determined based on the types of commits since the last release. Follow semantic versioning (major.minor.patch). The CHANGELOG is automatically generated from commit messages.</p>"},{"location":"COMMIT_GUIDELINES/#examples_1","title":"Examples","text":"<p>Here are some examples of versioning based on commit messages:</p> <ul> <li>feat: Increment the minor version (1.2.0).</li> <li>fix: Increment the patch version (1.1.1).</li> <li>chore: No version change.</li> </ul> <p>For more details, refer to the Conventional Commits Specification.</p> <p>Thank you for following these commit guidelines! \ud83d\ude80\u2728</p>"},{"location":"CONTRIBUTION/","title":"Contribution Guidelines for niceML \ud83c\udf66","text":"<p>Hello and welcome to the niceML community! We're thrilled that you want to contribute to our project. Here are some guidelines to help you get started and make your contribution smooth and enjoyable. \ud83d\ude80</p>"},{"location":"CONTRIBUTION/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Code of Conduct</li> <li>How to Contribute<ul> <li>Reporting Bugs</li> <li>Feature Requests</li> <li>Pull Requests</li> </ul> </li> <li>Setting Up Your Development Environment</li> <li>Coding Standards</li> <li>Commit Guidelines</li> <li>Branching Strategy</li> <li>Documentation</li> <li>Community</li> <li>Acknowledgments</li> </ul>"},{"location":"CONTRIBUTION/#code-of-conduct","title":"Code of Conduct","text":"<p>Please review and adhere to our Code of Conduct to ensure a positive and inclusive community.</p>"},{"location":"CONTRIBUTION/#how-to-contribute","title":"How to Contribute","text":""},{"location":"CONTRIBUTION/#reporting-bugs","title":"Reporting Bugs","text":"<p>If you encounter a bug, please open an issue and provide detailed information about the problem, including steps to reproduce.</p>"},{"location":"CONTRIBUTION/#feature-requests","title":"Feature Requests","text":"<p>We welcome your ideas for new features! Feel free to submit a feature request and outline the functionality you'd like to see.</p>"},{"location":"CONTRIBUTION/#pull-requests","title":"Pull Requests","text":"<ol> <li>Fork the repository and create a branch for your feature or bug fix.</li> <li>Make your changes and ensure that tests pass.</li> <li>Submit a pull request with a clear and concise description of your changes following    our Pull Request Template.</li> <li>There is a Checklist in the Pull Request Template.     Please ensure that you follow the checklist where appropriate.</li> <li>If the Git history contains only conventional commits,     your code contribution will be rebased.</li> <li>If the Git history contains at least one commit that isn't a conventional commit    your code contribution will be squashed with a single conventional commit.</li> </ol>"},{"location":"CONTRIBUTION/#setting-up-your-development-environment","title":"Setting Up Your Development Environment","text":"<p>To set up your local development environment, follow the instructions in Development Environment Setup.</p>"},{"location":"CONTRIBUTION/#coding-standards","title":"Coding Standards","text":"<p>Please adhere to our coding standards to maintain a consistent codebase.</p>"},{"location":"CONTRIBUTION/#commit-guidelines","title":"Commit Guidelines","text":"<p>Follow our commit guidelines when making changes. This helps keep our commit history clean and meaningful.</p>"},{"location":"CONTRIBUTION/#branching-strategy","title":"Branching Strategy","text":"<p>We use the Gitflow branching model. Ensure your branch names align with the conventions outlined there.</p>"},{"location":"CONTRIBUTION/#documentation","title":"Documentation","text":"<p>Improvements to documentation are always appreciated. Please submit documentation changes along with your code changes. We are using mkdocs to create the niceML documentation. Please use Markdown to create new documentation pages and add it inside the <code>docs</code> folder. Make sure to add the file in the <code>SUMMARY.md</code> file, so it can will be displayed on the website.</p>"},{"location":"CONTRIBUTION/#community","title":"Community","text":"<p>Connect with other contributors and users in our discussion section. Feel free to ask questions or share your experiences. If you want to directly connect with us, write an Email to contact-niceml@codecentric.de.</p>"},{"location":"CONTRIBUTION/#acknowledgments","title":"Acknowledgments","text":"<p>A big thanks to all contributors who help make niceML even better!</p> <p>Thank you for being part of the niceML community! \ud83d\ude4c\ud83c\udf89</p>"},{"location":"DEV_ENV_SETUP/","title":"Developer Environment Setup Guide for niceML \ud83c\udf66","text":""},{"location":"DEV_ENV_SETUP/#overview","title":"Overview","text":"<p>\ud83d\udc4b Welcome to the development environment setup guide for niceML! This guide will walk you through the process of setting up a development environment for contributing to our open-source project.  We use Poetry for managing dependencies, and we recommend using conda environments for a seamless development experience but pipenv or comparable solution are also possible.  Let's get your environment up and running smoothly! \ud83d\ude80</p>"},{"location":"DEV_ENV_SETUP/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, ensure that you have the following installed on your system:</p> <ul> <li>Git</li> <li>Poetry</li> <li>Conda (miniconda or anaconda)</li> </ul>"},{"location":"DEV_ENV_SETUP/#clone-the-repository","title":"Clone the Repository","text":"<pre><code>git clone https://github.com/codecentric-oss/niceml.git\ncd niceml\n</code></pre>"},{"location":"DEV_ENV_SETUP/#create-a-conda-environment","title":"Create a Conda Environment","text":"<p>We recommend using conda to manage your Python environment. Navigate to the project directory and create a conda environment:</p> <pre><code>conda create --name your-env-name python=3.x\nconda activate your-env-name\n</code></pre> <p>Replace <code>your-env-name</code> with your desired environment name and <code>3.x</code> with a Python version above 3.8 and below 3.12. For Apple Silicon we recommend python 3.8.</p>"},{"location":"DEV_ENV_SETUP/#install-poetry-dependencies","title":"Install Poetry Dependencies","text":"<p>We recommend that you don't use Poetry environments. Deactivate the creation of poetry environments:</p> <pre><code>poetry config virtualenvs.create false\n</code></pre> <p>Once your conda environment is active, use Poetry to install project dependencies:</p>"},{"location":"DEV_ENV_SETUP/#default-dependency-installation","title":"Default dependency installation","text":"<pre><code>poetry install -E tensorflow -E visu\n</code></pre>"},{"location":"DEV_ENV_SETUP/#dependency-installation-for-apple-silicon","title":"Dependency installation for Apple Silicon","text":"<pre><code>poetry install -E tensorflow-macos -E visu\n</code></pre> <p>This will install all the required dependencies specified in the <code>pyproject.toml</code> file.</p>"},{"location":"DEV_ENV_SETUP/#running-tests","title":"Running Tests","text":"<p>Ensure everything is set up correctly by running the tests:</p> <pre><code>pytest\n</code></pre> <p>If all tests pass, you're ready to start contributing to the project! \ud83c\udf89</p>"},{"location":"DEV_ENV_SETUP/#contributing-guidelines","title":"Contributing Guidelines","text":"<p>Before you start contributing, make sure to check our contribution guidelines for information on coding standards, pull request procedures, and more.</p> <p>Happy coding! \ud83d\ude80\ud83d\udc69\u200d\ud83d\udcbb\ud83d\udc68\u200d\ud83d\udcbb</p>"},{"location":"SUMMARY/","title":"SUMMARY","text":"<ul> <li>Tutorials<ul> <li>Getting Started</li> <li>Generating Test Data</li> <li>Writing custom pipelines</li> </ul> </li> <li>How-to Guides<ul> <li>How-to-guides</li> <li>Frequently Asked Questions</li> </ul> </li> <li>Concepts<ul> <li>Use Hydra and Dagster</li> <li>Use the niceML Dashboard</li> </ul> </li> <li>References<ul> <li>Dagster Jobs</li> <li>API</li> </ul> </li> <li>Contribute<ul> <li>Contribution Guidelines</li> <li>Code of Conduct</li> <li>Coding Standards</li> <li>Commit Guidelines</li> <li>Development Environment Setup</li> </ul> </li> </ul>"},{"location":"dashboard/","title":"Use the niceML Dashboard","text":"<p>niceML provides a nice and simple dashboard that allows you to visualize and explore the results of your machine learning experiments. In this section, we will show you how to use the <code>niceml dashboard</code> command to access and analyze your experiment data.</p>"},{"location":"dashboard/#launching-the-dashboard","title":"Launching the Dashboard","text":"<p>To launch the niceML dashboard, simply execute the following command in your terminal or command prompt:</p> <pre><code>niceml dashboard\n</code></pre> <p>This command will start the dashboard using the default configuration file <code>configs/dashboard/local.yaml</code>. When the local dashboard server is up, the dashboard will open in a new tab in your default web browser. Otherwise, you can click on the dashboard link in the terminal.</p>"},{"location":"dashboard/#exploring-experiment-results","title":"Exploring Experiment Results","text":"<p>Once the dashboard is launched, you will be presented with an overview of all completed trainings and their general configuration. Experiments are separated by their type, such as Semantic Segmentation (SemSeg). If you have run different experiment types, you can switch between them using the prefix filter in the left sidebar.</p> <p></p> <p>In the sidebar, you can also filter experiments based on different criteria, such as the selected model. This allows you to focus on specific subsets of data and compare the results of different experiments.</p> <p>On the main part of the dashboard, each training is listed with its metrics, configuration, and network data. You can access this information through the different tabs available. These tabs provide insights into specific aspects of the experiment, including metrics, visualizations, and analysis.</p>"},{"location":"dashboard/#downloading-experiments","title":"Downloading Experiments","text":"<p>In some cases, you may have run experiments on remote instances or different machines. The niceML dashboard offers a convenient option to download the experiment data directly from the dashboard interface. This feature allows you to access and analyze experiment results even if the experiment was performed on a different system. This can also be useful, if you need to share the experiment files with others.</p> <p>To download an experiment, follow these steps:</p> <ol> <li>Switch to the <code>Download</code> tab.</li> <li>Select the experiment you want to download from the list of completed trainings.</li> <li>Choose the file types you want to download. You can select from various options depending on the available experiment files.</li> <li>Click on the <code>Download</code> button.</li> </ol> <p>The experiment will be downloaded to your device, allowing you to access the experiment data locally.</p>"},{"location":"dashboard/#recap","title":"Recap","text":"<p>The niceML dashboard is a valuable tool for visualizing and analyzing your machine learning experiment results. </p> <p>You learned to</p> <ul> <li>launch the dashboard (<code>niceml dashboard</code>) to</li> <li>access a comprehensive overview of your completed trainings and</li> <li>download experiments from a remote instance to your defice via the <code>Download</code> tab for further evaluation or to share them with others.</li> </ul>"},{"location":"faq/","title":"Frequently asked Questions","text":""},{"location":"faq/#how-can-i-add-a-run-configuration-to-pycharm","title":"How can I add a run configuration to PyCharm?","text":"<p>If you want to use your own pipeline configuration or are tired to type the make commands into the terminal, PyCharm offers you to use run configurations.</p> <p>In PyCharm, search for the run configuration editor. Usually it can be found in the upper right corner of PyCharm. Otherwise, search the official PyCharm documentation to find it.</p> <p>Add a new configuration using the Python template. Switch the 'target' from 'script path' to 'module name', and set it to use 'dagster'. The 'Parameters' are what you would type in the terminal after the module name. In case of a training, you can adjust the following code to your needs and add it to the configuration:</p> <pre><code>job execute -m niceml.dagster.jobs.repository -j job_train -c configs/jobs/&lt;path to your job yaml&gt;\n</code></pre> <p>If needed, you can make the '.env' file available for your trainings run. Just add your .env-file and check 'Enable EnvFile' in the 'EnvFile' tab of the run configuration.</p> <p>Save everything, and you are ready to run and debug your experiment.</p> <p>Tip</p> <p>You can also add a run configuration for the dashboard. Just set the module name to <code>streamlit</code> and the parameters to <code>run niceml/dashboard/dashboard.py configs/dashboard/&lt;path to your dashboard yaml&gt;</code></p>"},{"location":"faq/#what-is-the-setup-of-the-trainings-pipeline","title":"What is the setup of the trainings pipeline?","text":"<p>The training process consists of three steps: training, prediction, and analysis. Each step serves a specific purpose in the training pipeline:</p> <ol> <li> <p>Training: During this step, the model learns from the training  data to improve its performance. The model parameters are updated iteratively based on the calculated loss and optimization algorithm.</p> </li> <li> <p>Prediction: After training, the trained model is used to make predictions on unseen data. This step allows you to evaluate the model's performance on new images and assess its ability to identify objects accurately.</p> </li> <li> <p>Analysis: Once the prediction step is complete, niceML performs an analysis of the trained model. This may include computing additional metrics, or providing insights into the model's behavior and performance, as well as checking if the training process was successful.</p> </li> </ol>"},{"location":"faq/#which-information-does-niceml-show-when-a-training-is-run","title":"Which information does niceML show, when a training is run?","text":"<p>During the training process, niceML provides real-time updates on the progress:</p> <ul> <li>First, niceML will give an overview about the layers of the model being trained. This allows you to inspect the architecture and understand the composition of the model.</li> <li>A progress bar indicates the number of images that have already been processed by the training.</li> <li>The loss and other metrics are being calculated and displayed during the training. This allows you to monitor the performance of the model.</li> </ul>"},{"location":"faq/#can-i-use-pytorch-with-niceml","title":"Can I use PyTorch with niceML?","text":"<p>Currently, no. But we want to implement it in future versions of niceML.</p>"},{"location":"faq/#how-does-the-test-data-generated-by-niceml-look-like","title":"How does the Test Data generated by niceML look like?","text":"<p>The <code>niceml generate</code> command allows you to create sample images with numbers randomly placed on them. The numbers represent the objects or regions, the model should be able to identify.</p> <p>The following five types of files are generated:</p> <ul> <li> <p>Test Images: The test images are created based on thumbnail images provided by niceML, which are augmented in varying degree. The numbers are randomly chosen, colored and placed on them. These images serve as the foundation for training and evaluating your model.</p> </li> <li> <p>Mask Images: For each test image, a corresponding mask image is generated. The mask image has the same dimensions as the reference image, with the numbers represented in black and the remaining regions in white. These masks help the model to locate the regions which it should learn to identify.</p> </li> <li> <p>Label Information: For each test image, label information in the form of a JSON file is generated. This file contains the location coordinates of the numbers on each test image. The label information serves as ground-truth data for the model to learn and evaluate its performance.</p> </li> <li> <p>Number Images: Additionally, niceML generates cropped versions of the test images, focusing only on the regions where the numbers are present. These number images provide isolated representations of the individual objects or regions that the model should be able to identify.</p> </li> <li> <p>Tabular: niceML converts the number images into a dataframe format. Each row in the dataframe represents the information of one number image. The number shown in the image can be read from the 'label' column. The images are converted from RGB to grayscale and scaled to a fixed size, the default is 10x10 pixels. If the original image is not square, black borders are added to fill the missing space. The dataframe represents the color of each pixel in the 10x10 image, with each column corresponding to one pixel. This dataframe can be useful for testing simple classification tasks with tabular data.</p> </li> </ul> <p>Test image and its mask image:</p> <p> </p> Generated label data augmented.json<pre><code>{\n  \"filename\": \"test-data.json\",\n  \"img_size\": {\n    \"width\": 1024,\n    \"height\": 1024\n  },\n  \"labels\": [\n    {\n      \"class_name\": \"3\",\n      \"class_index\": null,\n      \"color\": null,\n      \"active\": null,\n      \"bounding_box\": {\n        \"x_pos\": 605,\n        \"y_pos\": 258,\n        \"width\": 53,\n        \"height\": 52\n      },\n      \"score\": null,\n      \"rotation\": 133\n    },\n    {\n      \"class_name\": \"0\",\n      \"class_index\": null,\n      \"color\": null,\n      \"active\": null,\n      \"bounding_box\": {\n        \"x_pos\": 918,\n        \"y_pos\": 141,\n        \"width\": 41,\n        \"height\": 49\n      },\n      \"score\": null,\n      \"rotation\": 328\n    },\n    {\n      \"class_name\": \"1\",\n      \"class_index\": null,\n      \"color\": null,\n      \"active\": null,\n      \"bounding_box\": {\n        \"x_pos\": 122,\n        \"y_pos\": 696,\n        \"width\": 43,\n        \"height\": 50\n      },\n      \"score\": null,\n      \"rotation\": 198\n    }\n  ]\n}\n</code></pre> <p>Number image example:</p> <p> </p> Tabular data identifier label px_0_0 px_0_1 px_0_2 px_0_3 px_0_4 px_0_5 px_0_6 px_0_7 px_0_8 px_0_9 px_1_0 px_1_1 px_1_2 px_1_3 px_1_4 px_1_5 px_1_6 px_1_7 px_1_8 px_1_9 px_2_0 px_2_1 px_2_2 px_2_3 px_2_4 px_2_5 px_2_6 px_2_7 px_2_8 px_2_9 px_3_0 px_3_1 px_3_2 px_3_3 px_3_4 px_3_5 px_3_6 px_3_7 px_3_8 px_3_9 px_4_0 px_4_1 px_4_2 px_4_3 px_4_4 px_4_5 px_4_6 px_4_7 px_4_8 px_4_9 px_5_0 px_5_1 px_5_2 px_5_3 px_5_4 px_5_5 px_5_6 px_5_7 px_5_8 px_5_9 px_6_0 px_6_1 px_6_2 px_6_3 px_6_4 px_6_5 px_6_6 px_6_7 px_6_8 px_6_9 px_7_0 px_7_1 px_7_2 px_7_3 px_7_4 px_7_5 px_7_6 px_7_7 px_7_8 px_7_9 px_8_0 px_8_1 px_8_2 px_8_3 px_8_4 px_8_5 px_8_6 px_8_7 px_8_8 px_8_9 px_9_0 px_9_1 px_9_2 px_9_3 px_9_4 px_9_5 px_9_6 px_9_7 px_9_8 px_9_9 4af0f654_000_0.png 0 31 31 72 98 95 86 80 85 86 82 81 76 47 29 23 20 19 159 108 77 78 87 79 63 45 49 41 31 27 21 18 19 25 63 97 108 24 35 84 97 90 83 85 87 84 81 78 52 209 209 209 209 207 209 209 209 197 112 191 55 37 36 28 24 22 20 19 20 27 73 97 107 32 61 90 95 88 85 86 79 85 122 169 209 209 209 209 209 209 209 209 209 209 209 209 209 70 23 19 19 74b46882_000_1.png 1 48 41 37 51 51 54 60 57 54 58 57 57 68 79 86 79 64 47 81 125 109 78 74 81 106 88 97 93 108 116 89 56 51 48 56 60 61 60 58 60 64 65 67 69 60 62 51 56 77 88 124 96 138 76 138 132 138 78 88 77 67 75 73 74 76 73 68 61 53 99 74 138 64 131 112 138 138 136 138 124 138 138 138 138 138 138 138 83 78 66 74 78 76 78 79 78 68 138 100 138 d2cfe383_001_0.png 0 32 32 33 34 33 35 36 32 38 33 35 35 34 35 33 37 36 35 35 36 36 36 37 37 37 37 38 38 38 38 38 38 38 37 37 37 37 37 37 37 32 32 32 32 32 33 33 35 34 35 35 34 34 32 36 35 35 34 34 34 34 34 33 60 33 57 38 31 41 33 33 33 33 33 33 33 32 32 32 32 32 32 32 33 32 34 35 34 35 35 37 36 35 35 35 34 35 35 35 35 76d53953_000_0.png 0 13 12 27 29 18 2 37 82 70 17 10 7 11 29 37 59 75 70 71 48 18 19 74 64 57 81 93 74 72 15 20 27 40 30 0 0 58 106 50 22 18 6 5 44 37 55 170 96 66 136 15 99 64 68 64 98 71 73 14 26 29 47 46 11 1 15 81 83 41 36 70 55 208 208 208 208 208 208 208 208 208 208 116 77 76 80 66 15 27 34 37 57 27 0 3 32 93 95 90 208 d365655f_000_3.png 3 113 115 117 114 100 75 58 80 98 100 86 80 82 92 93 85 80 88 91 81 57 40 102 87 59 37 136 45 42 44 46 49 53 54 52 115 115 118 115 101 85 69 70 94 101 105 107 92 88 98 96 90 91 94 81 91 100 195 195 195 195 195 195 90 42 44 46 49 50 50 111 107 110 108 96 82 68 67 84 93 110 120 108 86 89 104 103 89 172 195 195 195 195 195 195 195 195 195 195 106 <p>Data split and cropping</p> <p>After generating the test data using niceML, the resulting folder structure will have the following subfolders:</p> <ul> <li>number_data: This folder contains the generated images,     their corresponding labels, and masks.</li> <li>number_data_split: In this folder, the generated data is     split into three subfolders: <code>train</code>, <code>test</code>, and <code>validation</code>.     Each subfolder contains the images, labels, and masks     corresponding to the respective dataset split. The image files     are sorted together with their corresponding label and mask     files.</li> <li>numbers_cropped_split: This folder contains cropped     versions of the generated images, focusing only on the regions     where the numbers are present. Each cropped number image is     named after the test image it originated from and is placed in     the same split folder as the original image (<code>train</code>, <code>test</code>, or     <code>validation</code>). This allows for convenient access to the isolated     number images for further analysis or processing.</li> <li>numbers_tabular_data: This folder contains the tabular data     of the cropped images. Each split folder contains a separate     dataframe with only the information of images of that split.</li> </ul>"},{"location":"first-steps/","title":"First steps with your Use-case","text":""},{"location":"first-steps/#how-to-adjust-niceml-to-my-own-dataset","title":"How to adjust niceML to my own dataset","text":"<p>More documentation will be provided soon.</p>"},{"location":"first-steps/#how-to-configure-a-training","title":"How to configure a training","text":"<p>More documentation will be provided soon.</p>"},{"location":"generate-data/","title":"Generating a Test Dataset with niceML","text":"<p>In addition to providing pipelines for various machine learning tasks, niceML also offers a convenient way to generate synthetic test datasets. This can be particularly useful when you need to quickly create a sample dataset for testing or prototyping your models. In this tutorial, we will</p> <ul> <li>set the amount of test data,</li> <li>set the output directory of the test data,</li> <li>configure the targets (= numbers) generated on the test data and</li> <li>generate a test dataset using the <code>niceml gendata</code> command.</li> </ul>"},{"location":"generate-data/#generate-a-test-data-set","title":"Generate a Test data set","text":"<p>Follow the steps below to generate a test dataset:</p>"},{"location":"generate-data/#step-1-run-the-niceml-gendata-command","title":"Step 1: Run the <code>niceml gendata</code> Command","text":"<p>Open your terminal or command prompt and navigate to your project directory. Then, execute the following command:</p> <pre><code>niceml gendata\n</code></pre> <p>This will generate the test data according to the default configuration (<code>configs/jobs/job_data_generation/job_data_generation.yaml</code>). Below you find help to adjust these configurations to your needs.</p> <p>Data will be overwritten</p> <p>Each time you run <code>niceml gendata</code> the folders and images generated by this command will be exchanged. If you want to keep multiple versions of generated data, make sure to rename the old folders or set a new output directory before creating a new test data set.</p>"},{"location":"generate-data/#step-2-explore-the-generated-dataset","title":"Step 2: Explore the Generated Dataset","text":"<p>After the command execution is complete, you will find the generated images in the <code>DATA_URI</code> directory specified in your <code>.env</code> file. Each image will have numbers randomly placed on it, and the label information will be available as well.</p> <p>How does the Test Data generated by niceML look like?</p> <p>More information about what kind of data is generated and the corresponding folder structure is provided here.</p>"},{"location":"generate-data/#step-3-customizing-data-generation-optional","title":"Step 3: Customizing Data Generation (Optional)","text":"<p>niceML generates sample images with numbers placed randomly. However, you can further customize the data generation process according to your requirements. This includes defining the number of images you need, specifying the maximum number to display on the images, and configuring other generation options.</p> <p>Make sure to rerun the <code>niceml gendata</code> command, to create your new test data set.</p>"},{"location":"generate-data/#set-the-output-directory-of-the-test-data","title":"Set the output directory of the test data","text":"<p>The test data will be written to your data directory set in the <code>.env</code> file. To change the direcory, modify the <code>.env</code> file in your project directory. Uncomment and adjust the following parameter as needed:</p> <pre><code># Access data\nDATA_URI=./data  # path to your data\n</code></pre>"},{"location":"generate-data/#set-the-number-of-test-images-to-be-generated","title":"Set the number of test images to be generated","text":"<p>Modify the <code>.env</code> file in your project directory. Uncomment and adjust the following parameter as needed:</p> <pre><code># Optional for number data generation\n# SAMPLE_COUNT=&lt;number of sample images to generate; e.g., 500&gt;\n</code></pre>"},{"location":"generate-data/#set-the-highest-number-to-be-placed-on-the-images-maximum-number-of-target-classes","title":"Set the highest number to be placed on the images (= maximum number of target classes)","text":"<p>The <code>MAX_NUMBER</code> parameter defines the highest number, which should be drawn on the images. Therefore, it also represents the highest number of target classes present in the test dataset.</p> <p>Modify the <code>.env</code> file in your project directory. Uncomment and adjust the following parameter as needed:</p> <pre><code># Optional for number data generation\n...\n# MAX_NUMBER=&lt;highest number to display on test images; e.g., 5&gt;\n</code></pre>"},{"location":"generate-data/#other-configurations","title":"Other configurations","text":"<p>Besides the three main configurations described above, you can adjust the data generation by modifying the corresponding YAML-file.</p> <p>Configurable parameters are:</p> <p><code>configs/ops/data_generation/op_data_generation_number.yaml</code>:</p> <ul> <li><code>seed</code> = seed of the random image generation</li> <li><code>img_size:width</code> = output test image width</li> <li><code>img_size:height</code> = output test image height</li> <li><code>font_size_min</code> = minimum font size of the numbers generated</li> <li><code>font_size_max</code> = maximum font size of the numbers generated</li> <li><code>max_amount</code> = maximum amount of numbers on one image</li> <li><code>detection_labels</code> = whether the label JSON-file should contain  bounding box information</li> <li><code>rotate</code> = whether the numbers should be rotated on the image</li> </ul> <p><code>configs/ops/split_data/op_split_data_number.yaml</code>:</p> <ul> <li><code>set_infos</code>:  probability = probability of a split (train,   test, validation)"},{"location":"generate-data/#recap","title":"Recap","text":"<p>Congratulations! You have learned how to</p> <ul> <li>generate a test dataset using the <code>niceml gendata</code> command</li> <li>configure the test dataset generation to your needs.</li> </ul> <p>This feature allows you to quickly create sample images with numbers placed randomly and obtain label information for each image.</p> <p>You now know how to bootstrap your machine learning project using niceMLs convenient data generation.</p>"},{"location":"getting-started/","title":"niceML Tutorial","text":"<p>Welcome to the tutorial for niceML, a Python package that helps you set up your machine learning projects faster.</p> <p>In this tutorial, we will </p> <ul> <li>walk you through the installation process,</li> <li>initialize a new niceML project,</li> <li>demonstrate how to generate a test data set,</li> <li>train a semantic segmentation with niceMLs default configuration and </li> <li>introduce you to the awesome niceML-dashboard.</li> </ul> <p>Let's get started!</p>"},{"location":"getting-started/#prerequisites","title":"Prerequisites","text":"<p>Before we get started, please ensure that you have the following prerequisites:</p> <ul> <li>Python version above 3.8.0 and below 3.12.0 installed on your system</li> <li>Poetry package manager installed (Install Poetry)</li> <li>Basic knowledge of Python programming</li> </ul>"},{"location":"getting-started/#installation","title":"Installation","text":"<p>To install niceML, follow these steps:</p>"},{"location":"getting-started/#step-1-create-a-new-project","title":"Step 1: Create a New Project","text":"<p>First, create a new directory for your project and navigate into it  using your terminal or command prompt:</p> <pre><code>mkdir niceml-tutorial\ncd niceml-tutorial\n</code></pre>"},{"location":"getting-started/#step-2-initialize-a-poetry-project","title":"Step 2: Initialize a Poetry Project","text":"<p>Next, initialize a new Poetry project within your project directory:</p> <pre><code>poetry init --no-interaction\n</code></pre> <p>This will create a <code>pyproject.toml</code> file, which will serve as the configuration file for your poetry project.</p>"},{"location":"getting-started/#step-3-add-niceml-as-a-dependency","title":"Step 3: Add niceML as a Dependency","text":"<p>To add niceML as a dependency to your project, use the following command:</p> <pre><code>poetry add niceml\n</code></pre> <p>This will automatically resolve and install the latest compatible version of niceML and its required dependencies.</p>"},{"location":"getting-started/#step-4-verify-installation","title":"Step 4: Verify Installation","text":"<p>You can verify that niceML is installed correctly by checking for the version of your niceml installation.</p> <pre><code>niceml --version\n</code></pre> <p>If the version information is shown, congratulations! You have successfully installed niceML.</p>"},{"location":"getting-started/#initialization-of-a-niceml-project","title":"Initialization of a niceML project","text":"<p>Once niceML is installed, you can initialize your project. This command will set up the necessary project structure and create a template folder in your project directory. To initialize niceML, run the following command:</p> <pre><code>niceml init\n</code></pre> <p>This command will guide you through a series of questions to set up niceML for your project. Provide the following answers based on your system and preferences:</p> <ul> <li><code>Do you want to use our pre-commit hooks?</code> Answer: Yes   (If you prefer to use your own pre-commit hooks, answer No)</li> <li><code>Should Poetry take care of creating a virtual environment?</code> Answer:    No (If you followed our installation guide, you are already using a   poetry environment)</li> <li><code>Do you use Apple Silicon as a GPU?</code> Answer: No (If you are using   Apple Silicon as a GPU, answer Yes)</li> <li><code>Do you want to use our awesome dashboard?</code> Answer: Yes (This is where   the experiment results can be shown)</li> </ul> <p>Once you have answered all the questions, niceML will be initialized according to your operating system and including the awesome dashboard.</p> <p>If you find two new folders named <code>niceml-tutorial</code> (or whatever name you chose for your project) and  <code>configs</code> within your project, everything is prepared for your first experiment.</p>"},{"location":"getting-started/#optional-adjust-the-env-file","title":"Optional: Adjust the .env File","text":"<p>Among the files generated by <code>niceml init</code>, you will find a <code>.env</code> file with some general configuration parameters. In the future, you can adjust the parameters according to your needs.</p> <p>If you like, you can define a new name for the data directory by setting the <code>DATA_URI</code> parameter or specify the output file of the experiments by setting the <code>EXPERIMENT_URI</code> parameter. You do not need to create these folders, niceML will take care of this. Leave the other parameters as they are for now.</p>"},{"location":"getting-started/#run-your-first-niceml-training","title":"Run your first niceML training","text":""},{"location":"getting-started/#step-1-generate-test-data","title":"Step 1: Generate test data","text":"<p>niceML provides a convenient way to generate test data for your machine learning projects. You can use the niceml generate command to generate a test dataset with sample images and label information. The sample images contain randomly placed numbers, and the labels indicate the locations of the numbers on the images.</p> <p>To generate the test data, run the following command:</p> <pre><code>niceml gendata\n</code></pre> <p>This will generate the test data according to the default configuration (<code>configs/jobs/job_data_generation/job_data_generation.yaml</code>). You can later configure your own data generation settings if needed. You will find the generated images in the specified <code>DATA_URI</code> directory. Go have a look before we continue.</p>"},{"location":"getting-started/#step-2-train-your-first-model","title":"Step 2: Train your first model","text":"<p>You will now train your first model using the easy-to-use command-line interface of niceml: <code>niceml train &lt;path to your configuration yaml&gt;</code>. In this tutorial, we will train a Semantic Segmentation using the default configuration.</p> <p>To start the training using the test data, run the following command:</p> <pre><code>niceml train configs/jobs/job_train/job_train_semseg/job_train_semseg_number.yaml\n</code></pre> <p>This command instructs niceML to start training a semantic segmentation model based on the configuration file <code>job_train_semseg_number.yaml</code>. The training may take a few minutes.</p> <p>During the training, you will see a progress bar indicating the number of images processed. The loss, metrics, and model layers will also be displayed in real-time updates.</p> <p>The training process consists of three steps: training, prediction, and analysis. Each step contributes to the overall training process and evaluation of the model.</p> <p>Tip</p> <p>You can find more details about the trainings pipeline and the provided monitoring by following the links.</p>"},{"location":"getting-started/#checking-the-experiment-output","title":"Checking the Experiment Output","text":"<p>After the training is completed, you can check the experiment output in the new experiments folder, which is named according to your <code>EXPERIMENT_URI</code> parameter. You will notice also notice new subfolder if it with the prefix <code>SEMSEG</code>, followed by the current date and a four-letter experiment ID in its name. This folder contains the trained model, its configurations, a slice of net data, performance results and other relevant information for the trained semantic segmentation model.</p> <p>If the training was completed without any errors and the experiment output folder was created, you successfully ran your first training with niceML. Very good, you are almost done!</p>"},{"location":"getting-started/#exploring-experiment-results-in-the-niceml-dashboard","title":"Exploring Experiment Results in the niceML Dashboard","text":"<p>niceML provides a simple and expandable dashboard that allows you to visualize and explore the results of your machine learning experiments.</p> <p>To launch the niceML dashboard, simply execute the following command:</p> <pre><code>niceml dashboard\n</code></pre> <p>This command will start the dashboard using the default configuration file <code>configs/dashboard/local.yaml</code>. When the local dashboard server is up, the dashboard will open in a new tab in your default web browser. Otherwise, you can click on the dashboard link in the terminal.</p> <p></p> <p>Try out navigating through the tabs and options of the dashboard. </p> <p>Tip</p> <p>If you want to know more about the features of the dashboard, you can find more information here.</p>"},{"location":"getting-started/#recap","title":"Recap","text":"<p>Congratulations! You have learned how to </p> <ul> <li>install niceML (<code>poetry add niceml</code>),</li> <li>initialize niceML for your project (<code>niceml init</code>),</li> <li>generate a test data set (<code>niceml generate</code>),</li> <li>train a model using default configuration (<code>niceml train &lt;config yaml&gt;</code>),</li> <li>and use the dashboard to evaluate its performance (<code>niceml dashboard</code>).</li> </ul>"},{"location":"how-to-guides/","title":"How-to Guides","text":"<p>This part of the project documentation focuses on a problem-oriented approach. You'll tackle common tasks that you might have, with the help of the code provided in this project.</p>"},{"location":"how-to-guides/#how-to-debug-my-experiment","title":"How to debug my experiment","text":"<p>To debug your experiment, you need to add a run configuration to your favorite IDE. Here is an example on how to add a run configuration in PyCharm.</p> <p>Some parts of the training need an additional configuration, to make them debuggable. E.g. Debugging metrics, the loss or net callbacks. To debug them, you need to set the <code>RUN_EAGERLY</code> parameter of your .env file to <code>True</code></p>"},{"location":"how-to-guides/#how-to-use-my-own-run-configuration-for-a-niceml-pipeline","title":"How to use my own run configuration for a niceML pipeline","text":"<p>niceML runs its pipelines via dagster. If you want to start the pipelines in the terminal, just use the following code snippet, replace the path and run it in your terminal. </p> <pre><code>dagster job execute -m niceml.dagster.jobs.repository -j job_train -c configs/jobs/&lt;path to your job yaml&gt;\n</code></pre>"},{"location":"how-to-guides/#how-to-configure-the-test-data-generation-to-my-needs","title":"How to configure the test data generation to my needs","text":"<p>Everything about test data generation and its adjustable parameters can be found in the Generating a Test Dataset with niceML</p>"},{"location":"how-to-guides/#how-to-add-a-custom-model","title":"How to add a custom model","text":"<p>In order to define a custom model in niceML we can make use of the niceML <code>ModelFactory</code> class and its create_model function. To create a new model, implement yours by inheriting from  the <code>ModelFactory</code> and configuring the functions you need. Here is an example: <pre><code>from typing import Any\n\nimport tensorflow as tf\nfrom keras import layers, Sequential, regularizers\nfrom niceml.data.datadescriptions.datadescription import DataDescription\nfrom niceml.data.datadescriptions.inputdatadescriptions import InputImageDataDescription\nfrom niceml.data.datadescriptions.outputdatadescriptions import OutputVectorDataDescription\nfrom niceml.mlcomponents.models.modelfactory import ModelFactory\nfrom niceml.utilities.commonutils import check_instance\n\n\nclass FlowerCNN(ModelFactory):\n    def __init__(self, regulation_value: float, activation_function: str, final_activation: str):\n        self.final_activation = final_activation\n        self.activation_function = activation_function\n        self.regulation_value = regulation_value\n\n    def create_model(self, data_description: DataDescription) -&gt; Any:\n        input_dd: InputImageDataDescription = check_instance(\n            data_description, InputImageDataDescription\n        )\n        output_dd: OutputVectorDataDescription = check_instance(\n            data_description, OutputVectorDataDescription\n        )\n\n        in_layer = tf.keras.layers.Input(input_dd.get_input_tensor_shape())\n\n        model = Sequential([\n            in_layer,\n\n            layers.Conv2D(16, 3, padding='same', activation=self.activation_function),\n            layers.MaxPooling2D(),\n\n            layers.Conv2D(32, 3, padding='same', activation=self.activation_function),\n            layers.MaxPooling2D(),\n\n            layers.Conv2D(64, 3, padding='same', activation=self.activation_function),\n            layers.MaxPooling2D(),\n\n            layers.Dropout(0.2),\n\n            layers.Flatten(),\n\n            layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(self.regulation_value)),\n            layers.Dense(output_dd.get_output_size(), name=\"outputs\", activation=self.final_activation)\n        ])\n        model.summary()\n        return model\n</code></pre> To use the model in your training pipeline change the target of the model setting to <code>nicemlproject.dir.of.custom.FlowerCNN</code> in the training operation configuration <code>configs/ops/prediction/op_train.yaml</code>.</p>"},{"location":"how-to-guides/#how-to-start-the-pipeline-via-the-dagster-ui","title":"How to start the pipeline via the dagster UI?","text":"<p>You start dagster via <pre><code>dagster dev -m nicemltutorial.dagster.jobs.repository\n</code></pre></p> <p>and paste the job configuration of your choice to the launchpad.</p>"},{"location":"how-to-guides/#how-to-implement-a-new-dashboard-component","title":"How to implement a new dashboard component","text":"<p>More documentation will be provided soon.</p>"},{"location":"how-to-guides/#how-to-use-a-remote-system-in-the-dashboard","title":"How to use a remote system in the dashboard","text":"<p>More documentation will be provided soon.</p>"},{"location":"how-to-guides/#how-to-use-minio-with-niceml","title":"How to use MinIO with niceML","text":"<p>More documentation will be provided soon.</p>"},{"location":"how-to-guides/#how-to-add-a-new-custom-metric","title":"How to add a new custom metric","text":"<p>More documentation will be provided soon.</p>"},{"location":"hydra-dagster/","title":"Use Hydra and Dagster","text":""},{"location":"hydra-dagster/#hydra-configuration-in-combination-with-dagster","title":"Hydra Configuration in combination with Dagster","text":"<p>Hydra is a powerful configuration system that makes it easy to write and manage configuration files for complex applications. Hydra uses a YAML file format to define configuration settings that can be used across different parts of an application. In this tutorial, we'll see how to use Hydra to configure niceML's machine learning pipeline with Dagster.</p>"},{"location":"hydra-dagster/#understanding-hydra-configurations","title":"Understanding Hydra Configurations","text":"<p>Hydra allows users to define a hierarchical set of configuration files that can be used to configure different parts of an application. The configuration hierarchy is defined in terms of \"groups\", which are essentially directories that contain YAML files. Each YAML file represents a configuration \"scope\" that can be used to define settings for different parts of an application.</p> <p>Hydra also allows for \"defaults\", which are YAML files that contain commonly used settings that can be imported into other YAML files. This is particularly useful for niceML's machine learning pipelines, where certain settings are shared across different parts of the pipeline.</p>"},{"location":"hydra-dagster/#using-hydra-with-dagster","title":"Using Hydra with Dagster","text":"<p>Dagster is a data orchestration tool that makes it easy to build pipelines. Dagster provides a way to define \"ops\", which are units of computation that can be connected together to form a pipeline. Each op takes in inputs and produces outputs, which can be connected to other ops. Besides that, each op can be configured individually and independently of the other ops of the pipeline.</p> <p>To use Hydra with Dagster, we can define a set of YAML files that define configuration settings for different parts of the pipeline. The default model training dagster training job is depicted below:</p> <pre><code>graph LR\n  experiment --&gt; train;\n  train --&gt; prediction;\n  prediction --&gt; analysis;\n  analysis --&gt; exptests;</code></pre> <p>Each node in the graph represents one op. An example configuration file looks like this:</p> <pre><code># train binary classification  \ndefaults:  \n  # experiment  \n  - ops/experiment@ops.experiment.config: op_experiment_default.yaml  \n  # train  \n  - /ops/train@ops.train.config: op_train_cls_binary.yaml  \n  # prediction  \n  - /ops/prediction@ops.prediction.config: op_prediction_cls.yaml  \n  # analysis  \n  - /ops/analysis@ops.analysis.config: op_analysis_cls_binary.yaml  \n  # exptests \n  - /ops/exptests@ops.exptests.config.tests: exptests_default.yaml  \n  # experiment locations  \n  - shared/locations@globals: exp_locations.yaml  \n  - _self_  \n\nhydra:  \n  searchpath:  \n    - file://configs  \n\nglobals:  \n  exp_name: SampleClsBinary  \n  exp_prefix: CLB  \n  data_location:  \n    uri: ${oc.env:DATA_URI,./data}/numbers_cropped_split\n</code></pre> <p>The <code>defaults</code> section specifies the loaded configurations for different operations:</p> <ul> <li><code>ops/experiment</code>: specifies the configuration file for the experiment operation, which is <code>op_experiment_default.yaml</code>.</li> <li><code>ops/train</code>: specifies the configuration file for the train operation for binary classification, which is <code>op_train_cls_binary.yaml</code>.</li> <li><code>ops/prediction</code>: specifies the configuration file for the prediction operation for binary classification, which is <code>op_prediction_cls.yaml</code>.</li> <li><code>ops/analysis</code>: specifies the configuration file for the analysis operation for binary classification, which is <code>op_analysis_cls_binary.yaml</code>.</li> <li><code>ops/exptests</code>: specifies the configuration file for the experiment tests operation, which is <code>exptests_default.yaml</code>.</li> <li><code>shared/locations</code>: specifies the configuration file for shared locations, which is <code>exp_locations.yaml</code>.</li> <li><code>_self_</code>: specifies that the position at which the current file is included in the output configuration.</li> </ul> <p>The <code>hydra</code> section sets the search path for the configuration files. Here, it specifies that the configuration files are located in the <code>configs</code> directory.</p> <p>The <code>globals</code> section sets the global variables for the experiment. Here, it sets the experiment name to <code>SampleClsBinary</code>, experiment prefix to <code>CLB</code>, and the location of the data to <code>${oc.env:DATA_URI,./data}/numbers_cropped_split</code>. The <code>${oc.env:DATA_URI,./data}</code> means that the value of the <code>DATA_URI</code> environment variable is used if it exists, and if not, the default value is <code>./data</code>. The <code>uri</code> is a sub-key of <code>data_location</code> that specifies the URI for the data location.</p> <p>This schema of imports is applied recursively which results in the following import graph.</p> <pre><code>graph LR;\n\nniceml/configs/jobs/job_train/job_train_cls/job_train_cls_binary.yaml(job_train_cls_binary) --&gt; niceml/configs/ops/experiment/op_experiment_default.yaml(op_experiment_default);\n\nniceml/configs/jobs/job_train/job_train_cls/job_train_cls_binary.yaml(job_train_cls_binary) --&gt; niceml/configs//ops/train/op_train_cls_binary.yaml(op_train_cls_binary);\n\nniceml/configs/jobs/job_train/job_train_cls/job_train_cls_binary.yaml(job_train_cls_binary) --&gt; niceml/configs//ops/prediction/op_prediction_cls.yaml(op_prediction_cls);\n\nniceml/configs/jobs/job_train/job_train_cls/job_train_cls_binary.yaml(job_train_cls_binary) --&gt; niceml/configs//ops/analysis/op_analysis_cls_binary.yaml(op_analysis_cls_binary);\n\nniceml/configs/jobs/job_train/job_train_cls/job_train_cls_binary.yaml(job_train_cls_binary) --&gt; niceml/configs//ops/exptests/exptests_default.yaml(exptests_default);\n\nniceml/configs/jobs/job_train/job_train_cls/job_train_cls_binary.yaml(job_train_cls_binary) --&gt; niceml/configs/shared/locations/exp_locations.yaml(exp_locations);\n\nniceml/configs//ops/train/op_train_cls_binary.yaml(op_train_cls_binary) --&gt; niceml/configs//ops/train/op_train_base.yaml(op_train_base);\n\nniceml/configs//ops/train/op_train_cls_binary.yaml(op_train_cls_binary) --&gt; niceml/configs//shared/datasets/dataset_cls_test.yaml(dataset_cls_test);\n\nniceml/configs//ops/train/op_train_base.yaml(op_train_base) --&gt; niceml/configs//ops/train/callbacks/callbacks_base.yaml(callbacks_base);\n\nniceml/configs//ops/train/op_train_base.yaml(op_train_base) --&gt; niceml/configs//ops/train/train_params/trainparams_default.yaml(trainparams_default);\n\nniceml/configs//ops/train/op_train_base.yaml(op_train_base) --&gt; niceml/configs//ops/train/exp_initializer/exp_initializer_default.yaml(exp_initializer_default);\n\nniceml/configs//ops/prediction/op_prediction_cls.yaml(op_prediction_cls) --&gt; niceml/configs//shared/datasets/dataset_cls_test.yaml(dataset_cls_test);\n\nniceml/configs//ops/prediction/op_prediction_cls.yaml(op_prediction_cls) --&gt; niceml/configs//ops/prediction/prediction_handler/prediction_handler_vector.yaml(prediction_handler_vector);\n\nniceml/configs//ops/prediction/op_prediction_cls.yaml(op_prediction_cls) --&gt; niceml/configs//ops/prediction/datasets/datasets_generic_default.yaml(datasets_generic_default);\n\nniceml/configs//ops/prediction/op_prediction_cls.yaml(op_prediction_cls) --&gt; niceml/configs//ops/prediction/op_prediction_base.yaml(op_prediction_base);\n\nniceml/configs/shared/locations/exp_locations.yaml(exp_locations) --&gt; niceml/configs//shared/credentials/credentials_minio.yaml(credentials_minio);</code></pre> <p>One of the benefits of using a modular configuration system is that each component can be exchanged and configured independently, making it easier to test the entire system. As a result, all components and configurations can be tested individually, contributing to a more robust and reliable system overall.</p>"},{"location":"hydra-dagster/#op-configuration","title":"Op configuration","text":"<p>In Dagster, each op in a pipeline has its own configuration defined in the code. This configuration specifies the behavior of the op.  In niceML we use this in combination with Hydra's instantiate feature to pass classes via configs to the ops. How each op should be  configured you can find either in the source code or at our ops reference page.</p> <p>Hydra-instantiate-feature</p> <p>Hydra's instantiate feature allows you to create instances of Python classes specified in your configuration files using their fully-qualified name. This is useful when you want to pass instantiated objects to your application, such as passing a logger to a module or passing a database connection to your data layer. Hydra will look for the fully-qualified class name specified in your configuration and then use Python's import system to import and instantiate the class. You can also pass arguments to the class constructor by specifying them in the configuration.</p> <p>For example, if you have a Python class called <code>MyClass</code> in a module called <code>my_module</code>, you can instantiate it in your configuration file like this:</p> <pre><code>my_class:\n  _target_: my_module.MyClass\n  arg1: value1\n  arg2: value2\n</code></pre> <p>When you use Hydra to load this configuration, it will create an instance of <code>MyClass</code> with <code>arg1</code> and <code>arg2</code> set to <code>value1</code> and <code>value2</code>, respectively.</p> <p>To do this, you can define a Python class that takes in the necessary configuration parameters and returns an instance of the op. This class can then be used as a config option for the op in your Dagster pipeline.</p>"},{"location":"hydra-dagster/#conclusion","title":"Conclusion","text":"<p>In this tutorial, we've seen how to use Hydra with Dagster to configure a machine learning pipeline. Hydra allows for a hierarchical set of configuration files that can be used to define settings for different parts of the pipeline.  The <code>defaults</code> section in the YAML file allows us to import the content of other YAML files, making it easy to reuse common settings across different parts of the pipeline.</p>"},{"location":"jobsdoc/","title":"Overview of DagsterJobs","text":""},{"location":"jobsdoc/#job-job_train","title":"Job: <code>job_train</code>","text":"<p>Job for training an experiment</p> <pre><code>graph LR\n  experiment --&gt; train;\n  acquire_locks --&gt; train;\n  train --&gt; prediction;\n  train --&gt; prediction;\n  prediction --&gt; analysis;\n  prediction --&gt; analysis;\n  prediction --&gt; analysis;\n  analysis --&gt; release_locks;\n  analysis --&gt; exptests;</code></pre>"},{"location":"jobsdoc/#op-acquire_locks","title":"Op: <code>acquire_locks</code>","text":"<p>op for acquiring locks</p> ConfigKey Description <code>filelock_dict</code> Abstract base class for file locks."},{"location":"jobsdoc/#op-experiment","title":"Op: <code>experiment</code>","text":"<p>This Op creates the experiment params</p> ConfigKey Description <code>exp_folder_pattern</code> Folder pattern of the experiment. Can use $RUN_ID and $SHORT_ID to make the name unique <code>exp_out_location</code> Folder to store the experiments"},{"location":"jobsdoc/#op-train","title":"Op: <code>train</code>","text":"<p>DagsterOp that trains the model</p> ConfigKey Description <code>data_description</code> This class is used to describe the data. E.g. how big the input image size is,     or what target classes are used. <code>data_train</code> Dataset to load, transform, shuffle the data before training <code>data_validation</code> Dataset to load, transform, shuffle the data before training <code>exp_initializer</code> This class creates the first folder and files for an experiment <code>learner</code> Wrapper to do the training <code>model</code> ABC for model factories. Used to create the model before training <code>remove_key_list</code> These key are removed from any config recursively before it is saved. <code>train_params</code> TrainParams are used to select the amount of steps and epochs for training"},{"location":"jobsdoc/#op-prediction","title":"Op: <code>prediction</code>","text":"<p>Dagster op to predict the stored model with the given datasets</p> ConfigKey Description <code>datasets</code> Dataset to load, transform, shuffle the data before training <code>model_loader</code> Callable that loads models <code>prediction_function</code> Abstract class for prediction functions <code>prediction_handler</code> Abstract PredictionHandler class to implement your own prediction handler <code>prediction_steps</code> If None the whole datasets are processed. Otherwise only <code>prediction_steps</code> are evaluated. <code>remove_key_list</code> These key are removed from any config recursively before it is saved."},{"location":"jobsdoc/#op-analysis","title":"Op: <code>analysis</code>","text":"<p>This dagster op analysis the previous predictions applied by the model</p> ConfigKey Description <code>remove_key_list</code> These key are removed from any config recursively before it is saved. <code>result_analyzer</code> After the prediction is done all data can be analyzed with a specific     implementation of the ResultAnalyzer"},{"location":"jobsdoc/#op-release_locks","title":"Op: <code>release_locks</code>","text":"<p>op for releasing locks</p> ConfigKey Description"},{"location":"jobsdoc/#op-exptests","title":"Op: <code>exptests</code>","text":"<p>op to run the experiment tests</p> ConfigKey Description <code>remove_key_list</code> These key are removed from any config recursively before it is saved. <code>tests</code> Class to execute a list of ExperimentTests"},{"location":"jobsdoc/#job-job_eval","title":"Job: <code>job_eval</code>","text":"<p>Job for evaluating experiment</p> <pre><code>graph LR\n  localize_experiment --&gt; eval_copy_exp;\n  eval_copy_exp --&gt; prediction;\n  acquire_locks --&gt; prediction;\n  prediction --&gt; analysis;\n  prediction --&gt; analysis;\n  prediction --&gt; analysis;\n  analysis --&gt; release_locks;\n  analysis --&gt; exptests;</code></pre>"},{"location":"jobsdoc/#op-acquire_locks_1","title":"Op: <code>acquire_locks</code>","text":"<p>op for acquiring locks</p> ConfigKey Description <code>filelock_dict</code> Abstract base class for file locks."},{"location":"jobsdoc/#op-localize_experiment","title":"Op: <code>localize_experiment</code>","text":"<p>This op localizes the experiment and returns the experiment context</p> ConfigKey Description <code>existing_experiment</code> Used to define the experiment id. This is an alpha numeric str with the lenth of 4 <code>exp_folder_pattern</code> Unused. Only required due to easier configuration <code>exp_out_location</code> Folder to store the experiments"},{"location":"jobsdoc/#op-eval_copy_exp","title":"Op: <code>eval_copy_exp</code>","text":"<p>Copy experiment from one to another.</p> ConfigKey Description <code>description</code> Description of the experiment. Replaces the training description <code>exp_folder_pattern</code> Folder pattern of the experiment. Can use $RUN_ID and $SHORT_ID to make the name unique <code>exp_out_location</code> Folder to store the experiments"},{"location":"jobsdoc/#op-prediction_1","title":"Op: <code>prediction</code>","text":"<p>Dagster op to predict the stored model with the given datasets</p> ConfigKey Description <code>datasets</code> Dataset to load, transform, shuffle the data before training <code>model_loader</code> Callable that loads models <code>prediction_function</code> Abstract class for prediction functions <code>prediction_handler</code> Abstract PredictionHandler class to implement your own prediction handler <code>prediction_steps</code> If None the whole datasets are processed. Otherwise only <code>prediction_steps</code> are evaluated. <code>remove_key_list</code> These key are removed from any config recursively before it is saved."},{"location":"jobsdoc/#op-analysis_1","title":"Op: <code>analysis</code>","text":"<p>This dagster op analysis the previous predictions applied by the model</p> ConfigKey Description <code>remove_key_list</code> These key are removed from any config recursively before it is saved. <code>result_analyzer</code> After the prediction is done all data can be analyzed with a specific     implementation of the ResultAnalyzer"},{"location":"jobsdoc/#op-release_locks_1","title":"Op: <code>release_locks</code>","text":"<p>op for releasing locks</p> ConfigKey Description"},{"location":"jobsdoc/#op-exptests_1","title":"Op: <code>exptests</code>","text":"<p>op to run the experiment tests</p> ConfigKey Description <code>remove_key_list</code> These key are removed from any config recursively before it is saved. <code>tests</code> Class to execute a list of ExperimentTests"},{"location":"jobsdoc/#job-job_copy_exp","title":"Job: <code>job_copy_exp</code>","text":"<p>Copy an experiment from one location to another</p>"},{"location":"jobsdoc/#op-copy_exp","title":"Op: <code>copy_exp</code>","text":"<p>Copy experiment from one to another.</p> ConfigKey Description <code>experiment_id</code> Alphanumeric 4-char string to identify the experiment <code>input_loc_name</code> Name of the input location ressource <code>output_loc_name</code> Name of the output location ressource"},{"location":"jobsdoc/#job-job_data_generation","title":"Job: <code>job_data_generation</code>","text":"<p>Job for data generation</p> <pre><code>graph LR\n  data_generation --&gt; split_data;\n  split_data --&gt; crop_numbers;\n  crop_numbers --&gt; image_to_tabular_data;\n  image_to_tabular_data --&gt; df_normalization;</code></pre>"},{"location":"jobsdoc/#op-data_generation","title":"Op: <code>data_generation</code>","text":"<p>Generates random test image dataset based on a given <code>data_generator</code></p> ConfigKey Description <code>data_generator</code> Generator of images with numbers for an object detection test dataset"},{"location":"jobsdoc/#op-split_data","title":"Op: <code>split_data</code>","text":"<p>Splits the data in input_location into subsets (set_infos)</p> ConfigKey Description <code>clear_folder</code> Flag if the output folder should be cleared before the split. <code>max_split</code> Maximum split of the name (e.g. 1) <code>name_delimiter</code> Character to seperate names. <code>output_location</code> Folder to save the split images <code>recursive</code> Flag if the input folder should be searched recursively. <code>set_infos</code> Split information how to split the data <code>sub_dir</code> Subdirectory to save the split images"},{"location":"jobsdoc/#op-crop_numbers","title":"Op: <code>crop_numbers</code>","text":"<p>Crops the numbers from the input images and stores them separately</p> ConfigKey Description <code>clear_folder</code> Flag if the output folder should be cleared before the split <code>name_delimiter</code> Delimiter used within the filenames <code>output_location</code> Foldername where the images are stored <code>recursive</code> Flag if the input folder should be searched recursively <code>sub_dir</code> Subdirectory to save the split images"},{"location":"jobsdoc/#op-image_to_tabular_data","title":"Op: <code>image_to_tabular_data</code>","text":"<p>The image_to_tabular_data function takes in a location of images and converts them to tabular data.</p> <p>Args:     context: OpExecutionContext: Pass in the configuration of the operation     input_location: dict: Specify the location of the input data</p> <p>Returns:     The output_location where the parquet files with the table values are stored.     The files are still divided into test, train and validation.</p> ConfigKey Description <code>clear_folder</code> Flag if the output folder should be cleared before the split <code>name_delimiter</code> Delimiter used within the filenames <code>output_location</code> Foldername where the images are stored <code>recursive</code> Flag if the input folder should be searched recursively <code>sub_dir</code> Subdirectory to save the split images <code>target_image_size</code> Image size to which the images should be scaled <code>use_dirs_as_subsets</code> Flag if the subdirectories should be used as subset names"},{"location":"jobsdoc/#op-df_normalization","title":"Op: <code>df_normalization</code>","text":"<p>The df_normalization function takes in a dataframe and normalizes the features specified in <code>scalar_feature_keys</code>, <code>categorical_feature_keys</code> and <code>binary_feature_keys</code>. The parameters for the feature keys can be a function that returns the feature keys as a list or a list of feature keys. The function returns a normalized parquet file with all columns normalized specified in feature_keys, as well as an output yaml file containing information about how each feature was normalized. The input_parq_location is where the input parquet files are located, while output_parq_location is where you want to save your new dataframes and norm info yaml.</p> <p>Args:     context: OpExecutionContext: Get the op_config     input_location: dict: Specify the location of the input data</p> <p>Returns:     The output_parq_location, which is the location of the normalized parquet files     and norm info</p> ConfigKey Description <code>binary_feature_keys</code> Column names to be normalized with binary values (list or function) <code>categorical_feature_keys</code> Column names to be normalized with categorical values (list or function) <code>output_norm_feature_info_file_name</code> File name for the file containing the normalization information of the features <code>output_parq_location</code> Target location for the normalized parq files <code>recursive</code> <code>scalar_feature_keys</code> Column names to be normalized with scalar values (list or function)"},{"location":"write-custom-pipeline/","title":"Writing a new training pipeline","text":"<p>This tutorial will walk you through how to set up your first custom training pipeline. The goal of this example pipeline is to orchestrate a classifier that can distinguish between daisies and roses.</p> <p>In this tutorial we will  - learn which configuration yaml files we have to write to get our pipeline running - have a look how the dataset, training, prediction, etc. configurations are connected with each other  - train a binary classifier with niceML</p>"},{"location":"write-custom-pipeline/#prerequisites","title":"Prerequisites","text":"<p>Before we get started, please ensure that you have followed the Getting Started tutorial and initialized a new niceML project.</p>"},{"location":"write-custom-pipeline/#step-1-data-ingestion","title":"Step 1: Data ingestion","text":"<p>Download the images from Kaggle and store the roses and daisies images in a <code>data</code> folder in your niceML project.</p>"},{"location":"write-custom-pipeline/#step-2-configure-the-pipeline-job","title":"Step 2: Configure the pipeline job","text":"<p>Let us start configuring at the highest level of niceML: The job  configuration. For this, navigate to <code>configs/jobs/job_train/job_train_cls</code>  and create a new file <code>job_train_cls_binary_flowers.yaml</code>.</p> <p>Paste the content of <code>configs/jobs/job_train/job_train_cls/job_train_cls_binary.yaml</code> which is a good starting point for our own pipeline.</p> <p>Adjust job parameters in <code>job_train_cls_binary_flowers.yaml</code>. Many parameters  are pre-configured and do not require adjustment. However, we want to configure our own  - train and prediction ops (<code>/ops/train@ops.train.config</code>, <code>/ops/train@ops.prediction.config</code>),  - experiment_id (<code>globals</code> -&gt; <code>exp_name</code> and <code>exp_prefix</code>) - and input data location (<code>globals</code> -&gt; <code>data_location</code>). </p> <p>In the job configuration, you can already point to the location where the Kaggle images are stored.  Also, you can change the path to the  dagster train and prediction operation configurations you are going to write in the next two steps.</p> <pre><code># train binary classification\ndefaults:\n  # experiment\n  - ops/experiment@ops.experiment.config: op_experiment_default.yaml\n  # train\n  - /ops/train@ops.train.config: op_train_cls_binary_flowers.yaml\n  # prediction\n  - /ops/prediction@ops.prediction.config: op_prediction_cls_binary_flowers.yaml\n  # analysis\n  - /ops/analysis@ops.analysis.config: op_analysis_cls_binary.yaml\n  # experiment tests\n  - /ops/exptests@ops.exptests.config.tests: exptests_default.yaml\n  # experiment locations\n  - shared/locations@globals: exp_locations.yaml\n  - _self_\n\nhydra:\n  searchpath:\n    - file://configs\n\nglobals:\n  exp_name: FlowersClsBinary\n  exp_prefix: FLOWERSCLB\n  data_location:\n    uri: ${oc.env:DATA_URI,./data}/kaggle_flowers\n</code></pre>"},{"location":"write-custom-pipeline/#step-3-configure-the-train-operation","title":"Step 3: Configure the train operation","text":"<p>Navigate to <code>configs/ops/train</code> and create <code>op_train_cls_binary_flowers.yaml</code>.</p> <p>You can use the content of <code>op_train_cls_binary_flowers.yaml</code> as a starting point  and change the definition where the training data is stored, what the image size is and which classes you use as labels. </p> <p>This means, you have to edit - <code>/shared/datasets@data_train</code> - <code>/shared/datasets@data_validation</code> - <code>classes</code> - <code>target_size width</code> and <code>target_size height</code></p> <p>For the time being, use the OwnMobileNetModel model of Tensorflow and do not implement your own model definition.</p> <pre><code>defaults:\n  - op_train_base.yaml@_here_\n  - /shared/datasets@data_train: dataset_kaggle_flowers.yaml\n  - /shared/datasets@data_validation: dataset_kaggle_flowers.yaml\n  - _self_\ntrain_params:\n  epochs: 5\ndata_description:\n  _target_: niceml.data.datadescriptions.clsdatadescription.ClsDataDescription\n  classes:\n  - \"daisy\"\n  - \"roses\"\n  use_binary: true\n  target_size:\n    _target_: niceml.utilities.imagesize.ImageSize\n    width: 180\n    height: 180\n\ndata_train:\n  datainfo_listing:\n    sub_dir: train\n  set_name: train\n  shuffle: true\ndata_validation:\n  datainfo_listing:\n    sub_dir: validation\n  set_name: validation\nmodel:\n  _target_: niceml.dlframeworks.keras.models.mobilenet.OwnMobileNetModel\n  final_activation: sigmoid\nmodel_load_custom_objects:\n  _target_: niceml.mlcomponents.modelcompiler.modelcustomloadobjects.ModelCustomLoadObjects\nlearner:\n  _target_: niceml.dlframeworks.keras.learners.defaultlearner.DefaultLearner\n  model_compiler:\n    _target_: niceml.dlframeworks.keras.modelcompiler.defaultmodelcompiler.DefaultModelCompiler\n    loss: binary_crossentropy\n    # Optimizer used in the experiment\n    optimizer:\n      _target_: tensorflow.keras.optimizers.Adam\n      learning_rate: 0.0001\n    metrics: [ \"accuracy\" ]   \n</code></pre> <p>You might have noticed, that you did not give a plain directory definition to tell niceml where the training images are stored. Instead, you define the datasets within a configuration yaml in <code>configs/shared/datasets/dataset_kaggle_flowers.yaml</code>. For now, use the same configuration as in <code>dataset_cls_test.yaml</code></p>"},{"location":"write-custom-pipeline/#step-4-configure-the-prediction-operation","title":"Step 4: Configure the prediction operation","text":"<p>Create <code>configs/ops/prediction/op_prediction_cls_binary_flowers.yaml</code> and use <code>op_prediction_cls.yaml</code> as a template.</p> <p>Here, only change the definition of the training, validation and test datasets with the yaml we wrote in the step before (<code>dataset_kaggle_flowers.yaml</code>).  The prediction configuration should look like this:</p> <pre><code>      defaults:\n   - /shared/datasets@datasets.validation: dataset_kaggle_flowers.yaml\n   - /shared/datasets@datasets.test: dataset_kaggle_flowers.yaml\n   - /shared/datasets@datasets.train_eval: dataset_kaggle_flowers.yaml\n   - prediction_handler: prediction_handler_vector.yaml\n   - datasets: datasets_generic_default.yaml\n   - op_prediction_base.yaml@_here_\n   - _self_\n</code></pre>"},{"location":"write-custom-pipeline/#optional-step-5-add-a-custom-model","title":"(Optional) Step 5: Add a custom model","text":"<p>If you want to add a custom model have a look at the How to add a custom model.</p>"},{"location":"write-custom-pipeline/#step-6-start-the-pipeline","title":"Step 6: Start the pipeline","text":"<p>Run niceML and hand over the top-level jon configuration file via</p> <pre><code>niceml train configs/jobs/job_train/job_train_cls/job_train_cls_binary_flowers.yaml\n</code></pre>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>cli<ul> <li>clicommands</li> <li>climain</li> </ul> </li> <li>config<ul> <li>configschemas</li> <li>defaultremoveconfigkeys</li> <li>envconfig</li> <li>hydra</li> <li>subsetnames</li> <li>trainparams</li> <li>writeopconfig</li> </ul> </li> <li>dagster<ul> <li>jobs<ul> <li>jobs</li> <li>repository</li> </ul> </li> <li>ops<ul> <li>analysis</li> <li>copyexp</li> <li>cropnumbers</li> <li>datageneration</li> <li>dfnormalization</li> <li>evalcopyexp</li> <li>experiment</li> <li>exptests</li> <li>filelockops</li> <li>imagetotable</li> <li>localizeexperiment</li> <li>prediction</li> <li>splitdata</li> <li>train</li> </ul> </li> <li>resources<ul> <li>locations</li> </ul> </li> </ul> </li> <li>dashboard<ul> <li>binprobvisu</li> <li>components<ul> <li>downloadexpviscomponent</li> <li>expviscomponent</li> <li>linearviscomponent</li> <li>metaviscomponent</li> <li>prefixviscomponent</li> <li>selectionviscomponent</li> </ul> </li> <li>configviscomponent</li> <li>dashboard</li> <li>expvisuhelper</li> <li>imagenetdataloggerviscomponent</li> <li>metricviscomponent</li> <li>netdataloggerviscomponent</li> <li>remotettrainutils</li> <li>visualizers<ul> <li>boundingboxvisualizer</li> <li>imagevisualizer</li> <li>maskvisualizer</li> </ul> </li> </ul> </li> <li>data<ul> <li>augmentation<ul> <li>augmentation</li> </ul> </li> <li>datadescriptions<ul> <li>clsdatadescription</li> <li>datadescription</li> <li>inputdatadescriptions</li> <li>objdetdatadescription</li> <li>outputdatadescriptions</li> <li>regdatadescription</li> <li>semsegdatadescritption</li> </ul> </li> <li>datafilters<ul> <li>dataframefilter</li> <li>nandataframefilter</li> </ul> </li> <li>datainfolistings<ul> <li>clsdatainfolisting</li> <li>datainfolisting</li> <li>objdetdatainfolisting</li> <li>semsegdatainfolisting</li> </ul> </li> <li>datainfos<ul> <li>clsdatainfo</li> <li>datainfo</li> <li>imagedatainfo</li> <li>objdetdatainfo</li> <li>semsegdatainfo</li> </ul> </li> <li>dataiterators<ul> <li>boundingboxdataiterator</li> <li>dataiterator</li> </ul> </li> <li>dataloaders<ul> <li>cachedimageloader</li> <li>clsdataloader</li> <li>dataloader</li> <li>dfloaders</li> <li>factories<ul> <li>dfloaderfactory</li> <li>imageloaderfactory</li> </ul> </li> <li>imageloaders</li> <li>interfaces<ul> <li>dfloader</li> <li>imageloader</li> </ul> </li> <li>objdetdataloader</li> <li>semseg<ul> <li>semsegdataloader</li> <li>transformmaskimage</li> </ul> </li> </ul> </li> <li>datasets<ul> <li>clsclassinfo</li> <li>dataset</li> <li>dfdataset</li> <li>genericdataset</li> </ul> </li> <li>datashuffler<ul> <li>datashuffler</li> <li>defaultshuffler</li> <li>uniformdistributionshuffler</li> </ul> </li> <li>datastatsgenerator<ul> <li>datastatsgenerator</li> <li>defaultstatsgenerator</li> </ul> </li> <li>featurecombiners<ul> <li>featurecombiner</li> </ul> </li> <li>netdataloggers<ul> <li>netdatalogger</li> <li>objdetnetdatalogger</li> <li>semsegnetdatalogger</li> </ul> </li> <li>normalization<ul> <li>minmax</li> <li>normalization</li> </ul> </li> <li>storages<ul> <li>fsfilesystemstorage</li> <li>fsspecstorage</li> <li>localstorage</li> <li>storagehandler</li> <li>storageinterface</li> </ul> </li> </ul> </li> <li>dlframeworks<ul> <li>keras<ul> <li>callbacks<ul> <li>callback_factories</li> <li>csvlogger</li> <li>modelcheckpoint</li> <li>nancheckcallback</li> </ul> </li> <li>datasets<ul> <li>kerasdfdataset</li> <li>kerasgenericdataset</li> </ul> </li> <li>kerasmetrics</li> <li>kerasmodelloader</li> <li>learners<ul> <li>keraslearner</li> </ul> </li> <li>losses<ul> <li>categoricalfocalloss</li> <li>objdetlosses</li> <li>semseglosses</li> </ul> </li> <li>metrics<ul> <li>objdetmetrics</li> <li>semsegmetrics</li> </ul> </li> <li>modelcompiler<ul> <li>defaultmodelcompiler</li> </ul> </li> <li>models<ul> <li>clsmodelfactory</li> <li>layerfactory</li> <li>loadweightsmodelfactory</li> <li>mlp</li> <li>mobilenet</li> <li>premodellayers</li> <li>retinanet</li> <li>unets</li> </ul> </li> <li>optimizers<ul> <li>schedules<ul> <li>cycliclrschedule</li> </ul> </li> </ul> </li> <li>predictionfunctions<ul> <li>keraspredictionfunction</li> </ul> </li> </ul> </li> </ul> </li> <li>experiments<ul> <li>confextractionmetafunction</li> <li>expdatalocalstorageloader</li> <li>expdatastorageloader</li> <li>experimentcontext</li> <li>experimentdata</li> <li>experimentdownloader</li> <li>experimenterrors</li> <li>experimentinfo</li> <li>experimentmanager</li> <li>experimenttests<ul> <li>checkfilesfolderstest</li> <li>exptests</li> <li>metriccheck</li> <li>testinitializer</li> <li>validateexps</li> </ul> </li> <li>expfilenames</li> <li>expoutinitializer</li> <li>exppathfinder</li> <li>filters<ul> <li>datefilter</li> <li>experimentfilter</li> <li>expselectionfilter</li> <li>selectboxfilter</li> <li>sliderfilter</li> </ul> </li> <li>loaddatafunctions</li> <li>loadexpinfo</li> <li>localexperimentcache</li> <li>metafunctions</li> <li>metainfotables</li> <li>metalists</li> <li>metatablefactory</li> <li>schemas<ul> <li>baseexpschema</li> <li>defaultexpschema</li> <li>expdocstring</li> <li>expmember</li> <li>objdetexpschema</li> <li>parquetframeexpmember</li> <li>sampleexpschemas</li> <li>schemalist</li> <li>schemavalidation</li> <li>yamlexpmember</li> </ul> </li> </ul> </li> <li>filechecksumprocessors<ul> <li>filechecksumprocessor</li> <li>zippedcsvtoparqprocessor</li> </ul> </li> <li>mkdocs<ul> <li>mdgraph</li> <li>mdjob</li> <li>mdop</li> <li>mdtable</li> <li>schemadocgeneration</li> </ul> </li> <li>mlcomponents<ul> <li>callbacks<ul> <li>callbackinitializer</li> </ul> </li> <li>learners<ul> <li>fitgenerators</li> <li>learner</li> </ul> </li> <li>modelcompiler<ul> <li>modelcompiler</li> <li>modelcustomloadobjects</li> </ul> </li> <li>modelloader<ul> <li>modelloader</li> </ul> </li> <li>models<ul> <li>modelbundle</li> <li>modelfactory</li> </ul> </li> <li>objdet<ul> <li>anchorencoding</li> <li>anchorgenerator</li> </ul> </li> <li>predictionfunction<ul> <li>predictionfunction</li> </ul> </li> <li>predictionhandlers<ul> <li>combinationpredictionhandler</li> <li>objdetpredictionhandler</li> <li>predictionhandler</li> <li>semsegpredictionhandler</li> <li>tensorpredictionhandler</li> <li>vectorpredictionhandler</li> </ul> </li> <li>resultanalyzers<ul> <li>analyzer</li> <li>dataframes<ul> <li>clsmetric</li> <li>dfanalyzer</li> <li>multilabeltobinary</li> <li>regmetric</li> </ul> </li> <li>instancefinders<ul> <li>instancecontour</li> <li>instancefinder</li> <li>maskinstance</li> <li>multichannelinstancefinder</li> </ul> </li> <li>multiresultanalyzer</li> <li>tensors<ul> <li>semsegdataiterator</li> <li>tensordataiterators</li> <li>tensordfmetricwrapper</li> <li>tensorgraphanalyzer</li> <li>tensoriou</li> <li>tensormetric</li> <li>tensorvisualizer</li> <li>zarrdataiterator</li> </ul> </li> </ul> </li> <li>targettransformer<ul> <li>imageinputtransformer</li> <li>objdettargettransformer</li> <li>semsegtargettransformer</li> <li>targettransformer</li> <li>targettransformercls</li> </ul> </li> </ul> </li> <li>scripts<ul> <li>hydraconfreader</li> <li>rundatatests</li> <li>splitdatasetindex</li> </ul> </li> <li>storages<ul> <li>abs</li> </ul> </li> <li>utilities<ul> <li>boundingboxes<ul> <li>bboxconversion</li> <li>bboxdrawing</li> <li>bboxencoding</li> <li>bboxlabeling</li> <li>boundingbox</li> <li>filtering<ul> <li>nmsfilter</li> <li>predictionfilter</li> <li>predictionfiltertype</li> <li>thresholdfilter</li> <li>unifiedboxfilter</li> </ul> </li> </ul> </li> <li>chartutils</li> <li>checksums</li> <li>colorutils</li> <li>commonutils</li> <li>copyutils</li> <li>encoding</li> <li>factoryutils</li> <li>filtering<ul> <li>probabilityclassselector</li> </ul> </li> <li>fsspec<ul> <li>locationutils</li> </ul> </li> <li>gitutils</li> <li>hydrautils</li> <li>idutils</li> <li>imagegeneration</li> <li>imageloading</li> <li>imagesize</li> <li>imageutils</li> <li>instancelabeling</li> <li>instancelabelmatching</li> <li>ioumatrix</li> <li>ioutils</li> <li>logutils</li> <li>masks<ul> <li>maskdownscale</li> </ul> </li> <li>matchingresult</li> <li>omegaconfutils</li> <li>pytestutils</li> <li>readwritelock</li> <li>regexutils</li> <li>semseg<ul> <li>semsegdrawing</li> <li>semseginstancelabeling</li> </ul> </li> <li>splitutils</li> <li>thumbnailshower</li> <li>timeutils</li> <li>userselection</li> </ul> </li> </ul>"},{"location":"reference/cli/__init__/","title":"cli","text":""},{"location":"reference/cli/__init__/#niceml.cli","title":"cli","text":"<p>The <code>cli</code> package contains modules for the <code>niceML</code> CLI. It contains e.g. the implementations for <code>niceML init</code>.</p>"},{"location":"reference/cli/clicommands/","title":"clicommands","text":""},{"location":"reference/cli/clicommands/#niceml.cli.clicommands","title":"clicommands","text":"<p>Module for clicommands provided with the package</p>"},{"location":"reference/cli/clicommands/#niceml.cli.clicommands-functions","title":"Functions","text":""},{"location":"reference/cli/clicommands/#niceml.cli.clicommands.dagit","title":"dagit","text":"<pre><code>dagit(context)\n</code></pre> <p>Starts dagit with the niceml repository</p> Source code in <code>niceml/cli/clicommands.py</code> <pre><code>@task\ndef dagit(context):\n    \"\"\"Starts dagit with the niceml repository\"\"\"\n    context.run(\"python -m dagster dev -m niceml.dagster.jobs.repository\")\n</code></pre>"},{"location":"reference/cli/clicommands/#niceml.cli.clicommands.dashboard","title":"dashboard","text":"<pre><code>dashboard(\n    context, config_path=\"configs/dashboard/local.yaml\"\n)\n</code></pre> <p>Starts the experiment dashboard</p> Source code in <code>niceml/cli/clicommands.py</code> <pre><code>@task(help={\"config_path\": \"config_path to your dashboard configuration\"})\ndef dashboard(context, config_path=\"configs/dashboard/local.yaml\"):\n    \"\"\"Starts the experiment dashboard\"\"\"\n    import niceml.dashboard.dashboard as db_module  # pylint: disable=import-outside-toplevel\n\n    run_file = db_module.__file__\n    context.run(f\"streamlit run {run_file} {config_path}\")\n</code></pre>"},{"location":"reference/cli/clicommands/#niceml.cli.clicommands.evaluation","title":"evaluation","text":"<pre><code>evaluation(context, config_path)\n</code></pre> <p>Starts a job_eval job</p> Source code in <code>niceml/cli/clicommands.py</code> <pre><code>@task(help={\"config_path\": \"config_path to your job_eval job config\"})\ndef evaluation(context, config_path):\n    \"\"\"Starts a job_eval job\"\"\"\n    execute_job(context, \"job_eval\", config_path)\n</code></pre>"},{"location":"reference/cli/clicommands/#niceml.cli.clicommands.execute","title":"execute","text":"<pre><code>execute(context, job_name, config_path)\n</code></pre> <p>Starts a job with given name</p> Source code in <code>niceml/cli/clicommands.py</code> <pre><code>@task\ndef execute(context, job_name, config_path):\n    \"\"\"Starts a job with given name\"\"\"\n    execute_job(context, job_name, config_path)\n</code></pre>"},{"location":"reference/cli/clicommands/#niceml.cli.clicommands.execute_job","title":"execute_job","text":"<pre><code>execute_job(context, job_name, config_path)\n</code></pre> <p>helper function to run jobs</p> Source code in <code>niceml/cli/clicommands.py</code> <pre><code>def execute_job(context, job_name, config_path):\n    \"\"\"helper function to run jobs\"\"\"\n    context.run(\n        f\"dagster job execute -m niceml.dagster.jobs.repository -j {job_name} -c {config_path}\"\n    )\n</code></pre>"},{"location":"reference/cli/clicommands/#niceml.cli.clicommands.gendata","title":"gendata","text":"<pre><code>gendata(\n    context,\n    config_path=\"configs/jobs/job_data_generation/job_data_generation.yaml\",\n)\n</code></pre> <p>Starts a job_data_generation job</p> Source code in <code>niceml/cli/clicommands.py</code> <pre><code>@task(help={\"config_path\": \"config_path to your job_data_generation job config\"})\ndef gendata(\n    context, config_path=\"configs/jobs/job_data_generation/job_data_generation.yaml\"\n):\n    \"\"\"Starts a job_data_generation job\"\"\"\n    execute_job(context, \"job_data_generation\", config_path)\n</code></pre>"},{"location":"reference/cli/clicommands/#niceml.cli.clicommands.init","title":"init","text":"<pre><code>init(context)\n</code></pre> <p>Initializes an empty niceml project</p> Source code in <code>niceml/cli/clicommands.py</code> <pre><code>@task\ndef init(context):\n    \"\"\"Initializes an empty niceml project\"\"\"\n\n    old_pyproject_toml = toml.load(\n        join(os.path.abspath(os.getcwd()), \"pyproject.toml\")\n    )[\"tool\"][\"poetry\"]\n\n    attributes_of_interest = [\n        \"name\",\n        \"version\",\n        \"description\",\n        \"authors\",\n        \"packages\",\n        \"dependencies\",\n    ]\n    copier_data_dict = {}\n\n    for attribute in attributes_of_interest:\n        try:\n            attribute_value = old_pyproject_toml[attribute]\n        except KeyError:\n            continue\n        copier_data_dict[attribute] = f\"{attribute_value}\"\n\n        if attribute == \"name\":\n            package_name = attribute_value.replace(\" \", \"\")\n            package_name = package_name.replace(\"-\", \"\")\n            package_name = package_name.replace(\"_\", \"\")\n            copier_data_dict[\"package_name\"] = package_name\n\n        if attribute == \"authors\":\n            copier_data_dict[attribute] = attribute_value\n\n        if attribute == \"dependencies\":\n            copier_data_dict[attribute] = toml.dumps(\n                attribute_value, encoder=toml.TomlPreserveInlineDictEncoder()\n            )\n\n    copier.run_auto(\n        src_path=\"gh:codecentric-oss/niceml\",\n        dst_path=f\"{os.path.abspath(os.getcwd())}\",\n        data=copier_data_dict,\n        overwrite=True,\n    )\n</code></pre>"},{"location":"reference/cli/clicommands/#niceml.cli.clicommands.train","title":"train","text":"<pre><code>train(context, config_path)\n</code></pre> <p>Starts a job_train job</p> Source code in <code>niceml/cli/clicommands.py</code> <pre><code>@task(help={\"config_path\": \"config_path to your job_train job config\"})\ndef train(context, config_path):\n    \"\"\"Starts a job_train job\"\"\"\n    execute_job(context, \"job_train\", config_path)\n</code></pre>"},{"location":"reference/cli/climain/","title":"climain","text":""},{"location":"reference/cli/climain/#niceml.cli.climain","title":"climain","text":"<p>Module for starting cli commands</p>"},{"location":"reference/config/__init__/","title":"config","text":""},{"location":"reference/config/__init__/#niceml.config","title":"config","text":""},{"location":"reference/config/configschemas/","title":"configschemas","text":""},{"location":"reference/config/configschemas/#niceml.config.configschemas","title":"configschemas","text":"<p>Module for configuration schemes</p>"},{"location":"reference/config/configschemas/#niceml.config.configschemas-classes","title":"Classes","text":""},{"location":"reference/config/configschemas/#niceml.config.configschemas.ConfigSchemaConversionException","title":"ConfigSchemaConversionException","text":"<p>             Bases: <code>BaseException</code></p> <p>Base class for exceptions when building config schema.</p>"},{"location":"reference/config/configschemas/#niceml.config.configschemas-functions","title":"Functions","text":""},{"location":"reference/config/configschemas/#niceml.config.configschemas.build_config_schema","title":"build_config_schema","text":"<pre><code>build_config_schema(\n    config_class, builders=_CONFIG_SCHEMA_BUILDERS\n)\n</code></pre> <p>Build dagster config schema from an configuration class.</p> <p>Here, a configuration class is</p> <ul> <li>a scalar type (bool, float, int, str) or</li> <li>a list or tuple of configuration classes or</li> <li>a mapping from scalar type to a configuration class or</li> <li>an attrs class whose attribute types are configuration classes.</li> </ul> <p>For anything else, return <code>dagster.Any</code>.</p> Source code in <code>niceml/config/configschemas.py</code> <pre><code>def build_config_schema(\n    config_class: Any, builders: Iterable[Callable[..., Any]] = _CONFIG_SCHEMA_BUILDERS\n):\n    \"\"\"Build dagster config schema from an configuration class.\n\n    Here, a configuration class is\n\n    - a scalar type (bool, float, int, str) or\n    - a list or tuple of configuration classes or\n    - a mapping from scalar type to a configuration class or\n    - an attrs class whose attribute types are configuration classes.\n\n    For anything else, return ``dagster.Any``.\n    \"\"\"\n    builders_list = list(builders)\n    for converter in builders_list:\n        result = converter(config_class, builders_list)\n        if result is not None:\n            return result  # type: ignore\n    return dagster.Any\n</code></pre>"},{"location":"reference/config/configschemas/#niceml.config.configschemas.define","title":"define","text":"<pre><code>define(\n    maybe_cls=None,\n    *,\n    these=None,\n    repr=None,\n    hash=None,\n    init=None,\n    slots=True,\n    frozen=False,\n    weakref_slot=True,\n    str=False,\n    auto_attribs=None,\n    kw_only=False,\n    cache_hash=False,\n    auto_exc=True,\n    eq=None,\n    order=False,\n    auto_detect=True,\n    getstate_setstate=None,\n    on_setattr=None,\n    field_transformer=None,\n    match_args=True\n)\n</code></pre> <p>Replacement of attr.define that updates class docstring with attributes.</p> Source code in <code>niceml/config/configschemas.py</code> <pre><code>def define(  # pylint: disable=too-many-locals\n    maybe_cls=None,\n    *,\n    these=None,\n    repr=None,  # pylint: disable=redefined-builtin\n    hash=None,  # pylint: disable=redefined-builtin\n    init=None,\n    slots=True,\n    frozen=False,\n    weakref_slot=True,\n    str=False,  # pylint: disable=redefined-builtin\n    auto_attribs=None,\n    kw_only=False,\n    cache_hash=False,\n    auto_exc=True,\n    eq=None,\n    order=False,\n    auto_detect=True,\n    getstate_setstate=None,\n    on_setattr=None,\n    field_transformer=None,\n    match_args=True,\n):\n    \"\"\"Replacement of attr.define that updates class docstring with attributes.\"\"\"\n\n    def decode(cls):\n        \"\"\"Actual decorator function.\"\"\"\n        cls = attr.define(\n            these=these,\n            repr=repr,  # pylint: disable=redefined-builtin\n            hash=hash,  # pylint: disable=redefined-builtin\n            init=init,\n            slots=slots,\n            frozen=frozen,\n            weakref_slot=weakref_slot,\n            str=str,\n            auto_attribs=auto_attribs,\n            kw_only=kw_only,\n            cache_hash=cache_hash,\n            auto_exc=auto_exc,\n            eq=eq,\n            order=order,\n            auto_detect=auto_detect,\n            getstate_setstate=getstate_setstate,\n            on_setattr=on_setattr,\n            field_transformer=field_transformer,\n            match_args=match_args,\n        )(cls)\n\n        cls.__doc__ = format_attrs_doc(cls)\n        return cls\n\n    return decode if maybe_cls is None else decode(maybe_cls)\n</code></pre>"},{"location":"reference/config/configschemas/#niceml.config.configschemas.field","title":"field","text":"<pre><code>field(\n    *,\n    default=NOTHING,\n    validator=None,\n    repr=True,\n    hash=None,\n    init=True,\n    metadata=None,\n    converter=None,\n    factory=None,\n    kw_only=False,\n    eq=None,\n    order=None,\n    on_setattr=None,\n    description=None\n)\n</code></pre> <p>Replacement of attr.field that moves <code>description</code> into metadata.</p> Source code in <code>niceml/config/configschemas.py</code> <pre><code>def field(  # pylint: disable=too-many-locals\n    *,\n    default=NOTHING,\n    validator=None,\n    repr=True,  # pylint: disable=redefined-builtin\n    hash=None,  # pylint: disable=redefined-builtin\n    init=True,\n    metadata=None,\n    converter=None,\n    factory=None,\n    kw_only=False,\n    eq=None,\n    order=None,\n    on_setattr=None,\n    description: Optional[str] = None,\n):\n    \"\"\"Replacement of attr.field that moves ``description`` into metadata.\"\"\"\n    if description:\n        metadata = {**(metadata or {}), \"description\": description}\n    return attr.field(  # type: ignore\n        default=default,\n        validator=validator,\n        repr=repr,  # pylint: disable=redefined-builtin\n        hash=hash,  # pylint: disable=redefined-builtin\n        init=init,\n        metadata=metadata,\n        converter=converter,\n        factory=factory,\n        kw_only=kw_only,\n        eq=eq,\n        order=order,\n        on_setattr=on_setattr,\n    )\n</code></pre>"},{"location":"reference/config/configschemas/#niceml.config.configschemas.format_attribute_doc","title":"format_attribute_doc","text":"<pre><code>format_attribute_doc(attribute)\n</code></pre> <p>Generates and returns attributes of attribute as string</p> Source code in <code>niceml/config/configschemas.py</code> <pre><code>def format_attribute_doc(attribute: attr.Attribute) -&gt; str:\n    \"\"\"Generates and returns attributes of attribute as string\"\"\"\n    attr_type = (\n        attribute.type.__name__\n        if attribute.type is not None and hasattr(attribute.type, \"__name__\")\n        else str(attribute.type)\n    )\n    doc = f\"{attribute.name}: {attr_type}\\n\\t\"\n    if \"description\" in attribute.metadata:\n        doc += f\"{attribute.metadata['description']}. \"\n    if attribute.default != NOTHING:\n        doc += f\"Default: {attribute.default}\"\n    return doc\n</code></pre>"},{"location":"reference/config/configschemas/#niceml.config.configschemas.format_attrs_doc","title":"format_attrs_doc","text":"<pre><code>format_attrs_doc(cls)\n</code></pre> <p>Add attributes section to attrs class docstring.</p> Source code in <code>niceml/config/configschemas.py</code> <pre><code>def format_attrs_doc(cls: Any) -&gt; str:\n    \"\"\"Add attributes section to attrs class docstring.\"\"\"\n    doc = cls.__doc__ or \"\"\n    try:\n        attributes = list(attr.fields(cls))\n    except (TypeError, attr.exceptions.NotAnAttrsClassError):\n        return doc\n    if attributes:\n        doc += \"\\n\\nAttributes\\n----------\\n\\n\"\n        doc += \"\\n\".join(map(format_attribute_doc, attributes))\n    return doc\n</code></pre>"},{"location":"reference/config/configschemas/#niceml.config.configschemas.parse_config","title":"parse_config","text":"<pre><code>parse_config(config, cls)\n</code></pre> <p>Parse configuration.</p> Source code in <code>niceml/config/configschemas.py</code> <pre><code>def parse_config(config: Any, cls: Type[_Config]) -&gt; _Config:\n    \"\"\"Parse configuration.\"\"\"\n    parsed: _Config = cattr.structure(config, cls)\n    return parsed\n</code></pre>"},{"location":"reference/config/defaultremoveconfigkeys/","title":"defaultremoveconfigkeys","text":""},{"location":"reference/config/defaultremoveconfigkeys/#niceml.config.defaultremoveconfigkeys","title":"defaultremoveconfigkeys","text":"<p>Contains the default keys to remove from the config file when saving.</p>"},{"location":"reference/config/envconfig/","title":"envconfig","text":""},{"location":"reference/config/envconfig/#niceml.config.envconfig","title":"envconfig","text":"<p>Module for extracting information from the environment</p>"},{"location":"reference/config/envconfig/#niceml.config.envconfig-functions","title":"Functions","text":""},{"location":"reference/config/envconfig/#niceml.config.envconfig.get_local_exp_cache_path","title":"get_local_exp_cache_path","text":"<pre><code>get_local_exp_cache_path()\n</code></pre> <p>Returns path of local exp cache from environment</p> Source code in <code>niceml/config/envconfig.py</code> <pre><code>def get_local_exp_cache_path() -&gt; Optional[str]:\n    \"\"\"Returns path of local exp cache from environment\"\"\"\n    return getenv(LOCAL_EXP_CACHE_PATH_KEY, None)\n</code></pre>"},{"location":"reference/config/envconfig/#niceml.config.envconfig.replace_id_keys","title":"replace_id_keys","text":"<pre><code>replace_id_keys(input_str, short_id, run_id)\n</code></pre> <p>Replaces the keys $SHORT_ID and $RUN_ID with their actual values</p> Source code in <code>niceml/config/envconfig.py</code> <pre><code>def replace_id_keys(input_str: str, short_id: str, run_id: str) -&gt; str:\n    \"\"\"Replaces the keys $SHORT_ID and $RUN_ID with their actual values\"\"\"\n    input_str = input_str.replace(\"$\" + SHORT_ID_KEY, short_id)\n    input_str = input_str.replace(\"$\" + RUN_ID_KEY, run_id)\n\n    return input_str\n</code></pre>"},{"location":"reference/config/hydra/","title":"hydra","text":""},{"location":"reference/config/hydra/#niceml.config.hydra","title":"hydra","text":"<p>Module containing all utils regarding hydra</p>"},{"location":"reference/config/hydra/#niceml.config.hydra-classes","title":"Classes","text":""},{"location":"reference/config/hydra/#niceml.config.hydra.HydraInitField","title":"HydraInitField","text":"<pre><code>HydraInitField(\n    target_class,\n    description=None,\n    default_value=None,\n    example_value=None,\n    **kwargs\n)\n</code></pre> <p>             Bases: <code>Field</code></p> <p>Used to configure Dagster Ops</p> <p>Used to configure Dagster Ops with a target class</p> <p>Parameters:</p> <ul> <li> <code>target_class</code>         \u2013          <p>class which is instantiated from the op</p> </li> <li> <code>description</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>description of the class or field</p> </li> <li> <code>default_value</code>             (<code>Optional[dict]</code>, default:                 <code>None</code> )         \u2013          <p>default value of the field when nothing is provided</p> </li> <li> <code>example_value</code>             (<code>Optional[dict]</code>, default:                 <code>None</code> )         \u2013          <p>example value of the field shown in the documentation</p> </li> <li> <code>**kwargs</code>         \u2013          <p>additional kwargs passed to the Field class</p> </li> </ul> Source code in <code>niceml/config/hydra.py</code> <pre><code>def __init__(\n    self,\n    target_class,\n    description: Optional[str] = None,\n    default_value: Optional[dict] = None,\n    example_value: Optional[dict] = None,\n    **kwargs,\n):\n    \"\"\"\n    Used to configure Dagster Ops with a target class\n\n    Args:\n        target_class: class which is instantiated from the op\n        description: description of the class or field\n        default_value: default value of the field when nothing is provided\n        example_value: example value of the field shown in the documentation\n        **kwargs: additional kwargs passed to the Field class\n    \"\"\"\n    if description is None:\n        description = target_class.__doc__\n    if default_value is None:\n        default_value = dict()\n    if example_value is None:\n        impl_str: str = \"implementation_of_\" if isabstract(target_class) else \"\"\n        default_value = {\"_target_\": f\"{impl_str}{target_class}\"}\n    super().__init__(\n        dict, description=description, default_value=default_value, **kwargs\n    )\n    self.target_class = target_class\n    self.example_value = example_value\n</code></pre>"},{"location":"reference/config/hydra/#niceml.config.hydra.HydraInitField-functions","title":"Functions","text":""},{"location":"reference/config/hydra/#niceml.config.hydra.HydraMapField","title":"HydraMapField","text":"<pre><code>HydraMapField(\n    target_class,\n    description=None,\n    default_value=None,\n    example_value=None,\n    **kwargs\n)\n</code></pre> <p>             Bases: <code>Field</code></p> <p>Used to configure Dagster Ops</p> <p>Used to configure Dagster Ops with a map</p> <p>Parameters:</p> <ul> <li> <code>target_class</code>         \u2013          <p>class which is instantiated from the op in the map</p> </li> <li> <code>description</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>description of the class or field</p> </li> <li> <code>default_value</code>             (<code>Optional[dict]</code>, default:                 <code>None</code> )         \u2013          <p>default value of the field when nothing is provided</p> </li> <li> <code>example_value</code>             (<code>Optional[dict]</code>, default:                 <code>None</code> )         \u2013          <p>example value of the field shown in the documentation</p> </li> <li> <code>**kwargs</code>         \u2013          <p>additional kwargs passed to the Field class</p> </li> </ul> Source code in <code>niceml/config/hydra.py</code> <pre><code>def __init__(\n    self,\n    target_class,\n    description: Optional[str] = None,\n    default_value: Optional[dict] = None,\n    example_value: Optional[dict] = None,\n    **kwargs,\n):\n    \"\"\"\n    Used to configure Dagster Ops with a map\n\n    Args:\n        target_class: class which is instantiated from the op in the map\n        description: description of the class or field\n        default_value: default value of the field when nothing is provided\n        example_value: example value of the field shown in the documentation\n        **kwargs: additional kwargs passed to the Field class\n    \"\"\"\n    if description is None:\n        description = target_class.__doc__\n    if default_value is None:\n        default_value = dict()\n    if example_value is None:\n        impl_str: str = \"implementation_of_\" if isabstract(target_class) else \"\"\n        example_value = {\"value\": {\"_target_\": f\"{impl_str}{target_class}\"}}\n    super().__init__(\n        Map(str, dict),\n        description=description,\n        default_value=default_value,\n        **kwargs,\n    )\n    self.target_class = target_class\n    self.example_value = example_value\n</code></pre>"},{"location":"reference/config/hydra/#niceml.config.hydra.HydraMapField-functions","title":"Functions","text":""},{"location":"reference/config/hydra/#niceml.config.hydra-functions","title":"Functions","text":""},{"location":"reference/config/hydra/#niceml.config.hydra.hydra_conf_mapping_factory","title":"hydra_conf_mapping_factory","text":"<pre><code>hydra_conf_mapping_factory(drop=('globals'))\n</code></pre> <p>Load hydra configuration from <code>config</code>.</p> <p>Parameters:</p> <ul> <li> <code>config</code>         \u2013          <p>Configuration to be processed with hydra.</p> </li> <li> <code>drop</code>             (<code>Iterable[str]</code>, default:                 <code>('globals')</code> )         \u2013          <p>Keys to remove from the processed configuration after processing    with hydra. Useful to define configuration variables that shall be used    for interpolation during processing but not enter the processed    configuration. Default: <code>(\"globals\",)</code>.</p> </li> </ul> Source code in <code>niceml/config/hydra.py</code> <pre><code>def hydra_conf_mapping_factory(drop: Iterable[str] = (\"globals\",)):\n    \"\"\"\n    Load hydra configuration from ``config``.\n\n    Args:\n        config: Configuration to be processed with hydra.\n        drop: Keys to remove from the processed configuration after processing\n               with hydra. Useful to define configuration variables that shall be used\n               for interpolation during processing but not enter the processed\n               configuration. Default: ``(\"globals\",)``.\n    \"\"\"\n\n    @config_mapping\n    def hydra_conf_mapping(config: Dict[str, Any]):\n        register_niceml_resolvers()\n        config = json.loads(json.dumps(config))\n        config_dir = TemporaryDirectory()  # pylint: disable=consider-using-with\n\n        _, config_file = mkstemp(suffix=\".yaml\", dir=config_dir.name, text=True)\n        with open(config_file, \"wt\", encoding=\"utf-8\") as file:\n            yaml.dump(config, file, Dumper=yaml.SafeDumper)\n\n        conf = load_hydra_conf(config_file)\n        try:\n            config_dir.cleanup()\n        except (PermissionError, NotADirectoryError):\n            pass\n\n        conf = {key: value for key, value in conf.items() if key not in set(drop)}\n        return conf\n\n    return hydra_conf_mapping\n</code></pre>"},{"location":"reference/config/hydra/#niceml.config.hydra.instantiate_from_yaml","title":"instantiate_from_yaml","text":"<pre><code>instantiate_from_yaml(yaml_path, file_system=None)\n</code></pre> <p>uses hydra instantiate to a yaml config</p> Source code in <code>niceml/config/hydra.py</code> <pre><code>def instantiate_from_yaml(\n    yaml_path: str, file_system: Optional[AbstractFileSystem] = None\n) -&gt; Any:\n    \"\"\"uses hydra instantiate to a yaml config\"\"\"\n    file_system = file_system or LocalFileSystem()\n    with file_system.open(yaml_path, \"r\", encoding=\"utf-8\") as file:\n        data = yaml.load(file, Loader=yaml.SafeLoader)\n\n    return instantiate(data)\n</code></pre>"},{"location":"reference/config/hydra/#niceml.config.hydra.prepend_hydra_search_paths","title":"prepend_hydra_search_paths","text":"<pre><code>prepend_hydra_search_paths(config, searchpaths)\n</code></pre> <p>Add searchpaths to config under hydra/searchpath.</p> Source code in <code>niceml/config/hydra.py</code> <pre><code>def prepend_hydra_search_paths(\n    config: Dict[str, Any], searchpaths: Iterable[str]\n) -&gt; Dict[str, Any]:\n    \"\"\"Add searchpaths to config under hydra/searchpath.\"\"\"\n    config_hydra = config.get(\"hydra\", {})\n    config_hydra_searchpaths = list(searchpaths) + config_hydra.get(\"searchpath\", [])\n    return {**config, \"hydra\": {**config_hydra, \"searchpath\": config_hydra_searchpaths}}\n</code></pre>"},{"location":"reference/config/subsetnames/","title":"subsetnames","text":""},{"location":"reference/config/subsetnames/#niceml.config.subsetnames","title":"subsetnames","text":"<p>Module for the subset names</p>"},{"location":"reference/config/subsetnames/#niceml.config.subsetnames-classes","title":"Classes","text":""},{"location":"reference/config/subsetnames/#niceml.config.subsetnames.SubsetNames","title":"SubsetNames","text":"<p>names for datasets in datasets.yml</p>"},{"location":"reference/config/subsetnames/#niceml.config.subsetnames-functions","title":"Functions","text":""},{"location":"reference/config/subsetnames/#niceml.config.subsetnames.get_eval_save_names","title":"get_eval_save_names","text":"<pre><code>get_eval_save_names()\n</code></pre> <p>Returns the names for the evaluation dataset names</p> Source code in <code>niceml/config/subsetnames.py</code> <pre><code>def get_eval_save_names() -&gt; List[str]:\n    \"\"\"Returns the names for the evaluation dataset names\"\"\"\n    return [get_save_name(x) for x in EVAL_DATASET_LIST]\n</code></pre>"},{"location":"reference/config/subsetnames/#niceml.config.subsetnames.get_save_name","title":"get_save_name","text":"<pre><code>get_save_name(dataset_name)\n</code></pre> <p>Removes only the data_ prefix</p> Source code in <code>niceml/config/subsetnames.py</code> <pre><code>def get_save_name(dataset_name: str) -&gt; str:\n    \"\"\"Removes only the data_ prefix\"\"\"\n    if dataset_name.startswith(\"data_\"):\n        return dataset_name[5:]\n    return dataset_name\n</code></pre>"},{"location":"reference/config/trainparams/","title":"trainparams","text":""},{"location":"reference/config/trainparams/#niceml.config.trainparams","title":"trainparams","text":"<p>module for trainparams</p>"},{"location":"reference/config/trainparams/#niceml.config.trainparams-classes","title":"Classes","text":""},{"location":"reference/config/trainparams/#niceml.config.trainparams.TrainParams","title":"TrainParams  <code>dataclass</code>","text":"<p>TrainParams are used to select the amount of steps and epochs for training</p>"},{"location":"reference/config/writeopconfig/","title":"writeopconfig","text":""},{"location":"reference/config/writeopconfig/#niceml.config.writeopconfig","title":"writeopconfig","text":"<p>module for writing config files</p>"},{"location":"reference/config/writeopconfig/#niceml.config.writeopconfig-classes","title":"Classes","text":""},{"location":"reference/config/writeopconfig/#niceml.config.writeopconfig-functions","title":"Functions","text":""},{"location":"reference/config/writeopconfig/#niceml.config.writeopconfig.remove_key_recursive","title":"remove_key_recursive","text":"<pre><code>remove_key_recursive(data, key_list)\n</code></pre> <p>Removes keys from a dict recursively. This is used for credentials.</p> Source code in <code>niceml/config/writeopconfig.py</code> <pre><code>def remove_key_recursive(data, key_list: List[str]):\n    \"\"\"Removes keys from a dict recursively. This is used for credentials.\"\"\"\n    if isinstance(data, list):  # handle lists\n        return [remove_key_recursive(item, key_list) for item in data]\n    elif isinstance(data, dict):  # handle dictionaries\n        return {\n            k: remove_key_recursive(v, key_list)\n            for k, v in data.items()\n            if k not in key_list\n        }\n    else:\n        return data\n</code></pre>"},{"location":"reference/config/writeopconfig/#niceml.config.writeopconfig.write_op_config","title":"write_op_config","text":"<pre><code>write_op_config(\n    op_conf, exp_context, op_name, remove_key_list\n)\n</code></pre> <p>Writes a dict as yamls. With one file per key</p> Source code in <code>niceml/config/writeopconfig.py</code> <pre><code>def write_op_config(\n    op_conf: dict,\n    exp_context: ExperimentContext,\n    op_name: str,\n    remove_key_list: List[str],\n):\n    \"\"\"Writes a dict as yamls. With one file per key\"\"\"\n    for key, values in op_conf.items():\n        removed_values = remove_key_recursive(values, remove_key_list)\n        outfile = join(ExperimentFilenames.CONFIGS_FOLDER, op_name, f\"{key}.yaml\")\n        mlflow.log_dict(removed_values, outfile)\n        exp_context.write_yaml(removed_values, outfile)\n</code></pre>"},{"location":"reference/dagster/__init__/","title":"dagster","text":""},{"location":"reference/dagster/__init__/#niceml.dagster","title":"dagster","text":""},{"location":"reference/dagster/jobs/__init__/","title":"jobs","text":""},{"location":"reference/dagster/jobs/__init__/#niceml.dagster.jobs","title":"jobs","text":""},{"location":"reference/dagster/jobs/jobs/","title":"jobs","text":""},{"location":"reference/dagster/jobs/jobs/#niceml.dagster.jobs.jobs","title":"jobs","text":"<p>Module containing all dagster jobs</p>"},{"location":"reference/dagster/jobs/jobs/#niceml.dagster.jobs.jobs-functions","title":"Functions","text":""},{"location":"reference/dagster/jobs/jobs/#niceml.dagster.jobs.jobs.job_clearlocks","title":"job_clearlocks","text":"<pre><code>job_clearlocks()\n</code></pre> <p>Clear locks from given lock entries</p> Source code in <code>niceml/dagster/jobs/jobs.py</code> <pre><code>@job(\n    config=hydra_conf_mapping_factory(),\n)\ndef job_clearlocks():\n    \"\"\"Clear locks from given lock entries\"\"\"\n    clear_locks()  # pylint: disable=no-value-for-parameter\n</code></pre>"},{"location":"reference/dagster/jobs/jobs/#niceml.dagster.jobs.jobs.job_copy_exp","title":"job_copy_exp","text":"<pre><code>job_copy_exp()\n</code></pre> <p>Copy an experiment from one location to another</p> Source code in <code>niceml/dagster/jobs/jobs.py</code> <pre><code>@job(\n    config=hydra_conf_mapping_factory(),\n    resource_defs={\n        \"locations\": locations_resource,\n    },\n)\ndef job_copy_exp():\n    \"\"\"Copy an experiment from one location to another\"\"\"\n    copy_exp()  # pylint: disable=no-value-for-parameter\n</code></pre>"},{"location":"reference/dagster/jobs/jobs/#niceml.dagster.jobs.jobs.job_data_generation","title":"job_data_generation","text":"<pre><code>job_data_generation()\n</code></pre> <p>Job for data generation</p> Source code in <code>niceml/dagster/jobs/jobs.py</code> <pre><code>@job(config=hydra_conf_mapping_factory())\ndef job_data_generation():\n    \"\"\"Job for data generation\"\"\"\n\n    current_data_location = data_generation()  # pylint: disable=no-value-for-parameter\n    current_data_location = split_data(\n        current_data_location\n    )  # pylint: disable=no-value-for-parameter\n    current_data_location = crop_numbers(\n        current_data_location\n    )  # pylint: disable=no-value-for-parameter\n    current_data_location = image_to_tabular_data(current_data_location)\n    df_normalization(current_data_location)\n</code></pre>"},{"location":"reference/dagster/jobs/jobs/#niceml.dagster.jobs.jobs.job_eval","title":"job_eval","text":"<pre><code>job_eval()\n</code></pre> <p>Job for evaluating experiment</p> Source code in <code>niceml/dagster/jobs/jobs.py</code> <pre><code>@job(config=hydra_conf_mapping_factory(), resource_defs={\"mlflow\": mlflow_tracking})\ndef job_eval():\n    \"\"\"Job for evaluating experiment\"\"\"\n    filelock_dict = acquire_locks()  # pylint: disable=no-value-for-parameter\n    exp_context = localize_experiment()  # pylint: disable=no-value-for-parameter\n    exp_context = eval_copy_exp(exp_context)  # pylint: disable=no-value-for-parameter\n    exp_context, datasets, filelock_dict = prediction(\n        exp_context, filelock_dict\n    )  # pylint: disable=no-value-for-parameter\n    exp_context, filelock_dict = analysis(\n        exp_context, datasets, filelock_dict\n    )  # pylint: disable=no-value-for-parameter\n    release_locks(filelock_dict)  # pylint: disable=no-value-for-parameter\n    exptests(exp_context)  # pylint: disable=no-value-for-parameter\n</code></pre>"},{"location":"reference/dagster/jobs/jobs/#niceml.dagster.jobs.jobs.job_train","title":"job_train","text":"<pre><code>job_train()\n</code></pre> <p>Job for training an experiment</p> Source code in <code>niceml/dagster/jobs/jobs.py</code> <pre><code>@job(config=hydra_conf_mapping_factory(), resource_defs={\"mlflow\": mlflow_tracking})\ndef job_train():\n    \"\"\"Job for training an experiment\"\"\"\n    filelock_dict = acquire_locks()  # pylint: disable=no-value-for-parameter\n    exp_context = experiment()  # pylint: disable=no-value-for-parameter\n    exp_context, filelock_dict = train(\n        exp_context, filelock_dict\n    )  # pylint: disable=no-value-for-parameter\n    exp_context, datasets, filelock_dict = prediction(\n        exp_context, filelock_dict\n    )  # pylint: disable=no-value-for-parameter\n    exp_context, filelock_dict = analysis(\n        exp_context, datasets, filelock_dict\n    )  # pylint: disable=no-value-for-parameter\n    release_locks(filelock_dict)  # pylint: disable=no-value-for-parameter\n    exptests(exp_context)  # pylint: disable=no-value-for-parameter\n</code></pre>"},{"location":"reference/dagster/jobs/repository/","title":"repository","text":""},{"location":"reference/dagster/jobs/repository/#niceml.dagster.jobs.repository","title":"repository","text":"<p>Repository of niceml pipelines.</p>"},{"location":"reference/dagster/jobs/repository/#niceml.dagster.jobs.repository-functions","title":"Functions","text":""},{"location":"reference/dagster/jobs/repository/#niceml.dagster.jobs.repository.get_job_list","title":"get_job_list","text":"<pre><code>get_job_list()\n</code></pre> <p>returns a list of all niceml jobs</p> Source code in <code>niceml/dagster/jobs/repository.py</code> <pre><code>def get_job_list() -&gt; List[JobDefinition]:\n    \"\"\"returns a list of all niceml jobs\"\"\"\n    return [job_train, job_eval, job_copy_exp, job_data_generation]\n</code></pre>"},{"location":"reference/dagster/jobs/repository/#niceml.dagster.jobs.repository.niceml_repository","title":"niceml_repository","text":"<pre><code>niceml_repository()\n</code></pre> <p>returns a list of all niceml jobs</p> Source code in <code>niceml/dagster/jobs/repository.py</code> <pre><code>@repository\ndef niceml_repository() -&gt; List[JobDefinition]:\n    \"\"\"returns a list of all niceml jobs\"\"\"\n    return get_job_list()\n</code></pre>"},{"location":"reference/dagster/ops/__init__/","title":"ops","text":""},{"location":"reference/dagster/ops/__init__/#niceml.dagster.ops","title":"ops","text":""},{"location":"reference/dagster/ops/analysis/","title":"analysis","text":""},{"location":"reference/dagster/ops/analysis/#niceml.dagster.ops.analysis","title":"analysis","text":"<p>Module for the analysis dagster op</p>"},{"location":"reference/dagster/ops/analysis/#niceml.dagster.ops.analysis-classes","title":"Classes","text":""},{"location":"reference/dagster/ops/analysis/#niceml.dagster.ops.analysis-functions","title":"Functions","text":""},{"location":"reference/dagster/ops/analysis/#niceml.dagster.ops.analysis.analysis","title":"analysis","text":"<pre><code>analysis(context, exp_context, datasets, filelock_dict)\n</code></pre> <p>This dagster op analysis the previous predictions applied by the model</p> Source code in <code>niceml/dagster/ops/analysis.py</code> <pre><code>@op(\n    config_schema=dict(\n        result_analyzer=HydraInitField(ResultAnalyzer),\n        remove_key_list=Field(\n            list,\n            default_value=DEFAULT_REMOVE_CONFIG_KEYS,\n            description=\"These key are removed from any config recursively before it is saved.\",\n        ),\n    ),\n    out={\"expcontext\": Out(), \"filelock_dict\": Out()},\n    required_resource_keys={\"mlflow\"},\n)\ndef analysis(\n    context: OpExecutionContext,\n    exp_context: ExperimentContext,\n    datasets: Dict[str, Dataset],\n    filelock_dict: Dict[str, FileLock],\n) -&gt; Tuple[ExperimentContext, Dict[str, FileLock]]:\n    \"\"\"This dagster op analysis the previous predictions applied by the model\"\"\"\n    op_config = json.loads(json.dumps(context.op_config))\n    write_op_config(\n        op_config, exp_context, OpNames.OP_ANALYSIS.value, op_config[\"remove_key_list\"]\n    )\n    instantiated_op_config = instantiate(op_config, _convert_=ConvertMode.ALL)\n    data_description: DataDescription = (\n        exp_context.instantiate_datadescription_from_yaml()\n    )\n\n    result_analyzer: ResultAnalyzer = instantiated_op_config[\"result_analyzer\"]\n    result_analyzer.initialize(data_description)\n\n    for dataset_key, cur_pred_set in datasets.items():\n        context.log.info(f\"Analyze dataset: {dataset_key}\")\n        cur_pred_set.initialize(data_description, exp_context)\n        result_analyzer(cur_pred_set, exp_context, dataset_key)\n\n    return exp_context, filelock_dict\n</code></pre>"},{"location":"reference/dagster/ops/copyexp/","title":"copyexp","text":""},{"location":"reference/dagster/ops/copyexp/#niceml.dagster.ops.copyexp","title":"copyexp","text":"<p>Module containing dagster op which copies experiments</p>"},{"location":"reference/dagster/ops/copyexp/#niceml.dagster.ops.copyexp-classes","title":"Classes","text":""},{"location":"reference/dagster/ops/copyexp/#niceml.dagster.ops.copyexp-functions","title":"Functions","text":""},{"location":"reference/dagster/ops/copyexp/#niceml.dagster.ops.copyexp.copy_exp","title":"copy_exp","text":"<pre><code>copy_exp(context)\n</code></pre> <p>Copy experiment from one to another.</p> Source code in <code>niceml/dagster/ops/copyexp.py</code> <pre><code>@op(\n    config_schema=dict(\n        input_loc_name=Field(str, description=\"Name of the input location ressource\"),\n        output_loc_name=Field(str, description=\"Name of the output location ressource\"),\n        experiment_id=Field(\n            str, description=\"Alphanumeric 4-char string to identify the experiment\"\n        ),\n    ),\n    required_resource_keys={\"locations\"},\n)\ndef copy_exp(context: OpExecutionContext):\n    \"\"\"Copy experiment from one to another.\"\"\"\n    input_location: Location = context.resources.locations[\n        context.op_config[\"input_loc_name\"]\n    ]\n    output_location: Location = context.resources.locations[\n        context.op_config[\"output_loc_name\"]\n    ]\n    exp_id: str = context.op_config[\"experiment_id\"]\n    input_fs: AbstractFileSystem\n    output_fs: AbstractFileSystem\n    with input_location.open_fs_path() as (input_fs, in_path):\n        exp_path_list: List[str] = [\n            x for x in input_fs.ls(in_path) if get_exp_id_from_name(x) == exp_id\n        ]\n        if len(exp_path_list) == 1:\n            exp_path = exp_path_list[0]\n            in_mapper = input_fs.get_mapper(exp_path)\n            exp_path_name = basename(exp_path)\n            with output_location.open_fs_path() as (output_fs, out_fs_path):\n                out_exp_path = join(out_fs_path, exp_path_name)\n                out_mapper = output_fs.get_mapper(out_exp_path)\n                logging.getLogger(__name__).info(\"Starting to copy experiment data\")\n                for key in tqdm(in_mapper):\n                    out_mapper[key] = in_mapper[key]\n            logging.getLogger(__name__).info(\"Removing old experiment data\")\n            input_fs.rm(exp_path, True)\n        elif len(exp_path_list) == 0:\n            logging.getLogger(__name__).warning(\"No exp found with the id: %s\", exp_id)\n        else:\n            logging.getLogger(__name__).warning(\n                \"Multiple exps found with id: %s\", exp_id\n            )\n</code></pre>"},{"location":"reference/dagster/ops/cropnumbers/","title":"cropnumbers","text":""},{"location":"reference/dagster/ops/cropnumbers/#niceml.dagster.ops.cropnumbers","title":"cropnumbers","text":"<p>Module for op crop_numbers</p>"},{"location":"reference/dagster/ops/cropnumbers/#niceml.dagster.ops.cropnumbers-classes","title":"Classes","text":""},{"location":"reference/dagster/ops/cropnumbers/#niceml.dagster.ops.cropnumbers-functions","title":"Functions","text":""},{"location":"reference/dagster/ops/cropnumbers/#niceml.dagster.ops.cropnumbers.crop_numbers","title":"crop_numbers","text":"<pre><code>crop_numbers(context, input_location)\n</code></pre> <p>Crops the numbers from the input images and stores them separately</p> Source code in <code>niceml/dagster/ops/cropnumbers.py</code> <pre><code>@op(\n    config_schema={\n        \"output_location\": Field(\n            dict, description=\"Foldername where the images are stored\"\n        ),\n        \"name_delimiter\": Field(\n            str, default_value=\"_\", description=\"Delimiter used within the filenames\"\n        ),\n        \"sub_dir\": Field(\n            str, default_value=\"\", description=\"Subdirectory to save the split images\"\n        ),\n        \"recursive\": Field(\n            bool,\n            default_value=True,\n            description=\"Flag if the input folder should be searched recursively\",\n        ),\n        \"clear_folder\": Field(\n            bool,\n            default_value=False,\n            description=\"Flag if the output folder should be cleared before the split\",\n        ),\n    }\n)\ndef crop_numbers(  # pylint: disable=too-many-locals\n    context: OpExecutionContext, input_location: dict\n):\n    \"\"\"Crops the numbers from the input images and stores them separately\"\"\"\n    op_config = json.loads(json.dumps(context.op_config))\n\n    instantiated_op_config = instantiate(op_config, _convert_=ConvertMode.ALL)\n\n    output_location: Union[dict, LocationConfig] = instantiated_op_config[\n        \"output_location\"\n    ]\n    if len(instantiated_op_config[\"sub_dir\"]) &gt; 0:\n        output_location = join_location_w_path(\n            output_location, instantiated_op_config[\"sub_dir\"]\n        )\n    if instantiated_op_config[\"clear_folder\"]:\n        clear_folder(output_location)\n    name_delimiter: str = instantiated_op_config[\"name_delimiter\"]\n    recursive: bool = instantiated_op_config[\"recursive\"]\n\n    with open_location(input_location) as (input_fs, input_root):\n        image_files = [\n            cur_file\n            for cur_file in list_dir(\n                input_root, recursive=recursive, file_system=input_fs\n            )\n            if splitext(cur_file)[1] == \".png\" and \"mask\" not in cur_file\n        ]\n\n        for cur_file in tqdm(image_files):\n            label_file = f\"{splitext(cur_file)[0]}.json\"\n            if not input_fs.isfile(join(input_root, label_file)):\n                continue\n            img = read_image(join(input_root, cur_file), file_system=input_fs)\n            image_label: ObjDetImageLabel = load_label_from_json(\n                input_location, label_file\n            )\n            for lbl_idx, cur_label in enumerate(image_label.labels):\n                class_name = cur_label.class_name\n                file_id = basename(splitext(cur_file)[0])\n                crop_box = cur_label.bounding_box.get_absolute_ullr(convert_to_int=True)\n                number_image = img.crop(crop_box)\n                cur_out_folder = dirname(cur_file)\n                out_filename = (\n                    f\"{file_id}{name_delimiter}{lbl_idx:03d}\"\n                    f\"{name_delimiter}{class_name}.png\"\n                )\n                with open_location(output_location) as (output_fs, output_root):\n                    write_image(\n                        number_image,\n                        join(output_root, cur_out_folder, out_filename),\n                        file_system=output_fs,\n                    )\n\n    if isinstance(output_location, LocationConfig):\n        output_location = asdict(output_location)\n\n    return output_location\n</code></pre>"},{"location":"reference/dagster/ops/datageneration/","title":"datageneration","text":""},{"location":"reference/dagster/ops/datageneration/#niceml.dagster.ops.datageneration","title":"datageneration","text":"<p>Module for dagster op to generate test images (object detection / classification)</p>"},{"location":"reference/dagster/ops/datageneration/#niceml.dagster.ops.datageneration-classes","title":"Classes","text":""},{"location":"reference/dagster/ops/datageneration/#niceml.dagster.ops.datageneration-functions","title":"Functions","text":""},{"location":"reference/dagster/ops/datageneration/#niceml.dagster.ops.datageneration.data_generation","title":"data_generation","text":"<pre><code>data_generation(context)\n</code></pre> <p>Generates random test image dataset based on a given <code>data_generator</code></p> Source code in <code>niceml/dagster/ops/datageneration.py</code> <pre><code>@op(config_schema={\"data_generator\": HydraInitField(NumberDataGenerator)})\ndef data_generation(\n    context: OpExecutionContext,\n):\n    \"\"\"Generates random test image dataset based on a given `data_generator`\"\"\"\n\n    op_config = json.loads(json.dumps(context.op_config))\n    instantiated_op_config = instantiate(op_config, _convert_=ConvertMode.ALL)\n    data_generator: NumberDataGenerator = instantiated_op_config[\"data_generator\"]\n\n    clear_folder(data_generator.location)\n    output_location = data_generator.generate_images()\n\n    return output_location\n</code></pre>"},{"location":"reference/dagster/ops/dfnormalization/","title":"dfnormalization","text":""},{"location":"reference/dagster/ops/dfnormalization/#niceml.dagster.ops.dfnormalization","title":"dfnormalization","text":"<p>Module for dataframe normalization op</p>"},{"location":"reference/dagster/ops/dfnormalization/#niceml.dagster.ops.dfnormalization-classes","title":"Classes","text":""},{"location":"reference/dagster/ops/dfnormalization/#niceml.dagster.ops.dfnormalization-functions","title":"Functions","text":""},{"location":"reference/dagster/ops/dfnormalization/#niceml.dagster.ops.dfnormalization.df_normalization","title":"df_normalization","text":"<pre><code>df_normalization(context, input_location)\n</code></pre> <p>The df_normalization function takes in a dataframe and normalizes the features specified in <code>scalar_feature_keys</code>, <code>categorical_feature_keys</code> and <code>binary_feature_keys</code>. The parameters for the feature keys can be a function that returns the feature keys as a list or a list of feature keys. The function returns a normalized parquet file with all columns normalized specified in feature_keys, as well as an output yaml file containing information about how each feature was normalized. The input_parq_location is where the input parquet files are located, while output_parq_location is where you want to save your new dataframes and norm info yaml.</p> <p>Parameters:</p> <ul> <li> <code>context</code>             (<code>OpExecutionContext</code>)         \u2013          <p>OpExecutionContext: Get the op_config</p> </li> <li> <code>input_location</code>             (<code>dict</code>)         \u2013          <p>dict: Specify the location of the input data</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code>         \u2013          <p>The output_parq_location, which is the location of the normalized parquet files</p> </li> <li> <code>dict</code>         \u2013          <p>and norm info</p> </li> </ul> Source code in <code>niceml/dagster/ops/dfnormalization.py</code> <pre><code>@op(\n    config_schema={\n        \"scalar_feature_keys\": Field(\n            Any,\n            description=\"Column names to be normalized with scalar values (list or function)\",\n            default_value=[],\n        ),\n        \"binary_feature_keys\": Field(\n            Any,\n            description=\"Column names to be normalized with binary values (list or function)\",\n            default_value=[],\n        ),\n        \"categorical_feature_keys\": Field(\n            Any,\n            description=\"Column names to be normalized with categorical values (list or function)\",\n            default_value=[],\n        ),\n        \"output_parq_location\": Field(\n            dict, description=\"Target location for the normalized parq files\"\n        ),\n        \"output_norm_feature_info_file_name\": Field(\n            str,\n            description=\"File name for the file containing the normalization \"\n            \"information of the features \",\n            default_value=\"normalization_info.yaml\",\n        ),\n        \"recursive\": Field(bool, description=\"\", default_value=False),\n    }\n)\ndef df_normalization(context: OpExecutionContext, input_location: dict) -&gt; dict:\n    \"\"\"\n    The df_normalization function takes in a dataframe and normalizes the features\n    specified in `scalar_feature_keys`, `categorical_feature_keys` and `binary_feature_keys`.\n    The parameters for the feature keys can be a function that returns the feature keys as\n    a list or a list of feature keys. The function returns a normalized parquet file with\n    all columns normalized specified in feature_keys, as well as an output yaml file\n    containing information about how each feature was normalized. The input_parq_location\n    is where the input parquet files are located, while output_parq_location is where you\n    want to save your new dataframes and norm info yaml.\n\n    Args:\n        context: OpExecutionContext: Get the op_config\n        input_location: dict: Specify the location of the input data\n\n    Returns:\n        The output_parq_location, which is the location of the normalized parquet files\n        and norm info\n    \"\"\"\n    op_config = json.loads(json.dumps(context.op_config))\n    instantiated_op_config = instantiate(op_config, _convert_=ConvertMode.ALL)\n    output_parq_location: dict = instantiated_op_config[\"output_parq_location\"]\n    scalar_feature_keys: List[str] = instantiated_op_config[\"scalar_feature_keys\"]\n\n    binary_feature_keys: List[str] = instantiated_op_config[\"binary_feature_keys\"]\n\n    categorical_feature_keys: List[str] = instantiated_op_config[\n        \"categorical_feature_keys\"\n    ]\n    output_norm_feature_info_file_name: str = instantiated_op_config[\n        \"output_norm_feature_info_file_name\"\n    ]\n\n    with open_location(input_location) as (input_fs, input_root):\n        input_files = list_dir(\n            join_fs_path(input_fs, input_root),\n            file_system=input_fs,\n            recursive=instantiated_op_config[\"recursive\"],\n        )\n        loaded_data_list: List[pd.DataFrame] = []\n        for input_file in input_files:\n            cur_df = read_parquet(\n                file_system=input_fs,\n                filepath=join_fs_path(input_fs, input_root, input_file),\n            )\n            cur_df[\"orig_file_name\"] = [input_file for _ in range(len(cur_df))]\n            loaded_data_list.append(cur_df)\n\n        data = pd.concat(loaded_data_list)\n\n        info_list: List[NormalizationInfo] = []\n        for scalar_feature in tqdm(\n            scalar_feature_keys, desc=\"Normalize scalar features\"\n        ):\n            data, scalar_norm_info = normalize_scalar_column(data, scalar_feature)\n            info_list.append(scalar_norm_info)\n        for categorical_feature in tqdm(\n            categorical_feature_keys, desc=\"Normalize categorical features\"\n        ):\n            data, categorical_norm_info = normalize_categorical_column(\n                data, categorical_feature\n            )\n            info_list.append(categorical_norm_info)\n        for binary_feature in tqdm(\n            binary_feature_keys, desc=\"Normalize binary features\"\n        ):\n            data, binary_norm_info = normalize_binary_column(data, binary_feature)\n            info_list.append(binary_norm_info)\n\n        with open_location(output_parq_location) as (output_fs, output_root):\n            info_dict_list: List[dict] = [asdict(info) for info in info_list]\n\n            write_yaml(\n                data={\"norm_infos\": info_dict_list},\n                file_system=output_fs,\n                filepath=join_fs_path(\n                    output_fs, output_root, output_norm_feature_info_file_name\n                ),\n            )\n            for file in input_files:\n                write_parquet(\n                    dataframe=data[data[\"orig_file_name\"] == file].drop(\n                        columns=\"orig_file_name\"\n                    ),\n                    filepath=join_fs_path(output_fs, output_root, file),\n                    file_system=output_fs,\n                )\n\n    return output_parq_location\n</code></pre>"},{"location":"reference/dagster/ops/evalcopyexp/","title":"evalcopyexp","text":""},{"location":"reference/dagster/ops/evalcopyexp/#niceml.dagster.ops.evalcopyexp","title":"evalcopyexp","text":"<p>Module containing dagster op which copies experiments for the evaluation pipeline</p>"},{"location":"reference/dagster/ops/evalcopyexp/#niceml.dagster.ops.evalcopyexp-classes","title":"Classes","text":""},{"location":"reference/dagster/ops/evalcopyexp/#niceml.dagster.ops.evalcopyexp-functions","title":"Functions","text":""},{"location":"reference/dagster/ops/evalcopyexp/#niceml.dagster.ops.evalcopyexp.change_ids_from_expinfo","title":"change_ids_from_expinfo","text":"<pre><code>change_ids_from_expinfo(\n    file_system,\n    exp_info_path,\n    run_id,\n    short_id,\n    description,\n)\n</code></pre> <p>Changes the run and short_id in an experiment info file</p> Source code in <code>niceml/dagster/ops/evalcopyexp.py</code> <pre><code>def change_ids_from_expinfo(\n    file_system: AbstractFileSystem,\n    exp_info_path: str,\n    run_id: str,\n    short_id: str,\n    description: str,\n):\n    \"\"\"Changes the run and short_id in an experiment info file\"\"\"\n    with file_system.open(exp_info_path, \"r\") as cur_file:\n        data = yaml.load(cur_file, Loader=yaml.SafeLoader)\n\n    data[RUN_ID_KEY] = run_id\n    data[SHORT_ID_KEY] = short_id\n    data[DESCRIPTION_KEY] = (\n        description\n        if len(description) &gt; 0\n        else f\"TrainDescription: {data[DESCRIPTION_KEY]}\"\n    )\n\n    with file_system.open(exp_info_path, \"w\") as cur_file:\n        yaml.dump(data, cur_file, Dumper=yaml.SafeDumper)\n</code></pre>"},{"location":"reference/dagster/ops/evalcopyexp/#niceml.dagster.ops.evalcopyexp.eval_copy_exp","title":"eval_copy_exp","text":"<pre><code>eval_copy_exp(context, exp_context)\n</code></pre> <p>Copy experiment from one to another.</p> Source code in <code>niceml/dagster/ops/evalcopyexp.py</code> <pre><code>@op(\n    config_schema=dict(\n        exp_out_location=Field(\n            dict,\n            default_value=dict(uri=\"experiments\"),\n            description=\"Folder to store the experiments\",\n        ),\n        exp_folder_pattern=Field(\n            str,\n            default_value=\"EXP-$RUN_ID-id_$SHORT_ID\",\n            description=\"Folder pattern of the experiment. \"\n            \"Can use $RUN_ID and $SHORT_ID to make the name unique\",\n        ),\n        description=Field(\n            str,\n            default_value=\"\",\n            description=\"Description of the experiment. Replaces the training description\",\n        ),\n    )\n)\ndef eval_copy_exp(  # pylint: disable=too-many-locals\n    context: OpExecutionContext, exp_context: ExperimentContext\n):\n    \"\"\"Copy experiment from one to another.\"\"\"\n    op_config = json.loads(json.dumps(context.op_config))\n    description: str = op_config[\"description\"]\n    exp_folder_pattern: str = op_config[\"exp_folder_pattern\"]\n    exp_out_location: dict = op_config[\"exp_out_location\"]\n    exp_folder, local_run_id, local_short_id = create_exp_settings(exp_folder_pattern)\n    new_exp_location = join_location_w_path(exp_out_location, exp_folder)\n\n    with open_location(exp_context.fs_config) as (\n        src_exp_fs,\n        src_exp_path,\n    ), open_location(new_exp_location) as (target_exp_fs, target_exp_path):\n        in_mapper = src_exp_fs.get_mapper(src_exp_path)\n\n        out_mapper = target_exp_fs.get_mapper(target_exp_path)\n        logging.getLogger(__name__).info(\"Starting to copy experiment data\")\n        eval_copy_exp_names = ExpEvalCopyNames()\n        for key in tqdm(in_mapper):\n            if key in eval_copy_exp_names:\n                out_mapper[key] = in_mapper[key]\n\n        change_ids_from_expinfo(\n            target_exp_fs,\n            join(target_exp_path, ExperimentFilenames.EXP_INFO),\n            local_run_id,\n            local_short_id,\n            description,\n        )\n\n    return ExperimentContext(\n        new_exp_location, run_id=local_run_id, short_id=local_short_id\n    )\n</code></pre>"},{"location":"reference/dagster/ops/experiment/","title":"experiment","text":""},{"location":"reference/dagster/ops/experiment/#niceml.dagster.ops.experiment","title":"experiment","text":"<p>Module for experiment op</p>"},{"location":"reference/dagster/ops/experiment/#niceml.dagster.ops.experiment-classes","title":"Classes","text":""},{"location":"reference/dagster/ops/experiment/#niceml.dagster.ops.experiment-functions","title":"Functions","text":""},{"location":"reference/dagster/ops/experiment/#niceml.dagster.ops.experiment.create_exp_settings","title":"create_exp_settings","text":"<pre><code>create_exp_settings(exp_folder_pattern)\n</code></pre> <p>Creates the experiment settings</p> Source code in <code>niceml/dagster/ops/experiment.py</code> <pre><code>def create_exp_settings(exp_folder_pattern):\n    \"\"\"Creates the experiment settings\"\"\"\n    local_run_id = generate_timestamp()\n    local_short_id = generate_short_id(local_run_id)\n    exp_folder = subs_path_and_create_folder(\n        exp_folder_pattern,\n        local_short_id,\n        local_run_id,\n    )\n    return exp_folder, local_run_id, local_short_id\n</code></pre>"},{"location":"reference/dagster/ops/experiment/#niceml.dagster.ops.experiment.experiment","title":"experiment","text":"<pre><code>experiment(context)\n</code></pre> <p>This Op creates the experiment params</p> Source code in <code>niceml/dagster/ops/experiment.py</code> <pre><code>@op(\n    config_schema=dict(\n        exp_out_location=Field(\n            dict,\n            default_value=dict(uri=\"experiments\"),\n            description=\"Folder to store the experiments\",\n        ),\n        exp_folder_pattern=Field(\n            str,\n            default_value=\"EXP-$RUN_ID-id_$SHORT_ID\",\n            description=\"Folder pattern of the experiment. \"\n            \"Can use $RUN_ID and $SHORT_ID to make the name unique\",\n        ),\n    ),\n    required_resource_keys={\"mlflow\"},\n)\ndef experiment(context: OpExecutionContext) -&gt; ExperimentContext:\n    \"\"\"This Op creates the experiment params\"\"\"\n    op_config = json.loads(json.dumps(context.op_config))\n    exp_out_location: dict = op_config[\"exp_out_location\"]\n    exp_folder_pattern: str = op_config[\"exp_folder_pattern\"]\n    exp_folder, local_run_id, local_short_id = create_exp_settings(exp_folder_pattern)\n    exp_location = join_location_w_path(exp_out_location, exp_folder)\n    exp_context = ExperimentContext(\n        fs_config=exp_location,\n        run_id=local_run_id,\n        short_id=local_short_id,\n    )\n    mlflow.set_tags(dict(run_id=local_run_id, short_id=local_short_id))\n    mlflow.set_tag(\"mlflow.runName\", local_short_id)\n\n    return exp_context\n</code></pre>"},{"location":"reference/dagster/ops/exptests/","title":"exptests","text":""},{"location":"reference/dagster/ops/exptests/#niceml.dagster.ops.exptests","title":"exptests","text":"<p>Module for exptests</p>"},{"location":"reference/dagster/ops/exptests/#niceml.dagster.ops.exptests-classes","title":"Classes","text":""},{"location":"reference/dagster/ops/exptests/#niceml.dagster.ops.exptests-functions","title":"Functions","text":""},{"location":"reference/dagster/ops/exptests/#niceml.dagster.ops.exptests.exptests","title":"exptests","text":"<pre><code>exptests(context, exp_context)\n</code></pre> <p>op to run the experiment tests</p> Source code in <code>niceml/dagster/ops/exptests.py</code> <pre><code>@op(\n    config_schema=dict(\n        tests=HydraInitField(ExpTestProcess),\n        remove_key_list=Field(\n            list,\n            default_value=DEFAULT_REMOVE_CONFIG_KEYS,\n            description=\"These key are removed from any config recursively before it is saved.\",\n        ),\n    ),\n    required_resource_keys={\"mlflow\"},\n)\ndef exptests(\n    context: OpExecutionContext, exp_context: ExperimentContext\n) -&gt; ExperimentContext:\n    \"\"\"op to run the experiment tests\"\"\"\n    op_config = json.loads(json.dumps(context.op_config))\n    write_op_config(\n        op_config, exp_context, OpNames.OP_EXPTESTS.value, op_config[\"remove_key_list\"]\n    )\n    instantiated_op_config = instantiate(op_config, _convert_=ConvertMode.ALL)\n    exp_test_process: ExpTestProcess = instantiated_op_config[\"tests\"]\n    with open_location(exp_context.fs_config) as (file_system, root_path):\n        exp_test_process(root_path, file_system=file_system)\n    return exp_context\n</code></pre>"},{"location":"reference/dagster/ops/filelockops/","title":"filelockops","text":""},{"location":"reference/dagster/ops/filelockops/#niceml.dagster.ops.filelockops","title":"filelockops","text":"<p>module for dagster ops regarding filelocks</p>"},{"location":"reference/dagster/ops/filelockops/#niceml.dagster.ops.filelockops-classes","title":"Classes","text":""},{"location":"reference/dagster/ops/filelockops/#niceml.dagster.ops.filelockops-functions","title":"Functions","text":""},{"location":"reference/dagster/ops/filelockops/#niceml.dagster.ops.filelockops.acquire_locks","title":"acquire_locks","text":"<pre><code>acquire_locks(context)\n</code></pre> <p>op for acquiring locks</p> Source code in <code>niceml/dagster/ops/filelockops.py</code> <pre><code>@op(config_schema=dict(filelock_dict=HydraMapField(FileLock)))\ndef acquire_locks(context: OpExecutionContext):\n    \"\"\"op for acquiring locks\"\"\"\n    op_config = json.loads(json.dumps(context.op_config))\n    instantiated_op_config = instantiate(op_config, _convert_=ConvertMode.ALL)\n    filelock_dict = instantiated_op_config[\"filelock_dict\"]\n    for filelock in filelock_dict.values():\n        filelock.acquire()\n    return filelock_dict\n</code></pre>"},{"location":"reference/dagster/ops/filelockops/#niceml.dagster.ops.filelockops.clear_locks","title":"clear_locks","text":"<pre><code>clear_locks(context)\n</code></pre> <p>op for clearing locks</p> Source code in <code>niceml/dagster/ops/filelockops.py</code> <pre><code>@op(config_schema=dict(filelock_dict=HydraMapField(FileLock)))\ndef clear_locks(context: OpExecutionContext):\n    \"\"\"op for clearing locks\"\"\"\n    op_config = json.loads(json.dumps(context.op_config))\n    instantiated_op_config = instantiate(op_config, _convert_=ConvertMode.ALL)\n    filelock_dict = instantiated_op_config[\"filelock_dict\"]\n    for filelock in filelock_dict.values():\n        filelock.force_delete()\n</code></pre>"},{"location":"reference/dagster/ops/filelockops/#niceml.dagster.ops.filelockops.release_locks","title":"release_locks","text":"<pre><code>release_locks(_, filelock_dict)\n</code></pre> <p>op for releasing locks</p> Source code in <code>niceml/dagster/ops/filelockops.py</code> <pre><code>@op\ndef release_locks(_: OpExecutionContext, filelock_dict: dict):\n    \"\"\"op for releasing locks\"\"\"\n    for filelock in filelock_dict.values():\n        filelock.release()\n</code></pre>"},{"location":"reference/dagster/ops/imagetotable/","title":"imagetotable","text":""},{"location":"reference/dagster/ops/imagetotable/#niceml.dagster.ops.imagetotable","title":"imagetotable","text":"<p>Module for functions to convert images into tabular data</p>"},{"location":"reference/dagster/ops/imagetotable/#niceml.dagster.ops.imagetotable-classes","title":"Classes","text":""},{"location":"reference/dagster/ops/imagetotable/#niceml.dagster.ops.imagetotable-functions","title":"Functions","text":""},{"location":"reference/dagster/ops/imagetotable/#niceml.dagster.ops.imagetotable.image_to_tabular_data","title":"image_to_tabular_data","text":"<pre><code>image_to_tabular_data(context, input_location)\n</code></pre> <p>The image_to_tabular_data function takes in a location of images and converts them to tabular data.</p> <p>Parameters:</p> <ul> <li> <code>context</code>             (<code>OpExecutionContext</code>)         \u2013          <p>OpExecutionContext: Pass in the configuration of the operation</p> </li> <li> <code>input_location</code>             (<code>dict</code>)         \u2013          <p>dict: Specify the location of the input data</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code>         \u2013          <p>The output_location where the parquet files with the table values are stored.</p> </li> <li> <code>dict</code>         \u2013          <p>The files are still divided into test, train and validation.</p> </li> </ul> Source code in <code>niceml/dagster/ops/imagetotable.py</code> <pre><code>@op(\n    config_schema={\n        \"output_location\": Field(\n            dict, description=\"Foldername where the images are stored\"\n        ),\n        \"name_delimiter\": Field(\n            str, default_value=\"_\", description=\"Delimiter used within the filenames\"\n        ),\n        \"sub_dir\": Field(\n            str, default_value=\"\", description=\"Subdirectory to save the split images\"\n        ),\n        \"recursive\": Field(\n            bool,\n            default_value=True,\n            description=\"Flag if the input folder should be searched recursively\",\n        ),\n        \"clear_folder\": Field(\n            bool,\n            default_value=False,\n            description=\"Flag if the output folder should be cleared before the split\",\n        ),\n        \"target_image_size\": HydraInitField(\n            ImageSize,\n            description=\"Image size to which the images should be scaled\",\n        ),\n        \"use_dirs_as_subsets\": Field(\n            bool,\n            default_value=True,\n            description=\"Flag if the subdirectories should be used as subset names\",\n        ),\n    }\n)\ndef image_to_tabular_data(context: OpExecutionContext, input_location: dict) -&gt; dict:\n    \"\"\"\n    The image_to_tabular_data function takes in a location of images\n    and converts them to tabular data.\n\n    Args:\n        context: OpExecutionContext: Pass in the configuration of the operation\n        input_location: dict: Specify the location of the input data\n\n    Returns:\n        The output_location where the parquet files with the table values are stored.\n        The files are still divided into test, train and validation.\n    \"\"\"\n    op_config = json.loads(json.dumps(context.op_config))\n\n    instantiated_op_config = instantiate(op_config, _convert_=ConvertMode.ALL)\n\n    output_location: Union[dict, LocationConfig] = instantiated_op_config[\n        \"output_location\"\n    ]\n    if len(instantiated_op_config[\"sub_dir\"]) &gt; 0:\n        output_location: LocationConfig = join_location_w_path(\n            output_location, instantiated_op_config[\"sub_dir\"]\n        )\n    if instantiated_op_config[\"clear_folder\"]:\n        clear_folder(output_location)\n    name_delimiter: str = instantiated_op_config[\"name_delimiter\"]\n    recursive: bool = instantiated_op_config[\"recursive\"]\n    target_size: Tuple[int, int] = instantiated_op_config[\"target_image_size\"]\n    use_dirs_as_subsets: bool = instantiated_op_config[\"use_dirs_as_subsets\"]\n\n    with open_location(input_location) as (input_fs, input_root):\n        image_files = [\n            cur_file\n            for cur_file in list_dir(\n                input_root, recursive=recursive, file_system=input_fs\n            )\n            if splitext(cur_file)[1] == \".png\"\n        ]\n        df_row_dict = defaultdict(list)\n        for cur_file in tqdm(image_files):\n            img = read_image(join(input_root, cur_file), file_system=input_fs)\n            label = splitext(cur_file)[0].split(sep=name_delimiter)[-1]\n            if use_dirs_as_subsets:\n                target_name = Path(cur_file).parts[0]\n\n            else:\n                target_name = \"_all_\"\n            df_row_dict[target_name].append(\n                convert_image_to_df_row(\n                    identifier=basename(cur_file),\n                    label=label,\n                    image=img,\n                    target_size=target_size,\n                )\n            )\n\n        for subset_name, cur_df_row in df_row_dict.items():\n            final_subset_name = f\"_{subset_name}\" if subset_name != \"_all_\" else \"\"\n            dataframe: pd.DataFrame = pd.DataFrame(cur_df_row)\n\n            with open_location(output_location) as (output_fs, output_root):\n                write_parquet(\n                    dataframe=dataframe,\n                    filepath=join(\n                        output_root, f\"numbers_tabular_data{final_subset_name}.parq\"\n                    ),\n                    file_system=output_fs,\n                )\n        if isinstance(output_location, LocationConfig):\n            output_location = asdict(output_location)\n    return output_location\n</code></pre>"},{"location":"reference/dagster/ops/localizeexperiment/","title":"localizeexperiment","text":""},{"location":"reference/dagster/ops/localizeexperiment/#niceml.dagster.ops.localizeexperiment","title":"localizeexperiment","text":"<p>Module for dagster op <code>localize experiment</code></p>"},{"location":"reference/dagster/ops/localizeexperiment/#niceml.dagster.ops.localizeexperiment-classes","title":"Classes","text":""},{"location":"reference/dagster/ops/localizeexperiment/#niceml.dagster.ops.localizeexperiment-functions","title":"Functions","text":""},{"location":"reference/dagster/ops/localizeexperiment/#niceml.dagster.ops.localizeexperiment.localize_experiment","title":"localize_experiment","text":"<pre><code>localize_experiment(context)\n</code></pre> <p>This op localizes the experiment and returns the experiment context</p> Source code in <code>niceml/dagster/ops/localizeexperiment.py</code> <pre><code>@op(\n    config_schema=dict(\n        existing_experiment=Field(\n            str,\n            description=\"Used to define the experiment id. \"\n            \"This is an alpha numeric str with the lenth of 4\",\n        ),\n        exp_out_location=Field(\n            dict,\n            default_value=dict(uri=\"experiments\"),\n            description=\"Folder to store the experiments\",\n        ),\n        exp_folder_pattern=Field(\n            Noneable(str),\n            default_value=None,\n            description=\"Unused. Only required due to easier configuration\",\n        ),\n    )\n)\ndef localize_experiment(context: OpExecutionContext) -&gt; ExperimentContext:\n    \"\"\"This op localizes the experiment and returns the experiment context\"\"\"\n    op_config = json.loads(json.dumps(context.op_config))\n    exp_out_location: dict = op_config[\"exp_out_location\"]\n\n    exp_path = get_exp_filepath(exp_out_location, op_config[\"existing_experiment\"])\n    try:\n        with open_location(exp_out_location) as (cur_fs, root_path):\n            experiment_info: ExperimentInfo = load_exp_info(\n                join(root_path, exp_path, ExperimentFilenames.EXP_INFO),\n                cur_fs,\n            )\n    except FileNotFoundError as error:\n        raise EmptyExperimentError(\n            f\"Experiment {exp_path} has no valid project file.\"\n        ) from error\n    local_run_id = experiment_info.run_id\n    local_short_id = experiment_info.short_id\n    exp_location = join_location_w_path(exp_out_location, exp_path)\n    return ExperimentContext(\n        fs_config=exp_location, run_id=local_run_id, short_id=local_short_id\n    )\n</code></pre>"},{"location":"reference/dagster/ops/prediction/","title":"prediction","text":""},{"location":"reference/dagster/ops/prediction/#niceml.dagster.ops.prediction","title":"prediction","text":"<p>Module for prediction op</p>"},{"location":"reference/dagster/ops/prediction/#niceml.dagster.ops.prediction-classes","title":"Classes","text":""},{"location":"reference/dagster/ops/prediction/#niceml.dagster.ops.prediction-functions","title":"Functions","text":""},{"location":"reference/dagster/ops/prediction/#niceml.dagster.ops.prediction.is_numpy_output","title":"is_numpy_output","text":"<pre><code>is_numpy_output(output)\n</code></pre> <p>Checks if the output of the model is a numpy array</p> Source code in <code>niceml/dagster/ops/prediction.py</code> <pre><code>def is_numpy_output(output) -&gt; bool:\n    \"\"\"Checks if the output of the model is a numpy array\"\"\"\n    if isinstance(output, np.ndarray):\n        return True\n    if isinstance(output, list) and isinstance(output[0], np.ndarray):\n        return True\n    if isinstance(output, dict) and isinstance(\n        output[list(output.keys())[0]], np.ndarray\n    ):\n        return True\n\n    return False\n</code></pre>"},{"location":"reference/dagster/ops/prediction/#niceml.dagster.ops.prediction.predict_dataset","title":"predict_dataset","text":"<pre><code>predict_dataset(\n    data_description,\n    model,\n    prediction_handler,\n    prediction_set,\n    filename,\n    exp_context,\n    prediction_function,\n    prediction_steps=None,\n)\n</code></pre> <p>Predicts the given dataset with the given model and prediction handler</p> Source code in <code>niceml/dagster/ops/prediction.py</code> <pre><code>def predict_dataset(  # noqa: PLR0913\n    data_description: DataDescription,\n    model,\n    prediction_handler: PredictionHandler,\n    prediction_set: Dataset,\n    filename: str,\n    exp_context: ExperimentContext,\n    prediction_function: PredictionFunction,\n    prediction_steps: Optional[int] = None,\n):\n    \"\"\"Predicts the given dataset with the given model and prediction handler\"\"\"\n    batch_count: int = len(prediction_set)\n    batch_count = (\n        batch_count if prediction_steps is None else min(batch_count, prediction_steps)\n    )\n    progress = tqdm.tqdm(total=batch_count)\n    prediction_handler.set_params(exp_context, filename, data_description)\n    prediction_handler.initialize()\n    with prediction_handler as handler:\n        for index, (data_info, batch) in enumerate(prediction_set.iter_with_info()):\n            data_x, _ = batch\n            pred = prediction_function.predict(model, data_x)\n            handler.add_prediction(data_info, pred)\n            progress.update()\n            if index &gt;= batch_count:\n                progress.close()\n                break\n</code></pre>"},{"location":"reference/dagster/ops/prediction/#niceml.dagster.ops.prediction.prediction","title":"prediction","text":"<pre><code>prediction(context, exp_context, filelock_dict)\n</code></pre> <p>Dagster op to predict the stored model with the given datasets</p> Source code in <code>niceml/dagster/ops/prediction.py</code> <pre><code>@op(\n    config_schema=dict(\n        prediction_handler=HydraInitField(PredictionHandler),\n        datasets=HydraMapField(Dataset),\n        prediction_steps=Field(\n            Noneable(int),\n            default_value=None,\n            description=\"If None the whole datasets are processed. \"\n            \"Otherwise only `prediction_steps` are evaluated.\",\n        ),\n        model_loader=HydraInitField(ModelLoader),\n        prediction_function=HydraInitField(PredictionFunction),\n        remove_key_list=Field(\n            list,\n            default_value=DEFAULT_REMOVE_CONFIG_KEYS,\n            description=\"These key are removed from any config recursively before it is saved.\",\n        ),\n    ),\n    out={\"expcontext\": Out(), \"datasets\": Out(), \"filelock_dict\": Out()},\n    required_resource_keys={\"mlflow\"},\n)\ndef prediction(\n    context: OpExecutionContext,\n    exp_context: ExperimentContext,\n    filelock_dict: Dict[str, FileLock],\n) -&gt; Tuple[ExperimentContext, Dict[str, Dataset], Dict[str, FileLock]]:\n    \"\"\"Dagster op to predict the stored model with the given datasets\"\"\"\n    op_config = json.loads(json.dumps(context.op_config))\n    write_op_config(\n        op_config,\n        exp_context,\n        OpNames.OP_PREDICTION.value,\n        op_config[\"remove_key_list\"],\n    )\n    instantiated_op_config = instantiate(op_config, _convert_=ConvertMode.ALL)\n    data_description: DataDescription = (\n        exp_context.instantiate_datadescription_from_yaml()\n    )\n\n    exp_data: ExperimentData = create_expdata_from_expcontext(exp_context)\n    model_path: str = exp_data.get_model_path(relative_path=True)\n    model_loader: ModelLoader = instantiated_op_config[\"model_loader\"]\n    with open_location(exp_context.fs_config) as (exp_fs, exp_root):\n        model = model_loader(\n            join_fs_path(exp_fs, exp_root, model_path),\n            file_system=exp_fs,\n        )\n\n    datasets_dict: Dict[str, Dataset] = instantiated_op_config[\"datasets\"]\n\n    for dataset_key, cur_pred_set in datasets_dict.items():\n        context.log.info(f\"Predict dataset: {dataset_key}\")\n        cur_pred_set.initialize(data_description, exp_context)\n        save_exp_data_stats(cur_pred_set, exp_context, ExperimentFilenames.STATS_PRED)\n        predict_dataset(\n            data_description=data_description,\n            prediction_steps=instantiated_op_config[\"prediction_steps\"],\n            model=model,\n            prediction_set=cur_pred_set,\n            prediction_handler=instantiated_op_config[\"prediction_handler\"],\n            exp_context=exp_context,\n            filename=dataset_key,\n            prediction_function=instantiated_op_config[\"prediction_function\"],\n        )\n\n    return exp_context, datasets_dict, filelock_dict\n</code></pre>"},{"location":"reference/dagster/ops/prediction/#niceml.dagster.ops.prediction.save_exp_data_stats","title":"save_exp_data_stats","text":"<pre><code>save_exp_data_stats(dataset, exp_context, output_name)\n</code></pre> <p>Save the stats of the experiment data to a yaml file</p> Source code in <code>niceml/dagster/ops/prediction.py</code> <pre><code>def save_exp_data_stats(\n    dataset: Dataset, exp_context: ExperimentContext, output_name: str\n):\n    \"\"\"Save the stats of the experiment data to a yaml file\"\"\"\n    yaml_file = join(ExperimentFilenames.DATASETS_STATS_FOLDER, output_name)\n    set_stats: dict = dataset.get_dataset_stats()\n    set_name: str = dataset.get_set_name()\n    stats_info = {}\n    try:\n        stats_info = exp_context.read_yaml(yaml_file)\n    except FileNotFoundError:\n        pass\n    stats_info[set_name] = set_stats\n    exp_context.write_yaml(stats_info, yaml_file)\n</code></pre>"},{"location":"reference/dagster/ops/splitdata/","title":"splitdata","text":""},{"location":"reference/dagster/ops/splitdata/#niceml.dagster.ops.splitdata","title":"splitdata","text":"<p>Module for split_data op</p>"},{"location":"reference/dagster/ops/splitdata/#niceml.dagster.ops.splitdata-classes","title":"Classes","text":""},{"location":"reference/dagster/ops/splitdata/#niceml.dagster.ops.splitdata-functions","title":"Functions","text":""},{"location":"reference/dagster/ops/splitdata/#niceml.dagster.ops.splitdata.split_data","title":"split_data","text":"<pre><code>split_data(context, input_location)\n</code></pre> <p>Splits the data in input_location into subsets (set_infos)</p> Source code in <code>niceml/dagster/ops/splitdata.py</code> <pre><code>@op(\n    config_schema={\n        \"output_location\": Field(dict, description=\"Folder to save the split images\"),\n        \"set_infos\": Field(list, description=\"Split information how to split the data\"),\n        \"name_delimiter\": Field(\n            str, default_value=\"_\", description=\"Character to seperate names.\"\n        ),\n        \"sub_dir\": Field(\n            str, default_value=\"\", description=\"Subdirectory to save the split images\"\n        ),\n        \"max_split\": Field(\n            int, default_value=1, description=\"Maximum split of the name (e.g. 1)\"\n        ),\n        \"recursive\": Field(\n            bool,\n            default_value=False,\n            description=\"Flag if the input folder should be searched recursively.\",\n        ),\n        \"clear_folder\": Field(\n            bool,\n            default_value=False,\n            description=\"Flag if the output folder should be cleared before the split.\",\n        ),\n    }\n)\ndef split_data(context: OpExecutionContext, input_location: dict):\n    \"\"\"Splits the data in input_location into subsets (set_infos)\"\"\"\n    op_config = json.loads(json.dumps(context.op_config))\n\n    instantiated_op_config = instantiate(op_config, _convert_=ConvertMode.ALL)\n\n    output_location = instantiated_op_config[\"output_location\"]\n    if len(instantiated_op_config[\"sub_dir\"]) &gt; 0:\n        output_location = join_location_w_path(\n            output_location, instantiated_op_config[\"sub_dir\"]\n        )\n    if instantiated_op_config[\"clear_folder\"]:\n        clear_folder(output_location)\n    dataset_info_list = instantiated_op_config[\"set_infos\"]\n    recursive = instantiated_op_config[\"recursive\"]\n    delimiter_maxsplit = instantiated_op_config[\"max_split\"]\n    name_delimiter = instantiated_op_config[\"name_delimiter\"]\n\n    logging.getLogger(__name__).info(\"Read input folders\")\n\n    copy_files: List[CopyFileInfo] = create_copy_files_container(\n        [\"\"],\n        input_location=input_location,\n        recursive=recursive,\n        dataset_info_list=dataset_info_list,\n        delimiter_maxsplit=delimiter_maxsplit,\n        name_delimiter=name_delimiter,\n        output_location=output_location,\n    )\n    logging.getLogger(__name__).info(\"Filter already existing files\")\n    copy_files = filter_for_required(copy_files)\n    logging.getLogger(__name__).info(\"Start to copy\")\n    process_copy_files(copy_files)\n    if isinstance(output_location, LocationConfig):\n        output_location = asdict(output_location)\n    return output_location\n</code></pre>"},{"location":"reference/dagster/ops/train/","title":"train","text":""},{"location":"reference/dagster/ops/train/#niceml.dagster.ops.train","title":"train","text":"<p>Module for train op</p>"},{"location":"reference/dagster/ops/train/#niceml.dagster.ops.train-classes","title":"Classes","text":""},{"location":"reference/dagster/ops/train/#niceml.dagster.ops.train-functions","title":"Functions","text":""},{"location":"reference/dagster/ops/train/#niceml.dagster.ops.train.train","title":"train","text":"<pre><code>train(context, exp_context, filelock_dict)\n</code></pre> <p>DagsterOp that trains the model</p> Source code in <code>niceml/dagster/ops/train.py</code> <pre><code>@op(\n    config_schema=train_config,\n    out={\"expcontext\": Out(), \"filelock_dict\": Out()},\n    required_resource_keys={\"mlflow\"},\n)\ndef train(\n    context: OpExecutionContext,\n    exp_context: ExperimentContext,\n    filelock_dict: Dict[str, FileLock],\n) -&gt; Tuple[ExperimentContext, Dict[str, FileLock]]:\n    \"\"\"DagsterOp that trains the model\"\"\"\n    op_config = json.loads(json.dumps(context.op_config))\n    write_op_config(\n        op_config, exp_context, OpNames.OP_TRAIN.value, op_config[\"remove_key_list\"]\n    )\n    instantiated_op_config = instantiate(op_config, _convert_=ConvertMode.ALL)\n\n    data_train = instantiated_op_config[\"data_train\"]\n    data_valid = instantiated_op_config[\"data_validation\"]\n    data_description = instantiated_op_config[\"data_description\"]\n\n    data_train.initialize(data_description, exp_context)\n    data_valid.initialize(data_description, exp_context)\n\n    save_exp_data_stats(data_train, exp_context, ExperimentFilenames.STATS_TRAIN)\n    save_exp_data_stats(data_valid, exp_context, ExperimentFilenames.STATS_TRAIN)\n\n    instantiated_op_config[\"exp_initializer\"](exp_context)\n\n    fit_generator(\n        exp_context,\n        instantiated_op_config[\"learner\"],\n        instantiated_op_config[\"model\"],\n        data_train,\n        data_valid,\n        instantiated_op_config[\"train_params\"],\n        data_description,\n    )\n    return exp_context, filelock_dict\n</code></pre>"},{"location":"reference/dagster/resources/__init__/","title":"resources","text":""},{"location":"reference/dagster/resources/__init__/#niceml.dagster.resources","title":"resources","text":""},{"location":"reference/dagster/resources/locations/","title":"locations","text":""},{"location":"reference/dagster/resources/locations/#niceml.dagster.resources.locations","title":"locations","text":"<p>Dagster resource for accessing filesystem locations.</p>"},{"location":"reference/dagster/resources/locations/#niceml.dagster.resources.locations-classes","title":"Classes","text":""},{"location":"reference/dagster/resources/locations/#niceml.dagster.resources.locations.Location","title":"Location","text":"<pre><code>Location(config)\n</code></pre> <p>Filesystem plus path.</p> Source code in <code>niceml/dagster/resources/locations.py</code> <pre><code>def __init__(self, config: LocationConfig):\n    self._config = deepcopy(config)\n</code></pre>"},{"location":"reference/dagster/resources/locations/#niceml.dagster.resources.locations.Location-functions","title":"Functions","text":""},{"location":"reference/dagster/resources/locations/#niceml.dagster.resources.locations.Location.__str__","title":"__str__","text":"<pre><code>__str__()\n</code></pre> <p>Return string representation of config.</p> Source code in <code>niceml/dagster/resources/locations.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Return string representation of config.\"\"\"\n    return str(self._config)\n</code></pre>"},{"location":"reference/dagster/resources/locations/#niceml.dagster.resources.locations.Location.open","title":"open","text":"<pre><code>open(rel_path, *args, **kwargs)\n</code></pre> <p>Open file at <code>rel_path</code> with <code>*args</code> and <code>**kwargs</code>.</p> Source code in <code>niceml/dagster/resources/locations.py</code> <pre><code>@contextmanager\ndef open(self, rel_path: str, *args, **kwargs) -&gt; Iterator[Any]:\n    \"\"\"Open file at ``rel_path`` with ``*args`` and ``**kwargs``.\"\"\"\n    with self.open_fs_path() as (filesystem, path):\n        absolute_path = os.path.join(path, rel_path)\n        yield filesystem.open(absolute_path, *args, **kwargs)\n</code></pre>"},{"location":"reference/dagster/resources/locations/#niceml.dagster.resources.locations.Location.open_fs_path","title":"open_fs_path","text":"<pre><code>open_fs_path()\n</code></pre> <p>Return filesystem and path as context manager.</p> Source code in <code>niceml/dagster/resources/locations.py</code> <pre><code>@contextmanager\ndef open_fs_path(self) -&gt; Iterator[FSPath]:\n    \"\"\"Return filesystem and path as context manager.\"\"\"\n    with open_location(asdict(self._config)) as (filesystem, path):\n        yield (filesystem, path)\n</code></pre>"},{"location":"reference/dagster/resources/locations/#niceml.dagster.resources.locations.LocationsResource","title":"LocationsResource","text":"<pre><code>LocationsResource(config)\n</code></pre> <p>Resource for accessing file system.</p> <p>Parameters:</p> <ul> <li> <code>config</code>             (<code>LocationsResourceConfig</code>)         \u2013          <p>resource configuration.</p> </li> </ul> Source code in <code>niceml/dagster/resources/locations.py</code> <pre><code>def __init__(self, config: LocationsResourceConfig):\n    location_items = config.locations.items()\n    self._locations = {key: Location(value) for key, value in location_items}\n</code></pre>"},{"location":"reference/dagster/resources/locations/#niceml.dagster.resources.locations.LocationsResource-functions","title":"Functions","text":""},{"location":"reference/dagster/resources/locations/#niceml.dagster.resources.locations.LocationsResource.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(location_name)\n</code></pre> <p>Return configured location.</p> Source code in <code>niceml/dagster/resources/locations.py</code> <pre><code>def __getitem__(self, location_name: str) -&gt; Location:\n    \"\"\"Return configured location.\"\"\"\n    try:\n        location = self._locations[location_name]\n    except KeyError as exception:\n        getLogger(__name__).error(\"location %s not configured\", location_name)\n        raise exception\n    getLogger(__name__).debug(\"opening location %s (%s)\", location_name, location)\n    return location\n</code></pre>"},{"location":"reference/dagster/resources/locations/#niceml.dagster.resources.locations.LocationsResourceConfig","title":"LocationsResourceConfig","text":"<p>Configuration of file system locations.</p>"},{"location":"reference/dagster/resources/locations/#niceml.dagster.resources.locations-functions","title":"Functions","text":""},{"location":"reference/dagster/resources/locations/#niceml.dagster.resources.locations.get_location","title":"get_location","text":"<pre><code>get_location(location_name)\n</code></pre> <p>Return location.</p> Source code in <code>niceml/dagster/resources/locations.py</code> <pre><code>def get_location(location_name: str) -&gt; Location:\n    \"\"\"Return location.\"\"\"\n    if _LOCATIONS_RESOURCE is None:\n        logging.error(\n            \"\"\"Locations resource not configured. Define the resource\n            ``global_fs_resource`` for your dagster job and require it for your op.\"\"\"\n        )\n        raise ValueError(\"Locations resource not configured. See log for details.\")\n    return _LOCATIONS_RESOURCE[location_name]\n</code></pre>"},{"location":"reference/dagster/resources/locations/#niceml.dagster.resources.locations.global_locations_resource","title":"global_locations_resource","text":"<pre><code>global_locations_resource(context)\n</code></pre> <p>Return <code>LocationsResource</code> and register it as module-level object <code>FS</code>.</p> Source code in <code>niceml/dagster/resources/locations.py</code> <pre><code>@resource\ndef global_locations_resource(context: InitResourceContext):\n    \"\"\"Return `LocationsResource` and register it as module-level object ``FS``.\"\"\"\n    global _LOCATIONS_RESOURCE  # pylint: disable=global-statement\n    _LOCATIONS_RESOURCE = locations_resource(context)\n    return _LOCATIONS_RESOURCE\n</code></pre>"},{"location":"reference/dagster/resources/locations/#niceml.dagster.resources.locations.locations_resource","title":"locations_resource","text":"<pre><code>locations_resource(context)\n</code></pre> <p>Create LocationsResource according to the configuration.</p> Source code in <code>niceml/dagster/resources/locations.py</code> <pre><code>@resource(config_schema=build_config_schema(LocationsResourceConfig))\ndef locations_resource(context: InitResourceContext):\n    \"\"\"Create LocationsResource according to the configuration.\"\"\"\n    config = parse_config(context.resource_config, LocationsResourceConfig)\n    return LocationsResource(config)\n</code></pre>"},{"location":"reference/dashboard/__init__/","title":"dashboard","text":""},{"location":"reference/dashboard/__init__/#niceml.dashboard","title":"dashboard","text":""},{"location":"reference/dashboard/binprobvisu/","title":"binprobvisu","text":""},{"location":"reference/dashboard/binprobvisu/#niceml.dashboard.binprobvisu","title":"binprobvisu","text":"<p>Module for the ProbDistributionChartGenerator</p>"},{"location":"reference/dashboard/binprobvisu/#niceml.dashboard.binprobvisu-classes","title":"Classes","text":""},{"location":"reference/dashboard/binprobvisu/#niceml.dashboard.binprobvisu.ProbDistributionChartGenerator","title":"ProbDistributionChartGenerator  <code>dataclass</code>","text":"<p>Generates a chart for a probability distribution.</p>"},{"location":"reference/dashboard/binprobvisu/#niceml.dashboard.binprobvisu.ProbDistributionChartGenerator-functions","title":"Functions","text":""},{"location":"reference/dashboard/binprobvisu/#niceml.dashboard.binprobvisu.ProbDistributionChartGenerator.__call__","title":"__call__","text":"<pre><code>__call__(prob_df, thres_min, thres_max)\n</code></pre> <p>Takes in a dataframe with probabilities and ground truth values, as well as two thresholds (thres_min and thres_max). It returns an altair histogram chart that visualize the prediction probability. The second return value is a dataframe containing metrics for the given thresholds.</p> <p>Parameters:</p> <ul> <li> <code>prob_df</code>             (<code>DataFrame</code>)         \u2013          <p>pd.DataFrame: Pass in the dataframe that contains the probabilities         and ground truth values</p> </li> <li> <code>thres_min</code>             (<code>float</code>)         \u2013          <p>float: Set the minimum threshold for the histogram</p> </li> <li> <code>thres_max</code>             (<code>float</code>)         \u2013          <p>float: Set the upper bound of the threshold</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tuple[Chart, DataFrame]</code>         \u2013          <p>A tuple of two elements, the first being a chart and the second being a dataframe</p> </li> </ul> Source code in <code>niceml/dashboard/binprobvisu.py</code> <pre><code>def __call__(\n    self, prob_df: pd.DataFrame, thres_min: float, thres_max: float\n) -&gt; Tuple[altair.Chart, pd.DataFrame]:\n    \"\"\"\n    Takes in a dataframe with probabilities and ground truth values, as well as two thresholds\n    (thres_min and thres_max). It returns an altair histogram chart that visualize\n    the prediction probability. The second return value is a dataframe containing\n    metrics for the given thresholds.\n\n    Args:\n        prob_df: pd.DataFrame: Pass in the dataframe that contains the probabilities\n                    and ground truth values\n        thres_min: float: Set the minimum threshold for the histogram\n        thres_max: float: Set the upper bound of the threshold\n\n    Returns:\n        A tuple of two elements, the first being a chart and the second being a dataframe\n    \"\"\"\n    pos_gt_name = self.pos_gt_val if self.pos_gt_name is None else self.pos_gt_name\n    neg_gt_name = self.neg_gt_val if self.neg_gt_name is None else self.neg_gt_name\n    pos_probs = prob_df[self.prob_col][prob_df[self.gt_col] == self.pos_gt_val]\n    pos_count = len(pos_probs)\n    neg_probs = prob_df[self.prob_col][prob_df[self.gt_col] == self.neg_gt_val]\n    neg_count = len(neg_probs)\n\n    pos_prob_hist = np.histogram(\n        pos_probs, self.bin_count, range=(self.range_min, self.range_max)\n    )\n    neg_prob_hist = np.histogram(\n        neg_probs, self.bin_count, range=(self.range_min, self.range_max)\n    )\n    # same for both\n    hist_x_vals = neg_prob_hist[1]\n    # mean of both borders\n    prob_x_values = [\n        (hist_x_vals[x] + hist_x_vals[x + 1]) / 2 for x in range(self.bin_count)\n    ]\n\n    df_pos_plot = pd.DataFrame(\n        {\n            self.y_name: pos_prob_hist[0],\n            self.x_name: prob_x_values,\n            \"name\": [pos_gt_name] * len(prob_x_values),\n        }\n    )\n\n    df_neg_plot = pd.DataFrame(\n        {\n            self.y_name: neg_prob_hist[0],\n            self.x_name: prob_x_values,\n            \"name\": [neg_gt_name] * len(prob_x_values),\n        }\n    )\n    concat_df_plot = pd.concat([df_pos_plot, df_neg_plot], ignore_index=True)\n    domain = [pos_gt_name, neg_gt_name]\n    color_range = [self.pos_color, self.neg_color]\n    line_chart = (\n        altair.Chart(concat_df_plot)\n        .mark_line()\n        .encode(\n            x=self.x_name,\n            y=self.y_name,\n            color=altair.Color(\n                \"name\", scale=altair.Scale(domain=domain, range=color_range)\n            ),\n        )\n    )\n\n    thres_min_df = pd.DataFrame([{\"thres_min\": thres_min}])\n    thres_max_df = pd.DataFrame([{\"thres_max\": thres_max}])\n\n    thres_min_chart = (\n        altair.Chart(thres_min_df).mark_rule(color=\"gray\").encode(x=\"thres_min\")\n    )\n    thres_max_chart = (\n        altair.Chart(thres_max_df).mark_rule(color=\"gray\").encode(x=\"thres_max\")\n    )\n\n    hover_chart = generate_hover_charts(\n        concat_df_plot,\n        self.x_name,\n        self.y_name,\n        line_chart,\n        self.chart_width,\n        self.chart_height,\n        [thres_min_chart, thres_max_chart],\n    )\n\n    true_neg_count = 0\n    false_pos_count = 0\n    false_check_count = 0\n    true_pos_count = 0\n    false_neg_count = 0\n    true_check_count = 0\n    for idx, x_val in enumerate(prob_x_values):\n        if x_val &lt;= thres_min:\n            true_neg_count += neg_prob_hist[0][idx]\n            false_neg_count += pos_prob_hist[0][idx]\n        elif thres_min &lt; x_val &lt; thres_max:\n            false_check_count += neg_prob_hist[0][idx]\n            true_check_count += pos_prob_hist[0][idx]\n        elif x_val &gt;= thres_max:\n            false_pos_count += neg_prob_hist[0][idx]\n            true_pos_count += pos_prob_hist[0][idx]\n\n    true_pos_perc = float(true_pos_count / pos_count)\n    true_neg_perc = float(true_neg_count / neg_count)\n    false_neg_perc = float(false_neg_count / pos_count)\n    false_pos_perc = float(false_pos_count / neg_count)\n    true_check_perc = float(true_check_count / pos_count)\n    false_check_perc = float(false_check_count / neg_count)\n\n    true_dict = {\n        \"class\": pos_gt_name,\n        pos_gt_name: true_pos_count,\n        neg_gt_name: false_neg_count,\n        \"check\": true_check_count,\n        f\"{pos_gt_name}_perc\": true_pos_perc,\n        f\"{neg_gt_name}_perc\": false_neg_perc,\n        \"check_perc\": true_check_perc,\n        \"count\": pos_count,\n    }\n\n    false_dict = {\n        \"class\": neg_gt_name,\n        pos_gt_name: false_pos_count,\n        neg_gt_name: true_neg_count,\n        \"check\": false_check_count,\n        f\"{pos_gt_name}_perc\": false_pos_perc,\n        f\"{neg_gt_name}_perc\": true_neg_perc,\n        \"check_perc\": false_check_perc,\n        \"count\": neg_count,\n    }\n\n    total_pos = false_pos_count + true_pos_count\n    total_neg = true_neg_count + false_neg_count\n    total_check = false_check_count + true_check_count\n    total_count = pos_count + neg_count\n\n    total_dict = {\n        \"class\": \"total\",\n        pos_gt_name: total_pos,\n        neg_gt_name: total_neg,\n        \"check\": total_check,\n        f\"{pos_gt_name}_perc\": total_pos / total_count,\n        f\"{neg_gt_name}_perc\": total_neg / total_count,\n        \"check_perc\": total_check / total_count,\n        \"count\": total_count,\n    }\n\n    metric_df = pd.DataFrame([true_dict, false_dict, total_dict])\n\n    return hover_chart, metric_df\n</code></pre>"},{"location":"reference/dashboard/binprobvisu/#niceml.dashboard.binprobvisu-functions","title":"Functions","text":""},{"location":"reference/dashboard/configviscomponent/","title":"configviscomponent","text":""},{"location":"reference/dashboard/configviscomponent/#niceml.dashboard.configviscomponent","title":"configviscomponent","text":"<p>Module for config visu component</p>"},{"location":"reference/dashboard/configviscomponent/#niceml.dashboard.configviscomponent-classes","title":"Classes","text":""},{"location":"reference/dashboard/configviscomponent/#niceml.dashboard.configviscomponent.ConfigVisComponent","title":"ConfigVisComponent","text":"<pre><code>ConfigVisComponent(\n    meta_function=None,\n    target_value_list=None,\n    assert_on_error=False,\n)\n</code></pre> <p>             Bases: <code>SingleExpVisComponent</code></p> <p>Visu component to show the configs of a single experiment as yaml code</p> Source code in <code>niceml/dashboard/components/expviscomponent.py</code> <pre><code>def __init__(\n    self,\n    meta_function: Optional[MetaFunction] = None,\n    target_value_list: Optional[List[Any]] = None,\n    assert_on_error: bool = False,\n):\n    # Create empty list for chart images\n    self.chart_images_list: List[Image.Image] = []\n    self.meta_function = meta_function\n    self.target_value_list = [] if target_value_list is None else target_value_list\n    self.assert_on_error = assert_on_error\n</code></pre>"},{"location":"reference/dashboard/dashboard/","title":"dashboard","text":""},{"location":"reference/dashboard/dashboard/#niceml.dashboard.dashboard","title":"dashboard","text":"<p>Module to run the dashboard</p>"},{"location":"reference/dashboard/dashboard/#niceml.dashboard.dashboard-classes","title":"Classes","text":""},{"location":"reference/dashboard/dashboard/#niceml.dashboard.dashboard-functions","title":"Functions","text":""},{"location":"reference/dashboard/dashboard/#niceml.dashboard.dashboard.cached_instantiate","title":"cached_instantiate","text":"<pre><code>cached_instantiate(hydra_conf)\n</code></pre> <p>Instantiate using hydra instantiate with a streamlit cache</p> Source code in <code>niceml/dashboard/dashboard.py</code> <pre><code>def cached_instantiate(hydra_conf):\n    \"\"\"Instantiate using hydra instantiate with a streamlit cache\"\"\"\n    GlobalHydra.instance().clear()\n    return instantiate(hydra_conf)\n</code></pre>"},{"location":"reference/dashboard/dashboard/#niceml.dashboard.dashboard.run_dashboard","title":"run_dashboard","text":"<pre><code>run_dashboard(conf_instances)\n</code></pre> <p>Runs the dashboard with already loaded configs</p> Source code in <code>niceml/dashboard/dashboard.py</code> <pre><code>def run_dashboard(conf_instances):\n    \"\"\"Runs the dashboard with already loaded configs\"\"\"\n    storage_handler: StorageHandler = conf_instances[\"storage_handler\"]\n    st.sidebar.title(conf_instances[\"title\"])\n    handler_name = st.sidebar.selectbox(\n        \"StorageName\", storage_handler.get_storage_names()\n    )\n    storage: StorageInterface = storage_handler.get_storage(handler_name)\n    exp_cache = conf_instances.get(\"exp_cache\", None)\n    st.sidebar.title(\"Filter Experiments\")\n\n    exp_manager = exp_manager_factory(id(storage))\n    exp_list: List[ExperimentInfo] = query_experiments(storage)\n    exps_to_load = select_to_load_exps(exp_list, exp_manager)\n    experiments = load_experiments(\n        storage,\n        exps_to_load,\n        local_exp_cache=exp_cache,\n        image_loader_factory=conf_instances[\"image_loader_factory\"],\n        df_loader_factory=conf_instances[\"df_loader_factory\"],\n    )\n    for experiment in experiments:\n        exp_manager.add_experiment(experiment)\n    if exp_manager.get_exp_count() &gt; 0:\n        exp_filter_list: List[ExperimentFilter] = conf_instances[\"sidebar_filters\"]\n        expdata_list: List[ExperimentData] = exp_manager.get_experiments()\n        for exp_filter in exp_filter_list:\n            exp_filter.render(expdata_list)\n        for exp_filter in exp_filter_list:\n            expdata_list = exp_filter.filter(expdata_list)\n\n        exp_id_list: List[str] = [x.exp_info.short_id for x in expdata_list]\n        conf_instances[\"component\"].render(exp_manager, storage, exp_id_list)\n    else:\n        st.markdown(\"No experiments downloaded!\")\n</code></pre>"},{"location":"reference/dashboard/dashboard/#niceml.dashboard.dashboard.run_dashboard_with_configs_from_path","title":"run_dashboard_with_configs_from_path","text":"<pre><code>run_dashboard_with_configs_from_path(config_path)\n</code></pre> <p>Runs the dashboard using configs from a given path</p> Source code in <code>niceml/dashboard/dashboard.py</code> <pre><code>def run_dashboard_with_configs_from_path(config_path: str):\n    \"\"\"Runs the dashboard using configs from a given path\"\"\"\n    config = load_hydra_conf(config_path)\n    st.set_page_config(\n        layout=\"wide\", page_title=config[\"title\"], page_icon=config.get(\"icon\", None)\n    )\n    conf_instances = cached_instantiate(config)\n    run_dashboard(conf_instances)\n</code></pre>"},{"location":"reference/dashboard/expvisuhelper/","title":"expvisuhelper","text":""},{"location":"reference/dashboard/expvisuhelper/#niceml.dashboard.expvisuhelper","title":"expvisuhelper","text":""},{"location":"reference/dashboard/imagenetdataloggerviscomponent/","title":"imagenetdataloggerviscomponent","text":""},{"location":"reference/dashboard/imagenetdataloggerviscomponent/#niceml.dashboard.imagenetdataloggerviscomponent","title":"imagenetdataloggerviscomponent","text":"<p>Module for the image netdata logger visualization components</p>"},{"location":"reference/dashboard/imagenetdataloggerviscomponent/#niceml.dashboard.imagenetdataloggerviscomponent-classes","title":"Classes","text":""},{"location":"reference/dashboard/imagenetdataloggerviscomponent/#niceml.dashboard.imagenetdataloggerviscomponent.ImageNetDataLoggerVisComponent","title":"ImageNetDataLoggerVisComponent","text":"<pre><code>ImageNetDataLoggerVisComponent(\n    image_loader,\n    column_amount=1,\n    max_output_count=10,\n    **kwargs\n)\n</code></pre> <p>             Bases: <code>NetDataLoggerVisComponent</code></p> <p>Dashboard component to visualize the net data of an experiment (currently images)</p> <p>Dashboard component to visualize the net data of an experiment (currently images)</p> <p>Parameters:</p> <ul> <li> <code>image_loader</code>             (<code>ImageLoader</code>)         \u2013          <p>Image loader to load the net data images</p> </li> <li> <code>column_amount</code>             (<code>int</code>, default:                 <code>1</code> )         \u2013          <p>Amount of columns that are used to visualize the images</p> </li> <li> <code>max_output_count</code>             (<code>int</code>, default:                 <code>10</code> )         \u2013          <p>Max number of net data to be displayed</p> </li> <li> <code>**kwargs</code>         \u2013          </li> </ul> Source code in <code>niceml/dashboard/imagenetdataloggerviscomponent.py</code> <pre><code>def __init__(\n    self,\n    image_loader: ImageLoader,\n    column_amount: int = 1,\n    max_output_count: int = 10,\n    **kwargs,\n):\n    \"\"\"\n    Dashboard component to visualize the net data of an experiment (currently images)\n\n    Args:\n        image_loader: Image loader to load the net data images\n        column_amount: Amount of columns that are used to visualize the images\n        max_output_count: Max number of net data to be displayed\n        **kwargs:\n    \"\"\"\n    super().__init__(**kwargs)\n    self.max_output = max_output_count\n    self.column_amount = column_amount\n    self.image_loader: ImageLoader = image_loader\n</code></pre>"},{"location":"reference/dashboard/imagenetdataloggerviscomponent/#niceml.dashboard.imagenetdataloggerviscomponent.ImageNetDataLoggerVisComponent-functions","title":"Functions","text":""},{"location":"reference/dashboard/metricviscomponent/","title":"metricviscomponent","text":""},{"location":"reference/dashboard/metricviscomponent/#niceml.dashboard.metricviscomponent","title":"metricviscomponent","text":"<p>Module for MetricVisComponent for the dashboard</p>"},{"location":"reference/dashboard/metricviscomponent/#niceml.dashboard.metricviscomponent-classes","title":"Classes","text":""},{"location":"reference/dashboard/metricviscomponent/#niceml.dashboard.metricviscomponent.MetricVisComponent","title":"MetricVisComponent","text":"<pre><code>MetricVisComponent(\n    component_name=None,\n    meta_function=None,\n    target_value_list=None,\n    assert_on_error=False,\n)\n</code></pre> <p>             Bases: <code>ExpVisComponent</code></p> <p>Dashboard ExpVisComponent to visualize all metrics in two columns (the right side starting with val_)</p> Source code in <code>niceml/dashboard/components/expviscomponent.py</code> <pre><code>def __init__(\n    self,\n    component_name: Optional[str] = None,\n    meta_function: Optional[MetaFunction] = None,\n    target_value_list: Optional[List[Any]] = None,\n    assert_on_error: bool = False,\n):\n    # Create empty list for chart images\n    self.component_name: Optional[str] = component_name\n    self.chart_images_list: List[Image.Image] = []\n    self.meta_function = meta_function\n    self.target_value_list = [] if target_value_list is None else target_value_list\n    self.assert_on_error = assert_on_error\n</code></pre>"},{"location":"reference/dashboard/metricviscomponent/#niceml.dashboard.metricviscomponent-functions","title":"Functions","text":""},{"location":"reference/dashboard/metricviscomponent/#niceml.dashboard.metricviscomponent.generate_charts_for_metrics","title":"generate_charts_for_metrics","text":"<pre><code>generate_charts_for_metrics(\n    exp_ids, exp_manager, metric_list\n)\n</code></pre> <p>Generates all charts for selected experiments and metrics and caches them</p> <p>Parameters:</p> <ul> <li> <code>exp_ids</code>             (<code>List[str]</code>)         \u2013          <p>Experiment Ids to get the metrics charts for</p> </li> <li> <code>exp_manager</code>             (<code>ExperimentManager</code>)         \u2013          <p>Experiment Manager to get the data from</p> </li> <li> <code>metric_list</code>             (<code>List[str]</code>)         \u2013          <p>Metrics to get the charts of</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>list</code>         \u2013          <p>List of charts for each metric</p> </li> </ul> Source code in <code>niceml/dashboard/metricviscomponent.py</code> <pre><code>def generate_charts_for_metrics(\n    exp_ids: List[str], exp_manager: ExperimentManager, metric_list: List[str]\n) -&gt; list:\n    \"\"\"\n    Generates all charts for selected experiments and metrics and caches them\n\n    Args:\n        exp_ids: Experiment Ids to get the metrics charts for\n        exp_manager: Experiment Manager to get the data from\n        metric_list: Metrics to get the charts of\n\n    Returns:\n        List of charts for each metric\n    \"\"\"\n\n    @st.cache_data()\n    def _get_metrics_charts(*args) -&gt; list:  # pylint: disable = unused-argument\n        \"\"\"Generates all charts for selected experiments and metrics\"\"\"\n        sorted_metrics = sort_metric_list(metric_list)\n        chart_data_list = []\n        for metric in sorted_metrics:\n            cur_df = exp_manager.get_visu_df(metric, list(exp_ids))\n            if cur_df is None:\n                continue\n            chart_data = generate_chart(cur_df, metric)\n            chart_data_list.append(chart_data)\n        return chart_data_list\n\n    return _get_metrics_charts(exp_ids, metric_list)\n</code></pre>"},{"location":"reference/dashboard/metricviscomponent/#niceml.dashboard.metricviscomponent.sort_metric_list","title":"sort_metric_list","text":"<pre><code>sort_metric_list(metric_list)\n</code></pre> <p>Sorts the metric list so that validation metrics are together with train metrics.</p> <p>Parameters:</p> <ul> <li> <code>metric_list</code>             (<code>List[str]</code>)         \u2013          <p>List[str]: list of metrics</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>List[str]</code>         \u2013          <p>A list of strings where the validation metrics are together with the train metrics</p> </li> </ul> Source code in <code>niceml/dashboard/metricviscomponent.py</code> <pre><code>def sort_metric_list(metric_list: List[str]) -&gt; List[str]:\n    \"\"\"\n    Sorts the metric list so that validation metrics are together with train metrics.\n\n    Args:\n        metric_list: List[str]: list of metrics\n\n    Returns:\n        A list of strings where the validation metrics are together with the train metrics\n\n    \"\"\"\n\n    train_metrics = sorted([x for x in metric_list if not x.startswith(\"val_\")])\n    sorted_metrics = []\n    for met in train_metrics:\n        sorted_metrics.append(met)\n        sorted_metrics.append(f\"val_{met}\")\n    return sorted_metrics\n</code></pre>"},{"location":"reference/dashboard/netdataloggerviscomponent/","title":"netdataloggerviscomponent","text":""},{"location":"reference/dashboard/netdataloggerviscomponent/#niceml.dashboard.netdataloggerviscomponent","title":"netdataloggerviscomponent","text":"<p>Module for the net data logger visualization component</p>"},{"location":"reference/dashboard/netdataloggerviscomponent/#niceml.dashboard.netdataloggerviscomponent-classes","title":"Classes","text":""},{"location":"reference/dashboard/netdataloggerviscomponent/#niceml.dashboard.netdataloggerviscomponent.NetDataLoggerVisComponent","title":"NetDataLoggerVisComponent","text":"<pre><code>NetDataLoggerVisComponent(\n    meta_function=None,\n    target_value_list=None,\n    assert_on_error=False,\n)\n</code></pre> <p>             Bases: <code>SingleExpVisComponent</code>, <code>ABC</code></p> <p>Abstract class of a net data logger visualization component</p> Source code in <code>niceml/dashboard/components/expviscomponent.py</code> <pre><code>def __init__(\n    self,\n    meta_function: Optional[MetaFunction] = None,\n    target_value_list: Optional[List[Any]] = None,\n    assert_on_error: bool = False,\n):\n    # Create empty list for chart images\n    self.chart_images_list: List[Image.Image] = []\n    self.meta_function = meta_function\n    self.target_value_list = [] if target_value_list is None else target_value_list\n    self.assert_on_error = assert_on_error\n</code></pre>"},{"location":"reference/dashboard/remotettrainutils/","title":"remotettrainutils","text":""},{"location":"reference/dashboard/remotettrainutils/#niceml.dashboard.remotettrainutils","title":"remotettrainutils","text":"<p>Module for the loading the experiments for the dashboard</p>"},{"location":"reference/dashboard/remotettrainutils/#niceml.dashboard.remotettrainutils-classes","title":"Classes","text":""},{"location":"reference/dashboard/remotettrainutils/#niceml.dashboard.remotettrainutils-functions","title":"Functions","text":""},{"location":"reference/dashboard/remotettrainutils/#niceml.dashboard.remotettrainutils.download_visu","title":"download_visu","text":"<pre><code>download_visu(experiment_downloader)\n</code></pre> <p>Download the visualization files for the experiment</p> Source code in <code>niceml/dashboard/remotettrainutils.py</code> <pre><code>def download_visu(experiment_downloader: ExperimentDownloader):\n    \"\"\"Download the visualization files for the experiment\"\"\"\n    selected_extensions = []\n    for ext in experiment_downloader.get_all_extensions():\n        if st.checkbox(ext):\n            selected_extensions.append(ext)\n    if st.button(\"Download\"):\n        to_download_files = experiment_downloader.get_downloads(selected_extensions)\n        download_count = len(to_download_files)\n        status_text = st.empty()\n        prog_bar = st.progress(0)\n        for idx, file in enumerate(to_download_files):\n            status_text.text(f\"({idx + 1}/{download_count}) - File: {file.source_file}\")\n            prog_bar.progress((idx + 1) / download_count)\n            file()\n</code></pre>"},{"location":"reference/dashboard/remotettrainutils/#niceml.dashboard.remotettrainutils.exp_manager_factory","title":"exp_manager_factory","text":"<pre><code>exp_manager_factory(*args)\n</code></pre> <p>Factory for the experiment manager cached with streamlit</p> Source code in <code>niceml/dashboard/remotettrainutils.py</code> <pre><code>@st.cache_resource()\ndef exp_manager_factory(*args):  # pylint: disable=unused-argument\n    \"\"\"Factory for the experiment manager cached with streamlit\"\"\"\n    return ExperimentManager([])\n</code></pre>"},{"location":"reference/dashboard/remotettrainutils/#niceml.dashboard.remotettrainutils.load_experiments","title":"load_experiments","text":"<pre><code>load_experiments(\n    storage,\n    exp_info_list,\n    df_loader_factory,\n    image_loader_factory,\n    local_exp_cache=None,\n)\n</code></pre> <p>Load the experiments from the cloud storage and stores them in the experiment manager. Additionally, they are saved in the local cache</p> Source code in <code>niceml/dashboard/remotettrainutils.py</code> <pre><code>def load_experiments(\n    storage,\n    exp_info_list: List[ExperimentInfo],\n    df_loader_factory: DfLoaderFactory,\n    image_loader_factory: ImageLoaderFactory,\n    local_exp_cache: Optional[ExperimentCache] = None,\n):\n    \"\"\"Load the experiments from the cloud storage and\n    stores them in the experiment manager. Additionally, they are saved in the local cache\n    \"\"\"\n    experiments: List[ExperimentData]\n    dir_info_list: List[str] = []\n    load_exp_info_list: List[ExperimentInfo] = []\n\n    # pylint: disable = unused-argument\n    @st.cache_data()\n    def _check_and_load_cache(\n        *args,\n    ) -&gt; List[ExperimentData]:\n        experiments_list = []\n        for cur_exp_info in exp_info_list:\n            if local_exp_cache is not None and not local_exp_cache.should_reload(\n                cur_exp_info\n            ):\n                initialized_df_loader: DfLoader = df_loader_factory.create_df_loader(\n                    storage, cur_exp_info.exp_filepath\n                )\n                initialized_image_loader: ImageLoader = (\n                    image_loader_factory.create_image_loader(\n                        storage, cur_exp_info.exp_filepath\n                    )\n                )\n                exp_data = local_exp_cache.load_experiment(\n                    cur_exp_info.short_id,\n                    df_loader=initialized_df_loader,\n                    image_loader=initialized_image_loader,\n                )\n                experiments_list.append(exp_data)\n            else:\n                dir_info_list.append(cur_exp_info.exp_filepath)\n                load_exp_info_list.append(cur_exp_info)\n        return experiments_list\n\n    exp_cache_count = local_exp_cache.get_exp_count_in_cache()\n    experiments = _check_and_load_cache(exp_info_list, exp_cache_count)\n    if len(load_exp_info_list) &gt; 0:\n        load_exp_count = len(load_exp_info_list)\n        prog_bar = st.progress(0)\n        status_text = st.empty()\n        status_text.text(f\"Cached 0/{load_exp_count} experiments\")\n\n        for idx, dir_info in enumerate(dir_info_list):\n            df_loader = df_loader_factory.create_df_loader(storage, dir_info)\n            image_loader = image_loader_factory.create_image_loader(storage, dir_info)\n            experiment = try_remote_exp_data_factory(\n                dir_info, storage, df_loader=df_loader, image_loader=image_loader\n            )\n            if experiment is not None:\n                experiments.append(experiment)\n                if local_exp_cache is not None:\n                    local_exp_cache.save_experiment(experiment)\n            prog_bar.progress(idx / load_exp_count)\n            status_text.text(f\"Cached {idx}/{load_exp_count} experiments\")\n        status_text.text(f\"Cached {load_exp_count}/{load_exp_count} experiments\")\n        prog_bar.progress(1.0)\n        st.success(\"Done\")\n    return experiments\n</code></pre>"},{"location":"reference/dashboard/remotettrainutils/#niceml.dashboard.remotettrainutils.query_experiments","title":"query_experiments","text":"<pre><code>query_experiments(storage)\n</code></pre> <p>Query the experiments from the cloud storage</p> Source code in <code>niceml/dashboard/remotettrainutils.py</code> <pre><code>def query_experiments(storage: StorageInterface) -&gt; List[ExperimentInfo]:\n    \"\"\"Query the experiments from the cloud storage\"\"\"\n\n    @st.cache_data(ttl=3600)\n    def _local_query_exps(*args):  # pylint: disable=unused-argument\n        exp_info_list: List[ExperimentInfo] = storage.list_experiments()\n        return exp_info_list\n\n    return _local_query_exps(id(storage))\n</code></pre>"},{"location":"reference/dashboard/remotettrainutils/#niceml.dashboard.remotettrainutils.select_to_load_exps","title":"select_to_load_exps","text":"<pre><code>select_to_load_exps(exp_info_list, exp_manager)\n</code></pre> <p>Select the experiments to load. That means which are not in the experiment manager</p> Source code in <code>niceml/dashboard/remotettrainutils.py</code> <pre><code>def select_to_load_exps(\n    exp_info_list: List[ExperimentInfo], exp_manager: ExperimentManager\n):\n    \"\"\"Select the experiments to load.\n    That means which are not in the experiment manager\"\"\"\n    experiments_to_load = []\n    for exp_info in exp_info_list:\n        if exp_manager.is_exp_modified(exp_info.short_id, exp_info.last_modified):\n            experiments_to_load.append(exp_info)\n    return experiments_to_load\n</code></pre>"},{"location":"reference/dashboard/remotettrainutils/#niceml.dashboard.remotettrainutils.try_remote_exp_data_factory","title":"try_remote_exp_data_factory","text":"<pre><code>try_remote_exp_data_factory(\n    filepath, storage, df_loader, image_loader\n)\n</code></pre> <p>Try to load experiment data from the filepath with the remote cloud storage</p> Source code in <code>niceml/dashboard/remotettrainutils.py</code> <pre><code>def try_remote_exp_data_factory(\n    filepath, storage, df_loader, image_loader\n) -&gt; Optional[ExperimentData]:\n    \"\"\"Try to load experiment data from the filepath with the remote cloud storage\"\"\"\n    try:\n        return create_expdata_from_storage(\n            filepath, storage, df_loader=df_loader, image_loader=image_loader\n        )\n    except FileNotFoundError:\n        return None\n</code></pre>"},{"location":"reference/dashboard/components/__init__/","title":"components","text":""},{"location":"reference/dashboard/components/__init__/#niceml.dashboard.components","title":"components","text":""},{"location":"reference/dashboard/components/downloadexpviscomponent/","title":"downloadexpviscomponent","text":""},{"location":"reference/dashboard/components/downloadexpviscomponent/#niceml.dashboard.components.downloadexpviscomponent","title":"downloadexpviscomponent","text":"<p>module for download experiments</p>"},{"location":"reference/dashboard/components/downloadexpviscomponent/#niceml.dashboard.components.downloadexpviscomponent-classes","title":"Classes","text":""},{"location":"reference/dashboard/components/downloadexpviscomponent/#niceml.dashboard.components.downloadexpviscomponent.DownloadVisu","title":"DownloadVisu","text":"<pre><code>DownloadVisu(\n    component_name=None,\n    meta_function=None,\n    target_value_list=None,\n    assert_on_error=False,\n)\n</code></pre> <p>             Bases: <code>ExpVisComponent</code></p> <p>Visualization of the download dialog</p> Source code in <code>niceml/dashboard/components/expviscomponent.py</code> <pre><code>def __init__(\n    self,\n    component_name: Optional[str] = None,\n    meta_function: Optional[MetaFunction] = None,\n    target_value_list: Optional[List[Any]] = None,\n    assert_on_error: bool = False,\n):\n    # Create empty list for chart images\n    self.component_name: Optional[str] = component_name\n    self.chart_images_list: List[Image.Image] = []\n    self.meta_function = meta_function\n    self.target_value_list = [] if target_value_list is None else target_value_list\n    self.assert_on_error = assert_on_error\n</code></pre>"},{"location":"reference/dashboard/components/downloadexpviscomponent/#niceml.dashboard.components.downloadexpviscomponent.DownloadVisu-functions","title":"Functions","text":""},{"location":"reference/dashboard/components/downloadexpviscomponent/#niceml.dashboard.components.downloadexpviscomponent.DownloadVisu.create_download_zip","title":"create_download_zip  <code>staticmethod</code>","text":"<pre><code>create_download_zip(zip_directory, zip_path, filename)\n</code></pre> <p>Zip a directory and provide a download link to the zipped file within a streamlit application</p> <p>Parameters:</p> <ul> <li> <code>zip_directory</code>             (<code>str</code>)         \u2013          <p>Path of the directory that should be zipped</p> </li> <li> <code>zip_path</code>             (<code>str</code>)         \u2013          <p>Path of the directory that should contain the output zip file</p> </li> <li> <code>filename</code>             (<code>str</code>)         \u2013          <p>Name of the generated zip file</p> </li> </ul> Source code in <code>niceml/dashboard/components/downloadexpviscomponent.py</code> <pre><code>@staticmethod\ndef create_download_zip(zip_directory: str, zip_path: str, filename: str):\n    \"\"\"\n    Zip a directory and provide a download link to the zipped\n    file within a streamlit application\n\n    Args:\n        zip_directory: Path of the directory that should be zipped\n        zip_path: Path of the directory that should contain the\n            output zip file\n        filename: Name of the generated zip file\n    \"\"\"\n    shutil.make_archive(zip_path, \"zip\", zip_directory)\n    with open(f\"{zip_path}.zip\", \"rb\") as file:\n        st.download_button(\n            label=\"Download ZIP\",\n            data=file,\n            file_name=filename,\n            mime=\"application/zip\",\n        )\n</code></pre>"},{"location":"reference/dashboard/components/downloadexpviscomponent/#niceml.dashboard.components.downloadexpviscomponent-functions","title":"Functions","text":""},{"location":"reference/dashboard/components/expviscomponent/","title":"expviscomponent","text":""},{"location":"reference/dashboard/components/expviscomponent/#niceml.dashboard.components.expviscomponent","title":"expviscomponent","text":"<p>Module for ExpVisComponent for the dashboard</p>"},{"location":"reference/dashboard/components/expviscomponent/#niceml.dashboard.components.expviscomponent-classes","title":"Classes","text":""},{"location":"reference/dashboard/components/expviscomponent/#niceml.dashboard.components.expviscomponent.ExpVisComponent","title":"ExpVisComponent","text":"<pre><code>ExpVisComponent(\n    component_name=None,\n    meta_function=None,\n    target_value_list=None,\n    assert_on_error=False,\n)\n</code></pre> <p>             Bases: <code>ABC</code></p> <p>Basic dashboard component to visualize experiments</p> Source code in <code>niceml/dashboard/components/expviscomponent.py</code> <pre><code>def __init__(\n    self,\n    component_name: Optional[str] = None,\n    meta_function: Optional[MetaFunction] = None,\n    target_value_list: Optional[List[Any]] = None,\n    assert_on_error: bool = False,\n):\n    # Create empty list for chart images\n    self.component_name: Optional[str] = component_name\n    self.chart_images_list: List[Image.Image] = []\n    self.meta_function = meta_function\n    self.target_value_list = [] if target_value_list is None else target_value_list\n    self.assert_on_error = assert_on_error\n</code></pre>"},{"location":"reference/dashboard/components/expviscomponent/#niceml.dashboard.components.expviscomponent.ExpVisComponent-functions","title":"Functions","text":""},{"location":"reference/dashboard/components/expviscomponent/#niceml.dashboard.components.expviscomponent.ExpVisComponent.get_component_name","title":"get_component_name","text":"<pre><code>get_component_name()\n</code></pre> <p>Returns the components_name for visualization</p> Source code in <code>niceml/dashboard/components/expviscomponent.py</code> <pre><code>def get_component_name(self) -&gt; Optional[str]:\n    \"\"\"Returns the components_name for visualization\"\"\"\n    return self.component_name\n</code></pre>"},{"location":"reference/dashboard/components/expviscomponent/#niceml.dashboard.components.expviscomponent.ExpVisComponent.get_images","title":"get_images","text":"<pre><code>get_images()\n</code></pre> <p>Returns the chart images</p> Source code in <code>niceml/dashboard/components/expviscomponent.py</code> <pre><code>def get_images(self) -&gt; List[Image.Image]:\n    \"\"\"Returns the chart images\"\"\"\n    return self.chart_images_list\n</code></pre>"},{"location":"reference/dashboard/components/expviscomponent/#niceml.dashboard.components.expviscomponent.ExpVisComponent.render","title":"render","text":"<pre><code>render(\n    exp_manager,\n    storage_interface,\n    exp_ids,\n    subset_name=None,\n)\n</code></pre> <p>Called when a component is rendered</p> Source code in <code>niceml/dashboard/components/expviscomponent.py</code> <pre><code>def render(\n    self,\n    exp_manager: ExperimentManager,\n    storage_interface: StorageInterface,\n    exp_ids: List[str],\n    subset_name: Optional[str] = None,\n):\n    \"\"\"Called when a component is rendered\"\"\"\n    try:\n        if self.meta_function is None:\n            self._render(exp_manager, storage_interface, exp_ids, subset_name)\n        else:\n            filtered_exp_list: List[str] = []\n            for exp_id in exp_ids:\n                exp_data: ExperimentData = exp_manager.get_exp_by_id(exp_id)\n                meta_target = self.meta_function(exp_data)\n                if meta_target in self.target_value_list:\n                    filtered_exp_list.append(exp_id)\n            self._render(\n                exp_manager, storage_interface, filtered_exp_list, subset_name\n            )\n    except Exception as error:  # pylint: disable=broad-except\n        st.error(f\"Rendering failed: {error}\")\n        if self.assert_on_error:\n            raise error\n</code></pre>"},{"location":"reference/dashboard/components/expviscomponent/#niceml.dashboard.components.expviscomponent.RenderingError","title":"RenderingError","text":"<p>             Bases: <code>Exception</code></p> <p>Error when component could not be rendered</p>"},{"location":"reference/dashboard/components/expviscomponent/#niceml.dashboard.components.expviscomponent.SingleExpVisComponent","title":"SingleExpVisComponent","text":"<pre><code>SingleExpVisComponent(\n    meta_function=None,\n    target_value_list=None,\n    assert_on_error=False,\n)\n</code></pre> <p>             Bases: <code>ABC</code></p> <p>Visualization component for a single experiment</p> Source code in <code>niceml/dashboard/components/expviscomponent.py</code> <pre><code>def __init__(\n    self,\n    meta_function: Optional[MetaFunction] = None,\n    target_value_list: Optional[List[Any]] = None,\n    assert_on_error: bool = False,\n):\n    # Create empty list for chart images\n    self.chart_images_list: List[Image.Image] = []\n    self.meta_function = meta_function\n    self.target_value_list = [] if target_value_list is None else target_value_list\n    self.assert_on_error = assert_on_error\n</code></pre>"},{"location":"reference/dashboard/components/expviscomponent/#niceml.dashboard.components.expviscomponent.SingleExpVisComponent-functions","title":"Functions","text":""},{"location":"reference/dashboard/components/expviscomponent/#niceml.dashboard.components.expviscomponent.SingleExpVisComponent.get_images","title":"get_images","text":"<pre><code>get_images()\n</code></pre> <p>Returns the chart images</p> Source code in <code>niceml/dashboard/components/expviscomponent.py</code> <pre><code>def get_images(self) -&gt; List[Image.Image]:\n    \"\"\"Returns the chart images\"\"\"\n    return self.chart_images_list\n</code></pre>"},{"location":"reference/dashboard/components/expviscomponent/#niceml.dashboard.components.expviscomponent.SingleExpVisComponent.render","title":"render","text":"<pre><code>render(\n    exp_manager, storage_interface, exp_id, subset_name=None\n)\n</code></pre> <p>Called when a component is rendered</p> Source code in <code>niceml/dashboard/components/expviscomponent.py</code> <pre><code>def render(\n    self,\n    exp_manager: ExperimentManager,\n    storage_interface: StorageInterface,\n    exp_id: str,\n    subset_name: Optional[str] = None,\n):\n    \"\"\"Called when a component is rendered\"\"\"\n    try:\n        if self.meta_function is None:\n            self._render(exp_manager, storage_interface, exp_id, subset_name)\n        else:\n            exp_data: ExperimentData = exp_manager.get_exp_by_id(exp_id)\n            meta_target = self.meta_function(exp_data)\n            if meta_target in self.target_value_list:\n                self._render(exp_manager, storage_interface, exp_id, subset_name)\n    except RenderingError as error:\n        st.error(f\"Rendering failed: {error}\")\n        if self.assert_on_error:\n            raise error\n</code></pre>"},{"location":"reference/dashboard/components/linearviscomponent/","title":"linearviscomponent","text":""},{"location":"reference/dashboard/components/linearviscomponent/#niceml.dashboard.components.linearviscomponent","title":"linearviscomponent","text":"<p>Module for LinearVisComponent</p>"},{"location":"reference/dashboard/components/linearviscomponent/#niceml.dashboard.components.linearviscomponent-classes","title":"Classes","text":""},{"location":"reference/dashboard/components/linearviscomponent/#niceml.dashboard.components.linearviscomponent.LinearVisComponent","title":"LinearVisComponent","text":"<pre><code>LinearVisComponent(\n    component_name, vis_components, **kwargs\n)\n</code></pre> <p>             Bases: <code>ExpVisComponent</code></p> <p>Visualizes ExpVisComponents one after another</p> Source code in <code>niceml/dashboard/components/linearviscomponent.py</code> <pre><code>def __init__(\n    self,\n    component_name: str,\n    vis_components: List[ExpVisComponent],\n    **kwargs,\n):\n    super().__init__(component_name=component_name, **kwargs)\n    self.vis_components: List[ExpVisComponent] = vis_components\n</code></pre>"},{"location":"reference/dashboard/components/linearviscomponent/#niceml.dashboard.components.linearviscomponent.LinearVisComponent-functions","title":"Functions","text":""},{"location":"reference/dashboard/components/linearviscomponent/#niceml.dashboard.components.linearviscomponent.LinearVisComponent.get_images","title":"get_images","text":"<pre><code>get_images()\n</code></pre> <p>gets all images from the subcomponents and returns them</p> Source code in <code>niceml/dashboard/components/linearviscomponent.py</code> <pre><code>def get_images(self) -&gt; List[Image.Image]:\n    \"\"\"gets all images from the subcomponents and returns them\"\"\"\n    images: List[Image.Image] = []\n    for vis_comp in self.vis_components:\n        images += vis_comp.get_images()\n    return images\n</code></pre>"},{"location":"reference/dashboard/components/metaviscomponent/","title":"metaviscomponent","text":""},{"location":"reference/dashboard/components/metaviscomponent/#niceml.dashboard.components.metaviscomponent","title":"metaviscomponent","text":"<p>Module for MetaVisComponent for the dashboard</p>"},{"location":"reference/dashboard/components/metaviscomponent/#niceml.dashboard.components.metaviscomponent-classes","title":"Classes","text":""},{"location":"reference/dashboard/components/metaviscomponent/#niceml.dashboard.components.metaviscomponent.MetaVisComponent","title":"MetaVisComponent","text":"<pre><code>MetaVisComponent(meta_tables, **kwargs)\n</code></pre> <p>             Bases: <code>ExpVisComponent</code></p> <p>Dashboard component to show Meta information about the experiments</p> Source code in <code>niceml/dashboard/components/metaviscomponent.py</code> <pre><code>def __init__(self, meta_tables: List[MetaTable], **kwargs):\n    super().__init__(**kwargs)\n    self.meta_tables = meta_tables\n</code></pre>"},{"location":"reference/dashboard/components/prefixviscomponent/","title":"prefixviscomponent","text":""},{"location":"reference/dashboard/components/prefixviscomponent/#niceml.dashboard.components.prefixviscomponent","title":"prefixviscomponent","text":"<p>Module for  prefixviscomponent</p>"},{"location":"reference/dashboard/components/prefixviscomponent/#niceml.dashboard.components.prefixviscomponent-classes","title":"Classes","text":""},{"location":"reference/dashboard/components/prefixviscomponent/#niceml.dashboard.components.prefixviscomponent.PrefixVisComponent","title":"PrefixVisComponent","text":"<pre><code>PrefixVisComponent(components, use_tabs=True, **kwargs)\n</code></pre> <p>             Bases: <code>ExpVisComponent</code></p> <p>This ExpVisComponent allows a rendering regarding the ExperimentPrefixes</p> Source code in <code>niceml/dashboard/components/prefixviscomponent.py</code> <pre><code>def __init__(\n    self,\n    components: Dict[str, List[ExpVisComponent]],\n    use_tabs: bool = True,\n    **kwargs,\n):\n    super().__init__(**kwargs)\n    self.components = components\n    self.use_tabs = use_tabs\n</code></pre>"},{"location":"reference/dashboard/components/selectionviscomponent/","title":"selectionviscomponent","text":""},{"location":"reference/dashboard/components/selectionviscomponent/#niceml.dashboard.components.selectionviscomponent","title":"selectionviscomponent","text":"<p>Module for SelectionVisComponent for the dashboard</p>"},{"location":"reference/dashboard/components/selectionviscomponent/#niceml.dashboard.components.selectionviscomponent-classes","title":"Classes","text":""},{"location":"reference/dashboard/components/selectionviscomponent/#niceml.dashboard.components.selectionviscomponent.SelectionVisComponent","title":"SelectionVisComponent","text":"<pre><code>SelectionVisComponent(\n    component_name,\n    vis_components,\n    expanded=False,\n    subset_names=None,\n    use_subset_selection=True,\n    **kwargs\n)\n</code></pre> <p>             Bases: <code>ExpVisComponent</code></p> <p>Dashboard component where one can select one subcomponent to visualize</p> Source code in <code>niceml/dashboard/components/selectionviscomponent.py</code> <pre><code>def __init__(  # pylint: disable=too-many-arguments\n    self,\n    component_name: str,\n    vis_components: List[SingleExpVisComponent],\n    expanded: bool = False,\n    subset_names: Optional[List[str]] = None,\n    use_subset_selection: bool = True,\n    **kwargs,\n):\n    super().__init__(component_name=component_name, **kwargs)\n    self.vis_components: List[SingleExpVisComponent] = vis_components\n    self.expanded = expanded\n    self.subset_names = subset_names or get_eval_save_names()\n    self.use_subset_selection = use_subset_selection\n</code></pre>"},{"location":"reference/dashboard/components/selectionviscomponent/#niceml.dashboard.components.selectionviscomponent.SelectionVisComponent-functions","title":"Functions","text":""},{"location":"reference/dashboard/components/selectionviscomponent/#niceml.dashboard.components.selectionviscomponent.SelectionVisComponent.get_exp_id_and_subset_name","title":"get_exp_id_and_subset_name","text":"<pre><code>get_exp_id_and_subset_name(exp_ids)\n</code></pre> <p>Gets the experiment id and subset name from the user selection via streamlit</p> Source code in <code>niceml/dashboard/components/selectionviscomponent.py</code> <pre><code>def get_exp_id_and_subset_name(self, exp_ids: List[str]) -&gt; Tuple[str, str]:\n    \"\"\"Gets the experiment id and subset name from the user selection via streamlit\"\"\"\n    if self.use_subset_selection:\n        col1, col2 = st.columns(2)\n        exp_id = col1.selectbox(\n            \"Select ExpID\",\n            options=exp_ids,\n            key=f\"selectbox-expid-{self.component_name}\",\n        )\n        subset_name = col2.selectbox(\n            \"Select subset\",\n            options=self.subset_names,\n            key=f\"selectbox-subset\" f\"-{self.component_name}\",\n        )\n    else:\n        exp_id = st.selectbox(\n            \"Select ExpID\",\n            options=exp_ids,\n            key=f\"selectbox-expid-{self.component_name}\",\n        )\n        subset_name = \"\"\n\n    return exp_id, subset_name\n</code></pre>"},{"location":"reference/dashboard/components/selectionviscomponent/#niceml.dashboard.components.selectionviscomponent.SelectionVisComponent.get_images","title":"get_images","text":"<pre><code>get_images()\n</code></pre> <p>Returns images from subcomponents</p> Source code in <code>niceml/dashboard/components/selectionviscomponent.py</code> <pre><code>def get_images(self) -&gt; List[Image.Image]:\n    \"\"\"Returns images from subcomponents\"\"\"\n    images: List[Image.Image] = []\n    for _, vis_comp in self.vis_components:\n        images += vis_comp.get_images()\n    return images\n</code></pre>"},{"location":"reference/dashboard/components/selectionviscomponent/#niceml.dashboard.components.selectionviscomponent-functions","title":"Functions","text":""},{"location":"reference/dashboard/visualizers/__init__/","title":"visualizers","text":""},{"location":"reference/dashboard/visualizers/__init__/#niceml.dashboard.visualizers","title":"visualizers","text":""},{"location":"reference/dashboard/visualizers/boundingboxvisualizer/","title":"boundingboxvisualizer","text":""},{"location":"reference/dashboard/visualizers/boundingboxvisualizer/#niceml.dashboard.visualizers.boundingboxvisualizer","title":"boundingboxvisualizer","text":"<p>Module for BoundingBoxVisualizer</p>"},{"location":"reference/dashboard/visualizers/boundingboxvisualizer/#niceml.dashboard.visualizers.boundingboxvisualizer-classes","title":"Classes","text":""},{"location":"reference/dashboard/visualizers/boundingboxvisualizer/#niceml.dashboard.visualizers.boundingboxvisualizer.BoundingBoxVisualizer","title":"BoundingBoxVisualizer","text":"<pre><code>BoundingBoxVisualizer(\n    hide_gt=False,\n    hide_gt_over_threshold=True,\n    iou_threshold=0.5,\n    **kwargs\n)\n</code></pre> <p>             Bases: <code>ImageVisualizer</code></p> <p>Visualizer for images with ObjDetInstanceLabels (prediction and ground truth)</p> Source code in <code>niceml/dashboard/visualizers/boundingboxvisualizer.py</code> <pre><code>def __init__(\n    self,\n    hide_gt: bool = False,\n    hide_gt_over_threshold: bool = True,\n    iou_threshold: float = 0.5,\n    **kwargs,\n):\n    super().__init__(**kwargs)\n    self.iou_threshold = iou_threshold\n    self.hide_gt = hide_gt\n    self.hide_gt_over_threshold = hide_gt_over_threshold\n</code></pre>"},{"location":"reference/dashboard/visualizers/boundingboxvisualizer/#niceml.dashboard.visualizers.boundingboxvisualizer.BoundingBoxVisualizer-functions","title":"Functions","text":""},{"location":"reference/dashboard/visualizers/boundingboxvisualizer/#niceml.dashboard.visualizers.boundingboxvisualizer.BoundingBoxVisualizer.get_images_with_labels","title":"get_images_with_labels","text":"<pre><code>get_images_with_labels(image_data_container)\n</code></pre> <p>Returns images of 'image_data_container' with drawn prediction and ground truth labels</p> <p>Parameters:</p> <ul> <li> <code>image_data_container</code>             (<code>ImageContainer</code>)         \u2013          <p>Container with an images label information</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>List[ndarray]</code>         \u2013          <p>List of images with prediction and ground truth labels drawn on them</p> </li> </ul> Source code in <code>niceml/dashboard/visualizers/boundingboxvisualizer.py</code> <pre><code>def get_images_with_labels(\n    self, image_data_container: ImageContainer\n) -&gt; List[np.ndarray]:\n    \"\"\"\n    Returns images of 'image_data_container' with drawn prediction and ground truth labels\n\n    Args:\n        image_data_container: Container with an images label information\n\n    Returns:\n        List of images with prediction and ground truth labels drawn on them\n    \"\"\"\n    images = []\n    for image_path in image_data_container.get_image_paths():\n        try:\n            image = self.image_loader(image_path).astype(np.uint8)\n            images.append(image)\n        except FileNotFoundError:\n            logging.getLogger(__name__).warning(\"FileNotFoundError: %s\", image_path)\n    images = [\n        Image.fromarray(image)\n        .convert(\"RGB\")\n        .resize(size=image_data_container.image_visu_size.to_pil_size())\n        for image in images\n    ]\n\n    draw_images = []\n\n    if not check_instance_label_type(\n        label_list=image_data_container.predictions, target_type=ObjDetInstanceLabel\n    ) and not check_instance_label_type(\n        label_list=image_data_container.ground_truth,\n        target_type=ObjDetInstanceLabel,\n    ):\n        raise ValueError(\n            \"Type of predictions and ground truth labels is not ObjDetInstanceLabel\"\n        )\n    scale_factor = image_data_container.image_visu_size.get_division_factor(\n        image_data_container.model_output_size\n    )\n    image_data_container = image_data_container.scale_instance_labels(\n        scale_factor=scale_factor\n    )\n\n    for image in images:\n        draw_image = draw_labels_on_image(\n            image=image,\n            pred_bbox_label_list=image_data_container.predictions,\n            gt_bbox_label_list=image_data_container.ground_truth,\n            hide_gt=self.hide_gt,\n            hide_gt_over_thresh=self.hide_gt_over_threshold,\n            iou_threshold=self.iou_threshold,\n        )\n        draw_images.append(draw_image)\n\n    return [np.array(draw_image) for draw_image in draw_images]\n</code></pre>"},{"location":"reference/dashboard/visualizers/boundingboxvisualizer/#niceml.dashboard.visualizers.boundingboxvisualizer-functions","title":"Functions","text":""},{"location":"reference/dashboard/visualizers/imagevisualizer/","title":"imagevisualizer","text":""},{"location":"reference/dashboard/visualizers/imagevisualizer/#niceml.dashboard.visualizers.imagevisualizer","title":"imagevisualizer","text":"<p>Module for ImageVisualizer</p>"},{"location":"reference/dashboard/visualizers/imagevisualizer/#niceml.dashboard.visualizers.imagevisualizer-classes","title":"Classes","text":""},{"location":"reference/dashboard/visualizers/imagevisualizer/#niceml.dashboard.visualizers.imagevisualizer.ImageContainer","title":"ImageContainer  <code>dataclass</code>","text":"<p>Collection of one or more images, the corresponding prediction and ground truth <code>InstanceLabel</code>s and the underlying data of the <code>InstanceLabel</code>s.</p>"},{"location":"reference/dashboard/visualizers/imagevisualizer/#niceml.dashboard.visualizers.imagevisualizer.ImageContainer-functions","title":"Functions","text":""},{"location":"reference/dashboard/visualizers/imagevisualizer/#niceml.dashboard.visualizers.imagevisualizer.ImageContainer.get_image_paths","title":"get_image_paths","text":"<pre><code>get_image_paths()\n</code></pre> <p>Returns image path(s) as list</p> <p>Returns:</p> <ul> <li> <code>List[str]</code>         \u2013          <p>List of image paths</p> </li> </ul> Source code in <code>niceml/dashboard/visualizers/imagevisualizer.py</code> <pre><code>def get_image_paths(self) -&gt; List[str]:\n    \"\"\"\n    Returns image path(s) as list\n\n    Returns:\n        List of image paths\n    \"\"\"\n    if isinstance(self.image_path, list):\n        return self.image_path\n    return [self.image_path]\n</code></pre>"},{"location":"reference/dashboard/visualizers/imagevisualizer/#niceml.dashboard.visualizers.imagevisualizer.ImageContainer.scale_instance_labels","title":"scale_instance_labels","text":"<pre><code>scale_instance_labels(scale_factor)\n</code></pre> <p>Scales the images prediction and ground truth instance labels with a given <code>scale_factor</code> and returns a new scaled instance of <code>ImageContainer</code></p> <p>Parameters:</p> <ul> <li> <code>scale_factor</code>             (<code>float</code>)         \u2013          <p>Factor to scale the prediction and ground truth labels by</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ImageContainer</code>         \u2013          <p>Scaled ImageContainer</p> </li> </ul> Source code in <code>niceml/dashboard/visualizers/imagevisualizer.py</code> <pre><code>def scale_instance_labels(self, scale_factor: float) -&gt; \"ImageContainer\":\n    \"\"\"\n    Scales the images prediction and ground truth instance labels with a given\n    `scale_factor` and returns a new scaled instance of `ImageContainer`\n\n    Args:\n        scale_factor: Factor to scale the prediction and ground truth labels by\n\n    Returns:\n        Scaled ImageContainer\n    \"\"\"\n\n    scaled_predictions = [\n        prediction.scale_label(scale_factor) for prediction in self.predictions\n    ]\n    scaled_ground_truth = [\n        ground_truth.scale_label(scale_factor) for ground_truth in self.ground_truth\n    ]\n\n    return ImageContainer(\n        image_path=self.image_path,\n        predictions=scaled_predictions,\n        ground_truth=scaled_ground_truth,\n        visualize_data=self.visualize_data,\n        image_visu_size=self.image_visu_size,\n        model_output_size=self.model_output_size,\n    )\n</code></pre>"},{"location":"reference/dashboard/visualizers/imagevisualizer/#niceml.dashboard.visualizers.imagevisualizer.ImageVisualizer","title":"ImageVisualizer","text":"<pre><code>ImageVisualizer(image_loader, columns_count=2)\n</code></pre> <p>             Bases: <code>ABC</code></p> <p>Visualizer for images of <code>ImageContainer</code>s</p> Source code in <code>niceml/dashboard/visualizers/imagevisualizer.py</code> <pre><code>def __init__(\n    self,\n    image_loader: ImageLoader,\n    columns_count: int = 2,\n):\n    self.columns_count = columns_count\n    self.image_loader = image_loader\n</code></pre>"},{"location":"reference/dashboard/visualizers/imagevisualizer/#niceml.dashboard.visualizers.imagevisualizer.ImageVisualizer-functions","title":"Functions","text":""},{"location":"reference/dashboard/visualizers/imagevisualizer/#niceml.dashboard.visualizers.imagevisualizer.ImageVisualizer.get_images_with_labels","title":"get_images_with_labels  <code>abstractmethod</code>","text":"<pre><code>get_images_with_labels(image_data_container)\n</code></pre> <p>Returns images of 'image_data_container' with drawn prediction and ground truth labels</p> Source code in <code>niceml/dashboard/visualizers/imagevisualizer.py</code> <pre><code>@abstractmethod\ndef get_images_with_labels(\n    self, image_data_container: ImageContainer\n) -&gt; List[np.ndarray]:\n    \"\"\"Returns images of 'image_data_container' with drawn prediction and ground truth labels\"\"\"\n</code></pre>"},{"location":"reference/dashboard/visualizers/imagevisualizer/#niceml.dashboard.visualizers.imagevisualizer.ImageVisualizer.visualize_images","title":"visualize_images","text":"<pre><code>visualize_images(image_data_containers)\n</code></pre> <p>Visualizes images from 'image_data_containers' with prediction and ground truth labels in streamlit container</p> <p>Parameters:</p> <ul> <li> <code>image_data_containers</code>             (<code>List[ImageContainer]</code>)         \u2013          <p>ImageContainer storing information about the images and labels to visualize</p> </li> </ul> Source code in <code>niceml/dashboard/visualizers/imagevisualizer.py</code> <pre><code>def visualize_images(  # pylint: disable = too-many-arguments\n    self,\n    image_data_containers: List[ImageContainer],\n):\n    \"\"\"\n    Visualizes images from 'image_data_containers' with prediction and ground truth\n    labels in streamlit container\n\n    Args:\n        image_data_containers: ImageContainer storing information about the images\n            and labels to visualize\n    \"\"\"\n\n    for image_data_container in image_data_containers:\n        image_data_list = self.get_images_with_labels(image_data_container)\n        dashboard_container = st.container()\n\n        columns = dashboard_container.columns(self.columns_count)\n\n        for idx, (image, path) in enumerate(\n            zip(image_data_list, image_data_container.get_image_paths())\n        ):\n            columns[idx % self.columns_count].image(image, caption=basename(path))\n\n        if image_data_container.visualize_data.empty:\n            dashboard_container.caption(\"No predictions found\")\n        elif len(image_data_list) == 0:\n            # pylint:disable = line-too-long\n            st.warning(\n                f\"File not found ({', '.join([basename(path)for path in image_data_container.get_image_paths()])}\"\n            )\n        else:\n            dashboard_container.dataframe(image_data_container.visualize_data)\n</code></pre>"},{"location":"reference/dashboard/visualizers/imagevisualizer/#niceml.dashboard.visualizers.imagevisualizer-functions","title":"Functions","text":""},{"location":"reference/dashboard/visualizers/imagevisualizer/#niceml.dashboard.visualizers.imagevisualizer.check_instance_label_type","title":"check_instance_label_type","text":"<pre><code>check_instance_label_type(label_list, target_type)\n</code></pre> <p>Check if each label in <code>label_list</code> is an instance of <code>target_type</code></p> <p>Parameters:</p> <ul> <li> <code>label_list</code>             (<code>List[InstanceLabel]</code>)         \u2013          <p>List of labels for which the type is to be checked</p> </li> <li> <code>target_type</code>             (<code>Type[InstanceLabel]</code>)         \u2013          <p>Type to be checked</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>         \u2013          <p>True if each label of <code>label_list</code> is an instance of <code>target_type</code>,</p> </li> <li> <code>bool</code>         \u2013          <p>otherwise False.</p> </li> </ul> Source code in <code>niceml/dashboard/visualizers/imagevisualizer.py</code> <pre><code>def check_instance_label_type(\n    label_list: List[InstanceLabel], target_type: Type[InstanceLabel]\n) -&gt; bool:\n    \"\"\"\n    Check if each label in `label_list` is an instance of `target_type`\n\n    Args:\n        label_list: List of labels for which the type is to be checked\n        target_type: Type to be checked\n\n    Returns:\n        True if each label of `label_list` is an instance of `target_type`,\n        otherwise False.\n    \"\"\"\n\n    return all(isinstance(label, target_type) for label in label_list)\n</code></pre>"},{"location":"reference/dashboard/visualizers/maskvisualizer/","title":"maskvisualizer","text":""},{"location":"reference/dashboard/visualizers/maskvisualizer/#niceml.dashboard.visualizers.maskvisualizer","title":"maskvisualizer","text":"<p>Module for MaskVisualizer</p>"},{"location":"reference/dashboard/visualizers/maskvisualizer/#niceml.dashboard.visualizers.maskvisualizer-classes","title":"Classes","text":""},{"location":"reference/dashboard/visualizers/maskvisualizer/#niceml.dashboard.visualizers.maskvisualizer.MaskVisualizer","title":"MaskVisualizer","text":"<pre><code>MaskVisualizer(\n    hide_gt=False,\n    hide_gt_over_threshold=True,\n    iou_threshold=0.5,\n    match_gt_pred=True,\n    **kwargs\n)\n</code></pre> <p>             Bases: <code>ImageVisualizer</code></p> <p>Visualizer for images with <code>SemSegInstanceLabel</code>s (prediction, ground truth)</p> Source code in <code>niceml/dashboard/visualizers/maskvisualizer.py</code> <pre><code>def __init__(\n    self,\n    hide_gt: bool = False,\n    hide_gt_over_threshold: bool = True,\n    iou_threshold: float = 0.5,\n    match_gt_pred: bool = True,\n    **kwargs,\n):\n    super().__init__(**kwargs)\n    self.match_gt_pred = match_gt_pred\n    self.hide_gt = hide_gt\n    self.hide_gt_over_threshold = hide_gt_over_threshold\n    self.iou_threshold = iou_threshold\n</code></pre>"},{"location":"reference/dashboard/visualizers/maskvisualizer/#niceml.dashboard.visualizers.maskvisualizer.MaskVisualizer-functions","title":"Functions","text":""},{"location":"reference/dashboard/visualizers/maskvisualizer/#niceml.dashboard.visualizers.maskvisualizer.MaskVisualizer.get_images_with_labels","title":"get_images_with_labels","text":"<pre><code>get_images_with_labels(image_data_container)\n</code></pre> <p>Returns images of 'image_data_container' with drawn prediction and ground truth labels</p> <p>Parameters:</p> <ul> <li> <code>image_data_container</code>             (<code>ImageContainer</code>)         \u2013          <p>Container with an images label information</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>List[ndarray]</code>         \u2013          <p>List of images with prediction and ground truth labels drawn on them</p> </li> </ul> Source code in <code>niceml/dashboard/visualizers/maskvisualizer.py</code> <pre><code>def get_images_with_labels(\n    self, image_data_container: ImageContainer\n) -&gt; List[np.ndarray]:\n    \"\"\"\n    Returns images of 'image_data_container' with drawn prediction and ground truth labels\n\n    Args:\n        image_data_container: Container with an images label information\n\n    Returns:\n        List of images with prediction and ground truth labels drawn on them\n    \"\"\"\n\n    if self.match_gt_pred:\n        (\n            image_data_container.predictions,\n            image_data_container.ground_truth,\n        ) = get_kind_of_label_match(\n            pred_label_list=image_data_container.predictions,\n            gt_label_list=image_data_container.ground_truth,\n            hide_gt_over_thresh=self.hide_gt_over_threshold,\n            iou_threshold=self.iou_threshold,\n        )\n\n    images = []\n    for image_path in image_data_container.get_image_paths():\n        try:\n            images.append(\n                self.image_loader(\n                    image_path, image_data_container.image_visu_size\n                ).astype(np.uint8)\n            )\n        except FileNotFoundError:\n            image = Image.new(\n                mode=\"L\",\n                size=image_data_container.image_visu_size.to_pil_size(),\n            )\n            image = np.array(image, dtype=np.uint8)\n            images.append(image)\n\n    images = [Image.fromarray(image).convert(\"RGB\") for image in images]\n\n    scale_factor = image_data_container.image_visu_size.get_division_factor(\n        image_data_container.model_output_size\n    )\n\n    image_data_container = image_data_container.scale_instance_labels(\n        scale_factor=scale_factor\n    )\n\n    draw_images = []\n\n    for image in images:\n        draw_image = draw_labels_on_image(\n            image=image,\n            pred_error_mask_label_list=image_data_container.predictions,\n            gt_error_mask_label_list=image_data_container.ground_truth,\n            hide_gt=self.hide_gt,\n        )\n        draw_images.append(draw_image)\n\n    return [np.array(draw_image) for draw_image in draw_images]\n</code></pre>"},{"location":"reference/dashboard/visualizers/maskvisualizer/#niceml.dashboard.visualizers.maskvisualizer-functions","title":"Functions","text":""},{"location":"reference/data/__init__/","title":"data","text":""},{"location":"reference/data/__init__/#niceml.data","title":"data","text":""},{"location":"reference/data/augmentation/__init__/","title":"augmentation","text":""},{"location":"reference/data/augmentation/__init__/#niceml.data.augmentation","title":"augmentation","text":""},{"location":"reference/data/augmentation/augmentation/","title":"augmentation","text":""},{"location":"reference/data/augmentation/augmentation/#niceml.data.augmentation.augmentation","title":"augmentation","text":"<p>Module for AugmentationProcessor</p>"},{"location":"reference/data/augmentation/augmentation/#niceml.data.augmentation.augmentation-classes","title":"Classes","text":""},{"location":"reference/data/augmentation/augmentation/#niceml.data.augmentation.augmentation.AugmentationProcessor","title":"AugmentationProcessor","text":"<p>             Bases: <code>ABC</code></p> <p>Is used by the GenericDataset to augument the input containers</p>"},{"location":"reference/data/augmentation/augmentation/#niceml.data.augmentation.augmentation.AugmentationProcessor-functions","title":"Functions","text":""},{"location":"reference/data/augmentation/augmentation/#niceml.data.augmentation.augmentation.AugmentationProcessor.__call__","title":"__call__  <code>abstractmethod</code>","text":"<pre><code>__call__(input_container)\n</code></pre> <p>The augmentation processor is called to augment an input container</p> Source code in <code>niceml/data/augmentation/augmentation.py</code> <pre><code>@abstractmethod\ndef __call__(self, input_container: Any) -&gt; Any:\n    \"\"\"The augmentation processor is called to augment an input container\"\"\"\n</code></pre>"},{"location":"reference/data/datadescriptions/__init__/","title":"datadescriptions","text":""},{"location":"reference/data/datadescriptions/__init__/#niceml.data.datadescriptions","title":"datadescriptions","text":""},{"location":"reference/data/datadescriptions/clsdatadescription/","title":"clsdatadescription","text":""},{"location":"reference/data/datadescriptions/clsdatadescription/#niceml.data.datadescriptions.clsdatadescription","title":"clsdatadescription","text":"<p>Module for ClsDataDescription</p>"},{"location":"reference/data/datadescriptions/clsdatadescription/#niceml.data.datadescriptions.clsdatadescription-classes","title":"Classes","text":""},{"location":"reference/data/datadescriptions/clsdatadescription/#niceml.data.datadescriptions.clsdatadescription.ClsDataDescription","title":"ClsDataDescription  <code>dataclass</code>","text":"<p>             Bases: <code>OutputVectorDataDescription</code>, <code>InputImageDataDescription</code></p> <p>DataDescription for Classification data</p>"},{"location":"reference/data/datadescriptions/clsdatadescription/#niceml.data.datadescriptions.clsdatadescription.ClsDataDescription-functions","title":"Functions","text":""},{"location":"reference/data/datadescriptions/clsdatadescription/#niceml.data.datadescriptions.clsdatadescription.ClsDataDescription.get_index_for_name","title":"get_index_for_name","text":"<pre><code>get_index_for_name(name)\n</code></pre> <p>Returns the index of the given output entry name(s) as int or list of indices</p> Source code in <code>niceml/data/datadescriptions/clsdatadescription.py</code> <pre><code>def get_index_for_name(\n    self, name: Union[str, List[str]]\n) -&gt; Optional[Union[int, List[int]]]:\n    \"\"\"Returns the index of the given output entry name(s) as int or list of indices\"\"\"\n    if isinstance(name, list):\n        return super().get_index_for_name(name)\n    if self.use_multitargets:\n        index_list = []\n        for cur_idx, cur_class in enumerate(self.classes):\n            if isinstance(cur_class, dict):\n                if cur_class[\"name\"] == name or name in cur_class.get(\n                    \"subclasses\", []\n                ):\n                    index_list.append(cur_idx)\n            elif cur_class == name:\n                index_list.append(cur_idx)\n        return index_list or None\n    return super().get_index_for_name(name)\n</code></pre>"},{"location":"reference/data/datadescriptions/clsdatadescription/#niceml.data.datadescriptions.clsdatadescription.ClsDataDescription.get_input_channel_count","title":"get_input_channel_count","text":"<pre><code>get_input_channel_count()\n</code></pre> <p>Returns the number of input channels</p> Source code in <code>niceml/data/datadescriptions/clsdatadescription.py</code> <pre><code>def get_input_channel_count(self) -&gt; int:\n    \"\"\"Returns the number of input channels\"\"\"\n    return self.channel_count\n</code></pre>"},{"location":"reference/data/datadescriptions/clsdatadescription/#niceml.data.datadescriptions.clsdatadescription.ClsDataDescription.get_output_entry_names","title":"get_output_entry_names","text":"<pre><code>get_output_entry_names()\n</code></pre> <p>Returns the names of the target classes</p> Source code in <code>niceml/data/datadescriptions/clsdatadescription.py</code> <pre><code>def get_output_entry_names(self) -&gt; List[str]:\n    \"\"\"Returns the names of the target classes\"\"\"\n    class_name_list = []\n    for cls in self.classes:\n        if isinstance(cls, dict):\n            class_name_list.append(cls[\"name\"])\n        else:\n            class_name_list.append(cls)\n    return class_name_list\n</code></pre>"},{"location":"reference/data/datadescriptions/clsdatadescription/#niceml.data.datadescriptions.clsdatadescription.ClsDataDescription.get_output_size","title":"get_output_size","text":"<pre><code>get_output_size()\n</code></pre> <p>Returns the size of the output</p> Source code in <code>niceml/data/datadescriptions/clsdatadescription.py</code> <pre><code>def get_output_size(self) -&gt; int:\n    \"\"\"Returns the size of the output\"\"\"\n    if self.use_binary and len(self.classes) != 2:\n        raise Exception(f\"Cannot use binary with {len(self.classes)} given!\")\n    return 1 if self.use_binary else len(self.classes)\n</code></pre>"},{"location":"reference/data/datadescriptions/datadescription/","title":"datadescription","text":""},{"location":"reference/data/datadescriptions/datadescription/#niceml.data.datadescriptions.datadescription","title":"datadescription","text":"<p>Module for abstract DataDescription</p>"},{"location":"reference/data/datadescriptions/datadescription/#niceml.data.datadescriptions.datadescription-classes","title":"Classes","text":""},{"location":"reference/data/datadescriptions/datadescription/#niceml.data.datadescriptions.datadescription.DataDescription","title":"DataDescription","text":"<p>             Bases: <code>ABC</code></p> <p>This class is used to describe the data. E.g. how big the input image size is, or what target classes are used.</p>"},{"location":"reference/data/datadescriptions/inputdatadescriptions/","title":"inputdatadescriptions","text":""},{"location":"reference/data/datadescriptions/inputdatadescriptions/#niceml.data.datadescriptions.inputdatadescriptions","title":"inputdatadescriptions","text":"<p>Module for data descriptions used for input</p>"},{"location":"reference/data/datadescriptions/inputdatadescriptions/#niceml.data.datadescriptions.inputdatadescriptions-classes","title":"Classes","text":""},{"location":"reference/data/datadescriptions/inputdatadescriptions/#niceml.data.datadescriptions.inputdatadescriptions.InputImageDataDescription","title":"InputImageDataDescription","text":"<p>             Bases: <code>DataDescription</code>, <code>ABC</code></p> <p>DataDescription used for models with images as input</p>"},{"location":"reference/data/datadescriptions/inputdatadescriptions/#niceml.data.datadescriptions.inputdatadescriptions.InputImageDataDescription-functions","title":"Functions","text":""},{"location":"reference/data/datadescriptions/inputdatadescriptions/#niceml.data.datadescriptions.inputdatadescriptions.InputImageDataDescription.get_input_channel_count","title":"get_input_channel_count  <code>abstractmethod</code>","text":"<pre><code>get_input_channel_count()\n</code></pre> <p>Returns the number of channels of the input image(s)</p> Source code in <code>niceml/data/datadescriptions/inputdatadescriptions.py</code> <pre><code>@abstractmethod\ndef get_input_channel_count(self) -&gt; int:\n    \"\"\"Returns the number of channels of the input image(s)\"\"\"\n</code></pre>"},{"location":"reference/data/datadescriptions/inputdatadescriptions/#niceml.data.datadescriptions.inputdatadescriptions.InputImageDataDescription.get_input_image_size","title":"get_input_image_size  <code>abstractmethod</code>","text":"<pre><code>get_input_image_size()\n</code></pre> <p>Returns the ImageSize of the input image(s)</p> Source code in <code>niceml/data/datadescriptions/inputdatadescriptions.py</code> <pre><code>@abstractmethod\ndef get_input_image_size(self) -&gt; ImageSize:\n    \"\"\"Returns the ImageSize of the input image(s)\"\"\"\n</code></pre>"},{"location":"reference/data/datadescriptions/inputdatadescriptions/#niceml.data.datadescriptions.inputdatadescriptions.InputImageDataDescription.get_input_tensor_shape","title":"get_input_tensor_shape","text":"<pre><code>get_input_tensor_shape()\n</code></pre> <p>Returns the 3-dim shape of the input tensor [height, width, channel_count]</p> Source code in <code>niceml/data/datadescriptions/inputdatadescriptions.py</code> <pre><code>def get_input_tensor_shape(self) -&gt; Tuple[int, int, int]:\n    \"\"\"Returns the 3-dim shape of the input tensor [height, width, channel_count]\"\"\"\n    return self.get_input_image_size().to_numpy_shape() + (\n        self.get_input_channel_count(),\n    )\n</code></pre>"},{"location":"reference/data/datadescriptions/inputdatadescriptions/#niceml.data.datadescriptions.inputdatadescriptions.InputVectorDataDescription","title":"InputVectorDataDescription","text":"<p>             Bases: <code>DataDescription</code>, <code>ABC</code></p> <p>DataDescription used by models with vectors as input</p>"},{"location":"reference/data/datadescriptions/inputdatadescriptions/#niceml.data.datadescriptions.inputdatadescriptions.InputVectorDataDescription-functions","title":"Functions","text":""},{"location":"reference/data/datadescriptions/inputdatadescriptions/#niceml.data.datadescriptions.inputdatadescriptions.InputVectorDataDescription.get_input_entry_names","title":"get_input_entry_names  <code>abstractmethod</code>","text":"<pre><code>get_input_entry_names()\n</code></pre> <p>Returns a name for each vector entry</p> Source code in <code>niceml/data/datadescriptions/inputdatadescriptions.py</code> <pre><code>@abstractmethod\ndef get_input_entry_names(self) -&gt; List[str]:\n    \"\"\"Returns a name for each vector entry\"\"\"\n</code></pre>"},{"location":"reference/data/datadescriptions/inputdatadescriptions/#niceml.data.datadescriptions.inputdatadescriptions.InputVectorDataDescription.get_input_size","title":"get_input_size  <code>abstractmethod</code>","text":"<pre><code>get_input_size()\n</code></pre> <p>Returns the size of the input vector(s)</p> Source code in <code>niceml/data/datadescriptions/inputdatadescriptions.py</code> <pre><code>@abstractmethod\ndef get_input_size(self) -&gt; int:\n    \"\"\"Returns the size of the input vector(s)\"\"\"\n</code></pre>"},{"location":"reference/data/datadescriptions/objdetdatadescription/","title":"objdetdatadescription","text":""},{"location":"reference/data/datadescriptions/objdetdatadescription/#niceml.data.datadescriptions.objdetdatadescription","title":"objdetdatadescription","text":"<p>Module for ObjDetDataDescription</p>"},{"location":"reference/data/datadescriptions/objdetdatadescription/#niceml.data.datadescriptions.objdetdatadescription-classes","title":"Classes","text":""},{"location":"reference/data/datadescriptions/objdetdatadescription/#niceml.data.datadescriptions.objdetdatadescription.ObjDetDataDescription","title":"ObjDetDataDescription  <code>dataclass</code>","text":"<p>             Bases: <code>OutputObjDetDataDescription</code>, <code>InputImageDataDescription</code></p> <p>The default implementation for OutputObjDetDataDescription</p>"},{"location":"reference/data/datadescriptions/objdetdatadescription/#niceml.data.datadescriptions.objdetdatadescription.ObjDetDataDescription-functions","title":"Functions","text":""},{"location":"reference/data/datadescriptions/objdetdatadescription/#niceml.data.datadescriptions.objdetdatadescription.ObjDetDataDescription.get_anchor_aspect_ratios","title":"get_anchor_aspect_ratios","text":"<pre><code>get_anchor_aspect_ratios()\n</code></pre> <p>Returns the aspect ratio of the anchors</p> Source code in <code>niceml/data/datadescriptions/objdetdatadescription.py</code> <pre><code>def get_anchor_aspect_ratios(self) -&gt; List[float]:\n    \"\"\"Returns the aspect ratio of the anchors\"\"\"\n    return self.anchor_aspect_ratios\n</code></pre>"},{"location":"reference/data/datadescriptions/objdetdatadescription/#niceml.data.datadescriptions.objdetdatadescription.ObjDetDataDescription.get_anchor_scales","title":"get_anchor_scales","text":"<pre><code>get_anchor_scales()\n</code></pre> <p>Returns the scale of the anchors</p> Source code in <code>niceml/data/datadescriptions/objdetdatadescription.py</code> <pre><code>def get_anchor_scales(self) -&gt; List[float]:\n    \"\"\"Returns the scale of the anchors\"\"\"\n    return self.anchor_scales\n</code></pre>"},{"location":"reference/data/datadescriptions/objdetdatadescription/#niceml.data.datadescriptions.objdetdatadescription.ObjDetDataDescription.get_anchorcount_for_scale","title":"get_anchorcount_for_scale","text":"<pre><code>get_anchorcount_for_scale(scale)\n</code></pre> <p>Calculates the anchor count for one feature map</p> Source code in <code>niceml/data/datadescriptions/objdetdatadescription.py</code> <pre><code>def get_anchorcount_for_scale(self, scale: int) -&gt; int:\n    \"\"\"Calculates the anchor count for one feature map\"\"\"\n    feature_width: int = self.input_image_size.width // scale\n    feature_height: int = self.input_image_size.height // scale\n    return feature_height * feature_width * self.get_anchorcount_per_feature()\n</code></pre>"},{"location":"reference/data/datadescriptions/objdetdatadescription/#niceml.data.datadescriptions.objdetdatadescription.ObjDetDataDescription.get_anchorcount_per_feature","title":"get_anchorcount_per_feature","text":"<pre><code>get_anchorcount_per_feature()\n</code></pre> <p>Returns the number of anchors per feature</p> Source code in <code>niceml/data/datadescriptions/objdetdatadescription.py</code> <pre><code>def get_anchorcount_per_feature(self) -&gt; int:\n    \"\"\"Returns the number of anchors per feature\"\"\"\n    return len(self.anchor_scales) * len(self.anchor_aspect_ratios)\n</code></pre>"},{"location":"reference/data/datadescriptions/objdetdatadescription/#niceml.data.datadescriptions.objdetdatadescription.ObjDetDataDescription.get_base_area_side","title":"get_base_area_side","text":"<pre><code>get_base_area_side()\n</code></pre> <p>Returns the base area side of the anchors</p> Source code in <code>niceml/data/datadescriptions/objdetdatadescription.py</code> <pre><code>def get_base_area_side(self) -&gt; float:\n    \"\"\"Returns the base area side of the anchors\"\"\"  # QUEST: what is this?\n    return self.anchor_base_area_side\n</code></pre>"},{"location":"reference/data/datadescriptions/objdetdatadescription/#niceml.data.datadescriptions.objdetdatadescription.ObjDetDataDescription.get_box_variance","title":"get_box_variance","text":"<pre><code>get_box_variance()\n</code></pre> <p>Returns variance of bounding boxes</p> Source code in <code>niceml/data/datadescriptions/objdetdatadescription.py</code> <pre><code>def get_box_variance(self) -&gt; List[float]:\n    \"\"\"Returns variance of bounding boxes\"\"\"\n    return self.box_variance\n</code></pre>"},{"location":"reference/data/datadescriptions/objdetdatadescription/#niceml.data.datadescriptions.objdetdatadescription.ObjDetDataDescription.get_coordinates_count","title":"get_coordinates_count","text":"<pre><code>get_coordinates_count()\n</code></pre> <p>Returns the number of coordinates of bounding boxes</p> Source code in <code>niceml/data/datadescriptions/objdetdatadescription.py</code> <pre><code>def get_coordinates_count(self) -&gt; int:\n    \"\"\"Returns the number of coordinates of bounding boxes\"\"\"\n    return self.coordinates_count\n</code></pre>"},{"location":"reference/data/datadescriptions/objdetdatadescription/#niceml.data.datadescriptions.objdetdatadescription.ObjDetDataDescription.get_featuremap_scales","title":"get_featuremap_scales","text":"<pre><code>get_featuremap_scales()\n</code></pre> <p>Returns the scale of feature maps</p> Source code in <code>niceml/data/datadescriptions/objdetdatadescription.py</code> <pre><code>def get_featuremap_scales(self) -&gt; List[int]:\n    \"\"\"Returns the scale of feature maps\"\"\"\n    return self.featuremap_scales\n</code></pre>"},{"location":"reference/data/datadescriptions/objdetdatadescription/#niceml.data.datadescriptions.objdetdatadescription.ObjDetDataDescription.get_input_channel_count","title":"get_input_channel_count","text":"<pre><code>get_input_channel_count()\n</code></pre> <p>Returns the number of input channels</p> Source code in <code>niceml/data/datadescriptions/objdetdatadescription.py</code> <pre><code>def get_input_channel_count(self) -&gt; int:\n    \"\"\"Returns the number of input channels\"\"\"\n    return self.input_channel_count\n</code></pre>"},{"location":"reference/data/datadescriptions/objdetdatadescription/#niceml.data.datadescriptions.objdetdatadescription.ObjDetDataDescription.get_input_image_size","title":"get_input_image_size","text":"<pre><code>get_input_image_size()\n</code></pre> <p>Returns the size of the input image(s)</p> Source code in <code>niceml/data/datadescriptions/objdetdatadescription.py</code> <pre><code>def get_input_image_size(self) -&gt; ImageSize:\n    \"\"\"Returns the size of the input image(s)\"\"\"\n    return self.input_image_size\n</code></pre>"},{"location":"reference/data/datadescriptions/objdetdatadescription/#niceml.data.datadescriptions.objdetdatadescription.ObjDetDataDescription.get_output_class_names","title":"get_output_class_names","text":"<pre><code>get_output_class_names()\n</code></pre> <p>Returns the names of the output classes</p> Source code in <code>niceml/data/datadescriptions/objdetdatadescription.py</code> <pre><code>def get_output_class_names(self) -&gt; List[str]:\n    \"\"\"Returns the names of the output classes\"\"\"\n    return self.classes\n</code></pre>"},{"location":"reference/data/datadescriptions/outputdatadescriptions/","title":"outputdatadescriptions","text":""},{"location":"reference/data/datadescriptions/outputdatadescriptions/#niceml.data.datadescriptions.outputdatadescriptions","title":"outputdatadescriptions","text":"<p>Module for output datadescriptions</p>"},{"location":"reference/data/datadescriptions/outputdatadescriptions/#niceml.data.datadescriptions.outputdatadescriptions-classes","title":"Classes","text":""},{"location":"reference/data/datadescriptions/outputdatadescriptions/#niceml.data.datadescriptions.outputdatadescriptions.OutputImageDataDescription","title":"OutputImageDataDescription","text":"<p>             Bases: <code>DataDescription</code>, <code>ABC</code></p> <p>DataDescription used for models with images as output (e.g. SemSeg)</p>"},{"location":"reference/data/datadescriptions/outputdatadescriptions/#niceml.data.datadescriptions.outputdatadescriptions.OutputImageDataDescription-functions","title":"Functions","text":""},{"location":"reference/data/datadescriptions/outputdatadescriptions/#niceml.data.datadescriptions.outputdatadescriptions.OutputImageDataDescription.get_output_channel_count","title":"get_output_channel_count","text":"<pre><code>get_output_channel_count()\n</code></pre> <p>Returns the number of output channels</p> Source code in <code>niceml/data/datadescriptions/outputdatadescriptions.py</code> <pre><code>def get_output_channel_count(self) -&gt; int:\n    \"\"\"Returns the number of output channels\"\"\"\n    return len(self.get_output_channel_names())\n</code></pre>"},{"location":"reference/data/datadescriptions/outputdatadescriptions/#niceml.data.datadescriptions.outputdatadescriptions.OutputImageDataDescription.get_output_channel_names","title":"get_output_channel_names  <code>abstractmethod</code>","text":"<pre><code>get_output_channel_names()\n</code></pre> <p>Returns a list of the output channel names</p> Source code in <code>niceml/data/datadescriptions/outputdatadescriptions.py</code> <pre><code>@abstractmethod\ndef get_output_channel_names(self) -&gt; List[str]:\n    \"\"\"Returns a list of the output channel names\"\"\"\n</code></pre>"},{"location":"reference/data/datadescriptions/outputdatadescriptions/#niceml.data.datadescriptions.outputdatadescriptions.OutputImageDataDescription.get_output_image_size","title":"get_output_image_size  <code>abstractmethod</code>","text":"<pre><code>get_output_image_size()\n</code></pre> <p>Returns the ImageSize of the input image(s)</p> Source code in <code>niceml/data/datadescriptions/outputdatadescriptions.py</code> <pre><code>@abstractmethod\ndef get_output_image_size(self) -&gt; ImageSize:\n    \"\"\"Returns the ImageSize of the input image(s)\"\"\"\n</code></pre>"},{"location":"reference/data/datadescriptions/outputdatadescriptions/#niceml.data.datadescriptions.outputdatadescriptions.OutputImageDataDescription.get_output_tensor_shape","title":"get_output_tensor_shape","text":"<pre><code>get_output_tensor_shape()\n</code></pre> <p>Returns the 3-dim shape of the input tensor [height, width, channel_count]</p> Source code in <code>niceml/data/datadescriptions/outputdatadescriptions.py</code> <pre><code>def get_output_tensor_shape(self) -&gt; Tuple[int, int, int]:\n    \"\"\"Returns the 3-dim shape of the input tensor [height, width, channel_count]\"\"\"\n    return self.get_output_image_size().to_numpy_shape() + (\n        self.get_output_channel_count(),\n    )\n</code></pre>"},{"location":"reference/data/datadescriptions/outputdatadescriptions/#niceml.data.datadescriptions.outputdatadescriptions.OutputImageDataDescription.get_use_void_class","title":"get_use_void_class  <code>abstractmethod</code>","text":"<pre><code>get_use_void_class()\n</code></pre> <p>Returns whether the model uses a default class (e.g. background)</p> Source code in <code>niceml/data/datadescriptions/outputdatadescriptions.py</code> <pre><code>@abstractmethod\ndef get_use_void_class(self) -&gt; bool:\n    \"\"\"Returns whether the model uses a default class (e.g. background)\"\"\"\n</code></pre>"},{"location":"reference/data/datadescriptions/outputdatadescriptions/#niceml.data.datadescriptions.outputdatadescriptions.OutputObjDetDataDescription","title":"OutputObjDetDataDescription","text":"<p>             Bases: <code>DataDescription</code>, <code>ABC</code></p> <p>Abstract baseclass for OutputObjDetDataDescription</p>"},{"location":"reference/data/datadescriptions/outputdatadescriptions/#niceml.data.datadescriptions.outputdatadescriptions.OutputObjDetDataDescription-functions","title":"Functions","text":""},{"location":"reference/data/datadescriptions/outputdatadescriptions/#niceml.data.datadescriptions.outputdatadescriptions.OutputObjDetDataDescription.get_anchor_aspect_ratios","title":"get_anchor_aspect_ratios  <code>abstractmethod</code>","text":"<pre><code>get_anchor_aspect_ratios()\n</code></pre> <p>Returns the aspect ratios for each feature map</p> Source code in <code>niceml/data/datadescriptions/outputdatadescriptions.py</code> <pre><code>@abstractmethod\ndef get_anchor_aspect_ratios(self) -&gt; List[float]:\n    \"\"\"Returns the aspect ratios for each feature map\"\"\"\n</code></pre>"},{"location":"reference/data/datadescriptions/outputdatadescriptions/#niceml.data.datadescriptions.outputdatadescriptions.OutputObjDetDataDescription.get_anchor_scales","title":"get_anchor_scales  <code>abstractmethod</code>","text":"<pre><code>get_anchor_scales()\n</code></pre> <p>Returns the scales for each feature map</p> Source code in <code>niceml/data/datadescriptions/outputdatadescriptions.py</code> <pre><code>@abstractmethod\ndef get_anchor_scales(self) -&gt; List[float]:\n    \"\"\"Returns the scales for each feature map\"\"\"\n</code></pre>"},{"location":"reference/data/datadescriptions/outputdatadescriptions/#niceml.data.datadescriptions.outputdatadescriptions.OutputObjDetDataDescription.get_anchorcount_featuremap_list","title":"get_anchorcount_featuremap_list","text":"<pre><code>get_anchorcount_featuremap_list()\n</code></pre> <p>Returns the anchorcount for the feature list</p> Source code in <code>niceml/data/datadescriptions/outputdatadescriptions.py</code> <pre><code>def get_anchorcount_featuremap_list(self) -&gt; List[int]:\n    \"\"\"Returns the anchorcount for the feature list\"\"\"\n    return [\n        self.get_anchorcount_for_scale(scale)\n        for scale in self.get_featuremap_scales()\n    ]\n</code></pre>"},{"location":"reference/data/datadescriptions/outputdatadescriptions/#niceml.data.datadescriptions.outputdatadescriptions.OutputObjDetDataDescription.get_anchorcount_for_scale","title":"get_anchorcount_for_scale  <code>abstractmethod</code>","text":"<pre><code>get_anchorcount_for_scale(scale)\n</code></pre> <p>Calculates the anchorcount for a specific scale</p> Source code in <code>niceml/data/datadescriptions/outputdatadescriptions.py</code> <pre><code>@abstractmethod\ndef get_anchorcount_for_scale(self, scale: int) -&gt; int:\n    \"\"\"Calculates the anchorcount for a specific scale\"\"\"\n</code></pre>"},{"location":"reference/data/datadescriptions/outputdatadescriptions/#niceml.data.datadescriptions.outputdatadescriptions.OutputObjDetDataDescription.get_anchorcount_per_feature","title":"get_anchorcount_per_feature  <code>abstractmethod</code>","text":"<pre><code>get_anchorcount_per_feature()\n</code></pre> <p>Returns the number of anchors which are generated per feature cell</p> Source code in <code>niceml/data/datadescriptions/outputdatadescriptions.py</code> <pre><code>@abstractmethod\ndef get_anchorcount_per_feature(self) -&gt; int:\n    \"\"\"Returns the number of anchors which are generated per feature cell\"\"\"\n</code></pre>"},{"location":"reference/data/datadescriptions/outputdatadescriptions/#niceml.data.datadescriptions.outputdatadescriptions.OutputObjDetDataDescription.get_anchorcount_per_image","title":"get_anchorcount_per_image","text":"<pre><code>get_anchorcount_per_image()\n</code></pre> <p>Sums up all generated anchors for all feature maps and returns it.</p> Source code in <code>niceml/data/datadescriptions/outputdatadescriptions.py</code> <pre><code>def get_anchorcount_per_image(self) -&gt; int:\n    \"\"\"Sums up all generated anchors for all feature maps and returns it.\"\"\"\n    return sum(self.get_anchorcount_featuremap_list())\n</code></pre>"},{"location":"reference/data/datadescriptions/outputdatadescriptions/#niceml.data.datadescriptions.outputdatadescriptions.OutputObjDetDataDescription.get_base_area_side","title":"get_base_area_side  <code>abstractmethod</code>","text":"<pre><code>get_base_area_side()\n</code></pre> <p>Returns one side of a square base, which is used to determine the anchor size</p> Source code in <code>niceml/data/datadescriptions/outputdatadescriptions.py</code> <pre><code>@abstractmethod\ndef get_base_area_side(self) -&gt; float:\n    \"\"\"Returns one side of a square base, which is used to determine the anchor size\"\"\"\n</code></pre>"},{"location":"reference/data/datadescriptions/outputdatadescriptions/#niceml.data.datadescriptions.outputdatadescriptions.OutputObjDetDataDescription.get_box_variance","title":"get_box_variance  <code>abstractmethod</code>","text":"<pre><code>get_box_variance()\n</code></pre> <p>Returns the box_variance list (length of 4)</p> Source code in <code>niceml/data/datadescriptions/outputdatadescriptions.py</code> <pre><code>@abstractmethod\ndef get_box_variance(self) -&gt; List[float]:\n    \"\"\"Returns the box_variance list (length of 4)\"\"\"\n</code></pre>"},{"location":"reference/data/datadescriptions/outputdatadescriptions/#niceml.data.datadescriptions.outputdatadescriptions.OutputObjDetDataDescription.get_coordinates_count","title":"get_coordinates_count  <code>abstractmethod</code>","text":"<pre><code>get_coordinates_count()\n</code></pre> <p>Returns the count of coordinates required to represent the object (e.g. bounding box: 4)</p> Source code in <code>niceml/data/datadescriptions/outputdatadescriptions.py</code> <pre><code>@abstractmethod\ndef get_coordinates_count(self) -&gt; int:\n    \"\"\"\n    Returns the count of coordinates required to represent\n    the object (e.g. bounding box: 4)\n    \"\"\"\n</code></pre>"},{"location":"reference/data/datadescriptions/outputdatadescriptions/#niceml.data.datadescriptions.outputdatadescriptions.OutputObjDetDataDescription.get_featuremap_count","title":"get_featuremap_count","text":"<pre><code>get_featuremap_count()\n</code></pre> <p>Returns the number of feature maps. Should be the length of the featuremap_scales.</p> Source code in <code>niceml/data/datadescriptions/outputdatadescriptions.py</code> <pre><code>def get_featuremap_count(self) -&gt; int:\n    \"\"\"Returns the number of feature maps. Should be the length of the featuremap_scales.\"\"\"\n    return len(self.get_featuremap_scales())\n</code></pre>"},{"location":"reference/data/datadescriptions/outputdatadescriptions/#niceml.data.datadescriptions.outputdatadescriptions.OutputObjDetDataDescription.get_featuremap_scales","title":"get_featuremap_scales  <code>abstractmethod</code>","text":"<pre><code>get_featuremap_scales()\n</code></pre> <p>Returns the scale per feature map as int. E.g. 2 means (1024,1024) -&gt; (512, 512) It is assumed that a feature map is always smaller than the original image.</p> Source code in <code>niceml/data/datadescriptions/outputdatadescriptions.py</code> <pre><code>@abstractmethod\ndef get_featuremap_scales(self) -&gt; List[int]:\n    \"\"\"\n    Returns the scale per feature map as int.\n    E.g. 2 means (1024,1024) -&gt; (512, 512)\n    It is assumed that a feature map is always smaller than\n    the original image.\n    \"\"\"\n</code></pre>"},{"location":"reference/data/datadescriptions/outputdatadescriptions/#niceml.data.datadescriptions.outputdatadescriptions.OutputObjDetDataDescription.get_output_class_count","title":"get_output_class_count","text":"<pre><code>get_output_class_count()\n</code></pre> <p>Returns the count of output classes used</p> Source code in <code>niceml/data/datadescriptions/outputdatadescriptions.py</code> <pre><code>def get_output_class_count(self) -&gt; int:\n    \"\"\"Returns the count of output classes used\"\"\"\n    return len(self.get_output_class_names())\n</code></pre>"},{"location":"reference/data/datadescriptions/outputdatadescriptions/#niceml.data.datadescriptions.outputdatadescriptions.OutputObjDetDataDescription.get_output_class_names","title":"get_output_class_names  <code>abstractmethod</code>","text":"<pre><code>get_output_class_names()\n</code></pre> <p>Returns the used output class names</p> Source code in <code>niceml/data/datadescriptions/outputdatadescriptions.py</code> <pre><code>@abstractmethod\ndef get_output_class_names(self) -&gt; List[str]:\n    \"\"\"Returns the used output class names\"\"\"\n</code></pre>"},{"location":"reference/data/datadescriptions/outputdatadescriptions/#niceml.data.datadescriptions.outputdatadescriptions.OutputVectorDataDescription","title":"OutputVectorDataDescription","text":"<p>             Bases: <code>DataDescription</code>, <code>ABC</code></p> <p>DataDescription used by models with vectors as output</p>"},{"location":"reference/data/datadescriptions/outputdatadescriptions/#niceml.data.datadescriptions.outputdatadescriptions.OutputVectorDataDescription-functions","title":"Functions","text":""},{"location":"reference/data/datadescriptions/outputdatadescriptions/#niceml.data.datadescriptions.outputdatadescriptions.OutputVectorDataDescription.get_index_for_name","title":"get_index_for_name","text":"<pre><code>get_index_for_name(name)\n</code></pre> <p>Returns the index of the given output entry name(s) as int or list of indices</p> Source code in <code>niceml/data/datadescriptions/outputdatadescriptions.py</code> <pre><code>def get_index_for_name(\n    self, name: Union[str, List[str]]\n) -&gt; Optional[Union[int, List[int]]]:\n    \"\"\"Returns the index of the given output entry name(s) as int or list of indices\"\"\"\n    if isinstance(name, str) and name in self.get_output_entry_names():\n        return self.get_output_entry_names().index(name)\n    if isinstance(name, list):\n        index_list = []\n        for cur_name in name:\n            cur_index = self.get_index_for_name(cur_name)\n            if cur_index is None:\n                continue\n            if isinstance(cur_index, list):\n                index_list += cur_index\n            else:\n                index_list.append(cur_index)\n        index_list = sorted(list(set(index_list)))\n        return None if len(index_list) == 0 else index_list\n    return None\n</code></pre>"},{"location":"reference/data/datadescriptions/outputdatadescriptions/#niceml.data.datadescriptions.outputdatadescriptions.OutputVectorDataDescription.get_name_for_index","title":"get_name_for_index","text":"<pre><code>get_name_for_index(index)\n</code></pre> <p>Returns a name or list of names for given class index or indices</p> Source code in <code>niceml/data/datadescriptions/outputdatadescriptions.py</code> <pre><code>def get_name_for_index(self, index: Union[int, List[int]]) -&gt; Union[str, List[str]]:\n    \"\"\"Returns a name or list of names for given class index or indices\"\"\"\n    output_names = self.get_output_entry_names()\n    if isinstance(index, list):\n        return [output_names[cur_idx] for cur_idx in index]\n    return output_names[index]\n</code></pre>"},{"location":"reference/data/datadescriptions/outputdatadescriptions/#niceml.data.datadescriptions.outputdatadescriptions.OutputVectorDataDescription.get_output_entry_names","title":"get_output_entry_names  <code>abstractmethod</code>","text":"<pre><code>get_output_entry_names()\n</code></pre> <p>Returns a name for each vector entry</p> Source code in <code>niceml/data/datadescriptions/outputdatadescriptions.py</code> <pre><code>@abstractmethod\ndef get_output_entry_names(self) -&gt; List[str]:\n    \"\"\"Returns a name for each vector entry\"\"\"\n</code></pre>"},{"location":"reference/data/datadescriptions/outputdatadescriptions/#niceml.data.datadescriptions.outputdatadescriptions.OutputVectorDataDescription.get_output_size","title":"get_output_size  <code>abstractmethod</code>","text":"<pre><code>get_output_size()\n</code></pre> <p>Returns the size of the output vector(s)</p> Source code in <code>niceml/data/datadescriptions/outputdatadescriptions.py</code> <pre><code>@abstractmethod\ndef get_output_size(self) -&gt; int:\n    \"\"\"Returns the size of the output vector(s)\"\"\"\n</code></pre>"},{"location":"reference/data/datadescriptions/regdatadescription/","title":"regdatadescription","text":""},{"location":"reference/data/datadescriptions/regdatadescription/#niceml.data.datadescriptions.regdatadescription","title":"regdatadescription","text":"<p>Module for RegDataDescription</p>"},{"location":"reference/data/datadescriptions/regdatadescription/#niceml.data.datadescriptions.regdatadescription-classes","title":"Classes","text":""},{"location":"reference/data/datadescriptions/regdatadescription/#niceml.data.datadescriptions.regdatadescription.FeatureType","title":"FeatureType","text":"<p>FeatureTypes are used for defining which kind of features are available.</p>"},{"location":"reference/data/datadescriptions/regdatadescription/#niceml.data.datadescriptions.regdatadescription.FeatureType-functions","title":"Functions","text":""},{"location":"reference/data/datadescriptions/regdatadescription/#niceml.data.datadescriptions.regdatadescription.FeatureType.get_available_features","title":"get_available_features  <code>classmethod</code>","text":"<pre><code>get_available_features()\n</code></pre> <p>Returns list of available feature types</p> Source code in <code>niceml/data/datadescriptions/regdatadescription.py</code> <pre><code>@classmethod\ndef get_available_features(cls) -&gt; List[str]:\n    \"\"\"Returns list of available feature types\"\"\"\n    return [cls.SCALAR, cls.CATEGORICAL, cls.BINARY]\n</code></pre>"},{"location":"reference/data/datadescriptions/regdatadescription/#niceml.data.datadescriptions.regdatadescription.RegDataDescription","title":"RegDataDescription  <code>dataclass</code>","text":"<p>             Bases: <code>InputVectorDataDescription</code>, <code>OutputVectorDataDescription</code></p> <p>DataDescription for Regression data. Uses vectors as input and output</p>"},{"location":"reference/data/datadescriptions/regdatadescription/#niceml.data.datadescriptions.regdatadescription.RegDataDescription-functions","title":"Functions","text":""},{"location":"reference/data/datadescriptions/regdatadescription/#niceml.data.datadescriptions.regdatadescription.RegDataDescription.get_dict","title":"get_dict","text":"<pre><code>get_dict()\n</code></pre> <p>Returns dictionary of inputs and targets</p> Source code in <code>niceml/data/datadescriptions/regdatadescription.py</code> <pre><code>def get_dict(self) -&gt; dict:\n    \"\"\"Returns dictionary of inputs and targets\"\"\"\n    return dict(inputs=self.inputs, targets=self.targets)\n</code></pre>"},{"location":"reference/data/datadescriptions/regdatadescription/#niceml.data.datadescriptions.regdatadescription.RegDataDescription.get_input_entry_names","title":"get_input_entry_names","text":"<pre><code>get_input_entry_names()\n</code></pre> <p>Returns names of input entries</p> Source code in <code>niceml/data/datadescriptions/regdatadescription.py</code> <pre><code>def get_input_entry_names(self) -&gt; List[str]:\n    \"\"\"Returns names of input entries\"\"\"\n    input_keys: List[str] = []\n    for cur_input in self.inputs:\n        if cur_input[\"type\"] in [FeatureType.SCALAR, FeatureType.BINARY]:\n            input_keys.append(cur_input[\"key\"])\n        elif cur_input[\"type\"] == FeatureType.CATEGORICAL:\n            input_keys += [\n                f\"{cur_input['key']}{x:03d}\"\n                for x in range(cur_input[\"value_count\"])\n            ]\n\n    return input_keys\n</code></pre>"},{"location":"reference/data/datadescriptions/regdatadescription/#niceml.data.datadescriptions.regdatadescription.RegDataDescription.get_input_size","title":"get_input_size","text":"<pre><code>get_input_size()\n</code></pre> <p>Returns size of input vector(s)</p> Source code in <code>niceml/data/datadescriptions/regdatadescription.py</code> <pre><code>def get_input_size(self) -&gt; int:\n    \"\"\"Returns size of input vector(s)\"\"\"\n    return get_feature_size(self.inputs)\n</code></pre>"},{"location":"reference/data/datadescriptions/regdatadescription/#niceml.data.datadescriptions.regdatadescription.RegDataDescription.get_min_max_vals","title":"get_min_max_vals","text":"<pre><code>get_min_max_vals()\n</code></pre> <p>Get min and max values for categorical and binary input values</p> Source code in <code>niceml/data/datadescriptions/regdatadescription.py</code> <pre><code>def get_min_max_vals(self) -&gt; Dict[str, Tuple[int, int]]:\n    \"\"\"Get min and max values for categorical and binary input values\"\"\"\n    min_max_dict: Dict[str, Tuple[int, int]] = {}\n    for input_vector in self.inputs:\n        if input_vector[\"type\"] == FeatureType.BINARY:\n            min_max_dict[input_vector[\"key\"]] = (0, 1)\n        elif input_vector[\"type\"] == FeatureType.CATEGORICAL:\n            min_max_dict[input_vector[\"key\"]] = (0, input_vector[\"value_count\"] - 1)\n\n    return min_max_dict\n</code></pre>"},{"location":"reference/data/datadescriptions/regdatadescription/#niceml.data.datadescriptions.regdatadescription.RegDataDescription.get_output_entry_names","title":"get_output_entry_names","text":"<pre><code>get_output_entry_names()\n</code></pre> <p>Returns names of targets</p> Source code in <code>niceml/data/datadescriptions/regdatadescription.py</code> <pre><code>def get_output_entry_names(self) -&gt; List[str]:\n    \"\"\"Returns names of targets\"\"\"\n    target_keys = []\n    for target in self.targets:\n        if target[\"type\"] != \"scalar\":\n            raise ValueError(\"Target feature type is not scalar\")\n        target_keys.append(target[\"key\"])\n    return target_keys\n</code></pre>"},{"location":"reference/data/datadescriptions/regdatadescription/#niceml.data.datadescriptions.regdatadescription.RegDataDescription.get_output_size","title":"get_output_size","text":"<pre><code>get_output_size()\n</code></pre> <p>Returns size of output vector(s) (targets)</p> Source code in <code>niceml/data/datadescriptions/regdatadescription.py</code> <pre><code>def get_output_size(self) -&gt; int:\n    \"\"\"Returns size of output vector(s) (targets)\"\"\"\n    return get_feature_size(self.targets)\n</code></pre>"},{"location":"reference/data/datadescriptions/regdatadescription/#niceml.data.datadescriptions.regdatadescription-functions","title":"Functions","text":""},{"location":"reference/data/datadescriptions/regdatadescription/#niceml.data.datadescriptions.regdatadescription.get_feature_size","title":"get_feature_size","text":"<pre><code>get_feature_size(features)\n</code></pre> <p>Returns size of features in 'features' dictionary</p> Source code in <code>niceml/data/datadescriptions/regdatadescription.py</code> <pre><code>def get_feature_size(features: List[dict]) -&gt; int:\n    \"\"\"Returns size of features in 'features' dictionary\"\"\"\n    count = 0\n    for feature in features:\n        feature_type = feature[\"type\"]\n        if feature_type not in FeatureType.get_available_features():\n            raise ModeNotImplementedError(\n                f\"Feature type {feature['type']} not implemented\"\n            )\n        count += (\n            1\n            if feature_type in [FeatureType.BINARY, FeatureType.SCALAR]\n            else feature[\"value_count\"]\n        )\n    return count\n</code></pre>"},{"location":"reference/data/datadescriptions/regdatadescription/#niceml.data.datadescriptions.regdatadescription.inputs_prefix_factory","title":"inputs_prefix_factory","text":"<pre><code>inputs_prefix_factory(\n    data_location,\n    prefix,\n    feature_type,\n    data_file_name=\"train.parq\",\n)\n</code></pre> <p>The inputs_prefix_factory function is a factory function that returns a list of input features as dictionaries.</p> <p>Parameters:</p> <ul> <li> <code>data_location</code>             (<code>Union[dict, LocationConfig]</code>)         \u2013          <p>Specify the location of the data</p> </li> <li> <code>prefix</code>             (<code>str</code>)         \u2013          <p>Filter the columns in the dataframe</p> </li> <li> <code>feature_type</code>             (<code>str</code>)         \u2013          <p>Specify the type of feature</p> </li> <li> <code>data_file_name</code>             (<code>str</code>, default:                 <code>'train.parq'</code> )         \u2013          <p>Specify the name of the file to be read from data_location</p> </li> </ul> <p>Returns:     A list of input features as dictionaries</p> Source code in <code>niceml/data/datadescriptions/regdatadescription.py</code> <pre><code>def inputs_prefix_factory(\n    data_location: Union[dict, LocationConfig],\n    prefix: str,\n    feature_type: str,\n    data_file_name: str = \"train.parq\",\n) -&gt; List[dict]:\n    \"\"\"\n    The inputs_prefix_factory function is a factory function that returns a list of\n    input features as dictionaries.\n\n    Args:\n        data_location: Specify the location of the data\n        prefix: Filter the columns in the dataframe\n        feature_type: Specify the type of feature\n        data_file_name: Specify the name of the file to be read from data_location\n    Returns:\n        A list of input features as dictionaries\n    \"\"\"\n    with open_location(data_location) as (\n        data_fs,\n        data_root,\n    ):\n        try:\n            loaded_data = read_parquet(\n                filepath=join_fs_path(data_fs, data_root, data_file_name),\n                file_system=data_fs,\n            )\n            return [\n                {\"key\": column, \"type\": feature_type}\n                for column in loaded_data.columns\n                if column.startswith(prefix)\n            ]\n        except FileNotFoundError:\n            logger = logging.getLogger(__name__)\n            logger.warning(\"Data file not found. Inputs will be empty.\")\n        return []\n</code></pre>"},{"location":"reference/data/datadescriptions/regdatadescription/#niceml.data.datadescriptions.regdatadescription.load_data_infos","title":"load_data_infos","text":"<pre><code>load_data_infos(yaml_path)\n</code></pre> <p>Loads and returns RegDataDescription from yaml-path</p> Source code in <code>niceml/data/datadescriptions/regdatadescription.py</code> <pre><code>def load_data_infos(yaml_path: str) -&gt; RegDataDescription:  # QUEST: still used?\n    \"\"\"Loads and returns RegDataDescription from yaml-path\"\"\"\n    with open(yaml_path, \"r\") as file:\n        data = yaml.load(file, Loader=yaml.SafeLoader)\n    return RegDataDescription(**data)\n</code></pre>"},{"location":"reference/data/datadescriptions/regdatadescription/#niceml.data.datadescriptions.regdatadescription.reg_data_description_factory","title":"reg_data_description_factory","text":"<pre><code>reg_data_description_factory(\n    train_data_location,\n    train_set_file_name,\n    filter_function,\n    **kwargs\n)\n</code></pre> <p>The reg_data_description_factory function is a factory function that returns a RegDataDescription object.The RegDataDescription object contains the inputs and targets of the regression data set. The reg_data_description_factory function takes in arguments for:     - train_data_location: The location of the training data set     - train_set_file name: The name of the training data set file     - filter function: A filtering function to apply to each row in order to                         extract input and target features from it</p> <p>Parameters:</p> <ul> <li> <code>train_data_location</code>             (<code>Union[dict, LocationConfig]</code>)         \u2013          <p>The location of the training data set</p> </li> <li> <code>train_set_file_name</code>             (<code>str</code>)         \u2013          <p>The name of the training data set file</p> </li> <li> <code>filter_function</code>             (<code>FunctionType</code>)         \u2013          <p>A filtering function to apply to each row in order to             extract input and target features from it</p> </li> <li> <code>**kwargs</code>         \u2013          <p>Pass in additional arguments to the filter_functions</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>RegDataDescription</code>         \u2013          <p>A RagDataDescription with inputs and targets created by the filter_function</p> </li> </ul> Source code in <code>niceml/data/datadescriptions/regdatadescription.py</code> <pre><code>def reg_data_description_factory(\n    train_data_location: Union[dict, LocationConfig],\n    train_set_file_name: str,\n    filter_function: FunctionType,\n    **kwargs,\n) -&gt; RegDataDescription:\n    \"\"\"\n    The reg_data_description_factory function is a factory function that returns a\n    RegDataDescription object.The RegDataDescription object contains the inputs and targets\n    of the regression data set.\n    The reg_data_description_factory function takes in arguments for:\n        - train_data_location: The location of the training data set\n        - train_set_file name: The name of the training data set file\n        - filter function: A filtering function to apply to each row in order to\n                            extract input and target features from it\n\n    Args:\n        train_data_location: The location of the training data set\n        train_set_file_name: The name of the training data set file\n        filter_function: A filtering function to apply to each row in order to\n                        extract input and target features from it\n        **kwargs: Pass in additional arguments to the filter_functions\n\n    Returns:\n        A RagDataDescription with inputs and targets created by the filter_function\n    \"\"\"\n    with open_location(train_data_location) as (\n        regression_data_fs,\n        regression_data_root,\n    ):\n        train_data = read_parquet(\n            filepath=join_fs_path(\n                regression_data_fs, regression_data_root, train_set_file_name\n            ),\n            file_system=regression_data_fs,\n        )\n\n        inputs: List[Dict[str, str]]\n        targets: List[Dict[str, str]]\n\n        inputs, targets = filter_function(data=train_data, **kwargs)\n\n        return RegDataDescription(inputs=inputs, targets=targets)\n</code></pre>"},{"location":"reference/data/datadescriptions/semsegdatadescritption/","title":"semsegdatadescritption","text":""},{"location":"reference/data/datadescriptions/semsegdatadescritption/#niceml.data.datadescriptions.semsegdatadescritption","title":"semsegdatadescritption","text":"<p>Module for SemSegClassInfo and SemSegDataDescription</p>"},{"location":"reference/data/datadescriptions/semsegdatadescritption/#niceml.data.datadescriptions.semsegdatadescritption-classes","title":"Classes","text":""},{"location":"reference/data/datadescriptions/semsegdatadescritption/#niceml.data.datadescriptions.semsegdatadescritption.SemSegClassInfo","title":"SemSegClassInfo  <code>dataclass</code>","text":"<p>Class for (target or output) class information (name and color of mask image)</p> <p>Parameters:</p> <ul> <li> <code>color</code>             (<code>List[int]</code>)         \u2013          <p>Color as list of three uint8 values (rgb) or -1 as any value. e.g. [-1, 255, -1] will look for 255 in the g-channel and ignore r- and b-channel.</p> </li> <li> <code>name</code>             (<code>str</code>)         \u2013          <p>Name of the class</p> </li> </ul>"},{"location":"reference/data/datadescriptions/semsegdatadescritption/#niceml.data.datadescriptions.semsegdatadescritption.SemSegDataDescription","title":"SemSegDataDescription  <code>dataclass</code>","text":"<p>             Bases: <code>InputImageDataDescription</code>, <code>OutputImageDataDescription</code></p> <p>DataDescription for SemSeg data</p> <p>Parameters:</p> <ul> <li> <code>classes</code>             (<code>List[SemSegClassInfo]</code>)         \u2013          <p>List[SemSegClassInfo]  Each entry is an initialized SemSegClassInfo, for which the name (str) and  color (List[int]) must be present.  The index in output array (third axis) is defined by the order of the classes list.  Usually the color has to be a list of length 3 with uint8 values. The only exception  is the usage of -1 as any value. e.g. [-1, 255, -1] will look for 255 in the g-channel  and ignore r- and b-channel.</p> </li> </ul>"},{"location":"reference/data/datadescriptions/semsegdatadescritption/#niceml.data.datadescriptions.semsegdatadescritption.SemSegDataDescription-functions","title":"Functions","text":""},{"location":"reference/data/datadescriptions/semsegdatadescritption/#niceml.data.datadescriptions.semsegdatadescritption.SemSegDataDescription.get_class_idx_lut","title":"get_class_idx_lut","text":"<pre><code>get_class_idx_lut()\n</code></pre> <p>Returns the class index lut to transform the mask image</p> Source code in <code>niceml/data/datadescriptions/semsegdatadescritption.py</code> <pre><code>def get_class_idx_lut(self) -&gt; np.ndarray:\n    \"\"\"Returns the class index lut to transform the mask image\"\"\"  # QUEST: what is lut?\n    return np.array([cls.color for cls in self.classes], dtype=int)\n</code></pre>"},{"location":"reference/data/datadescriptions/semsegdatadescritption/#niceml.data.datadescriptions.semsegdatadescritption.SemSegDataDescription.get_class_name_from_idx","title":"get_class_name_from_idx","text":"<pre><code>get_class_name_from_idx(idx)\n</code></pre> <p>Returns the class name of the class at position <code>idx</code> in <code>self.classes</code></p> Source code in <code>niceml/data/datadescriptions/semsegdatadescritption.py</code> <pre><code>def get_class_name_from_idx(self, idx: int) -&gt; str:\n    \"\"\"Returns the class name of the class at position `idx` in `self.classes`\"\"\"\n    return self.get_output_channel_names()[idx]\n</code></pre>"},{"location":"reference/data/datadescriptions/semsegdatadescritption/#niceml.data.datadescriptions.semsegdatadescritption.SemSegDataDescription.get_input_channel_count","title":"get_input_channel_count","text":"<pre><code>get_input_channel_count()\n</code></pre> <p>Returns the number of input channels</p> Source code in <code>niceml/data/datadescriptions/semsegdatadescritption.py</code> <pre><code>def get_input_channel_count(self) -&gt; int:\n    \"\"\"Returns the number of input channels\"\"\"\n    return self.channel_count\n</code></pre>"},{"location":"reference/data/datadescriptions/semsegdatadescritption/#niceml.data.datadescriptions.semsegdatadescritption.SemSegDataDescription.get_input_image_size","title":"get_input_image_size","text":"<pre><code>get_input_image_size()\n</code></pre> <p>Returns the input size of the image(s)</p> Source code in <code>niceml/data/datadescriptions/semsegdatadescritption.py</code> <pre><code>def get_input_image_size(self) -&gt; ImageSize:\n    \"\"\"Returns the input size of the image(s)\"\"\"\n    return self.input_image_size\n</code></pre>"},{"location":"reference/data/datadescriptions/semsegdatadescritption/#niceml.data.datadescriptions.semsegdatadescritption.SemSegDataDescription.get_output_channel_names","title":"get_output_channel_names","text":"<pre><code>get_output_channel_names()\n</code></pre> <p>Returns the names of the output channels</p> Source code in <code>niceml/data/datadescriptions/semsegdatadescritption.py</code> <pre><code>def get_output_channel_names(self) -&gt; List[str]:\n    \"\"\"Returns the names of the output channels\"\"\"\n    return [x.name for x in self.classes]\n</code></pre>"},{"location":"reference/data/datadescriptions/semsegdatadescritption/#niceml.data.datadescriptions.semsegdatadescritption.SemSegDataDescription.get_output_image_size","title":"get_output_image_size","text":"<pre><code>get_output_image_size()\n</code></pre> <p>Returns the output size of the image(s)</p> Source code in <code>niceml/data/datadescriptions/semsegdatadescritption.py</code> <pre><code>def get_output_image_size(self) -&gt; ImageSize:\n    \"\"\"Returns the output size of the image(s)\"\"\"\n    return self.output_image_size\n</code></pre>"},{"location":"reference/data/datadescriptions/semsegdatadescritption/#niceml.data.datadescriptions.semsegdatadescritption.SemSegDataDescription.get_use_void_class","title":"get_use_void_class","text":"<pre><code>get_use_void_class()\n</code></pre> <p>returns bool to use background_class</p> Source code in <code>niceml/data/datadescriptions/semsegdatadescritption.py</code> <pre><code>def get_use_void_class(self) -&gt; bool:\n    \"\"\"returns bool to use background_class\"\"\"\n    return self.use_background_class\n</code></pre>"},{"location":"reference/data/datadescriptions/semsegdatadescritption/#niceml.data.datadescriptions.semsegdatadescritption-functions","title":"Functions","text":""},{"location":"reference/data/datadescriptions/semsegdatadescritption/#niceml.data.datadescriptions.semsegdatadescritption.create_number_semseg_datadescription","title":"create_number_semseg_datadescription","text":"<pre><code>create_number_semseg_datadescription(max_number)\n</code></pre> <p>Creates a list of SemSegClassInfo for the number dataset</p> Source code in <code>niceml/data/datadescriptions/semsegdatadescritption.py</code> <pre><code>def create_number_semseg_datadescription(\n    max_number: int,\n) -&gt; List[SemSegClassInfo]:  # QUEST: still used?\n    \"\"\"Creates a list of SemSegClassInfo for the number dataset\"\"\"  # QUEST: better docstring\n    return [SemSegClassInfo([idx], f\"{idx}\") for idx in range(max_number)]\n</code></pre>"},{"location":"reference/data/datafilters/__init__/","title":"datafilters","text":""},{"location":"reference/data/datafilters/__init__/#niceml.data.datafilters","title":"datafilters","text":""},{"location":"reference/data/datafilters/dataframefilter/","title":"dataframefilter","text":""},{"location":"reference/data/datafilters/dataframefilter/#niceml.data.datafilters.dataframefilter","title":"dataframefilter","text":"<p>Module for abstract dataframe filter</p>"},{"location":"reference/data/datafilters/dataframefilter/#niceml.data.datafilters.dataframefilter-classes","title":"Classes","text":""},{"location":"reference/data/datafilters/dataframefilter/#niceml.data.datafilters.dataframefilter.DataframeFilter","title":"DataframeFilter","text":"<pre><code>DataframeFilter()\n</code></pre> <p>             Bases: <code>ABC</code></p> <p>Filter to filter data of a dataframe</p> <p>Filter to filter data of a dataframe</p> Source code in <code>niceml/data/datafilters/dataframefilter.py</code> <pre><code>def __init__(self):\n    \"\"\"Filter to filter data of a dataframe\"\"\"\n\n    self.data_description = None\n</code></pre>"},{"location":"reference/data/datafilters/dataframefilter/#niceml.data.datafilters.dataframefilter.DataframeFilter-functions","title":"Functions","text":""},{"location":"reference/data/datafilters/dataframefilter/#niceml.data.datafilters.dataframefilter.DataframeFilter.filter","title":"filter  <code>abstractmethod</code>","text":"<pre><code>filter(data)\n</code></pre> <p>The filter function takes a dataframe and returns a filtered version of the dataframe. The filter function should return the filtered data.</p> <p>Parameters:</p> <ul> <li> <code>data</code>             (<code>DataFrame</code>)         \u2013          <p>pd.DataFrame: Pass the data to be filtered</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>         \u2013          <p>A dataframe with the same columns as data, but only containing rows where the</p> </li> <li> <code>DataFrame</code>         \u2013          <p>filter condition is true</p> </li> </ul> Source code in <code>niceml/data/datafilters/dataframefilter.py</code> <pre><code>@abstractmethod\ndef filter(\n    self,\n    data: pd.DataFrame,\n) -&gt; pd.DataFrame:\n    \"\"\"\n    The filter function takes a dataframe and returns a filtered version of the\n    dataframe. The filter function should return the\n    filtered data.\n\n    Args:\n        data: pd.DataFrame: Pass the data to be filtered\n\n    Returns:\n        A dataframe with the same columns as data, but only containing rows where the\n        filter condition is true\n\n    \"\"\"\n</code></pre>"},{"location":"reference/data/datafilters/dataframefilter/#niceml.data.datafilters.dataframefilter.DataframeFilter.initialize","title":"initialize","text":"<pre><code>initialize(data_description)\n</code></pre> <p>The initialize function is called once at the beginning of a run. It can be used to set up any data structures that are needed for the rest of the run. The initialize function takes one argument, which is a data description containing information about what data will be available during this run.</p> <p>Parameters:</p> <ul> <li> <code>data_description</code>             (<code>DataDescription</code>)         \u2013          <p>DataDescription: Describe the data that is being passed into the model</p> </li> </ul> Source code in <code>niceml/data/datafilters/dataframefilter.py</code> <pre><code>def initialize(self, data_description: DataDescription):\n    \"\"\"\n    The initialize function is called once at the beginning of a run.\n    It can be used to set up any data structures that are needed for the rest of the run.\n    The initialize function takes one argument, which is a data description containing\n    information about what data will be available during this run.\n\n    Args:\n        data_description: DataDescription: Describe the data that is being passed into the model\n    \"\"\"\n\n    self.data_description = data_description\n</code></pre>"},{"location":"reference/data/datafilters/nandataframefilter/","title":"nandataframefilter","text":""},{"location":"reference/data/datafilters/nandataframefilter/#niceml.data.datafilters.nandataframefilter","title":"nandataframefilter","text":"<p>Add module for NanDataframeFilter</p>"},{"location":"reference/data/datafilters/nandataframefilter/#niceml.data.datafilters.nandataframefilter-classes","title":"Classes","text":""},{"location":"reference/data/datafilters/nandataframefilter/#niceml.data.datafilters.nandataframefilter.NanDataframeFilter","title":"NanDataframeFilter","text":"<pre><code>NanDataframeFilter()\n</code></pre> <p>             Bases: <code>DataframeFilter</code></p> <p>DataframeFilter that removes nan values from feature columns</p> <p>Filter to filter data of a dataframe</p> Source code in <code>niceml/data/datafilters/dataframefilter.py</code> <pre><code>def __init__(self):\n    \"\"\"Filter to filter data of a dataframe\"\"\"\n\n    self.data_description = None\n</code></pre>"},{"location":"reference/data/datafilters/nandataframefilter/#niceml.data.datafilters.nandataframefilter.NanDataframeFilter-functions","title":"Functions","text":""},{"location":"reference/data/datafilters/nandataframefilter/#niceml.data.datafilters.nandataframefilter.NanDataframeFilter.filter","title":"filter","text":"<pre><code>filter(data)\n</code></pre> <p>The filter function is used to remove rows from the data that have NaN values in any of the columns that are specified as inputs or targets of the <code>self.data_description</code>. This is done by dropping all rows where there are NaN values in any of these columns.</p> <p>Parameters:</p> <ul> <li> <code>data</code>             (<code>DataFrame</code>)         \u2013          <p>pd.DataFrame: Pass the data into the function</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>         \u2013          <p>A dataframe with the rows that have at least one nan value in the columns</p> </li> <li> <code>DataFrame</code>         \u2013          <p>specified by filter_columns removed</p> </li> </ul> Source code in <code>niceml/data/datafilters/nandataframefilter.py</code> <pre><code>def filter(self, data: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"\n    The filter function is used to remove rows from the data that have NaN values\n    in any of the columns that are specified as inputs or targets of the\n    `self.data_description`. This is done by dropping all rows where there are NaN\n    values in any of these columns.\n\n    Args:\n        data: pd.DataFrame: Pass the data into the function\n\n    Returns:\n        A dataframe with the rows that have at least one nan value in the columns\n        specified by filter_columns removed\n\n    \"\"\"\n    self.data_description: RegDataDescription = check_instance(\n        self.data_description, RegDataDescription\n    )\n    filter_columns: List[str] = []\n\n    for column in self.data_description.inputs + self.data_description.targets:\n        filter_columns.append(column[\"key\"])\n\n    return data.dropna(axis=0, subset=filter_columns)\n</code></pre>"},{"location":"reference/data/datafilters/nandataframefilter/#niceml.data.datafilters.nandataframefilter-functions","title":"Functions","text":""},{"location":"reference/data/datainfolistings/__init__/","title":"datainfolistings","text":""},{"location":"reference/data/datainfolistings/__init__/#niceml.data.datainfolistings","title":"datainfolistings","text":""},{"location":"reference/data/datainfolistings/clsdatainfolisting/","title":"clsdatainfolisting","text":""},{"location":"reference/data/datainfolistings/clsdatainfolisting/#niceml.data.datainfolistings.clsdatainfolisting","title":"clsdatainfolisting","text":"<p>Module for ClsDataInfoListing</p>"},{"location":"reference/data/datainfolistings/clsdatainfolisting/#niceml.data.datainfolistings.clsdatainfolisting-classes","title":"Classes","text":""},{"location":"reference/data/datainfolistings/clsdatainfolisting/#niceml.data.datainfolistings.clsdatainfolisting.DirClsDataInfoListing","title":"DirClsDataInfoListing","text":"<pre><code>DirClsDataInfoListing(\n    location,\n    sub_dir,\n    class_extractor=None,\n    image_suffixes=None,\n)\n</code></pre> <p>             Bases: <code>DataInfoListing</code></p> <p>Lists all images in one folder and takes the class from the filename</p> <p>Init method of DirClsDataInfoListing</p> Source code in <code>niceml/data/datainfolistings/clsdatainfolisting.py</code> <pre><code>def __init__(\n    self,\n    location: Union[dict, LocationConfig],\n    sub_dir: str,\n    class_extractor: Optional[Callable] = None,\n    image_suffixes: Optional[List[str]] = None,\n):\n    \"\"\"Init method of DirClsDataInfoListing\"\"\"\n    self.sub_dir = sub_dir\n    self.location = location\n    self.class_extractor = class_extractor or _default_class_extractor\n    self.image_suffixes = image_suffixes or [\".png\", \".jpg\", \".jpeg\"]\n</code></pre>"},{"location":"reference/data/datainfolistings/clsdatainfolisting/#niceml.data.datainfolistings.clsdatainfolisting.DirClsDataInfoListing-functions","title":"Functions","text":""},{"location":"reference/data/datainfolistings/clsdatainfolisting/#niceml.data.datainfolistings.clsdatainfolisting.DirClsDataInfoListing.list","title":"list","text":"<pre><code>list(data_description)\n</code></pre> <p>Lists all data infos</p> Source code in <code>niceml/data/datainfolistings/clsdatainfolisting.py</code> <pre><code>def list(self, data_description: DataDescription) -&gt; List[ClsDataInfo]:\n    \"\"\"Lists all data infos\"\"\"\n    output_data_description: OutputVectorDataDescription = check_instance(\n        data_description, OutputVectorDataDescription\n    )\n    if len(self.sub_dir) &gt; 0:\n        location = join_location_w_path(self.location, self.sub_dir)\n    else:\n        location = self.location\n    with open_location(location) as (data_fs, data_path):\n        all_files = list_dir(data_path, return_full_path=False, file_system=data_fs)\n    image_files = [\n        file for file in all_files if splitext(file)[1] in self.image_suffixes\n    ]\n    data_info_list: List[ClsDataInfo] = []\n    for cur_image in image_files:\n        cur_class = self.class_extractor(cur_image)\n        cls_index = output_data_description.get_index_for_name(cur_class)\n        if cls_index is not None:\n            cur_class = output_data_description.get_name_for_index(cls_index)\n            identifier = basename(cur_image)\n            image_location = join_location_w_path(location, cur_image)\n            cur_data_info = ClsDataInfo(\n                identifier=identifier,\n                image_location=image_location,\n                class_idx=cls_index,\n                class_name=cur_class,\n            )\n            data_info_list.append(cur_data_info)\n\n    return data_info_list\n</code></pre>"},{"location":"reference/data/datainfolistings/clsdatainfolisting/#niceml.data.datainfolistings.clsdatainfolisting.LabelClsDataInfoListing","title":"LabelClsDataInfoListing","text":"<pre><code>LabelClsDataInfoListing(\n    data_location,\n    sub_dir,\n    label_suffix=\".json\",\n    image_suffixes=None,\n)\n</code></pre> <p>             Bases: <code>DataInfoListing</code></p> <p>Lists all consistent clsdata in one folder and returns a list of data infos</p> <p>Init method of LabelClsDataInfoListing</p> Source code in <code>niceml/data/datainfolistings/clsdatainfolisting.py</code> <pre><code>def __init__(\n    self,\n    data_location: Union[dict, LocationConfig],\n    sub_dir: str,\n    label_suffix: str = \".json\",\n    image_suffixes: Optional[List[str]] = None,\n):\n    \"\"\"Init method of LabelClsDataInfoListing\"\"\"\n    self.sub_dir = sub_dir\n    self.data_location = data_location\n    self.label_suffix = label_suffix\n    self.image_suffixes = image_suffixes or [\".png\", \".jpg\", \".jpeg\"]\n</code></pre>"},{"location":"reference/data/datainfolistings/clsdatainfolisting/#niceml.data.datainfolistings.clsdatainfolisting.LabelClsDataInfoListing-functions","title":"Functions","text":""},{"location":"reference/data/datainfolistings/clsdatainfolisting/#niceml.data.datainfolistings.clsdatainfolisting.LabelClsDataInfoListing.list","title":"list","text":"<pre><code>list(data_description)\n</code></pre> <p>Lists all data infos</p> Source code in <code>niceml/data/datainfolistings/clsdatainfolisting.py</code> <pre><code>def list(self, data_description: DataDescription) -&gt; List[ClsDataInfo]:\n    \"\"\"Lists all data infos\"\"\"\n    output_data_description: OutputVectorDataDescription = check_instance(\n        data_description, OutputVectorDataDescription\n    )\n    if len(self.sub_dir) &gt; 0:\n        location = join_location_w_path(self.data_location, self.sub_dir)\n    else:\n        location = self.data_location\n    class_names = output_data_description.get_output_entry_names()\n    class_count = len(class_names)\n    data_info_list = list_data(\n        class_count=class_count,\n        class_names=class_names,\n        location=location,\n        label_suffix=self.label_suffix,\n        image_suffixes=self.image_suffixes,\n        use_empty_images=False,\n    )\n\n    new_data_info_list = []\n    cur_data_info: ObjDetDataInfo\n    for cur_data_info in data_info_list:\n        cur_cls_names = list({x.class_name for x in cur_data_info.labels})\n        cur_class_indexes = output_data_description.get_index_for_name(\n            cur_cls_names\n        )\n        new_data_info = ClsDataInfo(\n            identifier=cur_data_info.get_identifier(),\n            image_location=cur_data_info.image_location,\n            class_name=cur_cls_names,\n            class_idx=cur_class_indexes,\n        )\n        new_data_info_list.append(new_data_info)\n\n    return new_data_info_list\n</code></pre>"},{"location":"reference/data/datainfolistings/clsdatainfolisting/#niceml.data.datainfolistings.clsdatainfolisting-functions","title":"Functions","text":""},{"location":"reference/data/datainfolistings/datainfolisting/","title":"datainfolisting","text":""},{"location":"reference/data/datainfolistings/datainfolisting/#niceml.data.datainfolistings.datainfolisting","title":"datainfolisting","text":"<p>Module for datainfolisting</p>"},{"location":"reference/data/datainfolistings/datainfolisting/#niceml.data.datainfolistings.datainfolisting-classes","title":"Classes","text":""},{"location":"reference/data/datainfolistings/datainfolisting/#niceml.data.datainfolistings.datainfolisting.DataInfoListing","title":"DataInfoListing","text":"<p>             Bases: <code>ABC</code></p> <p>Abstract class for a data info listing which is used in the GenericDataSet</p>"},{"location":"reference/data/datainfolistings/datainfolisting/#niceml.data.datainfolistings.datainfolisting.DataInfoListing-functions","title":"Functions","text":""},{"location":"reference/data/datainfolistings/datainfolisting/#niceml.data.datainfolistings.datainfolisting.DataInfoListing.list","title":"list  <code>abstractmethod</code>","text":"<pre><code>list(data_description)\n</code></pre> <p>List all data infos for the given data description</p> Source code in <code>niceml/data/datainfolistings/datainfolisting.py</code> <pre><code>@abstractmethod\ndef list(self, data_description: DataDescription) -&gt; List[DataInfo]:\n    \"\"\"List all data infos for the given data description\"\"\"\n</code></pre>"},{"location":"reference/data/datainfolistings/objdetdatainfolisting/","title":"objdetdatainfolisting","text":""},{"location":"reference/data/datainfolistings/objdetdatainfolisting/#niceml.data.datainfolistings.objdetdatainfolisting","title":"objdetdatainfolisting","text":"<p>Module for ObjDetDataInfoListing</p>"},{"location":"reference/data/datainfolistings/objdetdatainfolisting/#niceml.data.datainfolistings.objdetdatainfolisting-classes","title":"Classes","text":""},{"location":"reference/data/datainfolistings/objdetdatainfolisting/#niceml.data.datainfolistings.objdetdatainfolisting.ObjDetDataInfoListing","title":"ObjDetDataInfoListing","text":"<pre><code>ObjDetDataInfoListing(\n    location,\n    sub_dir,\n    label_suffix=\".json\",\n    image_suffixes=None,\n    use_empty_images=True,\n)\n</code></pre> <p>             Bases: <code>DataInfoListing</code></p> <p>Lists all consistent objdetdata in one folder and returns datainfolist</p> Source code in <code>niceml/data/datainfolistings/objdetdatainfolisting.py</code> <pre><code>def __init__(\n    self,\n    location: Union[dict, LocationConfig],\n    sub_dir: str,\n    label_suffix: str = \".json\",\n    image_suffixes: Optional[List[str]] = None,\n    use_empty_images: bool = True,\n):\n    self.sub_dir = sub_dir\n    self.location = location\n    self.label_suffix = label_suffix\n    self.image_suffixes = image_suffixes or [\".png\", \".jpg\", \".jpeg\"]\n    self.use_empty_image = use_empty_images\n</code></pre>"},{"location":"reference/data/datainfolistings/objdetdatainfolisting/#niceml.data.datainfolistings.objdetdatainfolisting-functions","title":"Functions","text":""},{"location":"reference/data/datainfolistings/objdetdatainfolisting/#niceml.data.datainfolistings.objdetdatainfolisting.list_data","title":"list_data","text":"<pre><code>list_data(\n    class_count,\n    class_names,\n    location,\n    label_suffix,\n    image_suffixes,\n    use_empty_images,\n)\n</code></pre> <p>Lists all consistent objdetdata in one folder and returns datainfolist</p> Source code in <code>niceml/data/datainfolistings/objdetdatainfolisting.py</code> <pre><code>def list_data(\n    class_count: int,\n    class_names: List[str],\n    location: Union[dict, LocationConfig],\n    label_suffix: str,\n    image_suffixes: List[str],\n    use_empty_images: bool,\n) -&gt; List[ObjDetDataInfo]:\n    \"\"\"Lists all consistent objdetdata in one folder and returns datainfolist\"\"\"\n    with open_location(location) as (data_fs, data_path):\n        all_files = list_dir(data_path, file_system=data_fs)\n        label_file_set = set(\n            splitext(x)[0] for x in all_files if splitext(x)[1] == label_suffix\n        )\n        image_files = [\n            file\n            for file in all_files\n            if splitext(file)[1] in image_suffixes\n            and splitext(file)[0] in label_file_set\n        ]\n        data_info_list: List[ObjDetDataInfo] = []\n        for cur_img_file in image_files:\n            data = read_json(\n                join(data_path, splitext(cur_img_file)[0]) + label_suffix,\n                file_system=data_fs,\n            )\n            image_label: ObjDetImageLabel = ObjDetImageLabel(**data)\n            # pylint: disable=use-dict-literal\n            labels = [\n                ObjDetInstanceLabel(\n                    **{\n                        **asdict(lbl),\n                        **dict(class_index=class_names.index(lbl.class_name)),\n                    }\n                )\n                for lbl in image_label.labels\n                if lbl.class_name in class_names\n            ]\n            if use_empty_images or len(labels) &gt; 0:\n                cur_data_info = ObjDetDataInfo(\n                    image_location=join_location_w_path(location, cur_img_file),\n                    class_count_in_dataset=class_count,\n                    labels=labels,\n                )\n                data_info_list.append(cur_data_info)\n    return data_info_list\n</code></pre>"},{"location":"reference/data/datainfolistings/semsegdatainfolisting/","title":"semsegdatainfolisting","text":""},{"location":"reference/data/datainfolistings/semsegdatainfolisting/#niceml.data.datainfolistings.semsegdatainfolisting","title":"semsegdatainfolisting","text":"<p>Module for SemSegDataInfoListing</p>"},{"location":"reference/data/datainfolistings/semsegdatainfolisting/#niceml.data.datainfolistings.semsegdatainfolisting-classes","title":"Classes","text":""},{"location":"reference/data/datainfolistings/semsegdatainfolisting/#niceml.data.datainfolistings.semsegdatainfolisting.SemSegDataInfoListing","title":"SemSegDataInfoListing","text":"<pre><code>SemSegDataInfoListing(\n    location,\n    sub_dir,\n    mask_suffix=\"_mask\",\n    img_suffixes=None,\n)\n</code></pre> <p>             Bases: <code>DataInfoListing</code></p> <p>Lists all image files which have a corresponding mask suffix</p> Source code in <code>niceml/data/datainfolistings/semsegdatainfolisting.py</code> <pre><code>def __init__(\n    self,\n    location: Union[dict, LocationConfig],\n    sub_dir: str,\n    mask_suffix: str = \"_mask\",\n    img_suffixes: Optional[List[str]] = None,\n):\n    self.mask_suffix = mask_suffix\n    self.img_suffixes = img_suffixes or [\".png\", \".jpg\", \".jpeg\"]\n    self.sub_dir = sub_dir\n    self.location = location\n</code></pre>"},{"location":"reference/data/datainfolistings/semsegdatainfolisting/#niceml.data.datainfolistings.semsegdatainfolisting-functions","title":"Functions","text":""},{"location":"reference/data/datainfos/__init__/","title":"datainfos","text":""},{"location":"reference/data/datainfos/__init__/#niceml.data.datainfos","title":"datainfos","text":""},{"location":"reference/data/datainfos/clsdatainfo/","title":"clsdatainfo","text":""},{"location":"reference/data/datainfos/clsdatainfo/#niceml.data.datainfos.clsdatainfo","title":"clsdatainfo","text":"<p>Module for ClsDataInfo</p>"},{"location":"reference/data/datainfos/clsdatainfo/#niceml.data.datainfos.clsdatainfo-classes","title":"Classes","text":""},{"location":"reference/data/datainfos/clsdatainfo/#niceml.data.datainfos.clsdatainfo.ClsData","title":"ClsData  <code>dataclass</code>","text":"<p>Contains all data for classification</p>"},{"location":"reference/data/datainfos/clsdatainfo/#niceml.data.datainfos.clsdatainfo.ClsData-functions","title":"Functions","text":""},{"location":"reference/data/datainfos/clsdatainfo/#niceml.data.datainfos.clsdatainfo.ClsData.get_identifier","title":"get_identifier","text":"<pre><code>get_identifier()\n</code></pre> <p>Return the identifier</p> Source code in <code>niceml/data/datainfos/clsdatainfo.py</code> <pre><code>def get_identifier(self) -&gt; str:\n    \"\"\"Return the identifier\"\"\"\n    return self.identifier\n</code></pre>"},{"location":"reference/data/datainfos/clsdatainfo/#niceml.data.datainfos.clsdatainfo.ClsData.get_index_list","title":"get_index_list","text":"<pre><code>get_index_list()\n</code></pre> <p>Return a list of class indexes</p> Source code in <code>niceml/data/datainfos/clsdatainfo.py</code> <pre><code>def get_index_list(self) -&gt; List[int]:\n    \"\"\"Return a list of class indexes\"\"\"\n    return [self.class_idx] if isinstance(self.class_idx, int) else self.class_idx\n</code></pre>"},{"location":"reference/data/datainfos/clsdatainfo/#niceml.data.datainfos.clsdatainfo.ClsData.get_index_of_name","title":"get_index_of_name","text":"<pre><code>get_index_of_name(name)\n</code></pre> <p>Return the index of the class with the given name</p> Source code in <code>niceml/data/datainfos/clsdatainfo.py</code> <pre><code>def get_index_of_name(self, name: str) -&gt; int:\n    \"\"\"Return the index of the class with the given name\"\"\"\n    return self.get_name_list().index(name)\n</code></pre>"},{"location":"reference/data/datainfos/clsdatainfo/#niceml.data.datainfos.clsdatainfo.ClsData.get_name_list","title":"get_name_list","text":"<pre><code>get_name_list()\n</code></pre> <p>Return a list of class names</p> Source code in <code>niceml/data/datainfos/clsdatainfo.py</code> <pre><code>def get_name_list(self) -&gt; List[str]:\n    \"\"\"Return a list of class names\"\"\"\n    return (\n        [self.class_name] if isinstance(self.class_name, str) else self.class_name\n    )\n</code></pre>"},{"location":"reference/data/datainfos/clsdatainfo/#niceml.data.datainfos.clsdatainfo.ClsDataInfo","title":"ClsDataInfo  <code>dataclass</code>","text":"<p>             Bases: <code>ImageDataInfo</code></p> <p>Contains all information about one data point for classification</p>"},{"location":"reference/data/datainfos/clsdatainfo/#niceml.data.datainfos.clsdatainfo.ClsDataInfo-functions","title":"Functions","text":""},{"location":"reference/data/datainfos/clsdatainfo/#niceml.data.datainfos.clsdatainfo.ClsDataInfo.get_image_filepath","title":"get_image_filepath","text":"<pre><code>get_image_filepath()\n</code></pre> <p>Return the image filepath</p> Source code in <code>niceml/data/datainfos/clsdatainfo.py</code> <pre><code>def get_image_filepath(self) -&gt; str:\n    \"\"\"Return the image filepath\"\"\"\n    return get_location_uri(self.image_location)\n</code></pre>"},{"location":"reference/data/datainfos/clsdatainfo/#niceml.data.datainfos.clsdatainfo.ClsDataInfo.get_image_location","title":"get_image_location","text":"<pre><code>get_image_location()\n</code></pre> <p>Return the image filepath</p> Source code in <code>niceml/data/datainfos/clsdatainfo.py</code> <pre><code>def get_image_location(self) -&gt; Union[dict, LocationConfig]:\n    \"\"\"Return the image filepath\"\"\"\n    return self.image_location\n</code></pre>"},{"location":"reference/data/datainfos/clsdatainfo/#niceml.data.datainfos.clsdatainfo.ClsDataInfo.get_index_list","title":"get_index_list","text":"<pre><code>get_index_list()\n</code></pre> <p>Return a list of class indexes</p> Source code in <code>niceml/data/datainfos/clsdatainfo.py</code> <pre><code>def get_index_list(self) -&gt; List[int]:\n    \"\"\"Return a list of class indexes\"\"\"\n    return [self.class_idx] if isinstance(self.class_idx, int) else self.class_idx\n</code></pre>"},{"location":"reference/data/datainfos/clsdatainfo/#niceml.data.datainfos.clsdatainfo.ClsDataInfo.get_index_of_name","title":"get_index_of_name","text":"<pre><code>get_index_of_name(name)\n</code></pre> <p>Return the index of the class with the given name</p> Source code in <code>niceml/data/datainfos/clsdatainfo.py</code> <pre><code>def get_index_of_name(self, name: str) -&gt; int:\n    \"\"\"Return the index of the class with the given name\"\"\"\n    return self.get_name_list().index(name)\n</code></pre>"},{"location":"reference/data/datainfos/clsdatainfo/#niceml.data.datainfos.clsdatainfo.ClsDataInfo.get_name_list","title":"get_name_list","text":"<pre><code>get_name_list()\n</code></pre> <p>Return a list of class names</p> Source code in <code>niceml/data/datainfos/clsdatainfo.py</code> <pre><code>def get_name_list(self) -&gt; List[str]:\n    \"\"\"Return a list of class names\"\"\"\n    return (\n        [self.class_name] if isinstance(self.class_name, str) else self.class_name\n    )\n</code></pre>"},{"location":"reference/data/datainfos/clsdatainfo/#niceml.data.datainfos.clsdatainfo-functions","title":"Functions","text":""},{"location":"reference/data/datainfos/datainfo/","title":"datainfo","text":""},{"location":"reference/data/datainfos/datainfo/#niceml.data.datainfos.datainfo","title":"datainfo","text":"<p>module for datainfo class</p>"},{"location":"reference/data/datainfos/datainfo/#niceml.data.datainfos.datainfo-classes","title":"Classes","text":""},{"location":"reference/data/datainfos/datainfo/#niceml.data.datainfos.datainfo.DataInfo","title":"DataInfo  <code>dataclass</code>","text":"<p>             Bases: <code>ABC</code></p> <p>Abstract class for a data info which is used in the GenericDataSet</p>"},{"location":"reference/data/datainfos/datainfo/#niceml.data.datainfos.datainfo.DataInfo-functions","title":"Functions","text":""},{"location":"reference/data/datainfos/datainfo/#niceml.data.datainfos.datainfo.DataInfo.get_identifier","title":"get_identifier  <code>abstractmethod</code>","text":"<pre><code>get_identifier()\n</code></pre> <p>Returns the unique identifier for the data info</p> Source code in <code>niceml/data/datainfos/datainfo.py</code> <pre><code>@abstractmethod\ndef get_identifier(self) -&gt; str:\n    \"\"\"Returns the unique identifier for the data info\"\"\"\n</code></pre>"},{"location":"reference/data/datainfos/datainfo/#niceml.data.datainfos.datainfo.DataInfo.get_info_dict","title":"get_info_dict  <code>abstractmethod</code>","text":"<pre><code>get_info_dict()\n</code></pre> <p>Returns a dict with all information of the data info</p> Source code in <code>niceml/data/datainfos/datainfo.py</code> <pre><code>@abstractmethod\ndef get_info_dict(self) -&gt; dict:\n    \"\"\"Returns a dict with all information of the data info\"\"\"\n</code></pre>"},{"location":"reference/data/datainfos/imagedatainfo/","title":"imagedatainfo","text":""},{"location":"reference/data/datainfos/imagedatainfo/#niceml.data.datainfos.imagedatainfo","title":"imagedatainfo","text":"<p>Module of the ImageDataInfo</p>"},{"location":"reference/data/datainfos/imagedatainfo/#niceml.data.datainfos.imagedatainfo-classes","title":"Classes","text":""},{"location":"reference/data/datainfos/imagedatainfo/#niceml.data.datainfos.imagedatainfo.ImageDataInfo","title":"ImageDataInfo  <code>dataclass</code>","text":"<p>             Bases: <code>DataInfo</code>, <code>ABC</code></p> <p>Contains all information for image data</p>"},{"location":"reference/data/datainfos/imagedatainfo/#niceml.data.datainfos.imagedatainfo.ImageDataInfo-functions","title":"Functions","text":""},{"location":"reference/data/datainfos/imagedatainfo/#niceml.data.datainfos.imagedatainfo.ImageDataInfo.get_filename","title":"get_filename","text":"<pre><code>get_filename()\n</code></pre> <p>Split the image_location from <code>self.image_location</code></p> <p>Returns:</p> <ul> <li> <code>str</code>         \u2013          <p>Only the image_location as a str</p> </li> </ul> Source code in <code>niceml/data/datainfos/imagedatainfo.py</code> <pre><code>def get_filename(self) -&gt; str:\n    \"\"\"\n    Split the image_location from `self.image_location`\n\n    Returns:\n        Only the image_location as a str\n    \"\"\"\n    return basename(self.get_identifier())\n</code></pre>"},{"location":"reference/data/datainfos/imagedatainfo/#niceml.data.datainfos.imagedatainfo.ImageDataInfo.get_image_location","title":"get_image_location","text":"<pre><code>get_image_location()\n</code></pre> <p>Return the image filepath</p> Source code in <code>niceml/data/datainfos/imagedatainfo.py</code> <pre><code>def get_image_location(self) -&gt; str:\n    \"\"\"Return the image filepath\"\"\"\n    return self.image_location\n</code></pre>"},{"location":"reference/data/datainfos/objdetdatainfo/","title":"objdetdatainfo","text":""},{"location":"reference/data/datainfos/objdetdatainfo/#niceml.data.datainfos.objdetdatainfo","title":"objdetdatainfo","text":"<p>Module for ObjDetDataInfo</p>"},{"location":"reference/data/datainfos/objdetdatainfo/#niceml.data.datainfos.objdetdatainfo-classes","title":"Classes","text":""},{"location":"reference/data/datainfos/objdetdatainfo/#niceml.data.datainfos.objdetdatainfo.ObjDetData","title":"ObjDetData  <code>dataclass</code>","text":"<p>Dataclass containing object detection data</p>"},{"location":"reference/data/datainfos/objdetdatainfo/#niceml.data.datainfos.objdetdatainfo.ObjDetDataInfo","title":"ObjDetDataInfo  <code>dataclass</code>","text":"<p>             Bases: <code>ImageDataInfo</code></p> <p>Contains all information for object detection</p>"},{"location":"reference/data/datainfos/semsegdatainfo/","title":"semsegdatainfo","text":""},{"location":"reference/data/datainfos/semsegdatainfo/#niceml.data.datainfos.semsegdatainfo","title":"semsegdatainfo","text":"<p>Module for SemsegDataINfo and SemsegData</p>"},{"location":"reference/data/datainfos/semsegdatainfo/#niceml.data.datainfos.semsegdatainfo-classes","title":"Classes","text":""},{"location":"reference/data/datainfos/semsegdatainfo/#niceml.data.datainfos.semsegdatainfo.SemSegData","title":"SemSegData  <code>dataclass</code>","text":"<p>Stores content Data about SemSeg</p>"},{"location":"reference/data/datainfos/semsegdatainfo/#niceml.data.datainfos.semsegdatainfo.SemSegDataInfo","title":"SemSegDataInfo  <code>dataclass</code>","text":"<p>             Bases: <code>ImageDataInfo</code></p> <p>Stores information data about SemSeg</p>"},{"location":"reference/data/dataiterators/__init__/","title":"dataiterators","text":""},{"location":"reference/data/dataiterators/__init__/#niceml.data.dataiterators","title":"dataiterators","text":""},{"location":"reference/data/dataiterators/boundingboxdataiterator/","title":"boundingboxdataiterator","text":""},{"location":"reference/data/dataiterators/boundingboxdataiterator/#niceml.data.dataiterators.boundingboxdataiterator","title":"boundingboxdataiterator","text":"<p>Module containing BoundingBoxIterator</p>"},{"location":"reference/data/dataiterators/boundingboxdataiterator/#niceml.data.dataiterators.boundingboxdataiterator-classes","title":"Classes","text":""},{"location":"reference/data/dataiterators/boundingboxdataiterator/#niceml.data.dataiterators.boundingboxdataiterator.BoundingBoxIterator","title":"BoundingBoxIterator","text":"<pre><code>BoundingBoxIterator(parq_extension='.parq')\n</code></pre> <p>             Bases: <code>TensordataIterator</code></p> <p>Iterator for iterating over prediction data</p> Source code in <code>niceml/data/dataiterators/boundingboxdataiterator.py</code> <pre><code>def __init__(self, parq_extension: str = \".parq\"):\n    self.parq_extension = parq_extension\n    self.target_cols_prefix = \"pred\"\n    self.data = None\n    self.keys = None\n</code></pre>"},{"location":"reference/data/dataiterators/boundingboxdataiterator/#niceml.data.dataiterators.boundingboxdataiterator.ObjDetPredictionContainer","title":"ObjDetPredictionContainer  <code>dataclass</code>","text":"<p>Container class for iterating over prediction data</p>"},{"location":"reference/data/dataiterators/boundingboxdataiterator/#niceml.data.dataiterators.boundingboxdataiterator-functions","title":"Functions","text":""},{"location":"reference/data/dataiterators/dataiterator/","title":"dataiterator","text":""},{"location":"reference/data/dataiterators/dataiterator/#niceml.data.dataiterators.dataiterator","title":"dataiterator","text":""},{"location":"reference/data/dataloaders/__init__/","title":"dataloaders","text":""},{"location":"reference/data/dataloaders/__init__/#niceml.data.dataloaders","title":"dataloaders","text":""},{"location":"reference/data/dataloaders/cachedimageloader/","title":"cachedimageloader","text":""},{"location":"reference/data/dataloaders/cachedimageloader/#niceml.data.dataloaders.cachedimageloader","title":"cachedimageloader","text":"<p>Module for RemoteCachedImageLoader</p>"},{"location":"reference/data/dataloaders/cachedimageloader/#niceml.data.dataloaders.cachedimageloader-classes","title":"Classes","text":""},{"location":"reference/data/dataloaders/cachedimageloader/#niceml.data.dataloaders.cachedimageloader.RemoteDiskCacheImageLoader","title":"RemoteDiskCacheImageLoader","text":"<pre><code>RemoteDiskCacheImageLoader(\n    storage,\n    cache_dir=\"./image_cache\",\n    working_dir=None,\n    output_dtype=np.uint8,\n)\n</code></pre> <p>             Bases: <code>ImageLoader</code></p> <p>Loads and caches remote images on the disk</p> Source code in <code>niceml/data/dataloaders/cachedimageloader.py</code> <pre><code>def __init__(\n    self,\n    storage: StorageInterface,\n    cache_dir: str = \"./image_cache\",\n    working_dir: Optional[str] = None,\n    output_dtype=np.uint8,\n):\n    self.storage = storage\n    self.working_dir = working_dir\n    self.cache_dir = cache_dir\n    self.output_dtype = output_dtype\n</code></pre>"},{"location":"reference/data/dataloaders/cachedimageloader/#niceml.data.dataloaders.cachedimageloader.RemoteDiskCacheImageLoaderFactory","title":"RemoteDiskCacheImageLoaderFactory","text":"<pre><code>RemoteDiskCacheImageLoaderFactory(\n    cache_dir=\"./image_cache\",\n)\n</code></pre> <p>             Bases: <code>ImageLoaderFactory</code></p> <p>Creates RemoteDiskCacheImageLoader</p> Source code in <code>niceml/data/dataloaders/cachedimageloader.py</code> <pre><code>def __init__(self, cache_dir: str = \"./image_cache\"):\n    self.cache_dir = cache_dir\n</code></pre>"},{"location":"reference/data/dataloaders/cachedimageloader/#niceml.data.dataloaders.cachedimageloader.RemoteDiskCacheImageLoaderFactory-functions","title":"Functions","text":""},{"location":"reference/data/dataloaders/cachedimageloader/#niceml.data.dataloaders.cachedimageloader.RemoteDiskCacheImageLoaderFactory.create_image_loader","title":"create_image_loader","text":"<pre><code>create_image_loader(storage, working_dir)\n</code></pre> <p>Creates RemoteDiskCacheImageLoader</p> Source code in <code>niceml/data/dataloaders/cachedimageloader.py</code> <pre><code>def create_image_loader(\n    self, storage: StorageInterface, working_dir: str\n) -&gt; ImageLoader:\n    \"\"\"Creates RemoteDiskCacheImageLoader\"\"\"\n    return RemoteDiskCacheImageLoader(storage, self.cache_dir)\n</code></pre>"},{"location":"reference/data/dataloaders/clsdataloader/","title":"clsdataloader","text":""},{"location":"reference/data/dataloaders/clsdataloader/#niceml.data.dataloaders.clsdataloader","title":"clsdataloader","text":"<p>Module for ClsDataLoader</p>"},{"location":"reference/data/dataloaders/clsdataloader/#niceml.data.dataloaders.clsdataloader-classes","title":"Classes","text":""},{"location":"reference/data/dataloaders/clsdataloader/#niceml.data.dataloaders.clsdataloader.ClsDataLoader","title":"ClsDataLoader","text":"<pre><code>ClsDataLoader()\n</code></pre> <p>             Bases: <code>DataLoader</code></p> <p>DataLoader for image classification data</p> Source code in <code>niceml/data/dataloaders/dataloader.py</code> <pre><code>def __init__(self):\n    self.data_description = None\n</code></pre>"},{"location":"reference/data/dataloaders/clsdataloader/#niceml.data.dataloaders.clsdataloader.ClsDataLoader-functions","title":"Functions","text":""},{"location":"reference/data/dataloaders/clsdataloader/#niceml.data.dataloaders.clsdataloader.ClsDataLoader.load_data","title":"load_data","text":"<pre><code>load_data(data_info)\n</code></pre> <p>Loads and returns image classification data from 'data_info'</p> Source code in <code>niceml/data/dataloaders/clsdataloader.py</code> <pre><code>def load_data(self, data_info: ClsDataInfo) -&gt; ClsData:\n    \"\"\"Loads and returns image classification data from 'data_info'\"\"\"\n    input_data_description: InputImageDataDescription = check_instance(\n        self.data_description, InputImageDataDescription\n    )\n    image = load_img_uint8(\n        data_info.image_location,\n        target_image_size=input_data_description.get_input_image_size(),\n    )\n    return ClsData(\n        identifier=data_info.get_identifier(),\n        image=image,\n        class_name=data_info.get_name_list(),\n        class_idx=data_info.get_index_list(),\n    )\n</code></pre>"},{"location":"reference/data/dataloaders/clsdataloader/#niceml.data.dataloaders.clsdataloader-functions","title":"Functions","text":""},{"location":"reference/data/dataloaders/dataloader/","title":"dataloader","text":""},{"location":"reference/data/dataloaders/dataloader/#niceml.data.dataloaders.dataloader","title":"dataloader","text":"<p>Module for abstract DataLoader</p>"},{"location":"reference/data/dataloaders/dataloader/#niceml.data.dataloaders.dataloader-classes","title":"Classes","text":""},{"location":"reference/data/dataloaders/dataloader/#niceml.data.dataloaders.dataloader.DataLoader","title":"DataLoader","text":"<pre><code>DataLoader()\n</code></pre> <p>             Bases: <code>ABC</code></p> <p>Abstract implementation of a data loader which is used by the GenericDataset</p> Source code in <code>niceml/data/dataloaders/dataloader.py</code> <pre><code>def __init__(self):\n    self.data_description = None\n</code></pre>"},{"location":"reference/data/dataloaders/dataloader/#niceml.data.dataloaders.dataloader.DataLoader-functions","title":"Functions","text":""},{"location":"reference/data/dataloaders/dataloader/#niceml.data.dataloaders.dataloader.DataLoader.initialize","title":"initialize","text":"<pre><code>initialize(data_description)\n</code></pre> <p>Initializes the DataLoader with a DataDescription</p> Source code in <code>niceml/data/dataloaders/dataloader.py</code> <pre><code>def initialize(self, data_description: DataDescription):\n    \"\"\"Initializes the DataLoader with a DataDescription\"\"\"\n    self.data_description: DataDescription = data_description\n</code></pre>"},{"location":"reference/data/dataloaders/dataloader/#niceml.data.dataloaders.dataloader.DataLoader.load_data","title":"load_data  <code>abstractmethod</code>","text":"<pre><code>load_data(data_info)\n</code></pre> <p>Loads the data from a DataInfo object and puts it in a container class</p> Source code in <code>niceml/data/dataloaders/dataloader.py</code> <pre><code>@abstractmethod\ndef load_data(self, data_info: DataInfo) -&gt; Any:\n    \"\"\"Loads the data from a DataInfo object and puts it in a container class\"\"\"\n</code></pre>"},{"location":"reference/data/dataloaders/dfloaders/","title":"dfloaders","text":""},{"location":"reference/data/dataloaders/dfloaders/#niceml.data.dataloaders.dfloaders","title":"dfloaders","text":"<p>Module for dataframe loaders</p>"},{"location":"reference/data/dataloaders/dfloaders/#niceml.data.dataloaders.dfloaders-classes","title":"Classes","text":""},{"location":"reference/data/dataloaders/dfloaders/#niceml.data.dataloaders.dfloaders.RemoteDiskCachedDfLoader","title":"RemoteDiskCachedDfLoader","text":"<pre><code>RemoteDiskCachedDfLoader(\n    storage, cache_dir, working_dir=None\n)\n</code></pre> <p>             Bases: <code>DfLoader</code></p> <p>SimpleLoader for parquet files from cache or remote storage</p> <p>Initialize a SimpleLoader for parquet files from cache or remote storage</p> Source code in <code>niceml/data/dataloaders/dfloaders.py</code> <pre><code>def __init__(\n    self,\n    storage: StorageInterface,\n    cache_dir: str,\n    working_dir: Optional[str] = None,\n):\n    \"\"\"Initialize a SimpleLoader for parquet files from cache or remote storage\"\"\"\n    self.storage = storage\n    self.cache_path = cache_dir\n    self.working_dir = working_dir\n</code></pre>"},{"location":"reference/data/dataloaders/dfloaders/#niceml.data.dataloaders.dfloaders.RemoteDiskCachedDfLoader-functions","title":"Functions","text":""},{"location":"reference/data/dataloaders/dfloaders/#niceml.data.dataloaders.dfloaders.RemoteDiskCachedDfLoader.load_df","title":"load_df","text":"<pre><code>load_df(df_path)\n</code></pre> <p>Loads and returns dataframe from cache</p> Source code in <code>niceml/data/dataloaders/dfloaders.py</code> <pre><code>def load_df(self, df_path: str) -&gt; pd.DataFrame:\n    \"\"\"Loads and returns dataframe from cache\"\"\"\n    target_path = (\n        self.storage.join_paths(self.working_dir, df_path)\n        if self.working_dir\n        else df_path\n    )\n    cached_filepath = join(self.cache_path, target_path)\n    if isfile(cached_filepath):\n        dataframe = read_parquet(cached_filepath)\n    else:\n        dataframe = LoadParquetFile().load_data(target_path, self.storage)\n        write_parquet(dataframe, cached_filepath)\n    return dataframe\n</code></pre>"},{"location":"reference/data/dataloaders/dfloaders/#niceml.data.dataloaders.dfloaders.RemoteDiskCachedDfLoaderFactory","title":"RemoteDiskCachedDfLoaderFactory","text":"<pre><code>RemoteDiskCachedDfLoaderFactory(cache_dir)\n</code></pre> <p>             Bases: <code>DfLoaderFactory</code></p> <p>Factory of RemoteDiskCachedDfLoader</p> <p>Initialize a Factory for RemoteDiskCachedDfLoader</p> Source code in <code>niceml/data/dataloaders/dfloaders.py</code> <pre><code>def __init__(self, cache_dir: str):\n    \"\"\"Initialize a Factory for RemoteDiskCachedDfLoader\"\"\"\n\n    self.cache_path = cache_dir\n</code></pre>"},{"location":"reference/data/dataloaders/dfloaders/#niceml.data.dataloaders.dfloaders.RemoteDiskCachedDfLoaderFactory-functions","title":"Functions","text":""},{"location":"reference/data/dataloaders/dfloaders/#niceml.data.dataloaders.dfloaders.RemoteDiskCachedDfLoaderFactory.create_df_loader","title":"create_df_loader","text":"<pre><code>create_df_loader(storage, working_dir)\n</code></pre> <p>Returns RemoteDiskCachedDfLoader</p> Source code in <code>niceml/data/dataloaders/dfloaders.py</code> <pre><code>def create_df_loader(self, storage: StorageInterface, working_dir: str) -&gt; DfLoader:\n    \"\"\"Returns RemoteDiskCachedDfLoader\"\"\"\n    return RemoteDiskCachedDfLoader(storage, self.cache_path, working_dir)\n</code></pre>"},{"location":"reference/data/dataloaders/dfloaders/#niceml.data.dataloaders.dfloaders.SimpleDfLoader","title":"SimpleDfLoader","text":"<pre><code>SimpleDfLoader(storage=None, working_dir=None)\n</code></pre> <p>             Bases: <code>DfLoader</code></p> <p>SimpleLoader for parquet files</p> <p>SimpleLoader for parquet files</p> Source code in <code>niceml/data/dataloaders/dfloaders.py</code> <pre><code>def __init__(\n    self,\n    storage: Optional[StorageInterface] = None,\n    working_dir: Optional[str] = None,\n):\n    \"\"\"SimpleLoader for parquet files\"\"\"\n\n    self.storage = storage or LocalStorage()\n    self.working_dir = working_dir\n</code></pre>"},{"location":"reference/data/dataloaders/dfloaders/#niceml.data.dataloaders.dfloaders.SimpleDfLoader-functions","title":"Functions","text":""},{"location":"reference/data/dataloaders/dfloaders/#niceml.data.dataloaders.dfloaders.SimpleDfLoader.load_df","title":"load_df","text":"<pre><code>load_df(df_path)\n</code></pre> <p>Loads and returns a dataframe from a given parquet file path</p> Source code in <code>niceml/data/dataloaders/dfloaders.py</code> <pre><code>def load_df(self, df_path: str) -&gt; pd.DataFrame:\n    \"\"\"Loads and returns a dataframe from a given parquet file path\"\"\"\n    target_path = join(self.working_dir, df_path) if self.working_dir else df_path\n    return LoadParquetFile().load_data(target_path, self.storage)\n</code></pre>"},{"location":"reference/data/dataloaders/dfloaders/#niceml.data.dataloaders.dfloaders.SimpleDfLoaderFactory","title":"SimpleDfLoaderFactory","text":"<p>             Bases: <code>DfLoaderFactory</code></p> <p>SimpleLoader for parquet files</p>"},{"location":"reference/data/dataloaders/dfloaders/#niceml.data.dataloaders.dfloaders.SimpleDfLoaderFactory-functions","title":"Functions","text":""},{"location":"reference/data/dataloaders/dfloaders/#niceml.data.dataloaders.dfloaders.SimpleDfLoaderFactory.create_df_loader","title":"create_df_loader","text":"<pre><code>create_df_loader(storage, working_dir)\n</code></pre> <p>Returns SimpleDfLoader</p> Source code in <code>niceml/data/dataloaders/dfloaders.py</code> <pre><code>def create_df_loader(self, storage: StorageInterface, working_dir: str) -&gt; DfLoader:\n    \"\"\"Returns SimpleDfLoader\"\"\"\n    return SimpleDfLoader(storage, working_dir)\n</code></pre>"},{"location":"reference/data/dataloaders/dfloaders/#niceml.data.dataloaders.dfloaders-functions","title":"Functions","text":""},{"location":"reference/data/dataloaders/imageloaders/","title":"imageloaders","text":""},{"location":"reference/data/dataloaders/imageloaders/#niceml.data.dataloaders.imageloaders","title":"imageloaders","text":"<p>Module for SimpleImageLoader</p>"},{"location":"reference/data/dataloaders/imageloaders/#niceml.data.dataloaders.imageloaders-classes","title":"Classes","text":""},{"location":"reference/data/dataloaders/imageloaders/#niceml.data.dataloaders.imageloaders.SimpleImageLoader","title":"SimpleImageLoader","text":"<pre><code>SimpleImageLoader(\n    storage=None, working_dir=None, output_dtype=np.uint8\n)\n</code></pre> <p>             Bases: <code>ImageLoader</code></p> <p>Simple image loader that loads an image</p> Source code in <code>niceml/data/dataloaders/imageloaders.py</code> <pre><code>def __init__(\n    self,\n    storage: Optional[StorageInterface] = None,\n    working_dir: Optional[str] = None,\n    output_dtype=np.uint8,\n):\n    self.storage = storage or LocalStorage()\n    self.output_dtype = output_dtype\n    self.working_dir = working_dir\n</code></pre>"},{"location":"reference/data/dataloaders/imageloaders/#niceml.data.dataloaders.imageloaders.SimpleImageLoaderFactory","title":"SimpleImageLoaderFactory","text":"<p>             Bases: <code>ImageLoaderFactory</code></p> <p>SimpleImageLoaderFactory for image files</p>"},{"location":"reference/data/dataloaders/imageloaders/#niceml.data.dataloaders.imageloaders.SimpleImageLoaderFactory-functions","title":"Functions","text":""},{"location":"reference/data/dataloaders/imageloaders/#niceml.data.dataloaders.imageloaders.SimpleImageLoaderFactory.create_image_loader","title":"create_image_loader","text":"<pre><code>create_image_loader(storage, working_dir)\n</code></pre> <p>Creates an instance of ImageLoader</p> Source code in <code>niceml/data/dataloaders/imageloaders.py</code> <pre><code>def create_image_loader(\n    self, storage: StorageInterface, working_dir: str\n) -&gt; ImageLoader:\n    \"\"\"Creates an instance of ImageLoader\"\"\"\n    return SimpleImageLoader(storage, working_dir)\n</code></pre>"},{"location":"reference/data/dataloaders/objdetdataloader/","title":"objdetdataloader","text":""},{"location":"reference/data/dataloaders/objdetdataloader/#niceml.data.dataloaders.objdetdataloader","title":"objdetdataloader","text":"<p>Module for ObjDetDataLoader</p>"},{"location":"reference/data/dataloaders/objdetdataloader/#niceml.data.dataloaders.objdetdataloader-classes","title":"Classes","text":""},{"location":"reference/data/dataloaders/objdetdataloader/#niceml.data.dataloaders.objdetdataloader.ObjDetDataLoader","title":"ObjDetDataLoader","text":"<pre><code>ObjDetDataLoader()\n</code></pre> <p>             Bases: <code>DataLoader</code></p> <p>DataLoader for ObjDetDataLoader</p> Source code in <code>niceml/data/dataloaders/dataloader.py</code> <pre><code>def __init__(self):\n    self.data_description = None\n</code></pre>"},{"location":"reference/data/dataloaders/objdetdataloader/#niceml.data.dataloaders.objdetdataloader.ObjDetDataLoader-functions","title":"Functions","text":""},{"location":"reference/data/dataloaders/objdetdataloader/#niceml.data.dataloaders.objdetdataloader.ObjDetDataLoader.load_data","title":"load_data","text":"<pre><code>load_data(data_info)\n</code></pre> <p>Loads and returns object detection data (ObjDetData)</p> Source code in <code>niceml/data/dataloaders/objdetdataloader.py</code> <pre><code>def load_data(self, data_info: ObjDetDataInfo) -&gt; ObjDetData:\n    \"\"\"Loads and returns object detection data (ObjDetData)\"\"\"\n    input_data_description: InputImageDataDescription = check_instance(\n        self.data_description, InputImageDataDescription\n    )\n    with open_location(data_info.image_location) as (image_fs, image_path):\n        image = load_img_uint8(\n            image_path,\n            file_system=image_fs,\n            target_image_size=input_data_description.get_input_image_size(),\n        )\n\n    return ObjDetData(image=image, labels=data_info.labels)\n</code></pre>"},{"location":"reference/data/dataloaders/objdetdataloader/#niceml.data.dataloaders.objdetdataloader-functions","title":"Functions","text":""},{"location":"reference/data/dataloaders/factories/__init__/","title":"factories","text":""},{"location":"reference/data/dataloaders/factories/__init__/#niceml.data.dataloaders.factories","title":"factories","text":""},{"location":"reference/data/dataloaders/factories/dfloaderfactory/","title":"dfloaderfactory","text":""},{"location":"reference/data/dataloaders/factories/dfloaderfactory/#niceml.data.dataloaders.factories.dfloaderfactory","title":"dfloaderfactory","text":"<p>Module for DfLoaderFactory</p>"},{"location":"reference/data/dataloaders/factories/dfloaderfactory/#niceml.data.dataloaders.factories.dfloaderfactory-classes","title":"Classes","text":""},{"location":"reference/data/dataloaders/factories/dfloaderfactory/#niceml.data.dataloaders.factories.dfloaderfactory.DfLoaderFactory","title":"DfLoaderFactory","text":"<p>             Bases: <code>ABC</code></p> <p>Abstract implementation of DfLoaderFactory (Dataframe Loader Factory)</p>"},{"location":"reference/data/dataloaders/factories/dfloaderfactory/#niceml.data.dataloaders.factories.dfloaderfactory.DfLoaderFactory-functions","title":"Functions","text":""},{"location":"reference/data/dataloaders/factories/dfloaderfactory/#niceml.data.dataloaders.factories.dfloaderfactory.DfLoaderFactory.create_df_loader","title":"create_df_loader  <code>abstractmethod</code>","text":"<pre><code>create_df_loader(storage, working_dir)\n</code></pre> <p>Creates a dataframe loader (DFLoader)</p> Source code in <code>niceml/data/dataloaders/factories/dfloaderfactory.py</code> <pre><code>@abstractmethod\ndef create_df_loader(self, storage: StorageInterface, working_dir: str) -&gt; DfLoader:\n    \"\"\"Creates a dataframe loader (DFLoader)\"\"\"\n</code></pre>"},{"location":"reference/data/dataloaders/factories/imageloaderfactory/","title":"imageloaderfactory","text":""},{"location":"reference/data/dataloaders/factories/imageloaderfactory/#niceml.data.dataloaders.factories.imageloaderfactory","title":"imageloaderfactory","text":"<p>Module for ImageLoaderFactory</p>"},{"location":"reference/data/dataloaders/factories/imageloaderfactory/#niceml.data.dataloaders.factories.imageloaderfactory-classes","title":"Classes","text":""},{"location":"reference/data/dataloaders/factories/imageloaderfactory/#niceml.data.dataloaders.factories.imageloaderfactory.ImageLoaderFactory","title":"ImageLoaderFactory","text":"<p>             Bases: <code>ABC</code></p> <p>Abstract implementation of ImageLoaderFactory</p>"},{"location":"reference/data/dataloaders/factories/imageloaderfactory/#niceml.data.dataloaders.factories.imageloaderfactory.ImageLoaderFactory-functions","title":"Functions","text":""},{"location":"reference/data/dataloaders/factories/imageloaderfactory/#niceml.data.dataloaders.factories.imageloaderfactory.ImageLoaderFactory.create_image_loader","title":"create_image_loader  <code>abstractmethod</code>","text":"<pre><code>create_image_loader(storage, working_dir)\n</code></pre> <p>Creates an ImageLoader</p> Source code in <code>niceml/data/dataloaders/factories/imageloaderfactory.py</code> <pre><code>@abstractmethod\ndef create_image_loader(\n    self, storage: StorageInterface, working_dir: str\n) -&gt; ImageLoader:\n    \"\"\"Creates an ImageLoader\"\"\"\n</code></pre>"},{"location":"reference/data/dataloaders/interfaces/__init__/","title":"interfaces","text":""},{"location":"reference/data/dataloaders/interfaces/__init__/#niceml.data.dataloaders.interfaces","title":"interfaces","text":""},{"location":"reference/data/dataloaders/interfaces/dfloader/","title":"dfloader","text":""},{"location":"reference/data/dataloaders/interfaces/dfloader/#niceml.data.dataloaders.interfaces.dfloader","title":"dfloader","text":"<p>Module for abstract dataframe loader</p>"},{"location":"reference/data/dataloaders/interfaces/dfloader/#niceml.data.dataloaders.interfaces.dfloader-classes","title":"Classes","text":""},{"location":"reference/data/dataloaders/interfaces/dfloader/#niceml.data.dataloaders.interfaces.dfloader.DfLoader","title":"DfLoader","text":"<p>             Bases: <code>ABC</code></p> <p>Abstract class DfLoader (Dataframe Loader)</p>"},{"location":"reference/data/dataloaders/interfaces/dfloader/#niceml.data.dataloaders.interfaces.dfloader.DfLoader-functions","title":"Functions","text":""},{"location":"reference/data/dataloaders/interfaces/dfloader/#niceml.data.dataloaders.interfaces.dfloader.DfLoader.load_df","title":"load_df  <code>abstractmethod</code>","text":"<pre><code>load_df(df_path)\n</code></pre> <p>Loads and returns the dataframe</p> Source code in <code>niceml/data/dataloaders/interfaces/dfloader.py</code> <pre><code>@abstractmethod\ndef load_df(self, df_path: str) -&gt; pd.DataFrame:\n    \"\"\"Loads and returns the dataframe\"\"\"\n</code></pre>"},{"location":"reference/data/dataloaders/interfaces/imageloader/","title":"imageloader","text":""},{"location":"reference/data/dataloaders/interfaces/imageloader/#niceml.data.dataloaders.interfaces.imageloader","title":"imageloader","text":"<p>Module for abstract ImageLoader</p>"},{"location":"reference/data/dataloaders/interfaces/imageloader/#niceml.data.dataloaders.interfaces.imageloader-classes","title":"Classes","text":""},{"location":"reference/data/dataloaders/interfaces/imageloader/#niceml.data.dataloaders.interfaces.imageloader.ImageLoader","title":"ImageLoader","text":"<p>             Bases: <code>ABC</code></p> <p>Abstract implementation of ImageLoader</p>"},{"location":"reference/data/dataloaders/interfaces/imageloader/#niceml.data.dataloaders.interfaces.imageloader.ImageLoader-functions","title":"Functions","text":""},{"location":"reference/data/dataloaders/interfaces/imageloader/#niceml.data.dataloaders.interfaces.imageloader.ImageLoader.is_image","title":"is_image  <code>staticmethod</code>","text":"<pre><code>is_image(path)\n</code></pre> <p>checks if file from filepath is an image</p> Source code in <code>niceml/data/dataloaders/interfaces/imageloader.py</code> <pre><code>@staticmethod\ndef is_image(path: str) -&gt; bool:\n    \"\"\"checks if file from filepath is an image\"\"\"\n    img_path = Path(path)\n    return img_path.is_file() and img_path.name.split(\".\")[-1] in [\n        \"jpg\",\n        \"png\",\n        \"tiff\",\n        \"tif\",\n        \"bmp\",\n        \"jpeg\",\n    ]\n</code></pre>"},{"location":"reference/data/dataloaders/semseg/__init__/","title":"semseg","text":""},{"location":"reference/data/dataloaders/semseg/__init__/#niceml.data.dataloaders.semseg","title":"semseg","text":""},{"location":"reference/data/dataloaders/semseg/semsegdataloader/","title":"semsegdataloader","text":""},{"location":"reference/data/dataloaders/semseg/semsegdataloader/#niceml.data.dataloaders.semseg.semsegdataloader","title":"semsegdataloader","text":"<p>Module for SemSegDataLoader</p>"},{"location":"reference/data/dataloaders/semseg/semsegdataloader/#niceml.data.dataloaders.semseg.semsegdataloader-classes","title":"Classes","text":""},{"location":"reference/data/dataloaders/semseg/semsegdataloader/#niceml.data.dataloaders.semseg.semsegdataloader.SemSegDataLoader","title":"SemSegDataLoader","text":"<pre><code>SemSegDataLoader()\n</code></pre> <p>             Bases: <code>DataLoader</code></p> <p>Implementation of SemSegDataLoader</p> Source code in <code>niceml/data/dataloaders/dataloader.py</code> <pre><code>def __init__(self):\n    self.data_description = None\n</code></pre>"},{"location":"reference/data/dataloaders/semseg/semsegdataloader/#niceml.data.dataloaders.semseg.semsegdataloader.SemSegDataLoader-functions","title":"Functions","text":""},{"location":"reference/data/dataloaders/semseg/semsegdataloader/#niceml.data.dataloaders.semseg.semsegdataloader.SemSegDataLoader.load_data","title":"load_data","text":"<pre><code>load_data(data_info)\n</code></pre> <p>Takes a SemSegDataInfo object as input, which contains all the information needed to load the image and mask files. The function returns a SemSegData object, which contains both the image and mask data.</p> <p>Parameters:</p> <ul> <li> <code>data_info</code>             (<code>SemSegDataInfo</code>)         \u2013          <p>SemSegDataInfo: Contains SemSeg data info</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>SemSegData</code>         \u2013          <p>A SemSegData object</p> </li> </ul> Source code in <code>niceml/data/dataloaders/semseg/semsegdataloader.py</code> <pre><code>def load_data(self, data_info: SemSegDataInfo) -&gt; SemSegData:\n    \"\"\"\n    Takes a SemSegDataInfo object as input, which contains all the information needed to load\n    the image and mask files. The function returns a SemSegData object, which contains\n    both the image and mask data.\n\n    Args:\n        data_info: SemSegDataInfo: Contains SemSeg data info\n\n    Returns:\n        A SemSegData object\n\n    \"\"\"\n    semseg_dd: SemSegDataDescription = check_instance(\n        self.data_description, SemSegDataDescription\n    )\n\n    class_lut = semseg_dd.get_class_idx_lut()\n    with open_location(data_info.image_location) as (image_fs, image_path):\n        image = load_img_uint8(\n            image_path,\n            file_system=image_fs,\n            target_image_size=semseg_dd.get_input_image_size(),\n        )\n    with open_location(data_info.mask_location) as (mask_fs, mask_path):\n        mask_image = load_img_uint8(\n            mask_path,\n            file_system=mask_fs,\n            target_image_size=semseg_dd.get_input_image_size(),\n        )\n\n    mask_image = transform_mask_image(mask_image, class_lut)\n    return SemSegData(\n        file_id=data_info.get_identifier(), image=image, mask_image=mask_image\n    )\n</code></pre>"},{"location":"reference/data/dataloaders/semseg/semsegdataloader/#niceml.data.dataloaders.semseg.semsegdataloader-functions","title":"Functions","text":""},{"location":"reference/data/dataloaders/semseg/transformmaskimage/","title":"transformmaskimage","text":""},{"location":"reference/data/dataloaders/semseg/transformmaskimage/#niceml.data.dataloaders.semseg.transformmaskimage","title":"transformmaskimage","text":"<p>Module to use cython for transform mask images</p>"},{"location":"reference/data/dataloaders/semseg/transformmaskimage/#niceml.data.dataloaders.semseg.transformmaskimage-functions","title":"Functions","text":""},{"location":"reference/data/dataloaders/semseg/transformmaskimage/#niceml.data.dataloaders.semseg.transformmaskimage.transform_mask_image","title":"transform_mask_image","text":"<pre><code>transform_mask_image(input_mask_image, color_idx_lut)\n</code></pre> <p>Fast implementation with cython to load labels faster</p> Source code in <code>niceml/data/dataloaders/semseg/transformmaskimage.py</code> <pre><code>def transform_mask_image(\n    input_mask_image: np.ndarray, color_idx_lut: np.ndarray\n) -&gt; np.ndarray:\n    \"\"\"Fast implementation with cython to load labels faster\"\"\"\n    if len(input_mask_image.shape) == 2:\n        input_mask_image = input_mask_image[:, :, np.newaxis]\n    if len(color_idx_lut.shape) == 1:\n        color_idx_lut = color_idx_lut[:, np.newaxis]\n    input_shape = input_mask_image.shape\n    out_mask_array = np.ones((input_shape[0], input_shape[1]), dtype=int) * 255\n    return cy_transform_mask_image(input_mask_image, color_idx_lut, out_mask_array)\n</code></pre>"},{"location":"reference/data/datasets/__init__/","title":"datasets","text":""},{"location":"reference/data/datasets/__init__/#niceml.data.datasets","title":"datasets","text":""},{"location":"reference/data/datasets/clsclassinfo/","title":"clsclassinfo","text":""},{"location":"reference/data/datasets/clsclassinfo/#niceml.data.datasets.clsclassinfo","title":"clsclassinfo","text":""},{"location":"reference/data/datasets/clsclassinfo/#niceml.data.datasets.clsclassinfo-classes","title":"Classes","text":""},{"location":"reference/data/datasets/clsclassinfo/#niceml.data.datasets.clsclassinfo.ClsClassInfo","title":"ClsClassInfo  <code>dataclass</code>","text":"<p>This class can represent one classification class.</p>"},{"location":"reference/data/datasets/clsclassinfo/#niceml.data.datasets.clsclassinfo.ClsClassInfo--parameters","title":"Parameters:","text":"<p>name: str     name of the class, usually the same as the folder name weight: float, default 1.0     of this class are taken <code>weight * count</code> samples (e.g. for training) subclasses: List[str], default []      integrates the listed classes to this class. They are represented by      the actual <code>name</code> field of this object.</p>"},{"location":"reference/data/datasets/clsclassinfo/#niceml.data.datasets.clsclassinfo-functions","title":"Functions","text":""},{"location":"reference/data/datasets/dataset/","title":"dataset","text":""},{"location":"reference/data/datasets/dataset/#niceml.data.datasets.dataset","title":"dataset","text":"<p>Module for dataset</p>"},{"location":"reference/data/datasets/dataset/#niceml.data.datasets.dataset-classes","title":"Classes","text":""},{"location":"reference/data/datasets/dataset/#niceml.data.datasets.dataset.Dataset","title":"Dataset","text":"<p>             Bases: <code>ABC</code></p> <p>Dataset to load, transform, shuffle the data before training</p>"},{"location":"reference/data/datasets/dataset/#niceml.data.datasets.dataset.Dataset-functions","title":"Functions","text":""},{"location":"reference/data/datasets/dataset/#niceml.data.datasets.dataset.Dataset.__getitem__","title":"__getitem__  <code>abstractmethod</code>","text":"<pre><code>__getitem__(index)\n</code></pre> <p>Returns the data of the item/batch at index</p> Source code in <code>niceml/data/datasets/dataset.py</code> <pre><code>@abstractmethod\ndef __getitem__(self, index: int):\n    \"\"\"Returns the data of the item/batch at index\"\"\"\n    pass\n</code></pre>"},{"location":"reference/data/datasets/dataset/#niceml.data.datasets.dataset.Dataset.__len__","title":"__len__  <code>abstractmethod</code>","text":"<pre><code>__len__()\n</code></pre> <p>Returns the number of batches/items</p> Source code in <code>niceml/data/datasets/dataset.py</code> <pre><code>@abstractmethod\ndef __len__(self):\n    \"\"\"Returns the number of batches/items\"\"\"\n    pass\n</code></pre>"},{"location":"reference/data/datasets/dataset/#niceml.data.datasets.dataset.Dataset.get_data_by_key","title":"get_data_by_key  <code>abstractmethod</code>","text":"<pre><code>get_data_by_key(data_key)\n</code></pre> <p>Returns the data by the key (identifier of the data)</p> Source code in <code>niceml/data/datasets/dataset.py</code> <pre><code>@abstractmethod\ndef get_data_by_key(self, data_key):\n    \"\"\"Returns the data by the key (identifier of the data)\"\"\"\n</code></pre>"},{"location":"reference/data/datasets/dataset/#niceml.data.datasets.dataset.Dataset.get_datainfo","title":"get_datainfo  <code>abstractmethod</code>","text":"<pre><code>get_datainfo(batch_index)\n</code></pre> <p>returns the datainfo for the batch at index</p> Source code in <code>niceml/data/datasets/dataset.py</code> <pre><code>@abstractmethod\ndef get_datainfo(self, batch_index: int) -&gt; List[DataInfo]:\n    \"\"\"returns the datainfo for the batch at index\"\"\"\n</code></pre>"},{"location":"reference/data/datasets/dataset/#niceml.data.datasets.dataset.Dataset.get_dataset_stats","title":"get_dataset_stats","text":"<pre><code>get_dataset_stats()\n</code></pre> <p>Returns the dataset stats</p> Source code in <code>niceml/data/datasets/dataset.py</code> <pre><code>def get_dataset_stats(self) -&gt; dict:\n    \"\"\"Returns the dataset stats\"\"\"\n    return dict(size=self.get_item_count())\n</code></pre>"},{"location":"reference/data/datasets/dataset/#niceml.data.datasets.dataset.Dataset.get_item_count","title":"get_item_count  <code>abstractmethod</code>","text":"<pre><code>get_item_count()\n</code></pre> <p>Returns the current count of items in the dataset</p> Source code in <code>niceml/data/datasets/dataset.py</code> <pre><code>@abstractmethod\ndef get_item_count(self) -&gt; int:\n    \"\"\"Returns the current count of items in the dataset\"\"\"\n</code></pre>"},{"location":"reference/data/datasets/dataset/#niceml.data.datasets.dataset.Dataset.get_items_per_epoch","title":"get_items_per_epoch  <code>abstractmethod</code>","text":"<pre><code>get_items_per_epoch()\n</code></pre> <p>Returns the items per epoch</p> Source code in <code>niceml/data/datasets/dataset.py</code> <pre><code>@abstractmethod\ndef get_items_per_epoch(self) -&gt; int:\n    \"\"\"Returns the items per epoch\"\"\"\n</code></pre>"},{"location":"reference/data/datasets/dataset/#niceml.data.datasets.dataset.Dataset.get_set_name","title":"get_set_name  <code>abstractmethod</code>","text":"<pre><code>get_set_name()\n</code></pre> <p>Returns the name of the set e.g. train</p> Source code in <code>niceml/data/datasets/dataset.py</code> <pre><code>@abstractmethod\ndef get_set_name(self) -&gt; str:\n    \"\"\"Returns the name of the set e.g. train\"\"\"\n</code></pre>"},{"location":"reference/data/datasets/dataset/#niceml.data.datasets.dataset.Dataset.initialize","title":"initialize  <code>abstractmethod</code>","text":"<pre><code>initialize(data_description, exp_context)\n</code></pre> <p>Initializes with the data description and context</p> Source code in <code>niceml/data/datasets/dataset.py</code> <pre><code>@abstractmethod\ndef initialize(\n    self, data_description: DataDescription, exp_context: ExperimentContext\n):\n    \"\"\"Initializes with the data description and context\"\"\"\n</code></pre>"},{"location":"reference/data/datasets/dataset/#niceml.data.datasets.dataset.Dataset.iter_with_info","title":"iter_with_info","text":"<pre><code>iter_with_info()\n</code></pre> <p>Iterates over the dataset and adds the data_info to each data</p> Source code in <code>niceml/data/datasets/dataset.py</code> <pre><code>def iter_with_info(self) -&gt; Iterable:\n    \"\"\"Iterates over the dataset and adds the data_info to each data\"\"\"\n    return DataIterator(self)\n</code></pre>"},{"location":"reference/data/datasets/dfdataset/","title":"dfdataset","text":""},{"location":"reference/data/datasets/dfdataset/#niceml.data.datasets.dfdataset","title":"dfdataset","text":"<p>Module for dfdataset</p>"},{"location":"reference/data/datasets/dfdataset/#niceml.data.datasets.dfdataset-classes","title":"Classes","text":""},{"location":"reference/data/datasets/dfdataset/#niceml.data.datasets.dfdataset.DfDataset","title":"DfDataset","text":"<pre><code>DfDataset(\n    id_key,\n    subset_name,\n    data_location,\n    df_filename=ExperimentFilenames.SUBSET_NAME,\n    shuffle=False,\n    data_shuffler=None,\n    dataframe_filters=None,\n    feature_combiners=None,\n    extra_key_list=None,\n)\n</code></pre> <p>             Bases: <code>Dataset</code>, <code>ABC</code></p> <p>Dataset for dataframes</p> <p>Initializes an instance of DfDataset with the given arguments</p> <p>Parameters:</p> <ul> <li> <code>id_key</code>             (<code>str</code>)         \u2013          <p>Column name of the id column in your dataframe</p> </li> <li> <code>subset_name</code>             (<code>str</code>)         \u2013          <p>Name of the dataset</p> </li> <li> <code>data_location</code>             (<code>Union[dict, LocationConfig]</code>)         \u2013          <p>Location of the data used in the data set</p> </li> <li> <code>df_filename</code>             (<code>str</code>, default:                 <code>SUBSET_NAME</code> )         \u2013          <p>Specify the file name of the dataframe</p> </li> <li> <code>shuffle</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Flag to shuffle the data or not</p> </li> <li> <code>dataframe_filters</code>             (<code>Optional[List[DataframeFilter]]</code>, default:                 <code>None</code> )         \u2013          <p>Optional list of dataframe filters                 to filter the data</p> </li> </ul> Source code in <code>niceml/data/datasets/dfdataset.py</code> <pre><code>def __init__(  # ruff: noqa: PLR0913\n    self,\n    id_key: str,\n    subset_name: str,\n    data_location: Union[dict, LocationConfig],\n    df_filename: str = ExperimentFilenames.SUBSET_NAME,\n    shuffle: bool = False,\n    data_shuffler: Optional[DataShuffler] = None,\n    dataframe_filters: Optional[List[DataframeFilter]] = None,\n    feature_combiners: Optional[List[FeatureCombiner]] = None,\n    extra_key_list: Optional[List[str]] = None,\n):\n    \"\"\"\n    Initializes an instance of DfDataset with the given arguments\n\n    Args:\n        id_key: Column name of the id column in your dataframe\n        subset_name: Name of the dataset\n        data_location: Location of the data used in the data set\n        df_filename: Specify the file name of the dataframe\n        shuffle: Flag to shuffle the data or not\n        dataframe_filters: Optional list of dataframe filters\n                            to filter the data\n    \"\"\"\n    super().__init__()\n    self.data_shuffler = data_shuffler or DefaultDataShuffler()\n    self.dataframe_filters = dataframe_filters or []\n    self.df_path = df_filename\n    self.data_location = data_location\n    self.subset_name = subset_name\n    self.id_key = id_key\n    self.index_list = []\n    self.shuffle = shuffle\n    self.data: Optional[pd.DataFrame] = None\n    self.inputs: List[dict] = []\n    self.targets: List[dict] = []\n    self.extra_key_list: List[str] = extra_key_list or []\n    self.feature_combiners: List[FeatureCombiner] = feature_combiners or []\n</code></pre>"},{"location":"reference/data/datasets/dfdataset/#niceml.data.datasets.dfdataset.DfDataset-functions","title":"Functions","text":""},{"location":"reference/data/datasets/dfdataset/#niceml.data.datasets.dfdataset.DfDataset.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(index)\n</code></pre> <p>The getitem function returns the indexed data item.</p> <p>Args:      index: Specify <code>index</code> of the item</p> <p>Returns:      An item of input data and target data</p> Source code in <code>niceml/data/datasets/dfdataset.py</code> <pre><code>def __getitem__(self, index):\n    \"\"\"\n    The __getitem__ function returns the indexed data item.\n\n     Args:\n         index: Specify `index` of the item\n\n     Returns:\n         An item of input data and target data\n    \"\"\"\n    input_data, target_data = self.get_data(index, index + 1)\n\n    return input_data, target_data\n</code></pre>"},{"location":"reference/data/datasets/dfdataset/#niceml.data.datasets.dfdataset.DfDataset.__len__","title":"__len__","text":"<pre><code>__len__()\n</code></pre> <p>The len function is used to determine the number of steps in a dataset.</p> <p>Returns:</p> <ul> <li>         \u2013          <p>The number of items</p> </li> </ul> Source code in <code>niceml/data/datasets/dfdataset.py</code> <pre><code>def __len__(self):\n    \"\"\"\n    The __len__ function is used to determine the number of steps in a dataset.\n\n    Returns:\n        The number of items\n    \"\"\"\n    return self.get_items_per_epoch()\n</code></pre>"},{"location":"reference/data/datasets/dfdataset/#niceml.data.datasets.dfdataset.DfDataset.extract_data","title":"extract_data","text":"<pre><code>extract_data(cur_indexes, cur_input)\n</code></pre> <p>The extract_data function takes in a list of indexes and an input dictionary. The function then extracts the data from <code>self.data</code> using the key provided by the input dictionary, and returns it as a numpy array. If the type is categorical, it will convert it to one-hot encoding.</p> <p>Parameters:</p> <ul> <li> <code>self</code>         \u2013          <p>Bind the method to an object</p> </li> <li> <code>cur_indexes</code>             (<code>List[int]</code>)         \u2013          <p>Select the rows of data that are needed for the current batch</p> </li> <li> <code>cur_input</code>             (<code>dict</code>)         \u2013          <p>Get the key and type of the input</p> </li> </ul> <p>Returns:</p> <ul> <li>         \u2013          <p>The data of the current key</p> </li> </ul> Source code in <code>niceml/data/datasets/dfdataset.py</code> <pre><code>def extract_data(self, cur_indexes: List[int], cur_input: dict):\n    \"\"\"\n    The extract_data function takes in a list of indexes and an input dictionary.\n    The function then extracts the data from `self.data` using the key provided by\n    the input dictionary, and returns it as a numpy array. If the type is categorical,\n    it will convert it to one-hot encoding.\n\n    Args:\n        self: Bind the method to an object\n        cur_indexes: Select the rows of data that are needed for the current batch\n        cur_input: Get the key and type of the input\n\n    Returns:\n        The data of the current key\n    \"\"\"\n    cur_key = cur_input[\"key\"]\n    cur_data = self.data.iloc[cur_indexes][cur_key]\n    if cur_input[\"type\"] == FeatureType.CATEGORICAL:\n        cur_data = to_categorical(cur_data, cur_input[\"value_count\"])\n    return cur_data\n</code></pre>"},{"location":"reference/data/datasets/dfdataset/#niceml.data.datasets.dfdataset.DfDataset.get_all_data","title":"get_all_data","text":"<pre><code>get_all_data()\n</code></pre> <p>loads all data</p> Source code in <code>niceml/data/datasets/dfdataset.py</code> <pre><code>def get_all_data(self):\n    \"\"\"loads all data\"\"\"\n    return self.get_data_from_idx_list(self.index_list)\n</code></pre>"},{"location":"reference/data/datasets/dfdataset/#niceml.data.datasets.dfdataset.DfDataset.get_all_data_info","title":"get_all_data_info","text":"<pre><code>get_all_data_info()\n</code></pre> <p>The get_all_data_info function returns a list of <code>RegDataInfo</code> objects for all data in <code>self.data</code>.</p> <p>Returns:</p> <ul> <li> <code>List[RegDataInfo]</code>         \u2013          <p>A list of <code>RegDataInfo</code> objects</p> </li> </ul> Source code in <code>niceml/data/datasets/dfdataset.py</code> <pre><code>def get_all_data_info(self) -&gt; List[RegDataInfo]:\n    \"\"\"\n    The get_all_data_info function returns a list of `RegDataInfo` objects for\n    all data in `self.data`.\n\n    Returns:\n        A list of `RegDataInfo` objects\n\n    \"\"\"\n    input_keys = [input_dict[\"key\"] for input_dict in self.inputs]\n    target_keys = [target_dict[\"key\"] for target_dict in self.targets]\n    data_subset = self.data[\n        [self.id_key] + input_keys + target_keys + self.extra_key_list\n    ]\n    data_info_dicts: List[dict] = data_subset.to_dict(\"records\")\n    data_info_list: List[RegDataInfo] = []\n\n    for data_info_dict in data_info_dicts:\n        key = data_info_dict[self.id_key]\n        data_info_dict.pop(self.id_key)\n        data_info_list.append(RegDataInfo(key, data_info_dict))\n\n    return data_info_list\n</code></pre>"},{"location":"reference/data/datasets/dfdataset/#niceml.data.datasets.dfdataset.DfDataset.get_data","title":"get_data","text":"<pre><code>get_data(start_idx, end_idx)\n</code></pre> <p>loads data between indexes</p> Source code in <code>niceml/data/datasets/dfdataset.py</code> <pre><code>def get_data(self, start_idx: int, end_idx: int):\n    \"\"\"loads data between indexes\"\"\"\n    cur_indexes = self.index_list[start_idx:end_idx]\n    return self.get_data_from_idx_list(cur_indexes)\n</code></pre>"},{"location":"reference/data/datasets/dfdataset/#niceml.data.datasets.dfdataset.DfDataset.get_data_by_key","title":"get_data_by_key","text":"<pre><code>get_data_by_key(data_key)\n</code></pre> <p>Returns all rows of the data, whose 'id_key' matches the 'data_key'.</p> <p>Parameters:</p> <ul> <li> <code>data_key</code>         \u2013          <p>Identify the data that is being requested</p> </li> </ul> <p>Returns:</p> <ul> <li>         \u2013          <p>A dataframe of the rows where the <code>self.id_key</code> column matches the <code>data_key</code> parameter</p> </li> </ul> Source code in <code>niceml/data/datasets/dfdataset.py</code> <pre><code>def get_data_by_key(self, data_key):\n    \"\"\"\n    Returns all rows of the data, whose 'id_key' matches the 'data_key'.\n\n    Args:\n        data_key: Identify the data that is being requested\n\n    Returns:\n        A dataframe of the rows where the `self.id_key` column matches the `data_key` parameter\n    \"\"\"\n    return self.data.loc[self.data[self.id_key] == data_key]\n</code></pre>"},{"location":"reference/data/datasets/dfdataset/#niceml.data.datasets.dfdataset.DfDataset.get_data_from_idx_list","title":"get_data_from_idx_list","text":"<pre><code>get_data_from_idx_list(index_list)\n</code></pre> <p>returns data with a given <code>index_list</code></p> Source code in <code>niceml/data/datasets/dfdataset.py</code> <pre><code>def get_data_from_idx_list(self, index_list: List[int]):\n    \"\"\"returns data with a given `index_list`\"\"\"\n    input_data = []\n    for cur_input in self.inputs:\n        cur_data = self.extract_data(index_list, cur_input)\n        input_data.append(np.array(cur_data))\n    target_data = []\n    for cur_target in self.targets:\n        cur_data = self.extract_data(index_list, cur_target)\n        target_data.append(np.array(cur_data))\n\n    input_array = np.column_stack(input_data)\n    target_array = np.column_stack(target_data)\n    return input_array, target_array\n</code></pre>"},{"location":"reference/data/datasets/dfdataset/#niceml.data.datasets.dfdataset.DfDataset.get_item_count","title":"get_item_count","text":"<pre><code>get_item_count()\n</code></pre> <p>Get the number of items in the dataset</p> Source code in <code>niceml/data/datasets/dfdataset.py</code> <pre><code>def get_item_count(self) -&gt; int:\n    \"\"\"Get the number of items in the dataset\"\"\"\n    return len(self.data)\n</code></pre>"},{"location":"reference/data/datasets/dfdataset/#niceml.data.datasets.dfdataset.DfDataset.get_items_per_epoch","title":"get_items_per_epoch","text":"<pre><code>get_items_per_epoch()\n</code></pre> <p>Get the number of items per epoch</p> Source code in <code>niceml/data/datasets/dfdataset.py</code> <pre><code>def get_items_per_epoch(self) -&gt; int:\n    \"\"\"Get the number of items per epoch\"\"\"\n    return len(self.index_list)\n</code></pre>"},{"location":"reference/data/datasets/dfdataset/#niceml.data.datasets.dfdataset.DfDataset.get_set_name","title":"get_set_name","text":"<pre><code>get_set_name()\n</code></pre> <p>The get_set_name function returns the name of the set.</p> <p>Returns:</p> <ul> <li> <code>str</code>         \u2013          <p>The name of the data set</p> </li> </ul> Source code in <code>niceml/data/datasets/dfdataset.py</code> <pre><code>def get_set_name(self) -&gt; str:\n    \"\"\"\n    The get_set_name function returns the name of the set.\n\n    Returns:\n       The name of the data set\n    \"\"\"\n    return self.subset_name\n</code></pre>"},{"location":"reference/data/datasets/dfdataset/#niceml.data.datasets.dfdataset.DfDataset.initialize","title":"initialize","text":"<pre><code>initialize(data_description, exp_context)\n</code></pre> <p>The initialize function should read in all the necessary files from disk and store them as attributes on this class instance. This function is called when the data set is created. It takes in a <code>RegDataDescription</code> object, which contains information about the inputs and targets of your dataset. The initialize function should also take in an <code>ExperimentContext</code> object, which contains information about where to find your data on disk. The <code>ExperimentContext</code> is not used in this class.</p> <p>Parameters:</p> <ul> <li> <code>data_description</code>             (<code>RegDataDescription</code>)         \u2013          <p>RegDataDescription: Pass the data description of the dataset                 to this class</p> </li> <li> <code>exp_context</code>             (<code>ExperimentContext</code>)         \u2013          <p>ExperimentContext: Pass the experiment context.</p> </li> </ul> Source code in <code>niceml/data/datasets/dfdataset.py</code> <pre><code>def initialize(\n    self, data_description: RegDataDescription, exp_context: ExperimentContext\n):\n    \"\"\"\n    The initialize function should read in all the necessary files from disk and store them as\n    attributes on this class instance.\n    This function is called when the data set is created.\n    It takes in a `RegDataDescription` object, which contains information about the\n    inputs and targets of your dataset. The initialize function should also take in an\n    `ExperimentContext` object, which contains information about where to find your\n    data on disk. The `ExperimentContext` is not used in this class.\n\n\n    Args:\n        data_description: RegDataDescription: Pass the data description of the dataset\n                            to this class\n        exp_context: ExperimentContext: Pass the experiment context.\n    \"\"\"\n    self.inputs = data_description.inputs\n    self.targets = data_description.targets\n\n    with open_location(self.data_location) as (data_fs, data_root):\n        data_path = join_fs_path(\n            data_fs, data_root, self.df_path.format(subset_name=self.subset_name)\n        )\n        self.data = read_parquet(filepath=data_path, file_system=data_fs)\n\n    for feature_combiner in self.feature_combiners:\n        self.data = feature_combiner.combine_features(self.data)\n\n    for df_filter in self.dataframe_filters:\n        df_filter.initialize(data_description=data_description)\n        self.data = df_filter.filter(data=self.data)\n\n    self.data = self.data.reset_index(drop=True)\n    self.index_list = list(range(len(self.data)))\n\n    self.on_epoch_end()\n</code></pre>"},{"location":"reference/data/datasets/dfdataset/#niceml.data.datasets.dfdataset.DfDataset.iter_with_info","title":"iter_with_info","text":"<pre><code>iter_with_info()\n</code></pre> <p>The iter_with_info function is a generator that yields the next batch of data, along with some additional information about the batch. The additional information is useful for various diagnostic purposes. The function returns an object of type DataIterator, which has two fields:     * 'batch' contains the next batch of data.     * 'info' contains additional information about that batch.</p> <p>Returns:</p> <ul> <li>         \u2013          <p>A dataiterator object</p> </li> </ul> Source code in <code>niceml/data/datasets/dfdataset.py</code> <pre><code>def iter_with_info(self):\n    \"\"\"\n    The iter_with_info function is a generator that yields the next batch of data,\n    along with some additional information about the batch.\n    The additional information is useful for various diagnostic purposes.\n    The function returns an object of type DataIterator, which has two fields:\n        * 'batch' contains the next batch of data.\n        * 'info' contains additional information about that batch.\n\n    Returns:\n        A dataiterator object\n    \"\"\"\n    return DataIterator(self)\n</code></pre>"},{"location":"reference/data/datasets/dfdataset/#niceml.data.datasets.dfdataset.DfDataset.on_epoch_end","title":"on_epoch_end","text":"<pre><code>on_epoch_end()\n</code></pre> <p>Execute logic to be performed at the end of an epoch (e.g. shuffling the data)</p> Source code in <code>niceml/data/datasets/dfdataset.py</code> <pre><code>def on_epoch_end(self):\n    \"\"\"\n    Execute logic to be performed at the end of an epoch (e.g. shuffling the data)\n    \"\"\"\n    if self.shuffle:\n        self.index_list = self.data_shuffler.shuffle(\n            data_infos=self.get_all_data_info()\n        )\n</code></pre>"},{"location":"reference/data/datasets/dfdataset/#niceml.data.datasets.dfdataset.RegDataInfo","title":"RegDataInfo  <code>dataclass</code>","text":"<p>             Bases: <code>DataInfo</code></p> <p>Datainfo for Regression data</p>"},{"location":"reference/data/datasets/dfdataset/#niceml.data.datasets.dfdataset.RegDataInfo-functions","title":"Functions","text":""},{"location":"reference/data/datasets/dfdataset/#niceml.data.datasets.dfdataset.RegDataInfo.__getattr__","title":"__getattr__","text":"<pre><code>__getattr__(item)\n</code></pre> <p>The getattr function is called when an attribute lookup has not found the attribute in the usual places (i.e. it is not an instance attribute nor is it found in the class tree of self). In this case it is the value of the key (<code>item</code>) in the <code>self.data</code> dictionary</p> <p>Parameters:</p> <ul> <li> <code>item</code>         \u2013          <p>Access the value of a key in <code>self.data</code></p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Any</code>         \u2013          <p>The value of the key (<code>item</code>) in the <code>self.data</code> dictionary</p> </li> </ul> Source code in <code>niceml/data/datasets/dfdataset.py</code> <pre><code>def __getattr__(self, item) -&gt; Any:\n    \"\"\"\n    The __getattr__ function is called when an attribute lookup has not found the attribute\n    in the usual places (i.e. it is not an instance attribute nor is it\n    found in the class tree of self). In this case it is the value of the key (`item`)\n    in the `self.data` dictionary\n\n    Args:\n        item: Access the value of a key in `self.data`\n\n    Returns:\n        The value of the key (`item`) in the `self.data` dictionary\n    \"\"\"\n    return self.data[item]\n</code></pre>"},{"location":"reference/data/datasets/dfdataset/#niceml.data.datasets.dfdataset.RegDataInfo.get_identifier","title":"get_identifier","text":"<pre><code>get_identifier()\n</code></pre> <p>The get_identifier function returns the dataid of this object.</p> <p>Returns:</p> <ul> <li> <code>str</code>         \u2013          <p>The dataid</p> </li> </ul> Source code in <code>niceml/data/datasets/dfdataset.py</code> <pre><code>def get_identifier(self) -&gt; str:\n    \"\"\"\n    The get_identifier function returns the dataid of this object.\n\n    Returns:\n        The dataid\n    \"\"\"\n    return self.dataid\n</code></pre>"},{"location":"reference/data/datasets/dfdataset/#niceml.data.datasets.dfdataset.RegDataInfo.get_info_dict","title":"get_info_dict","text":"<pre><code>get_info_dict()\n</code></pre> <p>The get_info_dict function returns a dictionary containing the dataid and all the data in self.data.</p> <p>Returns:</p> <ul> <li> <code>dict</code>         \u2013          <p>A dictionary containing the dataid and all the other key-value pairs in self</p> </li> </ul> Source code in <code>niceml/data/datasets/dfdataset.py</code> <pre><code>def get_info_dict(self) -&gt; dict:\n    \"\"\"\n    The get_info_dict function returns a dictionary containing the dataid\n    and all the data in self.data.\n\n    Returns:\n        A dictionary containing the dataid and all the other key-value pairs in self\n    \"\"\"\n    info_dict = dict(dataid=self.dataid)\n    info_dict.update(self.data)\n    return info_dict\n</code></pre>"},{"location":"reference/data/datasets/dfdataset/#niceml.data.datasets.dfdataset-functions","title":"Functions","text":""},{"location":"reference/data/datasets/genericdataset/","title":"genericdataset","text":""},{"location":"reference/data/datasets/genericdataset/#niceml.data.datasets.genericdataset","title":"genericdataset","text":"<p>module for generic dataset implementation</p>"},{"location":"reference/data/datasets/genericdataset/#niceml.data.datasets.genericdataset-classes","title":"Classes","text":""},{"location":"reference/data/datasets/genericdataset/#niceml.data.datasets.genericdataset.GenericDataset","title":"GenericDataset","text":"<pre><code>GenericDataset(\n    set_name,\n    datainfo_listing,\n    data_loader,\n    target_transformer,\n    input_transformer,\n    shuffle,\n    data_shuffler=None,\n    stats_generator=None,\n    augmentator=None,\n    net_data_logger=None,\n)\n</code></pre> <p>             Bases: <code>Dataset</code>, <code>ABC</code></p> <p>Generic dataset implementation. This is a flexible dataset for multiple use cases. It can be used for classification, segmentation, object detection, etc. For specific frameworks, there are subclasses of this class, e.g. KerasGenericDataset</p> <p>Constructor of the GenericDataset Args:     set_name: Name of the subset e.g. train     datainfo_listing: How to list the data     data_loader: How to load the data     target_transformer: How to transform the         target of the model (e.g. one-hot encoding)     input_transformer: How to transform the input of the model     shuffle: bool if the data should be shuffled     data_shuffler: A way of shuffling the data (e.g. random, sampled)     stats_generator: Write dataset stats     augmentator: Augment the data on the fly     net_data_logger: Stores the in the way it is presented to the model</p> Source code in <code>niceml/data/datasets/genericdataset.py</code> <pre><code>def __init__(  # noqa: PLR0913\n    self,\n    set_name: str,\n    datainfo_listing: DataInfoListing,\n    data_loader: DataLoader,\n    target_transformer: NetTargetTransformer,\n    input_transformer: NetInputTransformer,\n    shuffle: bool,\n    data_shuffler: Optional[DataShuffler] = None,\n    stats_generator: Optional[DataStatsGenerator] = None,\n    augmentator: Optional[AugmentationProcessor] = None,\n    net_data_logger: Optional[NetDataLogger] = None,\n):\n    \"\"\"\n    Constructor of the GenericDataset\n    Args:\n        set_name: Name of the subset e.g. train\n        datainfo_listing: How to list the data\n        data_loader: How to load the data\n        target_transformer: How to transform the\n            target of the model (e.g. one-hot encoding)\n        input_transformer: How to transform the input of the model\n        shuffle: bool if the data should be shuffled\n        data_shuffler: A way of shuffling the data (e.g. random, sampled)\n        stats_generator: Write dataset stats\n        augmentator: Augment the data on the fly\n        net_data_logger: Stores the in the way it is presented to the model\n    \"\"\"\n    super().__init__()\n    self.net_data_logger = net_data_logger\n    self.set_name = set_name\n    self.datainfo_listing: DataInfoListing = datainfo_listing\n    self.data_loader: DataLoader = data_loader\n    self.shuffle = shuffle\n    self.data_shuffler: DataShuffler = data_shuffler or DefaultDataShuffler()\n    self.target_transformer: NetTargetTransformer = target_transformer\n    self.input_transformer: NetInputTransformer = input_transformer\n    self.augmentator: Optional[AugmentationProcessor] = augmentator\n\n    self.data_stats_generator: DataStatsGenerator = (\n        stats_generator or DefaultStatsGenerator()\n    )\n</code></pre>"},{"location":"reference/data/datasets/genericdataset/#niceml.data.datasets.genericdataset.GenericDataset-functions","title":"Functions","text":""},{"location":"reference/data/datasets/genericdataset/#niceml.data.datasets.genericdataset.GenericDataset.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(item_index)\n</code></pre> <p>Returns the data of the item at index</p> Source code in <code>niceml/data/datasets/genericdataset.py</code> <pre><code>def __getitem__(self, item_index: int):\n    \"\"\"Returns the data of the item at index\"\"\"\n    real_index = self.index_list[item_index]\n    data_info = self.data_info_list[real_index]\n    data_item = self.data_loader.load_data(data_info)\n    if self.augmentator is not None:\n        data_item = self.augmentator(data_item)\n    net_inputs = self.input_transformer.get_net_inputs([data_item])\n    net_targets = self.target_transformer.get_net_targets([data_item])\n    if self.net_data_logger is not None:\n        self.net_data_logger.log_data(\n            net_inputs=net_inputs,\n            net_targets=net_targets,\n            data_info_list=[data_info],\n        )\n    return net_inputs, net_targets\n</code></pre>"},{"location":"reference/data/datasets/genericdataset/#niceml.data.datasets.genericdataset.GenericDataset.__len__","title":"__len__","text":"<pre><code>__len__()\n</code></pre> <p>Returns the number of batches</p> Source code in <code>niceml/data/datasets/genericdataset.py</code> <pre><code>def __len__(self):\n    \"\"\"Returns the number of batches\"\"\"\n    return self.get_items_per_epoch()\n</code></pre>"},{"location":"reference/data/datasets/genericdataset/#niceml.data.datasets.genericdataset.GenericDataset.get_data_by_key","title":"get_data_by_key","text":"<pre><code>get_data_by_key(data_key)\n</code></pre> <p>Returns the data by the key (identifier of the data)</p> Source code in <code>niceml/data/datasets/genericdataset.py</code> <pre><code>def get_data_by_key(self, data_key):\n    \"\"\"Returns the data by the key (identifier of the data)\"\"\"\n    data_info: DataInfo = self.data_info_dict[data_key]\n    return self.data_loader.load_data(data_info)\n</code></pre>"},{"location":"reference/data/datasets/genericdataset/#niceml.data.datasets.genericdataset.GenericDataset.get_dataset_stats","title":"get_dataset_stats","text":"<pre><code>get_dataset_stats()\n</code></pre> <p>Returns the dataset stats</p> Source code in <code>niceml/data/datasets/genericdataset.py</code> <pre><code>def get_dataset_stats(self) -&gt; dict:\n    \"\"\"Returns the dataset stats\"\"\"\n    return self.data_stats_generator.generate_stats(\n        self.data_info_list, self.index_list\n    )\n</code></pre>"},{"location":"reference/data/datasets/genericdataset/#niceml.data.datasets.genericdataset.GenericDataset.get_item_count","title":"get_item_count","text":"<pre><code>get_item_count()\n</code></pre> <p>Returns the current count of items in the dataset</p> Source code in <code>niceml/data/datasets/genericdataset.py</code> <pre><code>def get_item_count(self) -&gt; int:\n    \"\"\"Returns the current count of items in the dataset\"\"\"\n    return len(self.data_info_list)\n</code></pre>"},{"location":"reference/data/datasets/genericdataset/#niceml.data.datasets.genericdataset.GenericDataset.get_items_per_epoch","title":"get_items_per_epoch","text":"<pre><code>get_items_per_epoch()\n</code></pre> <p>Returns the items per epoch</p> Source code in <code>niceml/data/datasets/genericdataset.py</code> <pre><code>def get_items_per_epoch(self) -&gt; int:\n    \"\"\"Returns the items per epoch\"\"\"\n    return len(self.index_list)\n</code></pre>"},{"location":"reference/data/datasets/genericdataset/#niceml.data.datasets.genericdataset.GenericDataset.get_set_name","title":"get_set_name","text":"<pre><code>get_set_name()\n</code></pre> <p>Returns the name of the set e.g. train</p> Source code in <code>niceml/data/datasets/genericdataset.py</code> <pre><code>def get_set_name(self) -&gt; str:\n    \"\"\"Returns the name of the set e.g. train\"\"\"\n    return self.set_name\n</code></pre>"},{"location":"reference/data/datasets/genericdataset/#niceml.data.datasets.genericdataset.GenericDataset.initialize","title":"initialize","text":"<pre><code>initialize(data_description, exp_context)\n</code></pre> <p>Initializes the dataset with the data description and context</p> Source code in <code>niceml/data/datasets/genericdataset.py</code> <pre><code>def initialize(\n    self, data_description: DataDescription, exp_context: ExperimentContext\n):\n    \"\"\"Initializes the dataset with the data description and context\"\"\"\n    self.data_description = data_description\n\n    self.data_loader.initialize(data_description)\n    self.data_shuffler.initialize(data_description)\n    self.target_transformer.initialize(data_description)\n    self.input_transformer.initialize(data_description)\n    self.data_info_list: List[DataInfo] = self.datainfo_listing.list(\n        data_description\n    )\n    self.index_list: List[int] = list(range(len(self.data_info_list)))\n    self.data_info_dict: Dict[str, DataInfo] = {\n        cur_data_info.get_identifier(): cur_data_info\n        for cur_data_info in self.data_info_list\n    }\n    if self.net_data_logger is not None:\n        self.net_data_logger.initialize(\n            self.data_description, exp_context, self.set_name\n        )\n\n    self.on_epoch_end()\n</code></pre>"},{"location":"reference/data/datasets/genericdataset/#niceml.data.datasets.genericdataset.GenericDataset.on_epoch_end","title":"on_epoch_end","text":"<pre><code>on_epoch_end()\n</code></pre> <p>Shuffles the data if required</p> Source code in <code>niceml/data/datasets/genericdataset.py</code> <pre><code>def on_epoch_end(self):\n    \"\"\"Shuffles the data if required\"\"\"\n    if self.shuffle:\n        self.index_list = self.data_shuffler.shuffle(self.data_info_list)\n</code></pre>"},{"location":"reference/data/datashuffler/__init__/","title":"datashuffler","text":""},{"location":"reference/data/datashuffler/__init__/#niceml.data.datashuffler","title":"datashuffler","text":""},{"location":"reference/data/datashuffler/datashuffler/","title":"datashuffler","text":""},{"location":"reference/data/datashuffler/datashuffler/#niceml.data.datashuffler.datashuffler","title":"datashuffler","text":"<p>module for datashuffler</p>"},{"location":"reference/data/datashuffler/datashuffler/#niceml.data.datashuffler.datashuffler-classes","title":"Classes","text":""},{"location":"reference/data/datashuffler/datashuffler/#niceml.data.datashuffler.datashuffler.DataShuffler","title":"DataShuffler","text":"<p>             Bases: <code>ABC</code></p> <p>Abstract class for data shufflers</p>"},{"location":"reference/data/datashuffler/datashuffler/#niceml.data.datashuffler.datashuffler.DataShuffler-functions","title":"Functions","text":""},{"location":"reference/data/datashuffler/datashuffler/#niceml.data.datashuffler.datashuffler.DataShuffler.shuffle","title":"shuffle  <code>abstractmethod</code>","text":"<pre><code>shuffle(data_infos, batch_size=None)\n</code></pre> <p>Returns a list of shuffled indexes</p> Source code in <code>niceml/data/datashuffler/datashuffler.py</code> <pre><code>@abstractmethod\ndef shuffle(\n    self, data_infos: List[DataInfo], batch_size: Optional[int] = None\n) -&gt; List[int]:\n    \"\"\"Returns a list of shuffled indexes\"\"\"\n    pass\n</code></pre>"},{"location":"reference/data/datashuffler/defaultshuffler/","title":"defaultshuffler","text":""},{"location":"reference/data/datashuffler/defaultshuffler/#niceml.data.datashuffler.defaultshuffler","title":"defaultshuffler","text":"<p>Module with default data shuffler</p>"},{"location":"reference/data/datashuffler/defaultshuffler/#niceml.data.datashuffler.defaultshuffler-classes","title":"Classes","text":""},{"location":"reference/data/datashuffler/defaultshuffler/#niceml.data.datashuffler.defaultshuffler.DefaultDataShuffler","title":"DefaultDataShuffler","text":"<p>             Bases: <code>DataShuffler</code></p> <p>Default data shuffler to shuffle the indices of the data</p>"},{"location":"reference/data/datashuffler/uniformdistributionshuffler/","title":"uniformdistributionshuffler","text":""},{"location":"reference/data/datashuffler/uniformdistributionshuffler/#niceml.data.datashuffler.uniformdistributionshuffler","title":"uniformdistributionshuffler","text":"<p>Module for the UniformDistributionShuffler and helper methods</p>"},{"location":"reference/data/datashuffler/uniformdistributionshuffler/#niceml.data.datashuffler.uniformdistributionshuffler-classes","title":"Classes","text":""},{"location":"reference/data/datashuffler/uniformdistributionshuffler/#niceml.data.datashuffler.uniformdistributionshuffler.UniformDistributionShuffler","title":"UniformDistributionShuffler","text":"<pre><code>UniformDistributionShuffler(class_attr, mode='max')\n</code></pre> <p>             Bases: <code>DataShuffler</code></p> <p>A shuffler which generates uniform distributed indexes</p>"},{"location":"reference/data/datashuffler/uniformdistributionshuffler/#niceml.data.datashuffler.uniformdistributionshuffler.UniformDistributionShuffler--parameters","title":"Parameters","text":"<p>class_attr: str     Classttribute name of the datainfo mode: str     How the target amount of each class should be calculated     such that they are evenly distributed (max, min, avg)</p> Source code in <code>niceml/data/datashuffler/uniformdistributionshuffler.py</code> <pre><code>def __init__(self, class_attr: str, mode: str = \"max\"):\n    \"\"\"\n    A shuffler which generates uniform distributed indexes\n\n    Parameters\n    ----------\n    class_attr: str\n        Classttribute name of the datainfo\n    mode: str\n        How the target amount of each class should be calculated\n        such that they are evenly distributed (max, min, avg)\n    \"\"\"\n    check_mode(mode)\n    self.class_attr = class_attr\n    self.mode = mode\n</code></pre>"},{"location":"reference/data/datashuffler/uniformdistributionshuffler/#niceml.data.datashuffler.uniformdistributionshuffler.UniformDistributionShuffler-functions","title":"Functions","text":""},{"location":"reference/data/datashuffler/uniformdistributionshuffler/#niceml.data.datashuffler.uniformdistributionshuffler-functions","title":"Functions","text":""},{"location":"reference/data/datashuffler/uniformdistributionshuffler/#niceml.data.datashuffler.uniformdistributionshuffler.check_mode","title":"check_mode","text":"<pre><code>check_mode(mode)\n</code></pre> <p>Checks if mode is available otherwise raises ModeNotImplementedError</p> Source code in <code>niceml/data/datashuffler/uniformdistributionshuffler.py</code> <pre><code>def check_mode(mode: str):\n    \"\"\"Checks if mode is available otherwise raises ModeNotImplementedError\"\"\"\n    if mode not in MODE_DICT:\n        mode_list: str = \",\".join(MODE_DICT.keys())\n        message: str = f\"{mode} not available, please use: {mode_list}\"\n        raise ModeNotImplementedError(message)\n</code></pre>"},{"location":"reference/data/datashuffler/uniformdistributionshuffler/#niceml.data.datashuffler.uniformdistributionshuffler.classdict_to_indexes","title":"classdict_to_indexes","text":"<pre><code>classdict_to_indexes(class_dict, mode)\n</code></pre> <p>Uses the class dict to return a list of indexes</p>"},{"location":"reference/data/datashuffler/uniformdistributionshuffler/#niceml.data.datashuffler.uniformdistributionshuffler.classdict_to_indexes--parameters","title":"Parameters","text":"<p>class_dict: Dict[Any, List[int]]     Contains for each class the list of indexes referring to it mode: str     How the target amount of each class should be calculated     such that they are evenly distributed (max, min, avg)</p>"},{"location":"reference/data/datashuffler/uniformdistributionshuffler/#niceml.data.datashuffler.uniformdistributionshuffler.classdict_to_indexes--returns","title":"Returns","text":"<pre><code>A shuffled list of indexes (each index can occur multiple times)\n</code></pre> Source code in <code>niceml/data/datashuffler/uniformdistributionshuffler.py</code> <pre><code>def classdict_to_indexes(class_dict: Dict[Any, List[int]], mode: str) -&gt; List[int]:\n    \"\"\"\n    Uses the class dict to return a list of indexes\n\n    Parameters\n    ----------\n    class_dict: Dict[Any, List[int]]\n        Contains for each class the list of indexes referring to it\n    mode: str\n        How the target amount of each class should be calculated\n        such that they are evenly distributed (max, min, avg)\n\n    Returns\n    -------\n        A shuffled list of indexes (each index can occur multiple times)\n    \"\"\"\n    check_mode(mode)\n    class_count_dict = {x: len(y) for x, y in class_dict.items()}\n    cur_mode = MODE_DICT[mode]\n    max_count = int(cur_mode(list(class_count_dict.values())))\n    out_list: List[int] = []\n    for class_list in class_dict.values():\n        count, parts = divmod(max_count, len(class_list))\n        out_list += class_list * count\n        out_list += sample(class_list, parts)\n    shuffle(out_list)\n    return out_list\n</code></pre>"},{"location":"reference/data/datastatsgenerator/__init__/","title":"datastatsgenerator","text":""},{"location":"reference/data/datastatsgenerator/__init__/#niceml.data.datastatsgenerator","title":"datastatsgenerator","text":""},{"location":"reference/data/datastatsgenerator/datastatsgenerator/","title":"datastatsgenerator","text":""},{"location":"reference/data/datastatsgenerator/datastatsgenerator/#niceml.data.datastatsgenerator.datastatsgenerator","title":"datastatsgenerator","text":"<p>Module for DataStatsGenerator</p>"},{"location":"reference/data/datastatsgenerator/datastatsgenerator/#niceml.data.datastatsgenerator.datastatsgenerator-classes","title":"Classes","text":""},{"location":"reference/data/datastatsgenerator/datastatsgenerator/#niceml.data.datastatsgenerator.datastatsgenerator.DataStatsGenerator","title":"DataStatsGenerator","text":"<p>             Bases: <code>ABC</code></p> <p>ABC for generating stats in a dataset</p>"},{"location":"reference/data/datastatsgenerator/datastatsgenerator/#niceml.data.datastatsgenerator.datastatsgenerator.DataStatsGenerator-functions","title":"Functions","text":""},{"location":"reference/data/datastatsgenerator/datastatsgenerator/#niceml.data.datastatsgenerator.datastatsgenerator.DataStatsGenerator.generate_stats","title":"generate_stats  <code>abstractmethod</code>","text":"<pre><code>generate_stats(data_info_list, index_list)\n</code></pre> <p>Creates stats from a data_info_list and an index list</p> Source code in <code>niceml/data/datastatsgenerator/datastatsgenerator.py</code> <pre><code>@abstractmethod\ndef generate_stats(\n    self, data_info_list: List[DataInfo], index_list: List[int]\n) -&gt; dict:\n    \"\"\"Creates stats from a data_info_list and an index list\"\"\"\n</code></pre>"},{"location":"reference/data/datastatsgenerator/defaultstatsgenerator/","title":"defaultstatsgenerator","text":""},{"location":"reference/data/datastatsgenerator/defaultstatsgenerator/#niceml.data.datastatsgenerator.defaultstatsgenerator","title":"defaultstatsgenerator","text":"<p>Module for DefaultStatsGenerator</p>"},{"location":"reference/data/datastatsgenerator/defaultstatsgenerator/#niceml.data.datastatsgenerator.defaultstatsgenerator-classes","title":"Classes","text":""},{"location":"reference/data/datastatsgenerator/defaultstatsgenerator/#niceml.data.datastatsgenerator.defaultstatsgenerator.DefaultStatsGenerator","title":"DefaultStatsGenerator","text":"<p>             Bases: <code>DataStatsGenerator</code></p> <p>Default stats generator</p>"},{"location":"reference/data/featurecombiners/__init__/","title":"featurecombiners","text":""},{"location":"reference/data/featurecombiners/__init__/#niceml.data.featurecombiners","title":"featurecombiners","text":""},{"location":"reference/data/featurecombiners/featurecombiner/","title":"featurecombiner","text":""},{"location":"reference/data/featurecombiners/featurecombiner/#niceml.data.featurecombiners.featurecombiner","title":"featurecombiner","text":"<p>Module for feature combiner</p>"},{"location":"reference/data/featurecombiners/featurecombiner/#niceml.data.featurecombiners.featurecombiner-classes","title":"Classes","text":""},{"location":"reference/data/featurecombiners/featurecombiner/#niceml.data.featurecombiners.featurecombiner.FeatureCombiner","title":"FeatureCombiner","text":"<p>             Bases: <code>ABC</code></p> <p>FeatureCombiner that can combine column-based features as part of a DfDataset to create new features.</p>"},{"location":"reference/data/featurecombiners/featurecombiner/#niceml.data.featurecombiners.featurecombiner.FeatureCombiner-functions","title":"Functions","text":""},{"location":"reference/data/featurecombiners/featurecombiner/#niceml.data.featurecombiners.featurecombiner.FeatureCombiner.combine_features","title":"combine_features  <code>abstractmethod</code>","text":"<pre><code>combine_features(data)\n</code></pre> <p>The combine_features function takes in a dataframe and returns a new dataframe with the features combined. The features to be combined must be initialized in the <code>__init__</code> of the concrete class implementation.</p> <p>Parameters:</p> <ul> <li> <code>data</code>             (<code>DataFrame</code>)         \u2013          <p>pd.DataFrame: Pass in the dataframe that we want to transform</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>         \u2013          <p>A dataframe with the new features</p> </li> </ul> Source code in <code>niceml/data/featurecombiners/featurecombiner.py</code> <pre><code>@abstractmethod\ndef combine_features(self, data: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"\n    The combine_features function takes in a dataframe and returns a new dataframe\n    with the features combined. The features to be combined must be initialized\n    in the `__init__` of the concrete class implementation.\n\n    Args:\n        data: pd.DataFrame: Pass in the dataframe that we want to transform\n\n    Returns:\n        A dataframe with the new features\n    \"\"\"\n</code></pre>"},{"location":"reference/data/netdataloggers/__init__/","title":"netdataloggers","text":""},{"location":"reference/data/netdataloggers/__init__/#niceml.data.netdataloggers","title":"netdataloggers","text":""},{"location":"reference/data/netdataloggers/netdatalogger/","title":"netdatalogger","text":""},{"location":"reference/data/netdataloggers/netdatalogger/#niceml.data.netdataloggers.netdatalogger","title":"netdatalogger","text":"<p>Module fot the abstract NetDataLogger</p>"},{"location":"reference/data/netdataloggers/netdatalogger/#niceml.data.netdataloggers.netdatalogger-classes","title":"Classes","text":""},{"location":"reference/data/netdataloggers/netdatalogger/#niceml.data.netdataloggers.netdatalogger.NetDataLogger","title":"NetDataLogger","text":"<pre><code>NetDataLogger()\n</code></pre> <p>             Bases: <code>ABC</code></p> <p>Abstract implementation of an NetDataLogger</p> <p>Initializes the NetDataLogger with default values</p> Source code in <code>niceml/data/netdataloggers/netdatalogger.py</code> <pre><code>def __init__(self):\n    \"\"\"Initializes the NetDataLogger with default values\"\"\"\n    self.data_description = None\n    self.exp_context = None\n    self.set_name = None\n    self.output_path = None\n</code></pre>"},{"location":"reference/data/netdataloggers/netdatalogger/#niceml.data.netdataloggers.netdatalogger.NetDataLogger-functions","title":"Functions","text":""},{"location":"reference/data/netdataloggers/netdatalogger/#niceml.data.netdataloggers.netdatalogger.NetDataLogger.initialize","title":"initialize","text":"<pre><code>initialize(data_description, exp_context, set_name)\n</code></pre> <p>Method to initialize the NetDataLogger</p> Source code in <code>niceml/data/netdataloggers/netdatalogger.py</code> <pre><code>def initialize(\n    self,\n    data_description: DataDescription,\n    exp_context: ExperimentContext,\n    set_name: str,\n):\n    \"\"\"Method to initialize the NetDataLogger\"\"\"\n    self.data_description = data_description\n    self.exp_context = exp_context\n    self.set_name = set_name\n</code></pre>"},{"location":"reference/data/netdataloggers/netdatalogger/#niceml.data.netdataloggers.netdatalogger.NetDataLogger.log_data","title":"log_data  <code>abstractmethod</code>","text":"<pre><code>log_data(net_inputs, net_targets, data_info_list)\n</code></pre> <p>Logs the data sent as inputs and targets to a model, e.g. images and class labels or bounding boxes.</p> <p>Parameters:</p> <ul> <li> <code>net_inputs</code>             (<code>ndarray</code>)         \u2013          <p>Input data of a model as <code>np.ndarray</code></p> </li> <li> <code>net_targets</code>             (<code>ndarray</code>)         \u2013          <p>Target data of a model as <code>np.ndarray</code></p> </li> <li> <code>data_info_list</code>             (<code>List[DataInfo]</code>)         \u2013          <p>Associated data information of input and</p> </li> </ul> <p>Returns:</p> <ul> <li>         \u2013          <p>None</p> </li> </ul> Source code in <code>niceml/data/netdataloggers/netdatalogger.py</code> <pre><code>@abstractmethod\ndef log_data(\n    self,\n    net_inputs: np.ndarray,\n    net_targets: np.ndarray,\n    data_info_list: List[DataInfo],\n):\n    \"\"\"\n    Logs the data sent as inputs and targets to a model,\n    e.g. images and class labels or bounding boxes.\n\n    Args:\n        net_inputs: Input data of a model as `np.ndarray`\n        net_targets: Target data of a model as `np.ndarray`\n        data_info_list: Associated data information of input and\n        destination with extended information\n\n    Returns:\n        None\n\n    \"\"\"\n</code></pre>"},{"location":"reference/data/netdataloggers/objdetnetdatalogger/","title":"objdetnetdatalogger","text":""},{"location":"reference/data/netdataloggers/objdetnetdatalogger/#niceml.data.netdataloggers.objdetnetdatalogger","title":"objdetnetdatalogger","text":"<p>Module of the ObjDetNetDataLogger</p>"},{"location":"reference/data/netdataloggers/objdetnetdatalogger/#niceml.data.netdataloggers.objdetnetdatalogger-classes","title":"Classes","text":""},{"location":"reference/data/netdataloggers/objdetnetdatalogger/#niceml.data.netdataloggers.objdetnetdatalogger.ObjDetNetDataLogger","title":"ObjDetNetDataLogger","text":"<pre><code>ObjDetNetDataLogger(max_log=5)\n</code></pre> <p>             Bases: <code>NetDataLogger</code></p> <p>NetDataLogger for object detection</p> Source code in <code>niceml/data/netdataloggers/objdetnetdatalogger.py</code> <pre><code>def __init__(self, max_log: int = 5):\n    super().__init__()\n    self.max_log: int = max_log\n    self.anchor_generator: AnchorGenerator = AnchorGenerator()\n    self.log_count: int = 0\n</code></pre>"},{"location":"reference/data/netdataloggers/objdetnetdatalogger/#niceml.data.netdataloggers.objdetnetdatalogger.ObjDetNetDataLogger-functions","title":"Functions","text":""},{"location":"reference/data/netdataloggers/objdetnetdatalogger/#niceml.data.netdataloggers.objdetnetdatalogger.ObjDetNetDataLogger.log_data","title":"log_data","text":"<pre><code>log_data(net_inputs, net_targets, data_info_list)\n</code></pre> <p>Saves as many images with corresponding anchor boxes as defined in <code>self.max_log</code>. The images are saved into <code>self.output_path</code>. For each input image, the associated positively marked anchor boxes are added to the image.</p> <p>Parameters:</p> <ul> <li> <code>net_inputs</code>             (<code>ndarray</code>)         \u2013          <p>Input images as <code>np.ndarray</code></p> </li> <li> <code>net_targets</code>             (<code>ndarray</code>)         \u2013          <p>Targets as <code>np.ndarray</code> with the coded coordinates of the anchor boxes, the mask value and the one-hot-encoded class vector</p> </li> <li> <code>data_info_list</code>             (<code>List[ObjDetDataInfo]</code>)         \u2013          <p>Associated data information of input and destination with extended information</p> </li> </ul> <p>Returns:</p> <ul> <li>         \u2013          <p>None</p> </li> </ul> Source code in <code>niceml/data/netdataloggers/objdetnetdatalogger.py</code> <pre><code>def log_data(\n    self,\n    net_inputs: np.ndarray,\n    net_targets: np.ndarray,\n    data_info_list: List[ObjDetDataInfo],\n):\n    \"\"\"\n    Saves as many images with corresponding anchor boxes as defined in `self.max_log`.\n    The images are saved into `self.output_path`. For each input image,\n    the associated positively marked anchor boxes are added to the image.\n\n    Args:\n        net_inputs: Input images as `np.ndarray`\n        net_targets: Targets as `np.ndarray` with the coded coordinates\n            of the anchor boxes, the mask value and the one-hot-encoded class vector\n        data_info_list: Associated data information of input and destination\n            with extended information\n\n    Returns:\n        None\n    \"\"\"\n    if self.log_count &gt;= self.max_log:\n        return\n\n    output_data_description = check_instance(\n        self.data_description, OutputObjDetDataDescription\n    )\n\n    anchors = self.anchor_generator.generate_anchors(\n        data_description=output_data_description\n    )\n\n    if len(net_inputs) != len(net_targets):\n        raise ValueError(\n            f\"Mismatching lengths of net_inputs \"\n            f\"and net_targets ({len(net_inputs)}, {len(net_targets)}\"\n        )\n\n    for net_input, net_target, data_info in zip(\n        net_inputs, net_targets, data_info_list\n    ):\n        decoded_bboxes = [\n            anchor.decode(\n                predicted_values=target[:4],\n                box_variance=output_data_description.get_box_variance(),\n            ).get_absolute_ullr()\n            for anchor, target in zip(anchors, net_target)\n        ]\n        net_target[:, :4] = decoded_bboxes\n        positive_targets = net_target[net_target[:, 4] == POSITIVE_MASK_VALUE]\n        labels = [\n            self._target_to_label(target=target) for target in positive_targets\n        ]\n        self._draw_image(\n            image=net_input, instance_labels=labels, data_info=data_info\n        )\n\n        self.log_count += 1\n\n        if self.log_count &gt;= self.max_log:\n            break\n</code></pre>"},{"location":"reference/data/netdataloggers/objdetnetdatalogger/#niceml.data.netdataloggers.objdetnetdatalogger-functions","title":"Functions","text":""},{"location":"reference/data/netdataloggers/semsegnetdatalogger/","title":"semsegnetdatalogger","text":""},{"location":"reference/data/netdataloggers/semsegnetdatalogger/#niceml.data.netdataloggers.semsegnetdatalogger","title":"semsegnetdatalogger","text":"<p>Module of the SemSegNetDataLogger</p>"},{"location":"reference/data/netdataloggers/semsegnetdatalogger/#niceml.data.netdataloggers.semsegnetdatalogger-classes","title":"Classes","text":""},{"location":"reference/data/netdataloggers/semsegnetdatalogger/#niceml.data.netdataloggers.semsegnetdatalogger.SemSegNetDataLogger","title":"SemSegNetDataLogger","text":"<pre><code>SemSegNetDataLogger(max_log=10, scale=True)\n</code></pre> <p>             Bases: <code>NetDataLogger</code></p> <p>NetDataLogger for semantic segmentation</p> <p>initialize SemSegNetDataLogger parameters</p> Source code in <code>niceml/data/netdataloggers/semsegnetdatalogger.py</code> <pre><code>def __init__(self, max_log: int = 10, scale: bool = True):\n    \"\"\"initialize SemSegNetDataLogger parameters\"\"\"\n    super().__init__()\n    self.scale: bool = scale  # If true, the masks are scaled to the image size.\n    # If false the images are scaled to the mask size.\n    self.max_log: int = max_log\n    self.log_count: int = 0\n    self.mask_colors: List[Tuple[int]] = []\n</code></pre>"},{"location":"reference/data/netdataloggers/semsegnetdatalogger/#niceml.data.netdataloggers.semsegnetdatalogger.SemSegNetDataLogger-functions","title":"Functions","text":""},{"location":"reference/data/netdataloggers/semsegnetdatalogger/#niceml.data.netdataloggers.semsegnetdatalogger.SemSegNetDataLogger.initialize","title":"initialize","text":"<pre><code>initialize(data_description, exp_context, set_name)\n</code></pre> <p>initialize SemSegNetDataLogger parameters before training</p> Source code in <code>niceml/data/netdataloggers/semsegnetdatalogger.py</code> <pre><code>def initialize(\n    self,\n    data_description: OutputImageDataDescription,\n    exp_context: ExperimentContext,\n    set_name: str,\n):\n    \"\"\"initialize SemSegNetDataLogger parameters before training\"\"\"\n    super().initialize(\n        data_description=data_description,\n        exp_context=exp_context,\n        set_name=set_name,\n    )\n\n    mask_colors = get_color_array(\n        list(range(self.data_description.get_output_channel_count()))\n    )\n    self.mask_colors = [\n        [int(value * 255) for value in color] for color in mask_colors\n    ]\n</code></pre>"},{"location":"reference/data/netdataloggers/semsegnetdatalogger/#niceml.data.netdataloggers.semsegnetdatalogger.SemSegNetDataLogger.log_data","title":"log_data","text":"<pre><code>log_data(net_inputs, net_targets, data_info_list)\n</code></pre> <p>Saves as many images with corresponding masks as defined in <code>self.max_log</code>. The images are saved into <code>self.output_path</code>. For each input image, the associated masks are added to the image.</p> <p>Parameters:</p> <ul> <li> <code>net_inputs</code>             (<code>ndarray</code>)         \u2013          <p>Input images as <code>np.ndarray</code></p> </li> <li> <code>net_targets</code>             (<code>ndarray</code>)         \u2013          <p>Target masks as <code>np.ndarray</code> scaled by OUTPUT_IMAGE_SIZE_DIVISOR</p> </li> <li> <code>data_info_list</code>             (<code>List[SemSegDataInfo]</code>)         \u2013          <p>Associated data information of input and</p> </li> </ul> <p>Returns:</p> <ul> <li>         \u2013          <p>None</p> </li> </ul> Source code in <code>niceml/data/netdataloggers/semsegnetdatalogger.py</code> <pre><code>def log_data(\n    self,\n    net_inputs: np.ndarray,\n    net_targets: np.ndarray,\n    data_info_list: List[SemSegDataInfo],\n):\n    \"\"\"\n    Saves as many images with corresponding masks as defined in `self.max_log`.\n    The images are saved into `self.output_path`. For each input image,\n    the associated masks are added to the image.\n\n    Args:\n        net_inputs: Input images as `np.ndarray`\n        net_targets: Target masks as `np.ndarray` scaled by OUTPUT_IMAGE_SIZE_DIVISOR\n        data_info_list: Associated data information of input and\n        destination with extended information\n\n    Returns:\n        None\n    \"\"\"\n    if self.log_count &gt;= self.max_log:\n        return\n\n    for net_input, net_target, data_info in zip(\n        net_inputs, net_targets, data_info_list\n    ):\n        instance_labels = [\n            SemSegInstanceLabel(\n                class_name=self.data_description.get_output_channel_names()[\n                    class_idx\n                ],\n                class_index=class_idx,\n                color=tuple(self.mask_colors[class_idx]),\n                active=True,\n                mask=net_target[:, :, class_idx] * 255,\n                # `draw_error_mask_on_image` doesn't work with binary masks.\n                # RGB values are required. * 255 converts mask to RGB\n            )\n            for class_idx in range(self.data_description.get_output_channel_count())\n            if net_target[:, :, class_idx].max() &gt; 0\n        ]\n\n        if self.scale:\n            factor = ImageSize(\n                net_input.shape[1], net_input.shape[0]\n            ).get_division_factor(self.data_description.get_output_image_size())\n            instance_labels = [\n                label.scale_label(scale_factor=factor) for label in instance_labels\n            ]\n\n        self._draw_image(\n            image=net_input,\n            instance_labels=instance_labels,\n            data_info=data_info,\n        )\n        self.log_count += 1\n        if self.log_count &gt;= self.max_log:\n            break\n</code></pre>"},{"location":"reference/data/netdataloggers/semsegnetdatalogger/#niceml.data.netdataloggers.semsegnetdatalogger-functions","title":"Functions","text":""},{"location":"reference/data/normalization/__init__/","title":"normalization","text":""},{"location":"reference/data/normalization/__init__/#niceml.data.normalization","title":"normalization","text":""},{"location":"reference/data/normalization/minmax/","title":"minmax","text":""},{"location":"reference/data/normalization/minmax/#niceml.data.normalization.minmax","title":"minmax","text":"<p>Module for dataframe normalization functions</p>"},{"location":"reference/data/normalization/minmax/#niceml.data.normalization.minmax-classes","title":"Classes","text":""},{"location":"reference/data/normalization/minmax/#niceml.data.normalization.minmax-functions","title":"Functions","text":""},{"location":"reference/data/normalization/minmax/#niceml.data.normalization.minmax.denormalize_column","title":"denormalize_column","text":"<pre><code>denormalize_column(norm_info, data)\n</code></pre> <p>The denormalize_column function takes a <code>norm_info</code> of data and denormalizes it.</p> <p>Parameters:</p> <ul> <li> <code>norm_info</code>             (<code>NormalizationInfo</code>)         \u2013          <p>NormalizationInfo: Specify the type of normalization used</p> </li> <li> <code>data</code>             (<code>DataFrame</code>)         \u2013          <p>pd.DataFrame: Pass in the dataframe that is being normalized</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>         \u2013          <p>A pandas dataframe with the column denormalized</p> </li> </ul> Source code in <code>niceml/data/normalization/minmax.py</code> <pre><code>def denormalize_column(\n    norm_info: NormalizationInfo, data: pd.DataFrame\n) -&gt; pd.DataFrame:\n    \"\"\"\n    The denormalize_column function takes a `norm_info` of data and denormalizes it.\n\n    Args:\n        norm_info: NormalizationInfo: Specify the type of normalization used\n        data: pd.DataFrame: Pass in the dataframe that is being normalized\n\n    Returns:\n        A pandas dataframe with the column denormalized\n    \"\"\"\n    if isinstance(norm_info, ScalarNormalizationInfo):\n        data[norm_info.feature_key] = (\n            data[norm_info.feature_key] * norm_info.divisor + norm_info.offset\n        )\n    elif isinstance(norm_info, (BinaryNormalizationInfo, CategoricalNormalizationInfo)):\n        data[norm_info.feature_key] = data[norm_info.feature_key].map(\n            lambda cur_val: norm_info.values[cur_val]\n        )\n    else:\n        raise NotImplementedError\n    return data\n</code></pre>"},{"location":"reference/data/normalization/minmax/#niceml.data.normalization.minmax.normalize_binary_column","title":"normalize_binary_column","text":"<pre><code>normalize_binary_column(dataframe, column_key)\n</code></pre> <p>The normalize_binary_column function takes a dataframe and the key of a column in that dataframe.It then checks to make sure that there are only two unique values in the column, and if so, it replaces those values with 0s and 1s. It returns both the normalized dataframe and an object containing information about how the normalization was performed.</p> <p>Parameters:</p> <ul> <li> <code>dataframe</code>             (<code>DataFrame</code>)         \u2013          <p>Pass in the dataframe that we want to normalize</p> </li> <li> <code>column_key</code>             (<code>str</code>)         \u2013          <p>Specify the column that we want to normalize</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>         \u2013          <p>A tuple of the dataframe with the normalized column (<code>column_key</code>)</p> </li> <li> <code>BinaryNormalizationInfo</code>         \u2013          <p>and a <code>BinaryNormalizationInfo</code> object</p> </li> </ul> Source code in <code>niceml/data/normalization/minmax.py</code> <pre><code>def normalize_binary_column(\n    dataframe: pd.DataFrame, column_key: str\n) -&gt; Tuple[pd.DataFrame, BinaryNormalizationInfo]:\n    \"\"\"\n    The normalize_binary_column function takes a dataframe and the key of a column in\n    that dataframe.It then checks to make sure that there are only two unique values\n    in the column, and if so, it replaces those values with 0s and 1s. It returns both\n    the normalized dataframe and an object containing information about how\n    the normalization was performed.\n\n    Args:\n        dataframe:  Pass in the dataframe that we want to normalize\n        column_key: Specify the column that we want to normalize\n\n    Returns:\n        A tuple of the dataframe with the normalized column (`column_key`)\n        and a `BinaryNormalizationInfo` object\n    \"\"\"\n    values = list(sorted(dataframe[column_key].unique()))\n    binary_value_count = 2\n    if len(values) &gt; binary_value_count:\n        raise ValueError(\"Binary column must have more than two unique values.\")\n\n    dataframe[column_key] = dataframe[column_key].apply(lambda x: values.index(x))\n\n    norm_info = BinaryNormalizationInfo(feature_key=column_key, values=values)\n    return dataframe, norm_info\n</code></pre>"},{"location":"reference/data/normalization/minmax/#niceml.data.normalization.minmax.normalize_categorical_column","title":"normalize_categorical_column","text":"<pre><code>normalize_categorical_column(dataframe, column_key)\n</code></pre> <p>Normalizes a categorical column in the given DataFrame.</p> <p>This function takes a <code>dataframe</code> and a `column_key\u00b4 representing a categorical column. It replaces the categorical values with their corresponding indices in a sorted order. The normalization information is also returned.</p> <p>Parameters:</p> <ul> <li> <code>dataframe</code>             (<code>DataFrame</code>)         \u2013          <p>The DataFrame containing the categorical column.</p> </li> <li> <code>column_key</code>             (<code>str</code>)         \u2013          <p>The column key of the categorical column to be normalized.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>         \u2013          <p>A tuple containing DataFrame with the normalized column (<code>column_key</code>) and a</p> </li> <li> <code>CategoricalNormalizationInfo</code>         \u2013          <p>CategoricalNormalizationInfo object.</p> </li> </ul> Source code in <code>niceml/data/normalization/minmax.py</code> <pre><code>def normalize_categorical_column(\n    dataframe: pd.DataFrame, column_key: str\n) -&gt; Tuple[pd.DataFrame, CategoricalNormalizationInfo]:\n    \"\"\"\n    Normalizes a categorical column in the given DataFrame.\n\n    This function takes a `dataframe` and a `column_key\u00b4 representing a categorical\n    column. It replaces the categorical values with their corresponding indices\n    in a sorted order. The normalization information is also returned.\n\n    Args:\n        dataframe: The DataFrame containing the categorical column.\n        column_key: The column key of the categorical column to be normalized.\n\n    Returns:\n        A tuple containing DataFrame with the normalized column (`column_key`) and a\n        CategoricalNormalizationInfo object.\n    \"\"\"\n\n    values = list(sorted(dataframe[column_key].unique()))\n    dataframe[column_key] = dataframe[column_key].apply(lambda x: values.index(x))\n    norm_info = CategoricalNormalizationInfo(feature_key=column_key, values=values)\n    return dataframe, norm_info\n</code></pre>"},{"location":"reference/data/normalization/minmax/#niceml.data.normalization.minmax.normalize_scalar_column","title":"normalize_scalar_column","text":"<pre><code>normalize_scalar_column(dataframe, column_key)\n</code></pre> <p>The normalize_scalar_col function takes a dataframe and a column key as input. It returns the normalized dataframe and the normalization information for that column. The normalization is done by subtracting the minimum value from each element in that column, and then dividing by (max - min). The offset is equal to min_val, and divisor = max_val - min_val.</p> <p>Parameters:</p> <ul> <li> <code>dataframe</code>             (<code>DataFrame</code>)         \u2013          <p>pd.DataFrame: Pass in the dataframe to be normalized</p> </li> <li> <code>column_key</code>         \u2013          <p>Specify which column to normalize</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>         \u2013          <p>A tuple of the dataframe with the normalized column (<code>column_key</code>)</p> </li> <li> <code>ScalarNormalizationInfo</code>         \u2013          <p>and a <code>ScalarNormalizationInfo</code> object</p> </li> </ul> Source code in <code>niceml/data/normalization/minmax.py</code> <pre><code>def normalize_scalar_column(\n    dataframe: pd.DataFrame, column_key\n) -&gt; Tuple[pd.DataFrame, ScalarNormalizationInfo]:\n    \"\"\"\n    The normalize_scalar_col function takes a dataframe and a column key as input.\n    It returns the normalized dataframe and the normalization information for that column.\n    The normalization is done by subtracting the minimum value from each element in that column,\n    and then dividing by (max - min). The offset is equal to min_val, and\n    divisor = max_val - min_val.\n\n    Args:\n        dataframe: pd.DataFrame: Pass in the dataframe to be normalized\n        column_key: Specify which column to normalize\n\n    Returns:\n        A tuple of the dataframe with the normalized column (`column_key`)\n        and a `ScalarNormalizationInfo` object\n\n    \"\"\"\n    min_val = dataframe[column_key].min()\n    max_val = dataframe[column_key].max()\n\n    divisor = max_val - min_val\n\n    if divisor == 0:\n        divisor = 1\n\n    dataframe[column_key] = (dataframe[column_key] - min_val) / divisor\n\n    norm_info = ScalarNormalizationInfo(\n        feature_key=column_key, offset=float(min_val), divisor=float(divisor)\n    )\n\n    return dataframe, norm_info\n</code></pre>"},{"location":"reference/data/normalization/normalization/","title":"normalization","text":""},{"location":"reference/data/normalization/normalization/#niceml.data.normalization.normalization","title":"normalization","text":"<p>Module for NormalizationInfo</p>"},{"location":"reference/data/normalization/normalization/#niceml.data.normalization.normalization-classes","title":"Classes","text":""},{"location":"reference/data/normalization/normalization/#niceml.data.normalization.normalization.BinaryNormalizationInfo","title":"BinaryNormalizationInfo","text":"<p>             Bases: <code>NormalizationInfo</code></p> <p>Class for binary normalization infos</p>"},{"location":"reference/data/normalization/normalization/#niceml.data.normalization.normalization.CategoricalNormalizationInfo","title":"CategoricalNormalizationInfo","text":"<p>             Bases: <code>NormalizationInfo</code></p> <p>Class for categorical normalization infos</p>"},{"location":"reference/data/normalization/normalization/#niceml.data.normalization.normalization.NormalizationInfo","title":"NormalizationInfo","text":"<p>Class for normalization infos</p>"},{"location":"reference/data/normalization/normalization/#niceml.data.normalization.normalization.ScalarNormalizationInfo","title":"ScalarNormalizationInfo","text":"<p>             Bases: <code>NormalizationInfo</code></p> <p>Class for scalar normalization infos</p>"},{"location":"reference/data/storages/__init__/","title":"storages","text":""},{"location":"reference/data/storages/__init__/#niceml.data.storages","title":"storages","text":""},{"location":"reference/data/storages/fsfilesystemstorage/","title":"fsfilesystemstorage","text":""},{"location":"reference/data/storages/fsfilesystemstorage/#niceml.data.storages.fsfilesystemstorage","title":"fsfilesystemstorage","text":"<p>Module for fsspec storage</p>"},{"location":"reference/data/storages/fsfilesystemstorage/#niceml.data.storages.fsfilesystemstorage-classes","title":"Classes","text":""},{"location":"reference/data/storages/fsfilesystemstorage/#niceml.data.storages.fsfilesystemstorage.FsFileSystemStorage","title":"FsFileSystemStorage","text":"<pre><code>FsFileSystemStorage(file_system, root_dir)\n</code></pre> <p>             Bases: <code>StorageInterface</code></p> <p>A CloudStorageInterface to interact with fsspec isntances</p> <p>Creates a new FSSpecStorage instance.</p> Source code in <code>niceml/data/storages/fsfilesystemstorage.py</code> <pre><code>def __init__(self, file_system: AbstractFileSystem, root_dir: str):\n    \"\"\"\n    Creates a new FSSpecStorage instance.\n    \"\"\"\n    self.file_system = file_system\n    self.root_dir = root_dir\n</code></pre>"},{"location":"reference/data/storages/fsfilesystemstorage/#niceml.data.storages.fsfilesystemstorage.FsFileSystemStorage-functions","title":"Functions","text":""},{"location":"reference/data/storages/fsfilesystemstorage/#niceml.data.storages.fsfilesystemstorage.FsFileSystemStorage.download_as_str","title":"download_as_str","text":"<pre><code>download_as_str(bucket_path)\n</code></pre> <p>returns the given bucket_path content as string</p> <p>Raises:</p> <ul> <li> <code>RuntimeError</code>           \u2013          <p>If the given bucket_path is not part of the currently opended filesystem.</p> </li> </ul> Source code in <code>niceml/data/storages/fsfilesystemstorage.py</code> <pre><code>def download_as_str(self, bucket_path: str) -&gt; str:\n    \"\"\"returns the given bucket_path content as string\n\n    Raises:\n        RuntimeError:\n            If the given bucket_path is not part of the currently opended\n            filesystem.\n    \"\"\"\n\n    return self.file_system.cat(self.join_paths(self.root_dir, bucket_path))\n</code></pre>"},{"location":"reference/data/storages/fsfilesystemstorage/#niceml.data.storages.fsfilesystemstorage.FsFileSystemStorage.download_data","title":"download_data","text":"<pre><code>download_data(bucket_path, local_path, recursive=True)\n</code></pre> <p>downloads a given object to the specified local_path</p> <p>Raises:</p> <ul> <li> <code>RuntimeError</code>           \u2013          <p>If the given bucket_path is not part of the currently opended filesystem.</p> </li> </ul> Source code in <code>niceml/data/storages/fsfilesystemstorage.py</code> <pre><code>def download_data(self, bucket_path: str, local_path: str, recursive: bool = True):\n    \"\"\"downloads a given object to the specified local_path\n\n    Raises:\n        RuntimeError:\n            If the given bucket_path is not part of the currently opended\n            filesystem.\n    \"\"\"\n    local_dir = dirname(local_path)\n    if not isdir(local_dir):\n        makedirs(local_dir)\n    self.file_system.download(\n        self.join_paths(self.root_dir, bucket_path), local_path, recursive=recursive\n    )\n</code></pre>"},{"location":"reference/data/storages/fsfilesystemstorage/#niceml.data.storages.fsfilesystemstorage.FsFileSystemStorage.join_paths","title":"join_paths","text":"<pre><code>join_paths(*paths)\n</code></pre> <p>joins the given paths with the fsspec specific path seperator</p> Source code in <code>niceml/data/storages/fsfilesystemstorage.py</code> <pre><code>def join_paths(self, *paths: str) -&gt; str:\n    \"\"\"joins the given paths with the fsspec specific path seperator\"\"\"\n    paths = [path for path in paths if len(path) &gt; 0]\n    return self.file_system.sep.join(paths)\n</code></pre>"},{"location":"reference/data/storages/fsfilesystemstorage/#niceml.data.storages.fsfilesystemstorage.FsFileSystemStorage.list_data","title":"list_data","text":"<pre><code>list_data(path=None)\n</code></pre> <p>recusively lists all objects in the given path</p> Source code in <code>niceml/data/storages/fsfilesystemstorage.py</code> <pre><code>def list_data(self, path: Optional[str] = None) -&gt; List[str]:\n    \"\"\"recusively lists all objects in the given path\"\"\"\n    target_path = (\n        self.root_dir if path is None else self.join_paths(self.root_dir, path)\n    )\n    item_list = list_dir(\n        target_path,\n        return_full_path=True,\n        recursive=True,\n        file_system=self.file_system,\n    )\n    item_list = [relpath(cur_file, self.root_dir) for cur_file in item_list]\n    return item_list\n</code></pre>"},{"location":"reference/data/storages/fsfilesystemstorage/#niceml.data.storages.fsfilesystemstorage-functions","title":"Functions","text":""},{"location":"reference/data/storages/fsspecstorage/","title":"fsspecstorage","text":""},{"location":"reference/data/storages/fsspecstorage/#niceml.data.storages.fsspecstorage","title":"fsspecstorage","text":"<p>Module for fsspec storage</p>"},{"location":"reference/data/storages/fsspecstorage/#niceml.data.storages.fsspecstorage-classes","title":"Classes","text":""},{"location":"reference/data/storages/fsspecstorage/#niceml.data.storages.fsspecstorage.FSSpecStorage","title":"FSSpecStorage","text":"<pre><code>FSSpecStorage(fsconfig)\n</code></pre> <p>             Bases: <code>StorageInterface</code></p> <p>A CloudStorageInterface to interact with fsspec isntances</p> <p>Creates a new FSSpecStorage instance.</p> <p>Parameters:</p> <ul> <li> <code>fsconfig</code>             (<code>FSSpecStorage |\u00a0Dict[str, Any]</code>)         \u2013          <p>The fsspec configuration to open the filesystem with</p> </li> </ul> Source code in <code>niceml/data/storages/fsspecstorage.py</code> <pre><code>def __init__(self, fsconfig: Union[LocationConfig, Dict[str, Any]]):\n    \"\"\"\n    Creates a new FSSpecStorage instance.\n\n    Args:\n        fsconfig (FSSpecStorage |\u00a0Dict[str, Any]):\n            The fsspec configuration to open the filesystem with\n    \"\"\"\n    self._fsconfig = fsconfig\n</code></pre>"},{"location":"reference/data/storages/fsspecstorage/#niceml.data.storages.fsspecstorage.FSSpecStorage-functions","title":"Functions","text":""},{"location":"reference/data/storages/fsspecstorage/#niceml.data.storages.fsspecstorage.FSSpecStorage.download_as_str","title":"download_as_str","text":"<pre><code>download_as_str(bucket_path)\n</code></pre> <p>returns the given bucket_path content as string</p> <p>Raises:</p> <ul> <li> <code>RuntimeError</code>           \u2013          <p>If the given bucket_path is not part of the currently opended filesystem.</p> </li> </ul> Source code in <code>niceml/data/storages/fsspecstorage.py</code> <pre><code>def download_as_str(self, bucket_path: str) -&gt; str:\n    \"\"\"returns the given bucket_path content as string\n\n    Raises:\n        RuntimeError:\n            If the given bucket_path is not part of the currently opended\n            filesystem.\n    \"\"\"\n    with open_location(self._fsconfig) as (filesystem, path):\n        return filesystem.cat(self.join_paths(path, bucket_path))\n</code></pre>"},{"location":"reference/data/storages/fsspecstorage/#niceml.data.storages.fsspecstorage.FSSpecStorage.download_data","title":"download_data","text":"<pre><code>download_data(bucket_path, local_path, recursive=True)\n</code></pre> <p>downloads a given object to the specified local_path</p> <p>Raises:</p> <ul> <li> <code>RuntimeError</code>           \u2013          <p>If the given bucket_path is not part of the currently opended filesystem.</p> </li> </ul> Source code in <code>niceml/data/storages/fsspecstorage.py</code> <pre><code>def download_data(self, bucket_path: str, local_path: str, recursive: bool = True):\n    \"\"\"downloads a given object to the specified local_path\n\n    Raises:\n        RuntimeError:\n            If the given bucket_path is not part of the currently opended\n            filesystem.\n    \"\"\"\n    with open_location(self._fsconfig) as (filesystem, path):\n        local_dir = dirname(local_path)\n        if not isdir(local_dir):\n            makedirs(local_dir)\n        filesystem.download(\n            self.join_paths(path, bucket_path), local_path, recursive=recursive\n        )\n</code></pre>"},{"location":"reference/data/storages/fsspecstorage/#niceml.data.storages.fsspecstorage.FSSpecStorage.join_paths","title":"join_paths","text":"<pre><code>join_paths(*paths)\n</code></pre> <p>joins the given paths with the fsspec specific path seperator</p> Source code in <code>niceml/data/storages/fsspecstorage.py</code> <pre><code>def join_paths(self, *paths: str) -&gt; str:\n    \"\"\"joins the given paths with the fsspec specific path seperator\"\"\"\n    paths = [path for path in paths if len(path) &gt; 0]\n    with open_location(self._fsconfig) as (filesystem, _):\n        return filesystem.sep.join(paths)\n</code></pre>"},{"location":"reference/data/storages/fsspecstorage/#niceml.data.storages.fsspecstorage.FSSpecStorage.list_data","title":"list_data","text":"<pre><code>list_data(path=None)\n</code></pre> <p>recusively lists all objects in the given path</p> Source code in <code>niceml/data/storages/fsspecstorage.py</code> <pre><code>def list_data(self, path: Optional[str] = None) -&gt; List[str]:\n    \"\"\"recusively lists all objects in the given path\"\"\"\n    with open_location(self._fsconfig) as (filesystem, fspath):\n        target_path = fspath if path is None else self.join_paths(fspath, path)\n        item_list = list_dir(\n            target_path,\n            return_full_path=True,\n            recursive=True,\n            file_system=filesystem,\n        )\n        item_list = [relpath(cur_file, fspath) for cur_file in item_list]\n    return item_list\n</code></pre>"},{"location":"reference/data/storages/fsspecstorage/#niceml.data.storages.fsspecstorage-functions","title":"Functions","text":""},{"location":"reference/data/storages/localstorage/","title":"localstorage","text":""},{"location":"reference/data/storages/localstorage/#niceml.data.storages.localstorage","title":"localstorage","text":"<p>Module for local storage</p>"},{"location":"reference/data/storages/localstorage/#niceml.data.storages.localstorage-classes","title":"Classes","text":""},{"location":"reference/data/storages/localstorage/#niceml.data.storages.localstorage.LocalStorage","title":"LocalStorage","text":"<pre><code>LocalStorage(working_directory=None)\n</code></pre> <p>             Bases: <code>StorageInterface</code></p> <p>Implementation of StorageInterface for local storage</p> Source code in <code>niceml/data/storages/localstorage.py</code> <pre><code>def __init__(self, working_directory: Optional[str] = None):\n    self.working_directory = working_directory\n</code></pre>"},{"location":"reference/data/storages/localstorage/#niceml.data.storages.localstorage-functions","title":"Functions","text":""},{"location":"reference/data/storages/storagehandler/","title":"storagehandler","text":""},{"location":"reference/data/storages/storagehandler/#niceml.data.storages.storagehandler","title":"storagehandler","text":"<p>Handles multiple storages for the dashboard</p>"},{"location":"reference/data/storages/storagehandler/#niceml.data.storages.storagehandler-classes","title":"Classes","text":""},{"location":"reference/data/storages/storagehandler/#niceml.data.storages.storagehandler.StorageHandler","title":"StorageHandler","text":"<pre><code>StorageHandler(storages)\n</code></pre> <p>Handles multiple storages for the dashboard</p> Source code in <code>niceml/data/storages/storagehandler.py</code> <pre><code>def __init__(self, storages: Dict[str, StorageInterface]):\n    self.storages = storages\n</code></pre>"},{"location":"reference/data/storages/storagehandler/#niceml.data.storages.storagehandler.StorageHandler-functions","title":"Functions","text":""},{"location":"reference/data/storages/storagehandler/#niceml.data.storages.storagehandler.StorageHandler.get_storage","title":"get_storage","text":"<pre><code>get_storage(name)\n</code></pre> <p>Returns the storage with the given name</p> Source code in <code>niceml/data/storages/storagehandler.py</code> <pre><code>def get_storage(self, name: str) -&gt; StorageInterface:\n    \"\"\"Returns the storage with the given name\"\"\"\n    try:\n        return self.storages[name]\n    except KeyError as error:\n        raise StorageNotAvailableError(\n            f\"Storage with name: {name} not available!\"\n        ) from error\n</code></pre>"},{"location":"reference/data/storages/storagehandler/#niceml.data.storages.storagehandler.StorageHandler.get_storage_names","title":"get_storage_names","text":"<pre><code>get_storage_names()\n</code></pre> <p>Returns a list of all storage names</p> Source code in <code>niceml/data/storages/storagehandler.py</code> <pre><code>def get_storage_names(self) -&gt; List[str]:\n    \"\"\"Returns a list of all storage names\"\"\"\n    return list(self.storages.keys())\n</code></pre>"},{"location":"reference/data/storages/storagehandler/#niceml.data.storages.storagehandler.StorageNotAvailableError","title":"StorageNotAvailableError","text":"<p>             Bases: <code>Exception</code></p> <p>Error when the name of the storage is not declared</p>"},{"location":"reference/data/storages/storageinterface/","title":"storageinterface","text":""},{"location":"reference/data/storages/storageinterface/#niceml.data.storages.storageinterface","title":"storageinterface","text":""},{"location":"reference/data/storages/storageinterface/#niceml.data.storages.storageinterface-classes","title":"Classes","text":""},{"location":"reference/data/storages/storageinterface/#niceml.data.storages.storageinterface.StorageInterface","title":"StorageInterface","text":"<p>             Bases: <code>ABC</code></p> <p>Interface for cloud storage access</p>"},{"location":"reference/data/storages/storageinterface/#niceml.data.storages.storageinterface.StorageInterface-functions","title":"Functions","text":""},{"location":"reference/data/storages/storageinterface/#niceml.data.storages.storageinterface.StorageInterface.download_as_str","title":"download_as_str  <code>abstractmethod</code>","text":"<pre><code>download_as_str(bucket_path)\n</code></pre> <p>Dowloads the file and returns it as byte string</p> Source code in <code>niceml/data/storages/storageinterface.py</code> <pre><code>@abstractmethod\ndef download_as_str(self, bucket_path: str) -&gt; bytes:\n    \"\"\"Dowloads the file and returns it as byte string\"\"\"\n</code></pre>"},{"location":"reference/data/storages/storageinterface/#niceml.data.storages.storageinterface.StorageInterface.download_data","title":"download_data  <code>abstractmethod</code>","text":"<pre><code>download_data(bucket_path, local_path)\n</code></pre> <p>Downloads the file from the bucket and stores it locally</p> Source code in <code>niceml/data/storages/storageinterface.py</code> <pre><code>@abstractmethod\ndef download_data(self, bucket_path: str, local_path: str):\n    \"\"\"Downloads the file from the bucket and stores it locally\"\"\"\n</code></pre>"},{"location":"reference/data/storages/storageinterface/#niceml.data.storages.storageinterface.StorageInterface.join_paths","title":"join_paths  <code>abstractmethod</code>","text":"<pre><code>join_paths(*paths)\n</code></pre> <p>Joins the paths with the correct separator</p> Source code in <code>niceml/data/storages/storageinterface.py</code> <pre><code>@abstractmethod\ndef join_paths(self, *paths) -&gt; str:\n    \"\"\"Joins the paths with the correct separator\"\"\"\n</code></pre>"},{"location":"reference/data/storages/storageinterface/#niceml.data.storages.storageinterface.StorageInterface.list_data","title":"list_data  <code>abstractmethod</code>","text":"<pre><code>list_data(path=None)\n</code></pre> <p>Lists all files recursively from the given directory Returns absolute paths</p> Source code in <code>niceml/data/storages/storageinterface.py</code> <pre><code>@abstractmethod\ndef list_data(self, path: Optional[str] = None) -&gt; List[str]:\n    \"\"\"Lists all files recursively from the given directory\n    Returns absolute paths\"\"\"\n</code></pre>"},{"location":"reference/data/storages/storageinterface/#niceml.data.storages.storageinterface.StorageInterface.list_experiments","title":"list_experiments  <code>abstractmethod</code>","text":"<pre><code>list_experiments(path=None)\n</code></pre> <p>Lists all experiment infos of the given path</p> Source code in <code>niceml/data/storages/storageinterface.py</code> <pre><code>@abstractmethod\ndef list_experiments(self, path: Optional[str] = None) -&gt; List[ExperimentInfo]:\n    \"\"\"Lists all experiment infos of the given path\"\"\"\n</code></pre>"},{"location":"reference/dlframeworks/__init__/","title":"dlframeworks","text":""},{"location":"reference/dlframeworks/__init__/#niceml.dlframeworks","title":"dlframeworks","text":""},{"location":"reference/dlframeworks/keras/__init__/","title":"keras","text":""},{"location":"reference/dlframeworks/keras/__init__/#niceml.dlframeworks.keras","title":"keras","text":""},{"location":"reference/dlframeworks/keras/kerasmetrics/","title":"kerasmetrics","text":""},{"location":"reference/dlframeworks/keras/kerasmetrics/#niceml.dlframeworks.keras.kerasmetrics","title":"kerasmetrics","text":"<p>Module for metrics in keras</p>"},{"location":"reference/dlframeworks/keras/kerasmetrics/#niceml.dlframeworks.keras.kerasmetrics-classes","title":"Classes","text":""},{"location":"reference/dlframeworks/keras/kerasmetrics/#niceml.dlframeworks.keras.kerasmetrics.MeanIoU","title":"MeanIoU","text":"<pre><code>MeanIoU(name='mean_iou')\n</code></pre> <p>Keras Metric for Mean IoU</p> Source code in <code>niceml/dlframeworks/keras/kerasmetrics.py</code> <pre><code>def __init__(self, name: str = \"mean_iou\"):\n    self.__name__ = name\n</code></pre>"},{"location":"reference/dlframeworks/keras/kerasmodelloader/","title":"kerasmodelloader","text":""},{"location":"reference/dlframeworks/keras/kerasmodelloader/#niceml.dlframeworks.keras.kerasmodelloader","title":"kerasmodelloader","text":"<p>Module for KerasModelLoader</p>"},{"location":"reference/dlframeworks/keras/kerasmodelloader/#niceml.dlframeworks.keras.kerasmodelloader-classes","title":"Classes","text":""},{"location":"reference/dlframeworks/keras/kerasmodelloader/#niceml.dlframeworks.keras.kerasmodelloader.KerasModelLoader","title":"KerasModelLoader","text":"<pre><code>KerasModelLoader(\n    model_custom_objects=None, compile_model=False\n)\n</code></pre> <p>             Bases: <code>ModelLoader</code></p> <p>Interface implementation to load a keras model</p> <p>Constructor for KerasModelLoader</p> <p>:param model_custom_objects: Optional custom objects to load the model. In Keras it is possible to pass custom objects during model loading. :param compile_model: Flag if the model should be compiled after loading</p> Source code in <code>niceml/dlframeworks/keras/kerasmodelloader.py</code> <pre><code>def __init__(\n    self,\n    model_custom_objects: Optional[ModelCustomLoadObjects] = None,\n    compile_model: bool = False,\n):\n    \"\"\"\n    Constructor for KerasModelLoader\n\n    :param model_custom_objects: Optional custom objects to load the model.\n    In Keras it is possible to pass custom objects during model loading.\n    :param compile_model: Flag if the model should be compiled after loading\n    \"\"\"\n    self.compile_model = compile_model\n    self.model_custom_objects: ModelCustomLoadObjects = (\n        model_custom_objects or ModelCustomLoadObjects()\n    )\n</code></pre>"},{"location":"reference/dlframeworks/keras/kerasmodelloader/#niceml.dlframeworks.keras.kerasmodelloader.KerasModelLoader-functions","title":"Functions","text":""},{"location":"reference/dlframeworks/keras/kerasmodelloader/#niceml.dlframeworks.keras.kerasmodelloader.KerasModelLoader.__call__","title":"__call__","text":"<pre><code>__call__(model_path, file_system=None)\n</code></pre> <p>Loads the model at the given path</p> Source code in <code>niceml/dlframeworks/keras/kerasmodelloader.py</code> <pre><code>def __call__(\n    self,\n    model_path: str,\n    file_system: Optional[AbstractFileSystem] = None,\n) -&gt; Any:\n    \"\"\"Loads the model at the given path\"\"\"\n    file_system = file_system or LocalFileSystem()\n    with TemporaryDirectory() as tmp_dir:\n        tmp_model_path = join(tmp_dir, \"model.hdf5\")\n        with open(tmp_model_path, \"wb\") as tmp_model_file, file_system.open(\n            model_path, \"rb\"\n        ) as model_file:\n            tmp_model_file.write(model_file.read())\n\n        model = load_model(\n            tmp_model_path, self.model_custom_objects(), compile=self.compile_model\n        )\n    return model\n</code></pre>"},{"location":"reference/dlframeworks/keras/callbacks/__init__/","title":"callbacks","text":""},{"location":"reference/dlframeworks/keras/callbacks/__init__/#niceml.dlframeworks.keras.callbacks","title":"callbacks","text":""},{"location":"reference/dlframeworks/keras/callbacks/callback_factories/","title":"callback_factories","text":""},{"location":"reference/dlframeworks/keras/callbacks/callback_factories/#niceml.dlframeworks.keras.callbacks.callback_factories","title":"callback_factories","text":"<p>Module for all callback factories</p>"},{"location":"reference/dlframeworks/keras/callbacks/callback_factories/#niceml.dlframeworks.keras.callbacks.callback_factories-classes","title":"Classes","text":""},{"location":"reference/dlframeworks/keras/callbacks/callback_factories/#niceml.dlframeworks.keras.callbacks.callback_factories.CallbackFactory","title":"CallbackFactory","text":"<p>             Bases: <code>ABC</code></p> <p>ABC for creating callbacks</p>"},{"location":"reference/dlframeworks/keras/callbacks/callback_factories/#niceml.dlframeworks.keras.callbacks.callback_factories.CallbackFactory-functions","title":"Functions","text":""},{"location":"reference/dlframeworks/keras/callbacks/callback_factories/#niceml.dlframeworks.keras.callbacks.callback_factories.CallbackFactory.create_callback","title":"create_callback  <code>abstractmethod</code>","text":"<pre><code>create_callback(exp_context)\n</code></pre> <p>Creates a callback from the given experiment context</p> Source code in <code>niceml/dlframeworks/keras/callbacks/callback_factories.py</code> <pre><code>@abstractmethod\ndef create_callback(self, exp_context: ExperimentContext):\n    \"\"\"Creates a callback from the given experiment context\"\"\"\n</code></pre>"},{"location":"reference/dlframeworks/keras/callbacks/callback_factories/#niceml.dlframeworks.keras.callbacks.callback_factories.CamCallbackFactory","title":"CamCallbackFactory","text":"<pre><code>CamCallbackFactory(images)\n</code></pre> <p>             Bases: <code>CallbackFactory</code></p> <p>Callback factory for a cam callback</p> Source code in <code>niceml/dlframeworks/keras/callbacks/callback_factories.py</code> <pre><code>def __init__(self, images: List[str]):\n    self.images = images\n</code></pre>"},{"location":"reference/dlframeworks/keras/callbacks/callback_factories/#niceml.dlframeworks.keras.callbacks.callback_factories.CamCallbackFactory-functions","title":"Functions","text":""},{"location":"reference/dlframeworks/keras/callbacks/callback_factories/#niceml.dlframeworks.keras.callbacks.callback_factories.CamCallbackFactory.create_callback","title":"create_callback","text":"<pre><code>create_callback(exp_context)\n</code></pre> <p>Factory method to initialize GRID-CAM callback</p> <p>Parameters will be set by parameters.yaml</p> <p>Examples:</p> <p>callbacks:     - type: niceml.callbacks.callback_factories.cam_callback_factory     params:         image_location: *experiment_path         images:             - /path/to/data/train/Lemon/r_304_100.jpg             - /path/to/data/train/Kiwi/2_100.jpg             - /path/to/data/train/Walnut/3_100.jpg             - /path/to/data/train/Watermelon/2_100.jpg</p> <p>Parameters:</p> <ul> <li> <code>image_location</code>         \u2013          <p>path to experiment folder</p> </li> <li> <code>images</code>         \u2013          <p>list of image paths</p> </li> </ul> Source code in <code>niceml/dlframeworks/keras/callbacks/callback_factories.py</code> <pre><code>def create_callback(self, exp_context: ExperimentContext):\n    \"\"\"\n    Factory method to initialize GRID-CAM callback\n\n    Parameters will be set by parameters.yaml\n\n    Examples:\n    callbacks:\n        - type: niceml.callbacks.callback_factories.cam_callback_factory\n        params:\n            image_location: *experiment_path\n            images:\n                - /path/to/data/train/Lemon/r_304_100.jpg\n                - /path/to/data/train/Kiwi/2_100.jpg\n                - /path/to/data/train/Walnut/3_100.jpg\n                - /path/to/data/train/Watermelon/2_100.jpg\n\n    Args:\n        image_location: path to experiment folder\n        images: list of image paths\n\n    \"\"\"\n    filepath = join(exp_context.filepath, \"cam\")\n    filepath = subs_path_and_create_folder(\n        filepath, exp_context.short_id, exp_context.run_id\n    )\n\n    Path(filepath).mkdir(exist_ok=True, parents=False)\n\n    # pylint: disable=import-outside-toplevel\n    from niceml.dlframeworks.keras.callbacks.cam_callback import CamCallback\n\n    return CamCallback(output_dir=filepath, images=self.images)\n</code></pre>"},{"location":"reference/dlframeworks/keras/callbacks/callback_factories/#niceml.dlframeworks.keras.callbacks.callback_factories.InitCallbackFactory","title":"InitCallbackFactory","text":"<pre><code>InitCallbackFactory(callback)\n</code></pre> <p>             Bases: <code>CallbackFactory</code></p> <p>Creates a callback which doesn't need any experiment specific parameters</p> Source code in <code>niceml/dlframeworks/keras/callbacks/callback_factories.py</code> <pre><code>def __init__(self, callback: Any):\n    self.callback = callback\n</code></pre>"},{"location":"reference/dlframeworks/keras/callbacks/callback_factories/#niceml.dlframeworks.keras.callbacks.callback_factories.LoggingOutputCallbackFactory","title":"LoggingOutputCallbackFactory","text":"<pre><code>LoggingOutputCallbackFactory(filename='train_logs.csv')\n</code></pre> <p>             Bases: <code>CallbackFactory</code></p> <p>Creates a callback that logs the metrics to a csv file</p> Source code in <code>niceml/dlframeworks/keras/callbacks/callback_factories.py</code> <pre><code>def __init__(self, filename: str = \"train_logs.csv\"):\n    self.filename = filename\n</code></pre>"},{"location":"reference/dlframeworks/keras/callbacks/callback_factories/#niceml.dlframeworks.keras.callbacks.callback_factories.ModelCallbackFactory","title":"ModelCallbackFactory","text":"<pre><code>ModelCallbackFactory(model_subfolder, **kwargs)\n</code></pre> <p>             Bases: <code>CallbackFactory</code></p> <p>Creates the model checkpoint callback</p> Source code in <code>niceml/dlframeworks/keras/callbacks/callback_factories.py</code> <pre><code>def __init__(self, model_subfolder: str, **kwargs):\n    self.kwargs = kwargs\n    self.model_subfolder = model_subfolder\n</code></pre>"},{"location":"reference/dlframeworks/keras/callbacks/callback_factories/#niceml.dlframeworks.keras.callbacks.callback_factories-functions","title":"Functions","text":""},{"location":"reference/dlframeworks/keras/callbacks/csvlogger/","title":"csvlogger","text":""},{"location":"reference/dlframeworks/keras/callbacks/csvlogger/#niceml.dlframeworks.keras.callbacks.csvlogger","title":"csvlogger","text":"<p>Implementation of the CSVLogger callback for TensorFlow.</p>"},{"location":"reference/dlframeworks/keras/callbacks/csvlogger/#niceml.dlframeworks.keras.callbacks.csvlogger-classes","title":"Classes","text":""},{"location":"reference/dlframeworks/keras/callbacks/csvlogger/#niceml.dlframeworks.keras.callbacks.csvlogger.CSVLogger","title":"CSVLogger","text":"<pre><code>CSVLogger(experiment_context, filename='train_logs.csv')\n</code></pre> <p>             Bases: <code>Callback</code></p> <p>Callback that streams epoch results to a CSV file.</p> <p>Supports all values that can be represented as a string, including 1D iterables such as np.ndarray.</p>"},{"location":"reference/dlframeworks/keras/callbacks/csvlogger/#niceml.dlframeworks.keras.callbacks.csvlogger.CSVLogger--example","title":"Example","text":"<pre><code>csv_logger = CSVLogger(exp_context=exp_context)\nmodel.fit(X_train, Y_train, callbacks=[csv_logger])\n</code></pre>"},{"location":"reference/dlframeworks/keras/callbacks/csvlogger/#niceml.dlframeworks.keras.callbacks.csvlogger.CSVLogger--arguments","title":"Arguments","text":"<pre><code>exp_context: An instance of ExperimentContext which is used to write csv files\n</code></pre> <p>Initialize CSVLogger with a given Context and csv filename.</p> <p>Supports all values that can be represented as a string, including 1D iterables such as np.ndarray.</p>"},{"location":"reference/dlframeworks/keras/callbacks/csvlogger/#niceml.dlframeworks.keras.callbacks.csvlogger.CSVLogger--example","title":"Example","text":"<pre><code>csv_logger = CSVLogger(exp_context=exp_context)\nmodel.fit(X_train, Y_train, callbacks=[csv_logger])\n</code></pre>"},{"location":"reference/dlframeworks/keras/callbacks/csvlogger/#niceml.dlframeworks.keras.callbacks.csvlogger.CSVLogger--arguments","title":"Arguments","text":"<pre><code>exp_context: An instance of ExperimentContext which is used to write csv files\nseparator: string used to separate elements in the CSV file.\n</code></pre> Source code in <code>niceml/dlframeworks/keras/callbacks/csvlogger.py</code> <pre><code>def __init__(\n    self, experiment_context: ExperimentContext, filename: str = \"train_logs.csv\"\n):\n    \"\"\"Initialize CSVLogger with a given Context and csv filename.\n\n    Supports all values that can be represented as a string,\n    including 1D iterables such as np.ndarray.\n\n    # Example\n    ```python\n    csv_logger = CSVLogger(exp_context=exp_context)\n    model.fit(X_train, Y_train, callbacks=[csv_logger])\n    ```\n\n    # Arguments\n        exp_context: An instance of ExperimentContext which is used to write csv files\n        separator: string used to separate elements in the CSV file.\n    \"\"\"\n\n    self.filename = filename\n    self.keys = None\n    self.data = None\n    self.experiment_context = experiment_context\n    super().__init__()\n</code></pre>"},{"location":"reference/dlframeworks/keras/callbacks/csvlogger/#niceml.dlframeworks.keras.callbacks.csvlogger.CSVLogger-functions","title":"Functions","text":""},{"location":"reference/dlframeworks/keras/callbacks/csvlogger/#niceml.dlframeworks.keras.callbacks.csvlogger.CSVLogger.flush","title":"flush","text":"<pre><code>flush()\n</code></pre> <p>The flush function is called when the training is finished or at the end of an epoch. It writes the data to a csv file in the data directory of your experiment.</p> Source code in <code>niceml/dlframeworks/keras/callbacks/csvlogger.py</code> <pre><code>def flush(self):\n    \"\"\"\n    The flush function is called when the training is finished\n    or at the end of an epoch. It writes the data to a csv file in the\n    data directory of your experiment.\n    \"\"\"\n    if self.experiment_context is not None:\n        self.experiment_context.write_csv(self.data, data_path=self.filename)\n</code></pre>"},{"location":"reference/dlframeworks/keras/callbacks/csvlogger/#niceml.dlframeworks.keras.callbacks.csvlogger.CSVLogger.on_epoch_end","title":"on_epoch_end","text":"<pre><code>on_epoch_end(epoch, logs=None)\n</code></pre> <p>The on_epoch_end function is called at the end of every epoch. It writes the logs to a CSV file.</p> <p>Parameters:</p> <ul> <li> <code>epoch</code>         \u2013          <p>Current epoch</p> </li> <li> <code>logs</code>         \u2013          <p>The logs of the current epoch to be written to the csv file.</p> </li> </ul> Source code in <code>niceml/dlframeworks/keras/callbacks/csvlogger.py</code> <pre><code>def on_epoch_end(self, epoch, logs=None):\n    \"\"\"\n    The on_epoch_end function is called at the end of every epoch.\n    It writes the logs to a CSV file.\n\n    Args:\n        epoch: Current epoch\n        logs: The logs of the current epoch to be written to the csv file.\n    \"\"\"\n    logs = logs or {}\n\n    if self.keys is None:\n        self.keys = sorted(logs.keys())\n\n    if self.data is None:\n        self.data = pd.DataFrame(columns=[\"epoch\"] + self.keys)\n\n    row_dict = {\"epoch\": epoch + 1}\n    row_dict.update({k: np.round(v, 6) for k, v in logs.items()})\n    self.data = pd.concat([self.data, pd.DataFrame([row_dict])], ignore_index=True)\n    self.flush()\n</code></pre>"},{"location":"reference/dlframeworks/keras/callbacks/csvlogger/#niceml.dlframeworks.keras.callbacks.csvlogger.CSVLogger.on_train_end","title":"on_train_end","text":"<pre><code>on_train_end(logs=None)\n</code></pre> <p>The on_train_end function is called at the end of training. In this case it writes the logs of the current training to a csv file.</p> <p>Parameters:</p> <ul> <li> <code>logs</code>         \u2013          <p>The logs of the current training. Ignored here because the logs     are stored in the object (<code>self.keys</code>, <code>self.data</code>).</p> </li> </ul> Source code in <code>niceml/dlframeworks/keras/callbacks/csvlogger.py</code> <pre><code>def on_train_end(self, logs=None):\n    \"\"\"\n    The on_train_end function is called at the end of training.\n    In this case it writes the logs of the current training to a csv file.\n\n    Args:\n        logs: The logs of the current training. Ignored here because the logs\n                are stored in the object (`self.keys`, `self.data`).\n    \"\"\"\n    self.flush()\n</code></pre>"},{"location":"reference/dlframeworks/keras/callbacks/modelcheckpoint/","title":"modelcheckpoint","text":""},{"location":"reference/dlframeworks/keras/callbacks/modelcheckpoint/#niceml.dlframeworks.keras.callbacks.modelcheckpoint","title":"modelcheckpoint","text":"<p>ModelCheckpoint that supports fsspec filesystems.</p>"},{"location":"reference/dlframeworks/keras/callbacks/modelcheckpoint/#niceml.dlframeworks.keras.callbacks.modelcheckpoint-classes","title":"Classes","text":""},{"location":"reference/dlframeworks/keras/callbacks/modelcheckpoint/#niceml.dlframeworks.keras.callbacks.modelcheckpoint.ModelCheckpoint","title":"ModelCheckpoint","text":"<pre><code>ModelCheckpoint(\n    output_location, file_formats=None, **kwargs\n)\n</code></pre> <p>             Bases: <code>ModelCheckpoint</code></p> <p>ModelCheckpoint that supports fsspec filesystems. Subclassed and adapted from https://github.com/keras-team/keras/blob/master/keras/callbacks.py</p> Source code in <code>niceml/dlframeworks/keras/callbacks/modelcheckpoint.py</code> <pre><code>def __init__(\n    self,\n    output_location: Union[dict, LocationConfig],\n    file_formats: Optional[dict] = None,\n    **kwargs,\n):\n    super().__init__(\"\", **kwargs)\n    self.output_location = output_location\n    self.file_formats = file_formats or {}\n</code></pre>"},{"location":"reference/dlframeworks/keras/callbacks/modelcheckpoint/#niceml.dlframeworks.keras.callbacks.modelcheckpoint-functions","title":"Functions","text":""},{"location":"reference/dlframeworks/keras/callbacks/nancheckcallback/","title":"nancheckcallback","text":""},{"location":"reference/dlframeworks/keras/callbacks/nancheckcallback/#niceml.dlframeworks.keras.callbacks.nancheckcallback","title":"nancheckcallback","text":"<p>Module for keras callback to check Nan</p>"},{"location":"reference/dlframeworks/keras/callbacks/nancheckcallback/#niceml.dlframeworks.keras.callbacks.nancheckcallback-classes","title":"Classes","text":""},{"location":"reference/dlframeworks/keras/callbacks/nancheckcallback/#niceml.dlframeworks.keras.callbacks.nancheckcallback.LossNanCheckCallback","title":"LossNanCheckCallback","text":"<pre><code>LossNanCheckCallback(check_logs=None)\n</code></pre> <p>             Bases: <code>Callback</code></p> <p>Callback to check if nan is in loss</p> Source code in <code>niceml/dlframeworks/keras/callbacks/nancheckcallback.py</code> <pre><code>def __init__(self, check_logs: Optional[List[str]] = None):\n    super().__init__()\n    self.check_logs = check_logs or [\"loss\", \"val_loss\"]\n</code></pre>"},{"location":"reference/dlframeworks/keras/callbacks/nancheckcallback/#niceml.dlframeworks.keras.callbacks.nancheckcallback.NanInLossError","title":"NanInLossError","text":"<p>             Bases: <code>Exception</code></p> <p>Error when loss is NaN</p>"},{"location":"reference/dlframeworks/keras/datasets/__init__/","title":"datasets","text":""},{"location":"reference/dlframeworks/keras/datasets/__init__/#niceml.dlframeworks.keras.datasets","title":"datasets","text":""},{"location":"reference/dlframeworks/keras/datasets/kerasdfdataset/","title":"kerasdfdataset","text":""},{"location":"reference/dlframeworks/keras/datasets/kerasdfdataset/#niceml.dlframeworks.keras.datasets.kerasdfdataset","title":"kerasdfdataset","text":"<p>module for the KerasDfDataset class</p>"},{"location":"reference/dlframeworks/keras/datasets/kerasdfdataset/#niceml.dlframeworks.keras.datasets.kerasdfdataset-classes","title":"Classes","text":""},{"location":"reference/dlframeworks/keras/datasets/kerasdfdataset/#niceml.dlframeworks.keras.datasets.kerasdfdataset.KerasDfDataset","title":"KerasDfDataset","text":"<pre><code>KerasDfDataset(batch_size, *args, **kwargs)\n</code></pre> <p>             Bases: <code>DfDataset</code>, <code>Sequence</code></p> <p>Keras implementation of the DfDataset</p> <p>Constructor of the KerasdfDataset Args:     batch_size: Batch size     **kwargs: All arguments of the DfDataset</p> Source code in <code>niceml/dlframeworks/keras/datasets/kerasdfdataset.py</code> <pre><code>def __init__(self, batch_size: int, *args, **kwargs):\n    \"\"\"\n    Constructor of the KerasdfDataset\n    Args:\n        batch_size: Batch size\n        **kwargs: All arguments of the DfDataset\n    \"\"\"\n    super().__init__(*args, **kwargs)\n    self.batch_size = batch_size\n</code></pre>"},{"location":"reference/dlframeworks/keras/datasets/kerasdfdataset/#niceml.dlframeworks.keras.datasets.kerasdfdataset.KerasDfDataset-functions","title":"Functions","text":""},{"location":"reference/dlframeworks/keras/datasets/kerasdfdataset/#niceml.dlframeworks.keras.datasets.kerasdfdataset.KerasDfDataset.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(index)\n</code></pre> <p>The getitem function returns the indexed data batch in the size of <code>self.batch_size</code>. It is called when the DfDataset is accessed, using the notation self[<code>index</code>] (while training a model).</p> <p>Args:      index: Specify <code>index</code> of the batch</p> <p>Returns:      A batch of input data and target data with the batch size <code>self.batch_size</code></p> Source code in <code>niceml/dlframeworks/keras/datasets/kerasdfdataset.py</code> <pre><code>def __getitem__(self, index):\n    \"\"\"\n    The __getitem__ function returns the indexed data batch in the size of `self.batch_size`.\n    It is called when the DfDataset is accessed, using the notation self[`index`]\n    (while training a model).\n\n     Args:\n         index: Specify `index` of the batch\n\n     Returns:\n         A batch of input data and target data with the batch size `self.batch_size`\n    \"\"\"\n    start_idx = index * self.batch_size\n    end_idx = min(len(self.index_list), (index + 1) * self.batch_size)\n    input_data, target_data = self.get_data(start_idx, end_idx)\n\n    return input_data, target_data\n</code></pre>"},{"location":"reference/dlframeworks/keras/datasets/kerasdfdataset/#niceml.dlframeworks.keras.datasets.kerasdfdataset.KerasDfDataset.__len__","title":"__len__","text":"<pre><code>__len__()\n</code></pre> <p>The len function is used to determine the number of batches in an epoch.</p> <p>Returns:</p> <ul> <li>         \u2013          <p>The number of batches in an epoch</p> </li> </ul> Source code in <code>niceml/dlframeworks/keras/datasets/kerasdfdataset.py</code> <pre><code>def __len__(self):\n    \"\"\"\n    The __len__ function is used to determine the number of batches in an epoch.\n\n    Returns:\n        The number of batches in an epoch\n    \"\"\"\n    batch_count, rest = divmod(self.get_items_per_epoch(), self.batch_size)\n    if rest &gt; 0:\n        batch_count += 1\n    return batch_count\n</code></pre>"},{"location":"reference/dlframeworks/keras/datasets/kerasdfdataset/#niceml.dlframeworks.keras.datasets.kerasdfdataset.KerasDfDataset.get_batch_size","title":"get_batch_size","text":"<pre><code>get_batch_size()\n</code></pre> <p>The get_batch_size function returns the batch size of the dataset.</p> <p>Returns:</p> <ul> <li> <code>int</code>         \u2013          <p>The batch size</p> </li> </ul> Source code in <code>niceml/dlframeworks/keras/datasets/kerasdfdataset.py</code> <pre><code>def get_batch_size(self) -&gt; int:\n    \"\"\"\n    The get_batch_size function returns the batch size of the dataset.\n\n    Returns:\n        The batch size\n    \"\"\"\n    return self.batch_size\n</code></pre>"},{"location":"reference/dlframeworks/keras/datasets/kerasdfdataset/#niceml.dlframeworks.keras.datasets.kerasdfdataset.KerasDfDataset.get_datainfo","title":"get_datainfo","text":"<pre><code>get_datainfo(batch_index)\n</code></pre> <p>The get_datainfo function is used to get the data information for a given batch.</p> <p>Parameters:</p> <ul> <li> <code>batch_index</code>         \u2013          <p>Determine which batch of data (datainfo) to return</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>List[RegDataInfo]</code>         \u2013          <p>A list of <code>RegDataInfo</code> objects of the batch with index <code>batch_index</code></p> </li> </ul> Source code in <code>niceml/dlframeworks/keras/datasets/kerasdfdataset.py</code> <pre><code>def get_datainfo(self, batch_index) -&gt; List[RegDataInfo]:\n    \"\"\"\n    The get_datainfo function is used to get the data information for a given batch.\n\n    Args:\n        batch_index: Determine which batch of data (datainfo) to return\n\n    Returns:\n        A list of `RegDataInfo` objects of the batch with index `batch_index`\n    \"\"\"\n    start_idx = batch_index * self.batch_size\n    end_idx = min(len(self.index_list), (batch_index + 1) * self.batch_size)\n    data_info_list: List[RegDataInfo] = []\n    input_keys = [input_dict[\"key\"] for input_dict in self.inputs]\n    target_keys = [target_dict[\"key\"] for target_dict in self.targets]\n    data_subset = self.data[\n        [self.id_key] + input_keys + target_keys + self.extra_key_list\n    ]\n    real_index_list = [self.index_list[idx] for idx in range(start_idx, end_idx)]\n    data_info_dicts: List[dict] = data_subset.iloc[real_index_list].to_dict(\n        \"records\"\n    )\n\n    for data_info_dict in data_info_dicts:\n        key = data_info_dict[self.id_key]\n        data_info_dict.pop(self.id_key)\n        data_info_list.append(RegDataInfo(key, data_info_dict))\n    return data_info_list\n</code></pre>"},{"location":"reference/dlframeworks/keras/datasets/kerasdfdataset/#niceml.dlframeworks.keras.datasets.kerasdfdataset.KerasDfDataset.on_epoch_end","title":"on_epoch_end","text":"<pre><code>on_epoch_end()\n</code></pre> <p>Execute logic to be performed at the end of an epoch (e.g. shuffling the data)</p> Source code in <code>niceml/dlframeworks/keras/datasets/kerasdfdataset.py</code> <pre><code>def on_epoch_end(self):\n    \"\"\"\n    Execute logic to be performed at the end of an epoch (e.g. shuffling the data)\n    \"\"\"\n    if self.shuffle:\n        self.index_list = self.data_shuffler.shuffle(\n            data_infos=self.get_all_data_info(), batch_size=self.batch_size\n        )\n</code></pre>"},{"location":"reference/dlframeworks/keras/datasets/kerasgenericdataset/","title":"kerasgenericdataset","text":""},{"location":"reference/dlframeworks/keras/datasets/kerasgenericdataset/#niceml.dlframeworks.keras.datasets.kerasgenericdataset","title":"kerasgenericdataset","text":"<p>module for the KerasGenericDataset class</p>"},{"location":"reference/dlframeworks/keras/datasets/kerasgenericdataset/#niceml.dlframeworks.keras.datasets.kerasgenericdataset-classes","title":"Classes","text":""},{"location":"reference/dlframeworks/keras/datasets/kerasgenericdataset/#niceml.dlframeworks.keras.datasets.kerasgenericdataset.KerasGenericDataset","title":"KerasGenericDataset","text":"<pre><code>KerasGenericDataset(batch_size, **kwargs)\n</code></pre> <p>             Bases: <code>GenericDataset</code>, <code>Sequence</code></p> <p>Keras implementation of the GenericDataset</p> <p>Constructor of the KerasGenericDataset Args:     batch_size: Batch size     **kwargs: All arguments of the GenericDataset</p> Source code in <code>niceml/dlframeworks/keras/datasets/kerasgenericdataset.py</code> <pre><code>def __init__(self, batch_size: int, **kwargs):\n    \"\"\"\n    Constructor of the KerasGenericDataset\n    Args:\n        batch_size: Batch size\n        **kwargs: All arguments of the GenericDataset\n    \"\"\"\n    super().__init__(**kwargs)\n    self.batch_size = batch_size\n</code></pre>"},{"location":"reference/dlframeworks/keras/datasets/kerasgenericdataset/#niceml.dlframeworks.keras.datasets.kerasgenericdataset.KerasGenericDataset-functions","title":"Functions","text":""},{"location":"reference/dlframeworks/keras/datasets/kerasgenericdataset/#niceml.dlframeworks.keras.datasets.kerasgenericdataset.KerasGenericDataset.__getitem__","title":"__getitem__","text":"<pre><code>__getitem__(batch_index)\n</code></pre> <p>Returns the data of the batch at index</p> Source code in <code>niceml/dlframeworks/keras/datasets/kerasgenericdataset.py</code> <pre><code>def __getitem__(self, batch_index: int):\n    \"\"\"Returns the data of the batch at index\"\"\"\n    cur_data_infos = self.get_datainfo(batch_index)\n    dc_list: list = [self.data_loader.load_data(x) for x in cur_data_infos]\n    if self.augmentator is not None:\n        dc_list = [self.augmentator(x) for x in dc_list]\n    net_inputs = self.input_transformer.get_net_inputs(dc_list)\n    net_targets = self.target_transformer.get_net_targets(dc_list)\n    if self.net_data_logger is not None:\n        self.net_data_logger.log_data(\n            net_inputs=net_inputs,\n            net_targets=net_targets,\n            data_info_list=cur_data_infos,\n        )\n    return net_inputs, net_targets\n</code></pre>"},{"location":"reference/dlframeworks/keras/datasets/kerasgenericdataset/#niceml.dlframeworks.keras.datasets.kerasgenericdataset.KerasGenericDataset.__len__","title":"__len__","text":"<pre><code>__len__()\n</code></pre> <p>The len function is used to determine the number of batches in an epoch. Contrary to the len function of the GenericDataset, this function returns the number of items per epoch.</p> Source code in <code>niceml/dlframeworks/keras/datasets/kerasgenericdataset.py</code> <pre><code>def __len__(self):\n    \"\"\"\n    The __len__ function is used to determine the number of batches in an epoch.\n    Contrary to the __len__ function of the GenericDataset, this function\n    returns the number of items per epoch.\n    \"\"\"\n    batch_count, rest = divmod(self.get_items_per_epoch(), self.batch_size)\n    if rest &gt; 0:\n        batch_count += 1\n    return batch_count\n</code></pre>"},{"location":"reference/dlframeworks/keras/datasets/kerasgenericdataset/#niceml.dlframeworks.keras.datasets.kerasgenericdataset.KerasGenericDataset.get_datainfo","title":"get_datainfo","text":"<pre><code>get_datainfo(batch_index)\n</code></pre> <p>Returns the datainfo for the batch at index Args:     batch_index: index of the batch</p> <p>Returns:</p> <ul> <li> <code>List[DataInfo]</code>         \u2013          <p>List of DataInfo with regard to shuffling</p> </li> </ul> Source code in <code>niceml/dlframeworks/keras/datasets/kerasgenericdataset.py</code> <pre><code>def get_datainfo(self, batch_index: int) -&gt; List[DataInfo]:\n    \"\"\"\n    Returns the datainfo for the batch at index\n    Args:\n        batch_index: index of the batch\n\n    Returns:\n        List of DataInfo with regard to shuffling\n    \"\"\"\n    start_idx = batch_index * self.batch_size\n    end_idx = min(len(self.index_list), (batch_index + 1) * self.batch_size)\n    data_info_list: List[DataInfo] = []\n    for cur_idx in range(start_idx, end_idx):\n        real_index = self.index_list[cur_idx]\n        image_info = self.data_info_list[real_index]\n        data_info_list.append(image_info)\n    return data_info_list\n</code></pre>"},{"location":"reference/dlframeworks/keras/datasets/kerasgenericdataset/#niceml.dlframeworks.keras.datasets.kerasgenericdataset.KerasGenericDataset.on_epoch_end","title":"on_epoch_end","text":"<pre><code>on_epoch_end()\n</code></pre> <p>Shuffles the data if shuffle is True</p> Source code in <code>niceml/dlframeworks/keras/datasets/kerasgenericdataset.py</code> <pre><code>def on_epoch_end(self):\n    \"\"\"Shuffles the data if shuffle is True\"\"\"\n    if self.shuffle:\n        self.index_list = self.data_shuffler.shuffle(\n            self.data_info_list, batch_size=self.batch_size\n        )\n</code></pre>"},{"location":"reference/dlframeworks/keras/learners/__init__/","title":"learners","text":""},{"location":"reference/dlframeworks/keras/learners/__init__/#niceml.dlframeworks.keras.learners","title":"learners","text":""},{"location":"reference/dlframeworks/keras/learners/keraslearner/","title":"keraslearner","text":""},{"location":"reference/dlframeworks/keras/learners/keraslearner/#niceml.dlframeworks.keras.learners.keraslearner","title":"keraslearner","text":"<p>Module for default learner</p>"},{"location":"reference/dlframeworks/keras/learners/keraslearner/#niceml.dlframeworks.keras.learners.keraslearner-classes","title":"Classes","text":""},{"location":"reference/dlframeworks/keras/learners/keraslearner/#niceml.dlframeworks.keras.learners.keraslearner.KerasLearner","title":"KerasLearner","text":"<pre><code>KerasLearner(\n    model_compiler,\n    callback_initializer,\n    model_load_custom_objects,\n)\n</code></pre> <p>             Bases: <code>Learner</code></p> <p>default learner for keras/keras models</p> <p>Constructor for DefaultLearner Args:     model_compiler: model compiler for keras     callback_initializer: callback initializer for keras     model_load_custom_objects: custom objects to load the model</p> Source code in <code>niceml/dlframeworks/keras/learners/keraslearner.py</code> <pre><code>def __init__(\n    self,\n    model_compiler: ModelCompiler,\n    callback_initializer: CallbackInitializer,\n    model_load_custom_objects: ModelCustomLoadObjects,\n):\n    \"\"\"\n    Constructor for DefaultLearner\n    Args:\n        model_compiler: model compiler for keras\n        callback_initializer: callback initializer for keras\n        model_load_custom_objects: custom objects to load the model\n    \"\"\"\n    self.model_compiler: ModelCompiler = model_compiler\n    self.callback_initializer: CallbackInitializer = callback_initializer\n    self.model_load_custom_objects: ModelCustomLoadObjects = (\n        model_load_custom_objects\n    )\n</code></pre>"},{"location":"reference/dlframeworks/keras/learners/keraslearner/#niceml.dlframeworks.keras.learners.keraslearner.KerasLearner-functions","title":"Functions","text":""},{"location":"reference/dlframeworks/keras/learners/keraslearner/#niceml.dlframeworks.keras.learners.keraslearner.KerasLearner.run_training","title":"run_training","text":"<pre><code>run_training(\n    exp_context,\n    model_factory,\n    train_set,\n    validation_set,\n    train_params,\n    data_description,\n)\n</code></pre> <p>runs the training</p> Source code in <code>niceml/dlframeworks/keras/learners/keraslearner.py</code> <pre><code>def run_training(  # noqa: PLR0913\n    self,\n    exp_context: ExperimentContext,\n    model_factory: ModelFactory,\n    train_set: Dataset,\n    validation_set: Dataset,\n    train_params: TrainParams,\n    data_description: DataDescription,\n):\n    \"\"\"runs the training\"\"\"\n    mlflow.keras.autolog()\n    callbacks = self.callback_initializer(exp_context)\n    model_bundle: ModelBundle = self.model_compiler.compile(\n        model_factory, data_description\n    )\n    initialized_model: Model = model_bundle.model\n    train_params: TrainParams\n    validation_steps = None\n    if train_params.validation_steps is not None:\n        validation_steps = min(train_params.validation_steps, len(validation_set))\n    steps_per_epoch = None\n    if train_params.steps_per_epoch is not None:\n        steps_per_epoch = min(train_params.steps_per_epoch, len(train_set))\n    with tf.keras.utils.custom_object_scope(self.model_load_custom_objects()):\n        history = initialized_model.fit(\n            train_set,\n            epochs=train_params.epochs,\n            validation_data=validation_set,\n            callbacks=callbacks,\n            validation_steps=validation_steps,\n            steps_per_epoch=steps_per_epoch,\n        )\n    return history\n</code></pre>"},{"location":"reference/dlframeworks/keras/losses/__init__/","title":"losses","text":""},{"location":"reference/dlframeworks/keras/losses/__init__/#niceml.dlframeworks.keras.losses","title":"losses","text":""},{"location":"reference/dlframeworks/keras/losses/categoricalfocalloss/","title":"categoricalfocalloss","text":""},{"location":"reference/dlframeworks/keras/losses/categoricalfocalloss/#niceml.dlframeworks.keras.losses.categoricalfocalloss","title":"categoricalfocalloss","text":"<p>module for categorical focal loss</p>"},{"location":"reference/dlframeworks/keras/losses/categoricalfocalloss/#niceml.dlframeworks.keras.losses.categoricalfocalloss-classes","title":"Classes","text":""},{"location":"reference/dlframeworks/keras/losses/categoricalfocalloss/#niceml.dlframeworks.keras.losses.categoricalfocalloss.CategoricalFocalLoss","title":"CategoricalFocalLoss","text":"<pre><code>CategoricalFocalLoss(alpha, gamma=2.0, **kwargs)\n</code></pre> <p>             Bases: <code>Loss</code></p> <p>class for categorical focal loss</p> <p>Inspired by https://github.com/umbertogriffo/focal-loss-keras Focal loss which can be applied to softmax outputs. Official paper: https://arxiv.org/pdf/1708.02002.pdf Parameters</p> <p>alpha: float or list of float     When float alpha is applied to all classes otherwise the list     must have the same length as classes with each alpha applied     to it's own class gamma: float     gamma value of the paper kwargs:     all parameters are applied to keras loss</p> Source code in <code>niceml/dlframeworks/keras/losses/categoricalfocalloss.py</code> <pre><code>def __init__(self, alpha: Union[float, List[float]], gamma: float = 2.0, **kwargs):\n    \"\"\"\n    Inspired by https://github.com/umbertogriffo/focal-loss-keras\n    Focal loss which can be applied to softmax outputs.\n    Official paper: https://arxiv.org/pdf/1708.02002.pdf\n    Parameters\n    ----------\n    alpha: float or list of float\n        When float alpha is applied to all classes otherwise the list\n        must have the same length as classes with each alpha applied\n        to it's own class\n    gamma: float\n        gamma value of the paper\n    kwargs:\n        all parameters are applied to keras loss\n    \"\"\"\n    super().__init__(**kwargs)\n    self.alpha = np.array(alpha, dtype=np.float32)\n    self.gamma = gamma\n</code></pre>"},{"location":"reference/dlframeworks/keras/losses/categoricalfocalloss/#niceml.dlframeworks.keras.losses.categoricalfocalloss.CategoricalFocalLoss-functions","title":"Functions","text":""},{"location":"reference/dlframeworks/keras/losses/categoricalfocalloss/#niceml.dlframeworks.keras.losses.categoricalfocalloss.CategoricalFocalLoss.__call__","title":"__call__","text":"<pre><code>__call__(y_true, y_pred, sample_weight=None)\n</code></pre> <p>Call method for loss</p> Source code in <code>niceml/dlframeworks/keras/losses/categoricalfocalloss.py</code> <pre><code>def __call__(self, y_true, y_pred, sample_weight=None):\n    \"\"\"Call method for loss\"\"\"\n    # Clip the prediction value to prevent NaN's and Inf's\n    epsilon = kb.epsilon()\n    y_pred = kb.clip(y_pred, epsilon, 1.0 - epsilon)\n    # normal cross entropy calculation\n    cross_entropy = -y_true * kb.log(y_pred)\n    # reweight wrt focal loss paper\n    loss = self.alpha * kb.pow(1 - y_pred, self.gamma) * cross_entropy\n\n    return kb.mean(kb.sum(loss, axis=-1))\n</code></pre>"},{"location":"reference/dlframeworks/keras/losses/objdetlosses/","title":"objdetlosses","text":""},{"location":"reference/dlframeworks/keras/losses/objdetlosses/#niceml.dlframeworks.keras.losses.objdetlosses","title":"objdetlosses","text":"<p>losses for object detection</p>"},{"location":"reference/dlframeworks/keras/losses/objdetlosses/#niceml.dlframeworks.keras.losses.objdetlosses-classes","title":"Classes","text":""},{"location":"reference/dlframeworks/keras/losses/objdetlosses/#niceml.dlframeworks.keras.losses.objdetlosses.CombinationLoss","title":"CombinationLoss","text":"<pre><code>CombinationLoss(losses, weights=None)\n</code></pre> <p>             Bases: <code>Loss</code></p> <p>Wrapper to combine both the losses</p> Source code in <code>niceml/dlframeworks/keras/losses/objdetlosses.py</code> <pre><code>def __init__(self, losses: list, weights: Optional[List[float]] = None):\n    super().__init__(reduction=\"auto\", name=\"CombinationLoss\")\n    self.weights = weights or [1.0] * len(losses)\n    self.losses = losses\n\n    if len(self.weights) != len(self.losses):\n        raise ValueError(\n            f\"Length of self.weights ({len(self.weights)}) is not \"\n            f\"equal the length of self.losses ({self.losses})\"\n        )\n</code></pre>"},{"location":"reference/dlframeworks/keras/losses/objdetlosses/#niceml.dlframeworks.keras.losses.objdetlosses.CombinationLoss-functions","title":"Functions","text":""},{"location":"reference/dlframeworks/keras/losses/objdetlosses/#niceml.dlframeworks.keras.losses.objdetlosses.CombinationLoss.call","title":"call","text":"<pre><code>call(y_true, y_pred)\n</code></pre> <p>Calls sum of losses</p> Source code in <code>niceml/dlframeworks/keras/losses/objdetlosses.py</code> <pre><code>def call(self, y_true, y_pred):\n    \"\"\"Calls sum of losses\"\"\"\n    return sum(\n        cur_loss(y_true, y_pred) * cur_weight\n        for cur_loss, cur_weight in zip(self.losses, self.weights)\n    )\n</code></pre>"},{"location":"reference/dlframeworks/keras/losses/objdetlosses/#niceml.dlframeworks.keras.losses.objdetlosses.RetinaNetBoxLoss","title":"RetinaNetBoxLoss","text":"<pre><code>RetinaNetBoxLoss(delta=1.0)\n</code></pre> <p>             Bases: <code>Loss</code></p> <p>Implements Smooth L1 loss</p> Source code in <code>niceml/dlframeworks/keras/losses/objdetlosses.py</code> <pre><code>def __init__(self, delta: float = 1.0):\n    super().__init__(reduction=\"none\", name=\"RetinaNetBoxLoss\")\n    self._delta = delta\n</code></pre>"},{"location":"reference/dlframeworks/keras/losses/objdetlosses/#niceml.dlframeworks.keras.losses.objdetlosses.RetinaNetBoxLoss-functions","title":"Functions","text":""},{"location":"reference/dlframeworks/keras/losses/objdetlosses/#niceml.dlframeworks.keras.losses.objdetlosses.RetinaNetBoxLoss.call","title":"call","text":"<pre><code>call(y_true, y_pred)\n</code></pre>"},{"location":"reference/dlframeworks/keras/losses/objdetlosses/#niceml.dlframeworks.keras.losses.objdetlosses.RetinaNetBoxLoss.call--parameters","title":"Parameters","text":"<p>y_true: np.ndarray with shape (count_anchors x 4+1 + num_classes) y_pred: np.ndarray with shape (count_anchors x 4 + num_classes)</p> Source code in <code>niceml/dlframeworks/keras/losses/objdetlosses.py</code> <pre><code>def call(self, y_true, y_pred):\n    \"\"\"\n    Parameters\n    ----------\n    y_true: np.ndarray with shape (count_anchors x 4+1 + num_classes)\n    y_pred: np.ndarray with shape (count_anchors x 4 + num_classes)\n    \"\"\"\n    positive_mask = tf.cast(\n        tf.equal(y_true[:, :, 4], POSITIVE_MASK_VALUE), dtype=tf.float32\n    )\n    normalizer = tf.reduce_sum(positive_mask, axis=-1)\n\n    y_pred = tf.cast(y_pred, dtype=tf.float32)\n\n    box_labels = y_true[:, :, :4]\n    box_predictions = y_pred[:, :, :4]\n\n    difference = box_labels - box_predictions\n    absolute_difference = tf.abs(difference)\n    squared_difference = difference**2\n    loss = tf.where(\n        tf.less(absolute_difference, self._delta),\n        0.5 * squared_difference,\n        absolute_difference - 0.5,\n    )\n\n    box_loss = tf.reduce_sum(loss, axis=-1)\n\n    box_loss = tf.where(tf.equal(positive_mask, 1.0), box_loss, 0.0)\n    box_loss = tf.math.divide_no_nan(tf.reduce_sum(box_loss, axis=-1), normalizer)\n\n    return box_loss\n</code></pre>"},{"location":"reference/dlframeworks/keras/losses/objdetlosses/#niceml.dlframeworks.keras.losses.objdetlosses.RetinaNetClsLoss","title":"RetinaNetClsLoss","text":"<pre><code>RetinaNetClsLoss(alpha=0.25, gamma=2.0)\n</code></pre> <p>             Bases: <code>Loss</code></p> <p>Implements Focal loss</p> Source code in <code>niceml/dlframeworks/keras/losses/objdetlosses.py</code> <pre><code>def __init__(self, alpha: float = 0.25, gamma: float = 2.0):\n    super().__init__(reduction=\"none\", name=\"RetinaNetClsLoss\")\n    self._alpha = alpha\n    self._gamma = gamma\n</code></pre>"},{"location":"reference/dlframeworks/keras/losses/objdetlosses/#niceml.dlframeworks.keras.losses.objdetlosses.RetinaNetClsLoss-functions","title":"Functions","text":""},{"location":"reference/dlframeworks/keras/losses/objdetlosses/#niceml.dlframeworks.keras.losses.objdetlosses.RetinaNetClsLoss.call","title":"call","text":"<pre><code>call(y_true, y_pred)\n</code></pre>"},{"location":"reference/dlframeworks/keras/losses/objdetlosses/#niceml.dlframeworks.keras.losses.objdetlosses.RetinaNetClsLoss.call--parameters","title":"Parameters","text":"<p>y_true: np.ndarray with shape (count_anchors x 4+1 + num_classes) y_pred: np.ndarray with shape (count_anchors x 4 + num_classes)</p> Source code in <code>niceml/dlframeworks/keras/losses/objdetlosses.py</code> <pre><code>def call(self, y_true, y_pred):\n    \"\"\"\n    Parameters\n    ----------\n    y_true: np.ndarray with shape (count_anchors x 4+1 + num_classes)\n    y_pred: np.ndarray with shape (count_anchors x 4 + num_classes)\n    \"\"\"\n\n    ignore_mask = tf.cast(\n        tf.equal(y_true[:, :, 4], IGNORE_MASK_VALUE), dtype=tf.float32\n    )\n    not_ignore_mask = tf.cast(tf.equal(ignore_mask, 0.0), dtype=tf.float32)\n    normalizer = tf.reduce_sum(not_ignore_mask, axis=-1)\n\n    y_pred = tf.cast(y_pred, dtype=tf.float32)\n    cls_labels = y_true[:, :, 5:]\n    cls_predictions = y_pred[:, :, 4:]\n    cross_entropy = tf.nn.sigmoid_cross_entropy_with_logits(\n        labels=cls_labels, logits=cls_predictions\n    )\n    probs = tf.nn.sigmoid(cls_predictions)\n    alpha = tf.where(tf.equal(cls_labels, 1.0), self._alpha, (1.0 - self._alpha))\n    targets = tf.where(tf.equal(cls_labels, 1.0), probs, 1 - probs)\n    loss = alpha * tf.pow(1.0 - targets, self._gamma) * cross_entropy\n    cls_loss = tf.reduce_sum(loss, axis=-1)\n    cls_loss = tf.where(tf.equal(ignore_mask, 1.0), 0.0, cls_loss)\n    cls_loss = tf.math.divide_no_nan(tf.reduce_sum(cls_loss, axis=-1), normalizer)\n    return cls_loss\n</code></pre>"},{"location":"reference/dlframeworks/keras/losses/semseglosses/","title":"semseglosses","text":""},{"location":"reference/dlframeworks/keras/losses/semseglosses/#niceml.dlframeworks.keras.losses.semseglosses","title":"semseglosses","text":"<p>Module for focal loss for semantic segmentation</p>"},{"location":"reference/dlframeworks/keras/losses/semseglosses/#niceml.dlframeworks.keras.losses.semseglosses-classes","title":"Classes","text":""},{"location":"reference/dlframeworks/keras/losses/semseglosses/#niceml.dlframeworks.keras.losses.semseglosses.SemSegFocalLoss","title":"SemSegFocalLoss","text":"<pre><code>SemSegFocalLoss(\n    alpha=0.25,\n    gamma=2.0,\n    weight=1.0,\n    use_background_class=False,\n)\n</code></pre> <p>             Bases: <code>Loss</code></p> <p>Implements Focal loss</p> <p>initialize SemSegFocalLoss parameters</p> Source code in <code>niceml/dlframeworks/keras/losses/semseglosses.py</code> <pre><code>def __init__(\n    self,\n    alpha: float = 0.25,\n    gamma: float = 2.0,\n    weight: float = 1.0,\n    use_background_class: bool = False,\n):\n    \"\"\"initialize SemSegFocalLoss parameters\"\"\"\n    super().__init__(reduction=\"none\", name=\"SemSegFocalLoss\")\n    self._alpha = alpha\n    self._gamma = gamma\n    self._weight = weight\n    self.use_background_class = use_background_class\n</code></pre>"},{"location":"reference/dlframeworks/keras/losses/semseglosses/#niceml.dlframeworks.keras.losses.semseglosses.SemSegFocalLoss-functions","title":"Functions","text":""},{"location":"reference/dlframeworks/keras/losses/semseglosses/#niceml.dlframeworks.keras.losses.semseglosses.SemSegFocalLoss.call","title":"call","text":"<pre><code>call(y_true, y_pred)\n</code></pre> <p>Calculate SemSegFocalLoss based on prediction and ground-truth array</p> <p>Parameters:</p> <ul> <li> <code>y_true</code>         \u2013          <p>np.ndarray with shape (batch_size x height x width x num_classes)</p> </li> <li> <code>y_pred</code>         \u2013          <p>np.ndarray with shape (batch_size x height x width x num_classes)</p> </li> </ul> <p>Returns:</p> <ul> <li>         \u2013          <p>Focal loss</p> </li> </ul> Source code in <code>niceml/dlframeworks/keras/losses/semseglosses.py</code> <pre><code>def call(self, y_true, y_pred):\n    \"\"\"Calculate SemSegFocalLoss based on prediction and ground-truth array\n\n    Args:\n        y_true: np.ndarray with shape (batch_size x height x width x num_classes)\n        y_pred: np.ndarray with shape (batch_size x height x width x num_classes)\n\n    Returns:\n        Focal loss\n    \"\"\"\n    normalizer = tf.cast(\n        tf.shape(y_true, out_type=tf.int32)[1]\n        * tf.shape(y_true, out_type=tf.int32)[2],\n        dtype=tf.float32,\n    )\n\n    y_pred = tf.cast(y_pred, dtype=tf.float32)\n    # pylint: disable = invalid-unary-operand-type\n    targets = tf.where(tf.equal(y_true, 1.0), y_pred, (1.0 - y_pred))\n\n    binary_cross_entropy = -tf.math.log(targets + epsilon())\n\n    # set all prediction values of void_class to 0\n    if self.use_background_class:\n        shape = tf.shape(y_true)\n        zeros_tensor = tf.zeros(shape)\n        y_true = tf.concat(\n            [y_true[:, :, :, :-1], zeros_tensor[:, :, :, -1:]], axis=-1\n        )\n\n    alpha = tf.where(tf.equal(y_true, 1.0), self._alpha, (1.0 - self._alpha))\n    loss = alpha * tf.pow(1.0 - targets, self._gamma) * binary_cross_entropy\n    cls_loss = tf.reduce_sum(loss, axis=[1, 2, 3])\n    cls_loss = tf.math.divide_no_nan(cls_loss, normalizer)\n    return cls_loss * self._weight\n</code></pre>"},{"location":"reference/dlframeworks/keras/metrics/__init__/","title":"metrics","text":""},{"location":"reference/dlframeworks/keras/metrics/__init__/#niceml.dlframeworks.keras.metrics","title":"metrics","text":""},{"location":"reference/dlframeworks/keras/metrics/objdetmetrics/","title":"objdetmetrics","text":""},{"location":"reference/dlframeworks/keras/metrics/objdetmetrics/#niceml.dlframeworks.keras.metrics.objdetmetrics","title":"objdetmetrics","text":"<p>Module for object detection metrics for integration into model training</p>"},{"location":"reference/dlframeworks/keras/metrics/objdetmetrics/#niceml.dlframeworks.keras.metrics.objdetmetrics-classes","title":"Classes","text":""},{"location":"reference/dlframeworks/keras/metrics/objdetmetrics/#niceml.dlframeworks.keras.metrics.objdetmetrics.AvgNegPredObjDet","title":"AvgNegPredObjDet","text":"<pre><code>AvgNegPredObjDet(name='avg_neg_pred')\n</code></pre> <p>Negative Classification Values for object detection</p> <p>Initializes the AvgNegPredObjDet with the given name</p> Source code in <code>niceml/dlframeworks/keras/metrics/objdetmetrics.py</code> <pre><code>def __init__(self, name: str = \"avg_neg_pred\"):\n    \"\"\"Initializes the AvgNegPredObjDet with the given name\"\"\"\n    self.__name__ = name\n</code></pre>"},{"location":"reference/dlframeworks/keras/metrics/objdetmetrics/#niceml.dlframeworks.keras.metrics.objdetmetrics.AvgNegPredObjDet-functions","title":"Functions","text":""},{"location":"reference/dlframeworks/keras/metrics/objdetmetrics/#niceml.dlframeworks.keras.metrics.objdetmetrics.AvgNegPredObjDet.__call__","title":"__call__","text":"<pre><code>__call__(y_true, y_pred)\n</code></pre> <p>Call method is used as a default interface for the metric</p> Source code in <code>niceml/dlframeworks/keras/metrics/objdetmetrics.py</code> <pre><code>def __call__(self, y_true, y_pred):\n    \"\"\"Call method is used as a default interface for the metric\"\"\"\n    y_pred = tf.cast(y_pred, dtype=tf.float32)\n\n    cls_predictions = y_pred[:, :, 4:]\n    cls_labels = y_true[:, :, 5:]\n    ignore_mask = tf.cast(\n        tf.equal(y_true[:, :, 4], IGNORE_MASK_VALUE), dtype=tf.float32\n    )\n    not_ignore_mask = tf.cast(\n        tf.expand_dims(tf.equal(ignore_mask, 0.0), axis=2), dtype=tf.float32\n    )\n\n    probs = tf.nn.sigmoid(cls_predictions)\n    negative_count_mask = tf.cast(\n        tf.logical_and(tf.equal(cls_labels, 0.0), tf.equal(not_ignore_mask, 1.0)),\n        dtype=tf.float32,\n    )\n    probs = tf.where(tf.equal(negative_count_mask, 1.0), probs, 0.0)\n    probs = tf.reduce_sum(probs, axis=[-1, -2])\n    avg_probs = tf.math.divide_no_nan(\n        probs, tf.reduce_sum(negative_count_mask, axis=[-1, -2])\n    )\n    return avg_probs\n</code></pre>"},{"location":"reference/dlframeworks/keras/metrics/objdetmetrics/#niceml.dlframeworks.keras.metrics.objdetmetrics.AvgNegTargetCountObjDet","title":"AvgNegTargetCountObjDet","text":"<pre><code>AvgNegTargetCountObjDet(name='avg_neg_target_count')\n</code></pre> <p>Average negative target count for one image in object detection</p> <p>Initializes the AvgNegTargetCountObjDet</p> Source code in <code>niceml/dlframeworks/keras/metrics/objdetmetrics.py</code> <pre><code>def __init__(self, name: str = \"avg_neg_target_count\"):\n    \"\"\"Initializes the AvgNegTargetCountObjDet\"\"\"\n    self.__name__ = name\n</code></pre>"},{"location":"reference/dlframeworks/keras/metrics/objdetmetrics/#niceml.dlframeworks.keras.metrics.objdetmetrics.AvgNegTargetCountObjDet-functions","title":"Functions","text":""},{"location":"reference/dlframeworks/keras/metrics/objdetmetrics/#niceml.dlframeworks.keras.metrics.objdetmetrics.AvgNegTargetCountObjDet.__call__","title":"__call__","text":"<pre><code>__call__(y_true, y_pred)\n</code></pre> <p>Call method is used as a default interface for the metric</p> Source code in <code>niceml/dlframeworks/keras/metrics/objdetmetrics.py</code> <pre><code>def __call__(self, y_true, y_pred):\n    \"\"\"Call method is used as a default interface for the metric\"\"\"\n    negative_mask = tf.cast(\n        tf.equal(y_true[:, :, 4], NEGATIVE_MASK_VALUE), dtype=tf.float32\n    )\n    negative_mask_count = tf.reduce_sum(negative_mask, axis=-1)\n\n    return negative_mask_count\n</code></pre>"},{"location":"reference/dlframeworks/keras/metrics/objdetmetrics/#niceml.dlframeworks.keras.metrics.objdetmetrics.AvgPosPredObjDet","title":"AvgPosPredObjDet","text":"<pre><code>AvgPosPredObjDet(name='avg_pos_pred')\n</code></pre> <p>Positive Classification Values for object detection</p> <p>Initializes the AvgPosPredObjDet with the given name</p> Source code in <code>niceml/dlframeworks/keras/metrics/objdetmetrics.py</code> <pre><code>def __init__(self, name: str = \"avg_pos_pred\"):\n    \"\"\"Initializes the AvgPosPredObjDet with the given name\"\"\"\n    self.__name__ = name\n</code></pre>"},{"location":"reference/dlframeworks/keras/metrics/objdetmetrics/#niceml.dlframeworks.keras.metrics.objdetmetrics.AvgPosPredObjDet-functions","title":"Functions","text":""},{"location":"reference/dlframeworks/keras/metrics/objdetmetrics/#niceml.dlframeworks.keras.metrics.objdetmetrics.AvgPosPredObjDet.__call__","title":"__call__","text":"<pre><code>__call__(y_true, y_pred)\n</code></pre> <p>Call method is used as a default interface for the metric</p> Source code in <code>niceml/dlframeworks/keras/metrics/objdetmetrics.py</code> <pre><code>def __call__(self, y_true, y_pred):\n    \"\"\"Call method is used as a default interface for the metric\"\"\"\n    y_pred = tf.cast(y_pred, dtype=tf.float32)\n\n    cls_predictions = y_pred[:, :, 4:]\n    cls_labels = y_true[:, :, 5:]\n\n    probs = tf.nn.sigmoid(cls_predictions)\n    probs = tf.where(tf.equal(cls_labels, 1.0), probs, 0.0)\n    probs = tf.reduce_sum(probs, axis=[-1, -2])\n    avg_probs = tf.math.divide_no_nan(\n        probs, tf.reduce_sum(cls_labels, axis=[-1, -2])\n    )\n    return avg_probs\n</code></pre>"},{"location":"reference/dlframeworks/keras/metrics/objdetmetrics/#niceml.dlframeworks.keras.metrics.objdetmetrics.AvgPosTargetCountObjDet","title":"AvgPosTargetCountObjDet","text":"<pre><code>AvgPosTargetCountObjDet(name='avg_pos_target_count')\n</code></pre> <p>Average positive target count for one image in object detection</p> <p>Initializes the AvgPosTargetCountObjDet</p> Source code in <code>niceml/dlframeworks/keras/metrics/objdetmetrics.py</code> <pre><code>def __init__(self, name: str = \"avg_pos_target_count\"):\n    \"\"\"Initializes the AvgPosTargetCountObjDet\"\"\"\n    self.__name__ = name\n</code></pre>"},{"location":"reference/dlframeworks/keras/metrics/objdetmetrics/#niceml.dlframeworks.keras.metrics.objdetmetrics.AvgPosTargetCountObjDet-functions","title":"Functions","text":""},{"location":"reference/dlframeworks/keras/metrics/objdetmetrics/#niceml.dlframeworks.keras.metrics.objdetmetrics.AvgPosTargetCountObjDet.__call__","title":"__call__","text":"<pre><code>__call__(y_true, y_pred)\n</code></pre> <p>Call method is used as a default interface for the metric</p> Source code in <code>niceml/dlframeworks/keras/metrics/objdetmetrics.py</code> <pre><code>def __call__(self, y_true, y_pred):\n    \"\"\"Call method is used as a default interface for the metric\"\"\"\n    positive_mask = tf.cast(\n        tf.equal(y_true[:, :, 4], POSITIVE_MASK_VALUE), dtype=tf.float32\n    )\n    positive_mask_count = tf.reduce_sum(positive_mask, axis=-1)\n\n    return positive_mask_count\n</code></pre>"},{"location":"reference/dlframeworks/keras/metrics/semsegmetrics/","title":"semsegmetrics","text":""},{"location":"reference/dlframeworks/keras/metrics/semsegmetrics/#niceml.dlframeworks.keras.metrics.semsegmetrics","title":"semsegmetrics","text":"<p>Module for metrics for semantic segmentation</p>"},{"location":"reference/dlframeworks/keras/metrics/semsegmetrics/#niceml.dlframeworks.keras.metrics.semsegmetrics-classes","title":"Classes","text":""},{"location":"reference/dlframeworks/keras/metrics/semsegmetrics/#niceml.dlframeworks.keras.metrics.semsegmetrics.AvgNegPredSemSeg","title":"AvgNegPredSemSeg","text":"<pre><code>AvgNegPredSemSeg(name='avg_neg_pred')\n</code></pre> <p>Negative Classification Values for semantic segmentation</p> Source code in <code>niceml/dlframeworks/keras/metrics/semsegmetrics.py</code> <pre><code>def __init__(self, name: str = \"avg_neg_pred\"):\n    self.__name__ = name\n</code></pre>"},{"location":"reference/dlframeworks/keras/metrics/semsegmetrics/#niceml.dlframeworks.keras.metrics.semsegmetrics.AvgNegTargetCountSemSeg","title":"AvgNegTargetCountSemSeg","text":"<pre><code>AvgNegTargetCountSemSeg(name='avg_neg_target_count')\n</code></pre> <p>Average negative target count for one image in semantic segmentation</p> Source code in <code>niceml/dlframeworks/keras/metrics/semsegmetrics.py</code> <pre><code>def __init__(self, name: str = \"avg_neg_target_count\"):\n    self.__name__ = name\n</code></pre>"},{"location":"reference/dlframeworks/keras/metrics/semsegmetrics/#niceml.dlframeworks.keras.metrics.semsegmetrics.AvgPosPredSemSeg","title":"AvgPosPredSemSeg","text":"<pre><code>AvgPosPredSemSeg(name='avg_pos_pred')\n</code></pre> <p>Positive Classification Values for semantic segmentation</p> Source code in <code>niceml/dlframeworks/keras/metrics/semsegmetrics.py</code> <pre><code>def __init__(self, name: str = \"avg_pos_pred\"):\n    self.__name__ = name\n</code></pre>"},{"location":"reference/dlframeworks/keras/metrics/semsegmetrics/#niceml.dlframeworks.keras.metrics.semsegmetrics.AvgPosTargetCountSemSeg","title":"AvgPosTargetCountSemSeg","text":"<pre><code>AvgPosTargetCountSemSeg(name='avg_pos_target_count')\n</code></pre> <p>Average positive target count for one image in semantic segmentation</p> Source code in <code>niceml/dlframeworks/keras/metrics/semsegmetrics.py</code> <pre><code>def __init__(self, name: str = \"avg_pos_target_count\"):\n    self.__name__ = name\n</code></pre>"},{"location":"reference/dlframeworks/keras/metrics/semsegmetrics/#niceml.dlframeworks.keras.metrics.semsegmetrics-functions","title":"Functions","text":""},{"location":"reference/dlframeworks/keras/metrics/semsegmetrics/#niceml.dlframeworks.keras.metrics.semsegmetrics.avg_mask_prediction_value","title":"avg_mask_prediction_value","text":"<pre><code>avg_mask_prediction_value(mask, prediction)\n</code></pre> <p>Average prediction value for a given mask</p> Source code in <code>niceml/dlframeworks/keras/metrics/semsegmetrics.py</code> <pre><code>def avg_mask_prediction_value(mask, prediction):\n    \"\"\"Average prediction value for a given mask\"\"\"\n    prob_values = tf.where(tf.equal(mask, 1.0), prediction, 0.0)\n    probs = tf.reduce_sum(prob_values, axis=[-1, -2, -3])\n    mask_count = tf.reduce_sum(mask, axis=[-1, -2, -3])\n    avg_probs = tf.math.divide_no_nan(probs, mask_count)\n    return avg_probs\n</code></pre>"},{"location":"reference/dlframeworks/keras/modelcompiler/__init__/","title":"modelcompiler","text":""},{"location":"reference/dlframeworks/keras/modelcompiler/__init__/#niceml.dlframeworks.keras.modelcompiler","title":"modelcompiler","text":""},{"location":"reference/dlframeworks/keras/modelcompiler/defaultmodelcompiler/","title":"defaultmodelcompiler","text":""},{"location":"reference/dlframeworks/keras/modelcompiler/defaultmodelcompiler/#niceml.dlframeworks.keras.modelcompiler.defaultmodelcompiler","title":"defaultmodelcompiler","text":"<p>Module for model compilers in keras</p>"},{"location":"reference/dlframeworks/keras/modelcompiler/defaultmodelcompiler/#niceml.dlframeworks.keras.modelcompiler.defaultmodelcompiler-classes","title":"Classes","text":""},{"location":"reference/dlframeworks/keras/modelcompiler/defaultmodelcompiler/#niceml.dlframeworks.keras.modelcompiler.defaultmodelcompiler.ComplexModelCompiler","title":"ComplexModelCompiler","text":"<pre><code>ComplexModelCompiler(optimizer, metrics, losses=None)\n</code></pre> <p>             Bases: <code>ModelCompiler</code></p> <p>Complex model compiler for keras</p> Source code in <code>niceml/dlframeworks/keras/modelcompiler/defaultmodelcompiler.py</code> <pre><code>def __init__(\n    self,\n    optimizer: Union[dict, Any],\n    metrics: List,\n    losses: dict = None,\n):\n    self.losses = losses\n    self.optimizer = optimizer\n    self.metrics = metrics\n</code></pre>"},{"location":"reference/dlframeworks/keras/modelcompiler/defaultmodelcompiler/#niceml.dlframeworks.keras.modelcompiler.defaultmodelcompiler.DefaultModelCompiler","title":"DefaultModelCompiler","text":"<pre><code>DefaultModelCompiler(loss, metrics, optimizer, **kwargs)\n</code></pre> <p>             Bases: <code>ModelCompiler</code></p> <p>Simplest model compiler for keras</p> Source code in <code>niceml/dlframeworks/keras/modelcompiler/defaultmodelcompiler.py</code> <pre><code>def __init__(\n    self, loss: Union[str, dict], metrics: List, optimizer: dict, **kwargs\n):\n    self.loss = loss\n    self.metrics = metrics\n    self.optimizer = optimizer\n    self.compiler_args: dict = kwargs\n</code></pre>"},{"location":"reference/dlframeworks/keras/models/__init__/","title":"models","text":""},{"location":"reference/dlframeworks/keras/models/__init__/#niceml.dlframeworks.keras.models","title":"models","text":""},{"location":"reference/dlframeworks/keras/models/clsmodelfactory/","title":"clsmodelfactory","text":""},{"location":"reference/dlframeworks/keras/models/clsmodelfactory/#niceml.dlframeworks.keras.models.clsmodelfactory","title":"clsmodelfactory","text":""},{"location":"reference/dlframeworks/keras/models/clsmodelfactory/#niceml.dlframeworks.keras.models.clsmodelfactory-classes","title":"Classes","text":""},{"location":"reference/dlframeworks/keras/models/clsmodelfactory/#niceml.dlframeworks.keras.models.clsmodelfactory-functions","title":"Functions","text":""},{"location":"reference/dlframeworks/keras/models/layerfactory/","title":"layerfactory","text":""},{"location":"reference/dlframeworks/keras/models/layerfactory/#niceml.dlframeworks.keras.models.layerfactory","title":"layerfactory","text":"<p>Module for layerfactories</p>"},{"location":"reference/dlframeworks/keras/models/layerfactory/#niceml.dlframeworks.keras.models.layerfactory-classes","title":"Classes","text":""},{"location":"reference/dlframeworks/keras/models/layerfactory/#niceml.dlframeworks.keras.models.layerfactory.Conv2DBlockFactory","title":"Conv2DBlockFactory","text":"<pre><code>Conv2DBlockFactory(\n    channel_list,\n    kernel_size=3,\n    activation=\"relu\",\n    dropout_values=None,\n)\n</code></pre> <p>             Bases: <code>LayerFactory</code></p> <p>Layer factory for a convolution block</p> Source code in <code>niceml/dlframeworks/keras/models/layerfactory.py</code> <pre><code>def __init__(\n    self,\n    channel_list: List[int],\n    kernel_size: int = 3,\n    activation: str = \"relu\",\n    dropout_values: Optional[List[float]] = None,\n):\n    self.channel_list = channel_list\n    self.kernel_size = kernel_size\n    self.activation = activation\n    self.dropout_values = dropout_values\n</code></pre>"},{"location":"reference/dlframeworks/keras/models/layerfactory/#niceml.dlframeworks.keras.models.layerfactory.DownscaleConvBlockFactory","title":"DownscaleConvBlockFactory","text":"<pre><code>DownscaleConvBlockFactory(\n    channel_list,\n    kernel_size=3,\n    activation=\"relu\",\n    dropout_values=None,\n)\n</code></pre> <p>             Bases: <code>LayerFactory</code></p> <p>Layer factory for a downscale convolution block</p> Source code in <code>niceml/dlframeworks/keras/models/layerfactory.py</code> <pre><code>def __init__(\n    self,\n    channel_list: List[int],\n    kernel_size: int = 3,\n    activation: str = \"relu\",\n    dropout_values: Optional[List[float]] = None,\n):\n    self.channel_list = channel_list\n    self.kernel_size = kernel_size\n    self.activation = activation\n    self.dropout_values = dropout_values\n</code></pre>"},{"location":"reference/dlframeworks/keras/models/layerfactory/#niceml.dlframeworks.keras.models.layerfactory.LayerFactory","title":"LayerFactory","text":"<p>             Bases: <code>ABC</code></p> <p>Base class for layer factories</p>"},{"location":"reference/dlframeworks/keras/models/layerfactory/#niceml.dlframeworks.keras.models.layerfactory.LayerFactory-functions","title":"Functions","text":""},{"location":"reference/dlframeworks/keras/models/layerfactory/#niceml.dlframeworks.keras.models.layerfactory.LayerFactory.create_layers","title":"create_layers  <code>abstractmethod</code>","text":"<pre><code>create_layers(input_layer)\n</code></pre> <p>Creates one or multiple layers from an input layer</p> Source code in <code>niceml/dlframeworks/keras/models/layerfactory.py</code> <pre><code>@abstractmethod\ndef create_layers(self, input_layer):\n    \"\"\"Creates one or multiple layers from an input layer\"\"\"\n</code></pre>"},{"location":"reference/dlframeworks/keras/models/loadweightsmodelfactory/","title":"loadweightsmodelfactory","text":""},{"location":"reference/dlframeworks/keras/models/loadweightsmodelfactory/#niceml.dlframeworks.keras.models.loadweightsmodelfactory","title":"loadweightsmodelfactory","text":"<p>Module for LoadWeightsModelFactory</p>"},{"location":"reference/dlframeworks/keras/models/loadweightsmodelfactory/#niceml.dlframeworks.keras.models.loadweightsmodelfactory-classes","title":"Classes","text":""},{"location":"reference/dlframeworks/keras/models/loadweightsmodelfactory/#niceml.dlframeworks.keras.models.loadweightsmodelfactory.LoadWeightsModelFactory","title":"LoadWeightsModelFactory","text":"<pre><code>LoadWeightsModelFactory(\n    model_factory, weights_config, loading_options=None\n)\n</code></pre> <p>             Bases: <code>ModelFactory</code></p> <p>model factory to load weights before training starts</p> Source code in <code>niceml/dlframeworks/keras/models/loadweightsmodelfactory.py</code> <pre><code>def __init__(\n    self,\n    model_factory: ModelFactory,\n    weights_config: LocationConfig,\n    loading_options: Optional[dict] = None,\n):\n    self.model_factory = model_factory\n    self.weights_config = weights_config\n    self.loading_options = loading_options or {}\n</code></pre>"},{"location":"reference/dlframeworks/keras/models/loadweightsmodelfactory/#niceml.dlframeworks.keras.models.loadweightsmodelfactory-functions","title":"Functions","text":""},{"location":"reference/dlframeworks/keras/models/mlp/","title":"mlp","text":""},{"location":"reference/dlframeworks/keras/models/mlp/#niceml.dlframeworks.keras.models.mlp","title":"mlp","text":"<p>Module for ownmlp for keras model</p>"},{"location":"reference/dlframeworks/keras/models/mlp/#niceml.dlframeworks.keras.models.mlp-classes","title":"Classes","text":""},{"location":"reference/dlframeworks/keras/models/mlp/#niceml.dlframeworks.keras.models.mlp.OwnMLP","title":"OwnMLP","text":"<pre><code>OwnMLP(\n    hidden_layers,\n    activation=\"relu\",\n    final_activation=\"linear\",\n    do_summary=True,\n)\n</code></pre> <p>             Bases: <code>ModelFactory</code></p> <p>Modelfactory for a mlp</p> <p>Initializes the OwnMLP model factory</p> Source code in <code>niceml/dlframeworks/keras/models/mlp.py</code> <pre><code>def __init__(\n    self,\n    hidden_layers: List[int],\n    activation: str = \"relu\",\n    final_activation: str = \"linear\",\n    do_summary: bool = True,\n):\n    \"\"\"Initializes the OwnMLP model factory\"\"\"\n    self.hidden_layers = hidden_layers\n    self.activation = activation\n    self.do_summary = do_summary\n    self.final_activation = final_activation\n</code></pre>"},{"location":"reference/dlframeworks/keras/models/mlp/#niceml.dlframeworks.keras.models.mlp.OwnMLP-functions","title":"Functions","text":""},{"location":"reference/dlframeworks/keras/models/mlp/#niceml.dlframeworks.keras.models.mlp.OwnMLP.create_model","title":"create_model","text":"<pre><code>create_model(data_description)\n</code></pre> <p>Creates the mlp model</p> Source code in <code>niceml/dlframeworks/keras/models/mlp.py</code> <pre><code>def create_model(self, data_description: DataDescription) -&gt; Any:\n    \"\"\"Creates the mlp model\"\"\"\n    input_dd: InputVectorDataDescription = check_instance(\n        data_description, InputVectorDataDescription\n    )\n    output_dd: OutputVectorDataDescription = check_instance(\n        data_description, OutputVectorDataDescription\n    )\n    model = Sequential()\n    input_size = input_dd.get_input_size()\n    # first hidden layer\n    count = self.hidden_layers.pop(0)\n    model.add(\n        layers.Dense(count, activation=self.activation, input_shape=(input_size,))\n    )\n    for count in self.hidden_layers:\n        model.add(layers.Dense(count, activation=self.activation))\n\n    # Outputs from dense layer are projected onto output layer\n    target_size = output_dd.get_output_size()\n    model.add(layers.Dense(target_size, activation=self.final_activation))\n    if self.do_summary:\n        model.summary()\n\n    return model\n</code></pre>"},{"location":"reference/dlframeworks/keras/models/mlp/#niceml.dlframeworks.keras.models.mlp-functions","title":"Functions","text":""},{"location":"reference/dlframeworks/keras/models/mobilenet/","title":"mobilenet","text":""},{"location":"reference/dlframeworks/keras/models/mobilenet/#niceml.dlframeworks.keras.models.mobilenet","title":"mobilenet","text":""},{"location":"reference/dlframeworks/keras/models/mobilenet/#niceml.dlframeworks.keras.models.mobilenet-classes","title":"Classes","text":""},{"location":"reference/dlframeworks/keras/models/mobilenet/#niceml.dlframeworks.keras.models.mobilenet-functions","title":"Functions","text":""},{"location":"reference/dlframeworks/keras/models/premodellayers/","title":"premodellayers","text":""},{"location":"reference/dlframeworks/keras/models/premodellayers/#niceml.dlframeworks.keras.models.premodellayers","title":"premodellayers","text":""},{"location":"reference/dlframeworks/keras/models/premodellayers/#niceml.dlframeworks.keras.models.premodellayers-classes","title":"Classes","text":""},{"location":"reference/dlframeworks/keras/models/retinanet/","title":"retinanet","text":""},{"location":"reference/dlframeworks/keras/models/retinanet/#niceml.dlframeworks.keras.models.retinanet","title":"retinanet","text":"<p>niceml implementation of the retinanet This is a modified version of the original implementation</p> <p>https://github.com/keras-team/keras-io/blob/master/examples/vision/retinanet.py</p>"},{"location":"reference/dlframeworks/keras/models/retinanet/#niceml.dlframeworks.keras.models.retinanet-classes","title":"Classes","text":""},{"location":"reference/dlframeworks/keras/models/retinanet/#niceml.dlframeworks.keras.models.retinanet.RetinaNetFactory","title":"RetinaNetFactory","text":"<pre><code>RetinaNetFactory(\n    use_scale_lambda=True,\n    allow_preconvolution=False,\n    additional_conv_layers=None,\n)\n</code></pre> <p>             Bases: <code>ModelFactory</code></p> <p>Modelfactory which creates a RetinaNet for ObjectDetection</p> Source code in <code>niceml/dlframeworks/keras/models/retinanet.py</code> <pre><code>def __init__(\n    self,\n    use_scale_lambda: bool = True,\n    allow_preconvolution: bool = False,\n    additional_conv_layers: Optional[List[int]] = None,\n):\n    self.use_scale_lambda = use_scale_lambda\n    self.allow_preconvolution = allow_preconvolution\n    self.additional_conv_layers = additional_conv_layers\n</code></pre>"},{"location":"reference/dlframeworks/keras/models/retinanet/#niceml.dlframeworks.keras.models.retinanet-functions","title":"Functions","text":""},{"location":"reference/dlframeworks/keras/models/retinanet/#niceml.dlframeworks.keras.models.retinanet.build_head","title":"build_head","text":"<pre><code>build_head(output_filters, bias_init, layer_count=256)\n</code></pre> <p>Builds the class/box predictions head.</p> <p>Parameters:</p> <ul> <li> <code>output_filters</code>         \u2013          <p>Number of convolution filters in the final layer.</p> </li> <li> <code>bias_init</code>         \u2013          <p>Bias Initializer for the final convolution layer.</p> </li> <li> <code>layer_count</code>             (<code>int</code>, default:                 <code>256</code> )         \u2013          <p>number of layers for convolutions</p> </li> </ul> <p>Returns:</p> <ul> <li>         \u2013          <p>A keras sequential model representing either the classification or the box regression head depending on <code>output_filters</code>.</p> </li> </ul> Source code in <code>niceml/dlframeworks/keras/models/retinanet.py</code> <pre><code>def build_head(output_filters, bias_init, layer_count: int = 256):\n    \"\"\"Builds the class/box predictions head.\n\n    Arguments:\n      output_filters: Number of convolution filters in the final layer.\n      bias_init: Bias Initializer for the final convolution layer.\n      layer_count: number of layers for convolutions\n\n    Returns:\n      A keras sequential model representing either the classification\n        or the box regression head depending on `output_filters`.\n    \"\"\"\n    head = keras.Sequential([keras.Input(shape=[None, None, layer_count])])\n    kernel_init = tf.initializers.RandomNormal(0.0, 0.01)\n    for _ in range(4):\n        head.add(\n            keras.layers.Conv2D(\n                layer_count, 3, padding=\"same\", kernel_initializer=kernel_init\n            )\n        )\n        head.add(keras.layers.ReLU())\n    head.add(\n        keras.layers.Conv2D(\n            output_filters,\n            3,\n            1,\n            padding=\"same\",\n            kernel_initializer=kernel_init,\n            bias_initializer=bias_init,\n        )\n    )\n    return head\n</code></pre>"},{"location":"reference/dlframeworks/keras/models/retinanet/#niceml.dlframeworks.keras.models.retinanet.feature_pyramid","title":"feature_pyramid","text":"<pre><code>feature_pyramid(\n    layer_scaled_x,\n    layer_scaled_2x,\n    layer_scaled_4x,\n    filter_count=256,\n)\n</code></pre> <p>creates a feature pyramid</p> Source code in <code>niceml/dlframeworks/keras/models/retinanet.py</code> <pre><code>def feature_pyramid(\n    layer_scaled_x, layer_scaled_2x, layer_scaled_4x, filter_count: int = 256\n):\n    \"\"\"creates a feature pyramid\"\"\"\n    conv_c3_1x1 = layers.Conv2D(filter_count, 1, 1, \"same\")\n    conv_c4_1x1 = layers.Conv2D(filter_count, 1, 1, \"same\")\n    conv_c5_1x1 = layers.Conv2D(filter_count, 1, 1, \"same\")\n    conv_c3_3x3 = layers.Conv2D(filter_count, 3, 1, \"same\")\n    conv_c4_3x3 = layers.Conv2D(filter_count, 3, 1, \"same\")\n    conv_c5_3x3 = layers.Conv2D(filter_count, 3, 1, \"same\")\n    conv_c6_3x3 = layers.Conv2D(filter_count, 3, 2, \"same\")\n    conv_c7_3x3 = layers.Conv2D(filter_count, 3, 2, \"same\")\n    upsample_2x = layers.UpSampling2D(2)\n    layer_scaled_x = conv_c3_1x1(layer_scaled_x)\n    layer_scaled_2x = conv_c4_1x1(layer_scaled_2x)\n    layer_scaled_4x = conv_c5_1x1(layer_scaled_4x)\n    layer_scaled_2x = layer_scaled_2x + upsample_2x(layer_scaled_4x)\n    layer_scaled_x = layer_scaled_x + upsample_2x(layer_scaled_2x)\n    layer_scaled_x = conv_c3_3x3(layer_scaled_x)\n    layer_scaled_2x = conv_c4_3x3(layer_scaled_2x)\n    layer_scaled_4x = conv_c5_3x3(layer_scaled_4x)\n    layer_scaled_8x = conv_c6_3x3(layer_scaled_4x)\n    layer_scaled_16x = conv_c7_3x3(tf.nn.relu(layer_scaled_8x))\n    return [\n        layer_scaled_x,\n        layer_scaled_2x,\n        layer_scaled_4x,\n        layer_scaled_8x,\n        layer_scaled_16x,\n    ]\n</code></pre>"},{"location":"reference/dlframeworks/keras/models/retinanet/#niceml.dlframeworks.keras.models.retinanet.get_backbone","title":"get_backbone","text":"<pre><code>get_backbone(input_size)\n</code></pre> <p>Builds ResNet50 with pre-trained imagenet weights</p> Source code in <code>niceml/dlframeworks/keras/models/retinanet.py</code> <pre><code>def get_backbone(input_size: ImageSize) -&gt; Model:\n    \"\"\"Builds ResNet50 with pre-trained imagenet weights\"\"\"\n    input_shape = input_size.to_numpy_shape() + (3,)\n    backbone = ResNet50(include_top=False, input_shape=input_shape)\n    c3_output, c4_output, c5_output = [\n        backbone.get_layer(layer_name).output\n        for layer_name in [\"conv3_block4_out\", \"conv4_block6_out\", \"conv5_block3_out\"]\n    ]\n    return keras.Model(\n        inputs=[backbone.inputs], outputs=[c3_output, c4_output, c5_output]\n    )\n</code></pre>"},{"location":"reference/dlframeworks/keras/models/retinanet/#niceml.dlframeworks.keras.models.retinanet.retina_net","title":"retina_net","text":"<pre><code>retina_net(\n    feature_layers,\n    num_classes,\n    anchor_per_cell,\n    coordinates_count,\n    anchor_feature_count_list,\n)\n</code></pre> <p>Builds the heads of the feature_layers and returns one output tensor</p> <p>:param feature_layers: tensors with all feature maps :param num_classes: count of classes :param anchor_per_cell: how many anchors are generated per feature cell :param coordinates_count: how many coordinates are required to        represent the object (e.g. bounding box) :param anchor_feature_count_list: a list of anchors per feature map :return: output_tensor with shape [batch_size, num_anchors, coordinates_count + num_classes]</p> Source code in <code>niceml/dlframeworks/keras/models/retinanet.py</code> <pre><code>def retina_net(\n    feature_layers: list,\n    num_classes: int,\n    anchor_per_cell: int,\n    coordinates_count: int,\n    anchor_feature_count_list: List[int],\n):\n    \"\"\"\n    Builds the heads of the feature_layers and returns one output tensor\n\n    :param feature_layers: tensors with all feature maps\n    :param num_classes: count of classes\n    :param anchor_per_cell: how many anchors are generated per feature cell\n    :param coordinates_count: how many coordinates are required to\n           represent the object (e.g. bounding box)\n    :param anchor_feature_count_list: a list of anchors per feature map\n    :return: output_tensor with shape [batch_size, num_anchors, coordinates_count + num_classes]\n    \"\"\"\n    prior_probability = tf.constant_initializer(-np.log((1 - 0.01) / 0.01))\n    cls_head = build_head(anchor_per_cell * num_classes, prior_probability)\n    box_head = build_head(anchor_per_cell * coordinates_count, \"zeros\")\n\n    cls_outputs = []\n    box_outputs = []\n\n    assert len(feature_layers) == len(anchor_feature_count_list)\n\n    for feature, cur_anchor_count in zip(feature_layers, anchor_feature_count_list):\n        cur_box_head = box_head(feature)\n        box_outputs.append(\n            tf.reshape(cur_box_head, [-1, cur_anchor_count, coordinates_count])\n        )\n        cur_cls_head = cls_head(feature)\n        cls_outputs.append(\n            tf.reshape(cur_cls_head, [-1, cur_anchor_count, num_classes])\n        )\n    cls_outputs = tf.concat(cls_outputs, axis=1)\n    box_outputs = tf.concat(box_outputs, axis=1)\n    return tf.concat([box_outputs, cls_outputs], axis=-1)\n</code></pre>"},{"location":"reference/dlframeworks/keras/models/unets/","title":"unets","text":""},{"location":"reference/dlframeworks/keras/models/unets/#niceml.dlframeworks.keras.models.unets","title":"unets","text":"<p>Module for unets</p>"},{"location":"reference/dlframeworks/keras/models/unets/#niceml.dlframeworks.keras.models.unets-classes","title":"Classes","text":""},{"location":"reference/dlframeworks/keras/models/unets/#niceml.dlframeworks.keras.models.unets.UNetModel","title":"UNetModel","text":"<pre><code>UNetModel(\n    channels,\n    skip_connection_names,\n    model_factory,\n    depth=None,\n    use_input_scale=False,\n    use_output_scale=False,\n    activation=\"sigmoid\",\n    enable_skip_connections=True,\n    allow_preconvolution=False,\n    additional_conv_layers=None,\n    downscale_layer_factory=None,\n    post_layer_factory=None,\n    **kwargs\n)\n</code></pre> <p>             Bases: <code>ModelFactory</code></p> <p>Factory method for creating a UNet model</p> <p>Creates a Resnet50 UNet variation for pixelwise output. The output has the same dimension as the input.</p>"},{"location":"reference/dlframeworks/keras/models/unets/#niceml.dlframeworks.keras.models.unets.UNetModel--parameters","title":"Parameters","text":"<p>skip_connection_names: List[str]     The names of the layers to use as skip connections. depth: Optional[int], default None     Describes the amount of skip_connections used.     If not given it uses the maximal amount w.r.t the given     channels or the the maximal mobilenet depth (count of downsamplings, 5). channels: Optional[List[int]], default [16, 32, 48, 64, 128]     How many channels after each upsampling should be used. use_input_scale: bool, default False     If true the input is divided by 255.0 use_output_scale: bool, default False     If true the output is multiplied by 255.0 activation: Optional[str], default sigmoid     Final activation, used for last layer enable_skip_connections: Optional[bool], default True,     Determines, whether to use skip connections allow_preconvolution: bool, default False     Uses a convolution to normalize the amount of layers to three. model_params: Optional[dict], default None     Additional params to init the modelfactory additional_conv_layers: Optional[List[int]], default None     Additional conv layers to add between the input and model. downscale_layer_factory: Optional[LayerFactory], default None     Factory to create the downscale layers. post_layer_factory: Optional[LayerFactory], default None     Factory to create the post layers.</p> Source code in <code>niceml/dlframeworks/keras/models/unets.py</code> <pre><code>def __init__(  # pylint: disable=too-many-arguments,too-many-locals\n    self,\n    channels: List[int],\n    skip_connection_names: List[str],\n    model_factory: Callable,\n    depth: Optional[int] = None,\n    use_input_scale: bool = False,\n    use_output_scale: bool = False,\n    activation: str = \"sigmoid\",\n    enable_skip_connections: bool = True,\n    allow_preconvolution: bool = False,\n    additional_conv_layers: Optional[List[int]] = None,\n    downscale_layer_factory: Optional[LayerFactory] = None,\n    post_layer_factory: Optional[LayerFactory] = None,\n    **kwargs,\n):\n    \"\"\"\n    Creates a Resnet50 UNet variation for pixelwise output.\n    The output has the same dimension as the input.\n\n    Parameters\n    ----------\n    skip_connection_names: List[str]\n        The names of the layers to use as skip connections.\n    depth: Optional[int], default None\n        Describes the amount of skip_connections used.\n        If not given it uses the maximal amount w.r.t the given\n        channels or the the maximal mobilenet depth (count of downsamplings, 5).\n    channels: Optional[List[int]], default [16, 32, 48, 64, 128]\n        How many channels after each upsampling should be used.\n    use_input_scale: bool, default False\n        If true the input is divided by 255.0\n    use_output_scale: bool, default False\n        If true the output is multiplied by 255.0\n    activation: Optional[str], default sigmoid\n        Final activation, used for last layer\n    enable_skip_connections: Optional[bool], default True,\n        Determines, whether to use skip connections\n    allow_preconvolution: bool, default False\n        Uses a convolution to normalize the amount of layers to three.\n    model_params: Optional[dict], default None\n        Additional params to init the modelfactory\n    additional_conv_layers: Optional[List[int]], default None\n        Additional conv layers to add between the input and model.\n    downscale_layer_factory: Optional[LayerFactory], default None\n        Factory to create the downscale layers.\n    post_layer_factory: Optional[LayerFactory], default None\n        Factory to create the post layers.\n\n    \"\"\"\n    self.model_factory = model_factory\n    self.model_params = kwargs\n    self.channels: List[int] = [64, 128, 256, 512] if channels is None else channels\n    self.depth: int = len(self.channels) + 1 if depth is None else depth\n    # adjust channels again\n    self.channels = self.channels[: self.depth - 1]\n    self.skip_connection_names = skip_connection_names[: self.depth]\n    self.activation = activation\n    self.use_input_scale = use_input_scale\n    self.use_output_scale = use_output_scale\n    self.enable_skip_connections = enable_skip_connections\n    self.allow_preconvolution = allow_preconvolution\n    self.additional_conv_layers = additional_conv_layers\n    self.downscale_layer_factory = downscale_layer_factory\n    self.post_layer_factory = post_layer_factory\n</code></pre>"},{"location":"reference/dlframeworks/keras/models/unets/#niceml.dlframeworks.keras.models.unets.UNetModel-functions","title":"Functions","text":""},{"location":"reference/dlframeworks/keras/models/unets/#niceml.dlframeworks.keras.models.unets.UNetModel.create_model","title":"create_model","text":"<pre><code>create_model(data_description)\n</code></pre> <p>Create a model for the given data description.</p> <p>Parameters:</p> <ul> <li> <code>data_description</code>             (<code>DataDescription</code>)         \u2013          <p>Data description the model is based on</p> </li> </ul> <p>Returns:     A Unet model object</p> Source code in <code>niceml/dlframeworks/keras/models/unets.py</code> <pre><code>def create_model(self, data_description: DataDescription) -&gt; Any:\n    \"\"\"\n    Create a model for the given data description.\n\n    Args:\n        data_description: Data description the model is based on\n    Returns:\n        A Unet model object\n    \"\"\"\n    input_dd: InputImageDataDescription = check_instance(\n        data_description, InputImageDataDescription\n    )\n    output_dd: OutputImageDataDescription = check_instance(\n        data_description, OutputImageDataDescription\n    )\n    expected_input_channels = 3\n    if (\n        not self.allow_preconvolution\n        and input_dd.get_input_channel_count() != expected_input_channels\n    ):\n        raise Exception(\n            f\"Input channels must have the size of {expected_input_channels}!\"\n            f\" Instead size == {input_dd.get_input_channel_count()}\"\n        )\n    input_image_size = input_dd.get_input_image_size()\n    output_image_size = output_dd.get_output_image_size()\n    skip_connection_count = len(self.skip_connection_names)\n    image_size_scale = input_image_size.get_division_factor(output_image_size)\n\n    if not math.log(image_size_scale, 2).is_integer():\n        raise Exception(\n            f\"Image size scale must be a power of 2! Instead {image_size_scale}\"\n        )\n    input_shape = input_image_size.to_numpy_shape() + (3,)\n    inputs = layers.Input(shape=input_shape, name=\"image\")\n    actual_layer = inputs\n\n    encoder = self.model_factory(\n        input_tensor=actual_layer,\n        weights=\"imagenet\",\n        include_top=False,\n        **self.model_params,\n    )\n    encoder_output = encoder.get_layer(self.skip_connection_names.pop()).output\n\n    actual_layer = encoder_output\n    actual_image_size = input_image_size / (2 ** (skip_connection_count - 1))\n    for skip_connection_name in reversed(self.skip_connection_names):\n        if actual_image_size &gt;= output_image_size:\n            break\n        channels = self.channels.pop()\n        x_skip = encoder.get_layer(skip_connection_name).output\n        actual_layer = layers.UpSampling2D((2, 2))(actual_layer)\n        if self.enable_skip_connections:\n            actual_layer = layers.Concatenate()([actual_layer, x_skip])\n\n        actual_layer = layers.Conv2D(channels, (3, 3), padding=\"same\")(actual_layer)\n        actual_layer = layers.BatchNormalization()(actual_layer)\n        actual_layer = layers.Activation(\"relu\")(actual_layer)\n\n        actual_layer = layers.Conv2D(channels, (3, 3), padding=\"same\")(actual_layer)\n        actual_layer = layers.BatchNormalization()(actual_layer)\n        actual_layer = layers.Activation(\"relu\")(actual_layer)\n        actual_image_size *= 2\n\n    while actual_image_size &gt; output_image_size:\n        if self.downscale_layer_factory is None:\n            raise Exception(\n                \"Downscale layer factory must be given, if the image size \"\n                \"after the skip connections is larger than the output image size!\"\n            )\n        actual_layer = self.downscale_layer_factory.create_layers(actual_layer)\n        actual_image_size /= 2\n\n    if self.post_layer_factory is not None:\n        actual_layer = self.post_layer_factory.create_layers(actual_layer)\n\n    output_conv_name = \"output_conv\" if self.use_output_scale else \"output\"\n    filters = output_dd.get_output_channel_count()\n    if output_dd.get_use_void_class():\n        filters += 1\n    actual_layer = layers.Conv2D(\n        name=output_conv_name,\n        filters=filters,\n        kernel_size=(1, 1),\n        activation=self.activation,\n        padding=\"same\",\n    )(actual_layer)\n\n    if self.use_output_scale:\n        actual_layer = layers.Lambda(lambda x: x * 255.0, name=\"output\")(\n            actual_layer\n        )\n\n    model = Model(inputs, actual_layer)\n    model.summary()\n\n    model = add_premodel_layers(\n        allow_preconvolution=self.allow_preconvolution,\n        use_input_scale=self.use_input_scale,\n        data_desc=input_dd,\n        model=model,\n        additional_conv_layers=self.additional_conv_layers,\n    )\n\n    return model\n</code></pre>"},{"location":"reference/dlframeworks/keras/models/unets/#niceml.dlframeworks.keras.models.unets-functions","title":"Functions","text":""},{"location":"reference/dlframeworks/keras/models/unets/#niceml.dlframeworks.keras.models.unets.mobilenetv2_unet","title":"mobilenetv2_unet","text":"<pre><code>mobilenetv2_unet(**kwargs)\n</code></pre> <p>Creates a MobileNetV2 U-Net model.</p> Source code in <code>niceml/dlframeworks/keras/models/unets.py</code> <pre><code>def mobilenetv2_unet(**kwargs):\n    \"\"\"Creates a MobileNetV2 U-Net model.\"\"\"\n    skip_connections: List[str] = [\n        \"image\",\n        \"block_1_expand_relu\",\n        \"block_3_expand_relu\",\n        \"block_6_expand_relu\",\n        \"block_13_expand_relu\",\n        \"out_relu\",\n    ]\n    channels = [48, 64, 128, 256, 512]\n    return UNetModel(\n        channels=channels,\n        skip_connection_names=skip_connections,\n        model_factory=MobileNetV2,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/dlframeworks/keras/models/unets/#niceml.dlframeworks.keras.models.unets.resnet50_unet","title":"resnet50_unet","text":"<pre><code>resnet50_unet(**kwargs)\n</code></pre> <p>Creates a ResNet50 U-Net model.</p> Source code in <code>niceml/dlframeworks/keras/models/unets.py</code> <pre><code>def resnet50_unet(**kwargs):\n    \"\"\"Creates a ResNet50 U-Net model.\"\"\"\n    resnet_50_skipconnections: List[str] = [\n        \"image\",\n        \"conv1_relu\",\n        \"conv2_block3_out\",\n        \"conv3_block4_out\",\n        \"conv4_block6_out\",\n    ]\n    channels = [64, 128, 256, 512]\n    return UNetModel(\n        channels=channels,\n        skip_connection_names=resnet_50_skipconnections,\n        model_factory=ResNet50,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/dlframeworks/keras/models/unets/#niceml.dlframeworks.keras.models.unets.resnet50v2_unet","title":"resnet50v2_unet","text":"<pre><code>resnet50v2_unet(**kwargs)\n</code></pre> <p>Creates a ResNet50V2 U-Net model.</p> Source code in <code>niceml/dlframeworks/keras/models/unets.py</code> <pre><code>def resnet50v2_unet(**kwargs):\n    \"\"\"Creates a ResNet50V2 U-Net model.\"\"\"\n    skip_connections: List[str] = [\n        \"image\",\n        \"conv1_conv\",\n        \"conv2_block3_1_relu\",\n        \"conv3_block4_1_relu\",\n        \"conv4_block6_1_relu\",\n        \"post_relu\",\n    ]\n    channels = [48, 64, 128, 256, 512]\n    return UNetModel(\n        channels=channels,\n        skip_connection_names=skip_connections,\n        model_factory=ResNet50V2,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/dlframeworks/keras/models/unets/#niceml.dlframeworks.keras.models.unets.vgg16_unet","title":"vgg16_unet","text":"<pre><code>vgg16_unet(**kwargs)\n</code></pre> <p>Creates a VGG16 U-Net model.</p> Source code in <code>niceml/dlframeworks/keras/models/unets.py</code> <pre><code>def vgg16_unet(**kwargs):\n    \"\"\"Creates a VGG16 U-Net model.\"\"\"\n    skip_connections: List[str] = [\n        \"block1_conv2\",\n        \"block2_conv2\",\n        \"block3_conv3\",\n        \"block4_conv3\",\n        \"block5_conv3\",\n        \"block5_pool\",\n    ]\n    channels = [48, 64, 128, 256, 512]\n    return UNetModel(\n        channels=channels,\n        skip_connection_names=skip_connections,\n        model_factory=VGG16,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/dlframeworks/keras/models/unets/#niceml.dlframeworks.keras.models.unets.xception_unet","title":"xception_unet","text":"<pre><code>xception_unet(**kwargs)\n</code></pre> <p>Creates a Xception U-Net model. WARNING: Downscaling needs to be 16 or greater!</p> Source code in <code>niceml/dlframeworks/keras/models/unets.py</code> <pre><code>def xception_unet(**kwargs):\n    \"\"\"Creates a Xception U-Net model.\n    WARNING: Downscaling needs to be 16 or greater!\"\"\"\n    skip_connections: List[str] = [\n        \"image\",\n        \"block2_sepconv2_bn\",\n        \"block3_sepconv2_bn\",\n        \"block4_sepconv2_bn\",\n        \"block13_sepconv2_bn\",\n        \"block14_sepconv2_act\",\n    ]\n    channels = [64, 128, 256, 728, 1024]\n    return UNetModel(\n        channels=channels,\n        skip_connection_names=skip_connections,\n        model_factory=Xception,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/dlframeworks/keras/optimizers/__init__/","title":"optimizers","text":""},{"location":"reference/dlframeworks/keras/optimizers/__init__/#niceml.dlframeworks.keras.optimizers","title":"optimizers","text":""},{"location":"reference/dlframeworks/keras/optimizers/schedules/__init__/","title":"schedules","text":""},{"location":"reference/dlframeworks/keras/optimizers/schedules/__init__/#niceml.dlframeworks.keras.optimizers.schedules","title":"schedules","text":""},{"location":"reference/dlframeworks/keras/optimizers/schedules/cycliclrschedule/","title":"cycliclrschedule","text":""},{"location":"reference/dlframeworks/keras/optimizers/schedules/cycliclrschedule/#niceml.dlframeworks.keras.optimizers.schedules.cycliclrschedule","title":"cycliclrschedule","text":"<p>Module for cycliclearningrateschedule</p>"},{"location":"reference/dlframeworks/keras/optimizers/schedules/cycliclrschedule/#niceml.dlframeworks.keras.optimizers.schedules.cycliclrschedule-classes","title":"Classes","text":""},{"location":"reference/dlframeworks/keras/optimizers/schedules/cycliclrschedule/#niceml.dlframeworks.keras.optimizers.schedules.cycliclrschedule.CyclicLRSchedule","title":"CyclicLRSchedule","text":"<pre><code>CyclicLRSchedule(max_lr, cycle_size, min_lr=None)\n</code></pre> <p>             Bases: <code>LearningRateSchedule</code></p> <p>Cyclic learning rate schedule</p> <p>Constructor for CyclicLRSchedule Args:     max_lr: maximum learning rate     cycle_size: steps per cycle     min_lr: minimum learning rate (default: max_lr / 10)</p> Source code in <code>niceml/dlframeworks/keras/optimizers/schedules/cycliclrschedule.py</code> <pre><code>def __init__(self, max_lr: float, cycle_size: int, min_lr: Optional[float] = None):\n    \"\"\"\n    Constructor for CyclicLRSchedule\n    Args:\n        max_lr: maximum learning rate\n        cycle_size: steps per cycle\n        min_lr: minimum learning rate (default: max_lr / 10)\n    \"\"\"\n    super().__init__()\n    self.max_lr = max_lr\n    self.cycle_size = cycle_size\n    self.min_lr = min_lr or max_lr / 10\n</code></pre>"},{"location":"reference/dlframeworks/keras/optimizers/schedules/cycliclrschedule/#niceml.dlframeworks.keras.optimizers.schedules.cycliclrschedule.CyclicLRSchedule-functions","title":"Functions","text":""},{"location":"reference/dlframeworks/keras/optimizers/schedules/cycliclrschedule/#niceml.dlframeworks.keras.optimizers.schedules.cycliclrschedule.CyclicLRSchedule.__call__","title":"__call__","text":"<pre><code>__call__(step)\n</code></pre> <p>Return the learning rate for a given step</p> Source code in <code>niceml/dlframeworks/keras/optimizers/schedules/cycliclrschedule.py</code> <pre><code>def __call__(self, step):\n    \"\"\"Return the learning rate for a given step\"\"\"\n    step = tf.cast(step, tf.float32)\n    cycle = tf.floor(1 + step / self.cycle_size)\n    x_value = tf.abs(step / (self.cycle_size / 2) - 2 * cycle + 1)\n    learning_rate = self.min_lr + (self.max_lr - self.min_lr) * tf.maximum(\n        0.0, (1 - x_value)\n    )\n    return learning_rate\n</code></pre>"},{"location":"reference/dlframeworks/keras/optimizers/schedules/cycliclrschedule/#niceml.dlframeworks.keras.optimizers.schedules.cycliclrschedule.CyclicLRSchedule.get_config","title":"get_config","text":"<pre><code>get_config()\n</code></pre> <p>Return the config of the schedule</p> Source code in <code>niceml/dlframeworks/keras/optimizers/schedules/cycliclrschedule.py</code> <pre><code>def get_config(self) -&gt; dict:\n    \"\"\"Return the config of the schedule\"\"\"\n    return {\n        \"max_lr\": self.max_lr,\n        \"cycle_size\": self.cycle_size,\n        \"min_lr\": self.min_lr,\n    }\n</code></pre>"},{"location":"reference/dlframeworks/keras/predictionfunctions/__init__/","title":"predictionfunctions","text":""},{"location":"reference/dlframeworks/keras/predictionfunctions/__init__/#niceml.dlframeworks.keras.predictionfunctions","title":"predictionfunctions","text":""},{"location":"reference/dlframeworks/keras/predictionfunctions/keraspredictionfunction/","title":"keraspredictionfunction","text":""},{"location":"reference/dlframeworks/keras/predictionfunctions/keraspredictionfunction/#niceml.dlframeworks.keras.predictionfunctions.keraspredictionfunction","title":"keraspredictionfunction","text":"<p>module for keras prediction function</p>"},{"location":"reference/dlframeworks/keras/predictionfunctions/keraspredictionfunction/#niceml.dlframeworks.keras.predictionfunctions.keraspredictionfunction-classes","title":"Classes","text":""},{"location":"reference/dlframeworks/keras/predictionfunctions/keraspredictionfunction/#niceml.dlframeworks.keras.predictionfunctions.keraspredictionfunction.KerasPredictionFunction","title":"KerasPredictionFunction","text":"<p>             Bases: <code>PredictionFunction</code></p> <p>Prediction function for keras models</p>"},{"location":"reference/dlframeworks/keras/predictionfunctions/keraspredictionfunction/#niceml.dlframeworks.keras.predictionfunctions.keraspredictionfunction.KerasPredictionFunction-functions","title":"Functions","text":""},{"location":"reference/dlframeworks/keras/predictionfunctions/keraspredictionfunction/#niceml.dlframeworks.keras.predictionfunctions.keraspredictionfunction.KerasPredictionFunction.predict","title":"predict","text":"<pre><code>predict(model, data_x)\n</code></pre> <p>uses a keras model to predict the data</p> Source code in <code>niceml/dlframeworks/keras/predictionfunctions/keraspredictionfunction.py</code> <pre><code>def predict(self, model, data_x) -&gt; Any:\n    \"\"\"uses a keras model to predict the data\"\"\"\n    pred = model.predict_step(data_x).numpy()\n    return pred\n</code></pre>"},{"location":"reference/experiments/__init__/","title":"experiments","text":""},{"location":"reference/experiments/__init__/#niceml.experiments","title":"experiments","text":""},{"location":"reference/experiments/confextractionmetafunction/","title":"confextractionmetafunction","text":""},{"location":"reference/experiments/confextractionmetafunction/#niceml.experiments.confextractionmetafunction","title":"confextractionmetafunction","text":"<p>modules for configinfoextractor</p>"},{"location":"reference/experiments/confextractionmetafunction/#niceml.experiments.confextractionmetafunction-classes","title":"Classes","text":""},{"location":"reference/experiments/confextractionmetafunction/#niceml.experiments.confextractionmetafunction.ConfigInfoExtractor","title":"ConfigInfoExtractor","text":"<pre><code>ConfigInfoExtractor(\n    name,\n    info_path,\n    info_format_func=None,\n    use_yaml_files=False,\n)\n</code></pre> <p>             Bases: <code>MetaFunction</code></p> <p>Extracts information from ExperimentData</p> Source code in <code>niceml/experiments/confextractionmetafunction.py</code> <pre><code>def __init__(\n    self,\n    name: str,\n    info_path: Union[List[Union[str, int]], List[List[Union[str, int]]]],\n    info_format_func: Optional[Callable] = None,\n    use_yaml_files: bool = False,\n):\n    self.name = name\n    self.info_path_list: List[List[Union[str, int]]] = (\n        info_path if isinstance(info_path[0], list) else [info_path]\n    )\n    self.info_format_func = info_format_func\n    self.use_yaml_files = use_yaml_files\n</code></pre>"},{"location":"reference/experiments/confextractionmetafunction/#niceml.experiments.confextractionmetafunction.DictKeysToStringFormatFunc","title":"DictKeysToStringFormatFunc","text":"<pre><code>DictKeysToStringFormatFunc(key_list, join_str='x')\n</code></pre> <p>Extracts the given key list from the dictionary</p> Source code in <code>niceml/experiments/confextractionmetafunction.py</code> <pre><code>def __init__(self, key_list: List[str], join_str: str = \"x\"):\n    self.key_list = key_list\n    self.join_str = join_str\n</code></pre>"},{"location":"reference/experiments/confextractionmetafunction/#niceml.experiments.confextractionmetafunction-functions","title":"Functions","text":""},{"location":"reference/experiments/confextractionmetafunction/#niceml.experiments.confextractionmetafunction.git_hashtag_shortener","title":"git_hashtag_shortener","text":"<pre><code>git_hashtag_shortener(hashtag)\n</code></pre> <p>Return a 6-digit hashtag</p> Source code in <code>niceml/experiments/confextractionmetafunction.py</code> <pre><code>def git_hashtag_shortener(hashtag: Union[str, bytes, None]):\n    \"\"\"Return a 6-digit hashtag\"\"\"\n    if hashtag is None:\n        return None\n    if isinstance(hashtag, bytes):\n        hashtag = hashtag.decode(\"utf-8\")\n    return hashtag[:6]\n</code></pre>"},{"location":"reference/experiments/confextractionmetafunction/#niceml.experiments.confextractionmetafunction.hydra_instance_format","title":"hydra_instance_format","text":"<pre><code>hydra_instance_format(input_data)\n</code></pre> <p>Selects between target (dict) and origignal str</p> Source code in <code>niceml/experiments/confextractionmetafunction.py</code> <pre><code>def hydra_instance_format(input_data: Union[str, dict]) -&gt; str:\n    \"\"\"Selects between _target_ (dict) and origignal str\"\"\"\n    if isinstance(input_data, dict):\n        if \"_target_\" not in input_data:\n            raise KeyError(f\"Key _target_ not in input: {input_data}\")\n        info: str = input_data[\"_target_\"]\n        info = rsplit_format_func(info) + \"(\"\n        args = [\n            f\"{cur_arg}={input_data[cur_arg]}\"\n            for cur_arg in input_data\n            if cur_arg != \"_target_\"\n        ]\n        info += \",\".join(args) + \")\"\n\n    elif isinstance(input_data, str):\n        info = input_data\n    else:\n        info = str(input_data)\n    return info\n</code></pre>"},{"location":"reference/experiments/confextractionmetafunction/#niceml.experiments.confextractionmetafunction.list_to_str_format_func","title":"list_to_str_format_func","text":"<pre><code>list_to_str_format_func(input_list)\n</code></pre> <p>Concatenates a list of str joined with a comma</p> Source code in <code>niceml/experiments/confextractionmetafunction.py</code> <pre><code>def list_to_str_format_func(input_list: Union[list, str, None]) -&gt; Optional[str]:\n    \"\"\"Concatenates a list of str joined with a comma\"\"\"\n    if input_list is None:\n        return None\n    if isinstance(input_list, str):\n        return input_list\n    str_list = [str(x) for x in input_list]\n    out_str = \",\".join(str_list)\n    return out_str\n</code></pre>"},{"location":"reference/experiments/confextractionmetafunction/#niceml.experiments.confextractionmetafunction.list_type_format_func","title":"list_type_format_func","text":"<pre><code>list_type_format_func(input_list)\n</code></pre> <p>Select from every list entry the target component</p> Source code in <code>niceml/experiments/confextractionmetafunction.py</code> <pre><code>def list_type_format_func(input_list: List[dict]):\n    \"\"\"Select from every list entry the _target_ component\"\"\"\n    out_list = []\n    for cur_type in input_list:\n        out_list.append(str_or_type_format_func(cur_type))\n    return out_list\n</code></pre>"},{"location":"reference/experiments/confextractionmetafunction/#niceml.experiments.confextractionmetafunction.rsplit_format_func","title":"rsplit_format_func","text":"<pre><code>rsplit_format_func(input_str)\n</code></pre> <p>Returns the last part after the dot</p> Source code in <code>niceml/experiments/confextractionmetafunction.py</code> <pre><code>def rsplit_format_func(input_str: str) -&gt; str:\n    \"\"\"Returns the last part after the dot\"\"\"\n    if \".\" not in input_str:\n        return input_str\n    if input_str.endswith(\".\"):\n        input_str = input_str[:-1]\n    return input_str.rsplit(\".\", maxsplit=1)[1]\n</code></pre>"},{"location":"reference/experiments/confextractionmetafunction/#niceml.experiments.confextractionmetafunction.str_or_type_format_func","title":"str_or_type_format_func","text":"<pre><code>str_or_type_format_func(input)\n</code></pre> <p>Selects between target (dict) and origignal str</p> Source code in <code>niceml/experiments/confextractionmetafunction.py</code> <pre><code>def str_or_type_format_func(input: Union[str, dict]) -&gt; str:\n    \"\"\"Selects between _target_ (dict) and origignal str\"\"\"\n    if isinstance(input, dict):\n        if \"_target_\" not in input:\n            raise KeyError(f\"Key _target_ not in input: {input}\")\n        info: str = input[\"_target_\"]\n        info = rsplit_format_func(info)\n    elif isinstance(input, str):\n        info = input\n    else:\n        info = str(input)\n    return info\n</code></pre>"},{"location":"reference/experiments/expdatalocalstorageloader/","title":"expdatalocalstorageloader","text":""},{"location":"reference/experiments/expdatalocalstorageloader/#niceml.experiments.expdatalocalstorageloader","title":"expdatalocalstorageloader","text":"<p>Module which contains factory methods for creating experiment data objects</p>"},{"location":"reference/experiments/expdatalocalstorageloader/#niceml.experiments.expdatalocalstorageloader-classes","title":"Classes","text":""},{"location":"reference/experiments/expdatalocalstorageloader/#niceml.experiments.expdatalocalstorageloader-functions","title":"Functions","text":""},{"location":"reference/experiments/expdatalocalstorageloader/#niceml.experiments.expdatalocalstorageloader.create_expdata_from_expcontext","title":"create_expdata_from_expcontext","text":"<pre><code>create_expdata_from_expcontext(exp_context)\n</code></pre> <p>Creates and loads an experiment data with the given experiment context</p> Source code in <code>niceml/experiments/expdatalocalstorageloader.py</code> <pre><code>def create_expdata_from_expcontext(exp_context: ExperimentContext) -&gt; ExperimentData:\n    \"\"\"Creates and loads an experiment data with the given experiment context\"\"\"\n    storage = FSSpecStorage(exp_context.fs_config)\n    return create_expdata_from_local_storage(storage=storage, exp_path=\"\")\n</code></pre>"},{"location":"reference/experiments/expdatalocalstorageloader/#niceml.experiments.expdatalocalstorageloader.create_expdata_from_local_storage","title":"create_expdata_from_local_storage","text":"<pre><code>create_expdata_from_local_storage(exp_path, storage=None)\n</code></pre> <p>Creates and loads an experiment data with the given path</p> Source code in <code>niceml/experiments/expdatalocalstorageloader.py</code> <pre><code>def create_expdata_from_local_storage(\n    exp_path: str,\n    storage: Optional[StorageInterface] = None,\n) -&gt; ExperimentData:\n    \"\"\"Creates and loads an experiment data with the given path\"\"\"\n    if storage is None:\n        storage = LocalStorage()\n    df_loader = SimpleDfLoader(storage, working_dir=exp_path)\n    image_loader = SimpleImageLoader(storage, working_dir=exp_path)\n    return create_expdata_from_storage(\n        exp_path, storage, image_loader=image_loader, df_loader=df_loader\n    )\n</code></pre>"},{"location":"reference/experiments/expdatastorageloader/","title":"expdatastorageloader","text":""},{"location":"reference/experiments/expdatastorageloader/#niceml.experiments.expdatastorageloader","title":"expdatastorageloader","text":"<p>Module for loading remote ExperimentData</p>"},{"location":"reference/experiments/expdatastorageloader/#niceml.experiments.expdatastorageloader-classes","title":"Classes","text":""},{"location":"reference/experiments/expdatastorageloader/#niceml.experiments.expdatastorageloader-functions","title":"Functions","text":""},{"location":"reference/experiments/expdatastorageloader/#niceml.experiments.expdatastorageloader.create_expdata_from_storage","title":"create_expdata_from_storage","text":"<pre><code>create_expdata_from_storage(\n    exp_path, storage, image_loader=None, df_loader=None\n)\n</code></pre> <p>Creates and loads an experiment data with the given path</p> Source code in <code>niceml/experiments/expdatastorageloader.py</code> <pre><code>def create_expdata_from_storage(\n    exp_path: str,\n    storage: StorageInterface,\n    image_loader: Optional[ImageLoader] = None,\n    df_loader: Optional[DfLoader] = None,\n) -&gt; ExperimentData:\n    \"\"\"Creates and loads an experiment data with the given path\"\"\"\n    exp_info: ExperimentInfo = load_exp_info(storage, exp_path)\n    try:\n        exp_file_df: pd.DataFrame = LoadParquetFile().load_data(\n            storage.join_paths(exp_path, ExperimentFilenames.EXP_FILES_FILE),\n            storage,\n        )\n        exp_files: List[str] = exp_file_df[ExperimentFilenames.EXP_FILES_COL].tolist()\n        exp_files = [storage.join_paths(exp_path, x) for x in exp_files]\n    except (EmptyDataError, FileNotFoundError):\n        exp_files = storage.list_data(exp_path)\n\n    try:\n        log_data: pd.DataFrame = LoadCsvFile().load_data(\n            storage.join_paths(exp_path, ExperimentFilenames.TRAIN_LOGS),\n            storage,\n        )\n    except (EmptyDataError, FileNotFoundError):\n        log_data = pd.DataFrame()\n    yaml_data = read_remote_data(\n        exp_path, exp_files, storage, [\".yaml\", \".yml\"], LoadYamlFile()\n    )\n\n    rel_exp_files = [relpath(x, exp_path) for x in exp_files]\n\n    exp_data = ExperimentData(\n        exp_path,\n        exp_info=exp_info,\n        log_data=log_data,\n        exp_files=rel_exp_files,\n        exp_dict_data=yaml_data,\n        image_loader=image_loader,\n        df_loader=df_loader,\n    )\n    return exp_data\n</code></pre>"},{"location":"reference/experiments/expdatastorageloader/#niceml.experiments.expdatastorageloader.read_remote_data","title":"read_remote_data","text":"<pre><code>read_remote_data(\n    exp_path, exp_files, storage, extensions, load_data_func\n)\n</code></pre> <p>Loads remote data and returns them in a dictionary with corresponding paths.</p>"},{"location":"reference/experiments/expdatastorageloader/#niceml.experiments.expdatastorageloader.read_remote_data--parameters","title":"Parameters","text":"<p>exp_path: str     path to the experiment exp_files: List[str]     all files which should be considered, absolute paths storage: StorageInterface     interface to load data from cloud storage extensions: List[str]     extension list to filter the files e.g. ['.yml', '.yaml'] load_data_func: LoadDataFunc     function to load the data Returns</p> <p>A dictionary with relative paths (without extension) to the data</p> Source code in <code>niceml/experiments/expdatastorageloader.py</code> <pre><code>def read_remote_data(\n    exp_path: str,\n    exp_files: List[str],\n    storage: StorageInterface,\n    extensions: List[str],\n    load_data_func: LoadDataFunc,\n) -&gt; Dict[str, Any]:\n    \"\"\"\n    Loads remote data and returns them in a dictionary with corresponding paths.\n\n    Parameters\n    ----------\n    exp_path: str\n        path to the experiment\n    exp_files: List[str]\n        all files which should be considered, absolute paths\n    storage: StorageInterface\n        interface to load data from cloud storage\n    extensions: List[str]\n        extension list to filter the files e.g. ['.yml', '.yaml']\n    load_data_func: LoadDataFunc\n        function to load the data\n    Returns\n    -------\n    A dictionary with relative paths (without extension) to the data\n    \"\"\"\n    load_files = [x for x in exp_files if splitext(x)[1] in extensions]\n    global_dict = {}\n    for cur_file in load_files:\n        fname = relpath(splitext(cur_file)[0], exp_path)\n        global_dict[fname] = load_data_func.load_data(cur_file, storage)\n    return global_dict\n</code></pre>"},{"location":"reference/experiments/experimentcontext/","title":"experimentcontext","text":""},{"location":"reference/experiments/experimentcontext/#niceml.experiments.experimentcontext","title":"experimentcontext","text":"<p>Module for the ExperimentContext</p>"},{"location":"reference/experiments/experimentcontext/#niceml.experiments.experimentcontext-classes","title":"Classes","text":""},{"location":"reference/experiments/experimentcontext/#niceml.experiments.experimentcontext.ExperimentContext","title":"ExperimentContext  <code>dataclass</code>","text":"<p>ExperimentContext to provide the ids and storage</p>"},{"location":"reference/experiments/experimentcontext/#niceml.experiments.experimentcontext.ExperimentContext-functions","title":"Functions","text":""},{"location":"reference/experiments/experimentcontext/#niceml.experiments.experimentcontext.ExperimentContext.create_folder","title":"create_folder","text":"<pre><code>create_folder(folder)\n</code></pre> <p>Creates a folder relative to the experiment</p> Source code in <code>niceml/experiments/experimentcontext.py</code> <pre><code>def create_folder(self, folder: str):\n    \"\"\"Creates a folder relative to the experiment\"\"\"\n    file_system: AbstractFileSystem\n    with open_location(self.fs_config) as (file_system, root_path):\n        abs_folder = join(root_path, folder)\n        file_system.makedirs(abs_folder, exist_ok=True)\n</code></pre>"},{"location":"reference/experiments/experimentcontext/#niceml.experiments.experimentcontext.ExperimentContext.instantiate_datadescription_from_yaml","title":"instantiate_datadescription_from_yaml","text":"<pre><code>instantiate_datadescription_from_yaml()\n</code></pre> <p>Instantiates a DataDescription from a yaml file</p> Source code in <code>niceml/experiments/experimentcontext.py</code> <pre><code>def instantiate_datadescription_from_yaml(self) -&gt; DataDescription:\n    \"\"\"Instantiates a DataDescription from a yaml file\"\"\"\n    with open_location(self.fs_config) as (exp_fs, exp_root):\n        data_description: DataDescription = instantiate_from_yaml(\n            join(\n                exp_root,\n                ExperimentFilenames.CONFIGS_FOLDER,\n                OpNames.OP_TRAIN.value,\n                ExperimentFilenames.DATA_DESCRIPTION,\n            ),\n            file_system=exp_fs,\n        )\n    return data_description\n</code></pre>"},{"location":"reference/experiments/experimentcontext/#niceml.experiments.experimentcontext.ExperimentContext.read_csv","title":"read_csv","text":"<pre><code>read_csv(data_path)\n</code></pre> <p>Reads a csv file relative to the experiment</p> Source code in <code>niceml/experiments/experimentcontext.py</code> <pre><code>def read_csv(self, data_path: str) -&gt; pd.DataFrame:\n    \"\"\"Reads a csv file relative to the experiment\"\"\"\n    with open_location(self.fs_config) as (file_system, root_path):\n        return read_csv(join(root_path, data_path), file_system=file_system)\n</code></pre>"},{"location":"reference/experiments/experimentcontext/#niceml.experiments.experimentcontext.ExperimentContext.read_image","title":"read_image","text":"<pre><code>read_image(data_path)\n</code></pre> <p>Reads an image relative to the experiment</p> Source code in <code>niceml/experiments/experimentcontext.py</code> <pre><code>def read_image(self, data_path: str) -&gt; Image.Image:\n    \"\"\"Reads an image relative to the experiment\"\"\"\n    with open_location(self.fs_config) as (file_system, root_path):\n        return read_image(join(root_path, data_path), file_system=file_system)\n</code></pre>"},{"location":"reference/experiments/experimentcontext/#niceml.experiments.experimentcontext.ExperimentContext.read_json","title":"read_json","text":"<pre><code>read_json(data_path)\n</code></pre> <p>reads the json file relative to the experiment</p> Source code in <code>niceml/experiments/experimentcontext.py</code> <pre><code>def read_json(self, data_path: str) -&gt; dict:\n    \"\"\"reads the json file relative to the experiment\"\"\"\n    with open_location(self.fs_config) as (file_system, root_path):\n        return read_json(join(root_path, data_path), file_system=file_system)\n</code></pre>"},{"location":"reference/experiments/experimentcontext/#niceml.experiments.experimentcontext.ExperimentContext.read_parquet","title":"read_parquet","text":"<pre><code>read_parquet(data_path)\n</code></pre> <p>reads the dataframe as parquet file relative to the experiment</p> Source code in <code>niceml/experiments/experimentcontext.py</code> <pre><code>def read_parquet(self, data_path: str) -&gt; pd.DataFrame:\n    \"\"\"reads the dataframe as parquet file relative to the experiment\"\"\"\n    with open_location(self.fs_config) as (file_system, root_path):\n        return read_parquet(join(root_path, data_path), file_system=file_system)\n</code></pre>"},{"location":"reference/experiments/experimentcontext/#niceml.experiments.experimentcontext.ExperimentContext.read_yaml","title":"read_yaml","text":"<pre><code>read_yaml(data_path)\n</code></pre> <p>reads the yaml file relative to the experiment</p> Source code in <code>niceml/experiments/experimentcontext.py</code> <pre><code>def read_yaml(self, data_path: str) -&gt; dict:\n    \"\"\"reads the yaml file relative to the experiment\"\"\"\n    with open_location(self.fs_config) as (file_system, root_path):\n        return read_yaml(join(root_path, data_path), file_system=file_system)\n</code></pre>"},{"location":"reference/experiments/experimentcontext/#niceml.experiments.experimentcontext.ExperimentContext.update_last_modified","title":"update_last_modified","text":"<pre><code>update_last_modified(timestamp=None)\n</code></pre> <p>Updates the last modified timestamp of the experiment info</p> Source code in <code>niceml/experiments/experimentcontext.py</code> <pre><code>def update_last_modified(self, timestamp: Optional[str] = None):\n    \"\"\"Updates the last modified timestamp of the experiment info\"\"\"\n    timestamp = timestamp or generate_timestamp()\n    try:\n        exp_info_dict = self.read_yaml(ExperimentFilenames.EXP_INFO)\n        exp_info_dict[LAST_MODIFIED_KEY] = timestamp\n        self.write_yaml(\n            exp_info_dict, ExperimentFilenames.EXP_INFO, apply_last_modified=False\n        )\n    except FileNotFoundError:\n        logging.getLogger(__name__).warning(\n            \"Could not update last modified timestamp, because the \"\n            \"experiment info file was not found.\"\n        )\n</code></pre>"},{"location":"reference/experiments/experimentcontext/#niceml.experiments.experimentcontext.ExperimentContext.write_csv","title":"write_csv","text":"<pre><code>write_csv(\n    data, data_path, apply_last_modified=True, **kwargs\n)\n</code></pre> <p>Writes a csv file relative to the experiment</p> Source code in <code>niceml/experiments/experimentcontext.py</code> <pre><code>def write_csv(\n    self,\n    data: pd.DataFrame,\n    data_path: str,\n    apply_last_modified: bool = True,\n    **kwargs,\n):\n    \"\"\"Writes a csv file relative to the experiment\"\"\"\n    with open_location(self.fs_config) as (file_system, root_path):\n        write_csv(\n            data,\n            join(root_path, data_path),\n            file_system=file_system,\n            **kwargs,\n        )\n    if apply_last_modified:\n        self.update_last_modified()\n</code></pre>"},{"location":"reference/experiments/experimentcontext/#niceml.experiments.experimentcontext.ExperimentContext.write_image","title":"write_image","text":"<pre><code>write_image(image, data_path, apply_last_modified=True)\n</code></pre> <p>Writes an image relative to the experiment</p> Source code in <code>niceml/experiments/experimentcontext.py</code> <pre><code>def write_image(\n    self, image: Image.Image, data_path: str, apply_last_modified: bool = True\n):\n    \"\"\"Writes an image relative to the experiment\"\"\"\n    with open_location(self.fs_config) as (file_system, root_path):\n        write_image(image, join(root_path, data_path), file_system=file_system)\n    if apply_last_modified:\n        self.update_last_modified()\n</code></pre>"},{"location":"reference/experiments/experimentcontext/#niceml.experiments.experimentcontext.ExperimentContext.write_json","title":"write_json","text":"<pre><code>write_json(\n    data, data_path, apply_last_modified=True, **kwargs\n)\n</code></pre> <p>Writes a json file relative to the experiment</p> Source code in <code>niceml/experiments/experimentcontext.py</code> <pre><code>def write_json(\n    self,\n    data: dict,\n    data_path: str,\n    apply_last_modified: bool = True,\n    **kwargs,\n):\n    \"\"\"Writes a json file relative to the experiment\"\"\"\n    with open_location(self.fs_config) as (file_system, root_path):\n        write_json(\n            data,\n            join(root_path, data_path),\n            file_system=file_system,\n            **kwargs,\n        )\n    if apply_last_modified:\n        self.update_last_modified()\n</code></pre>"},{"location":"reference/experiments/experimentcontext/#niceml.experiments.experimentcontext.ExperimentContext.write_parquet","title":"write_parquet","text":"<pre><code>write_parquet(\n    dataframe,\n    data_path,\n    compression=\"gzip\",\n    apply_last_modified=True,\n    **kwargs\n)\n</code></pre> <p>writes the dataframe as parquet file relative to the experiment</p> Source code in <code>niceml/experiments/experimentcontext.py</code> <pre><code>def write_parquet(\n    self,\n    dataframe: pd.DataFrame,\n    data_path: str,\n    compression: Optional[str] = \"gzip\",\n    apply_last_modified: bool = True,\n    **kwargs,\n):\n    \"\"\"writes the dataframe as parquet file relative to the experiment\"\"\"\n    with open_location(self.fs_config) as (file_system, root_path):\n        write_parquet(\n            dataframe,\n            # TODO: change with join_fs_path\n            join(root_path, data_path),\n            compression=compression,\n            file_system=file_system,\n            **kwargs,\n        )\n    if apply_last_modified:\n        self.update_last_modified()\n</code></pre>"},{"location":"reference/experiments/experimentcontext/#niceml.experiments.experimentcontext.ExperimentContext.write_yaml","title":"write_yaml","text":"<pre><code>write_yaml(\n    data, data_path, apply_last_modified=True, **kwargs\n)\n</code></pre> <p>writes the yaml file relative to the experiment</p> Source code in <code>niceml/experiments/experimentcontext.py</code> <pre><code>def write_yaml(\n    self, data: dict, data_path: str, apply_last_modified: bool = True, **kwargs\n):\n    \"\"\"writes the yaml file relative to the experiment\"\"\"\n    with open_location(self.fs_config) as (file_system, root_path):\n        write_yaml(\n            data,\n            join(root_path, data_path),\n            file_system=file_system,\n            **kwargs,\n        )\n    if apply_last_modified:\n        self.update_last_modified()\n</code></pre>"},{"location":"reference/experiments/experimentcontext/#niceml.experiments.experimentcontext-functions","title":"Functions","text":""},{"location":"reference/experiments/experimentdata/","title":"experimentdata","text":""},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata","title":"experimentdata","text":"<p>Module for experimentdata</p>"},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata-classes","title":"Classes","text":""},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.ExperimentData","title":"ExperimentData","text":"<pre><code>ExperimentData(\n    dir_name,\n    exp_info,\n    exp_dict_data,\n    log_data,\n    exp_files,\n    exp_tests=None,\n    image_loader=None,\n    df_loader=None,\n)\n</code></pre> <p>Implementation of Experiment Information</p> Source code in <code>niceml/experiments/experimentdata.py</code> <pre><code>def __init__(  # pylint: disable = too-many-arguments\n    self,\n    dir_name: str,\n    exp_info: ExperimentInfo,\n    exp_dict_data: dict,\n    log_data: pd.DataFrame,\n    exp_files: List[str],\n    exp_tests: Optional[pd.DataFrame] = None,\n    image_loader: Optional[ImageLoader] = None,\n    df_loader: Optional[DfLoader] = None,\n):\n    self.dir_name = dir_name\n    self.exp_info: ExperimentInfo = exp_info\n    self.log_data = log_data\n    self.all_exp_files: List[str] = exp_files\n    self.exp_dict_data: Dict[str, Any] = exp_dict_data\n    self.exp_tests: Optional[pd.DataFrame] = exp_tests\n    self.image_loader: Optional[ImageLoader] = image_loader\n    self.df_loader: Optional[DfLoader] = df_loader\n</code></pre>"},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.ExperimentData-functions","title":"Functions","text":""},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.ExperimentData.__eq__","title":"__eq__","text":"<pre><code>__eq__(other)\n</code></pre> <p>check if two experiments are equal</p> Source code in <code>niceml/experiments/experimentdata.py</code> <pre><code>def __eq__(self, other: \"ExperimentData\") -&gt; bool:\n    \"\"\"check if two experiments are equal\"\"\"\n    exp_info_equal = self.exp_info == other.exp_info\n    exp_dict_data_equal = self.exp_dict_data == other.exp_dict_data\n    has_file_list = [\n        cur_file in other.all_exp_files\n        for cur_file in self.all_exp_files\n        if \".\" in basename(cur_file)\n    ]\n    same_dir_name = self.dir_name == other.dir_name\n    return (\n        all(has_file_list)\n        and exp_info_equal\n        and exp_dict_data_equal\n        and same_dir_name\n    )\n</code></pre>"},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.ExperimentData.get_all_model_files","title":"get_all_model_files","text":"<pre><code>get_all_model_files()\n</code></pre> <p>get list of all model files. All model files are located in the models folder even if that are folders</p> Source code in <code>niceml/experiments/experimentdata.py</code> <pre><code>def get_all_model_files(self) -&gt; List[str]:\n    \"\"\"get list of all model files. All model files are located in the models folder\n    even if that are folders\"\"\"\n    model_files = sorted(\n        [\n            file[len(ExperimentFilenames.MODELS_FOLDER) + 1 :]\n            for file in self.all_exp_files\n            if file.startswith(ExperimentFilenames.MODELS_FOLDER)\n            and len(file) &gt; len(ExperimentFilenames.MODELS_FOLDER) + 1\n        ]\n    )\n    model_files = [file.replace(\"\\\\\", \"/\") for file in model_files]\n    model_files = set((file.split(\"/\")[0] for file in model_files))\n    model_files = [\n        join(ExperimentFilenames.MODELS_FOLDER, file) for file in model_files\n    ]\n    return model_files\n</code></pre>"},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.ExperimentData.get_analysis_path","title":"get_analysis_path","text":"<pre><code>get_analysis_path()\n</code></pre> <p>get path to analysis folder</p> Source code in <code>niceml/experiments/experimentdata.py</code> <pre><code>def get_analysis_path(self) -&gt; str:\n    \"\"\"get path to analysis folder\"\"\"\n    return join(self.get_experiment_path(), ExperimentFilenames.ANALYSIS_FOLDER)\n</code></pre>"},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.ExperimentData.get_best_metric_value","title":"get_best_metric_value","text":"<pre><code>get_best_metric_value(metric_name, mode)\n</code></pre> <p>Returns the best value of the given metric according to the mode. :param metric_name: name of the metric :param mode: either 'min' or 'max' :return: MetricValue</p> Source code in <code>niceml/experiments/experimentdata.py</code> <pre><code>def get_best_metric_value(self, metric_name: str, mode) -&gt; MetricValue:\n    \"\"\"\n    Returns the best value of the given metric according to the mode.\n    :param metric_name: name of the metric\n    :param mode: either 'min' or 'max'\n    :return: MetricValue\n    \"\"\"\n    series_epoch = self._get_epoch_series()\n    series_metrics = self.log_data[metric_name]\n    if mode == \"max\":\n        idx = np.argmax(series_metrics)\n    elif mode == \"min\":\n        idx = np.argmin(series_metrics)\n    else:\n        raise Exception(f\"Mode is neither 'max' nor 'min' but {mode}\")\n\n    val = series_metrics[idx]\n    epoch = series_epoch[idx]\n    return MetricValue(metric_name=metric_name, value=val, epoch=epoch)\n</code></pre>"},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.ExperimentData.get_config_dict","title":"get_config_dict","text":"<pre><code>get_config_dict()\n</code></pre> <p>Returns the config dict from the exp_dict_data</p> Source code in <code>niceml/experiments/experimentdata.py</code> <pre><code>def get_config_dict(self) -&gt; Dict[str, Any]:\n    \"\"\"Returns the config dict from the exp_dict_data\"\"\"\n    config_dict = {\n        key: value\n        for key, value in self.exp_dict_data.items()\n        if key.startswith(ExperimentFilenames.CONFIGS_FOLDER)\n    }\n    return config_dict\n</code></pre>"},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.ExperimentData.get_config_information","title":"get_config_information","text":"<pre><code>get_config_information(info_path)\n</code></pre> <p>Returns the information of the config (e.g. the input_image_size) The whole path of the information must be given: info_path = [\"datasets\", \"data_description\", \"input_image_size\"]</p> Source code in <code>niceml/experiments/experimentdata.py</code> <pre><code>def get_config_information(self, info_path: List[str]) -&gt; Any:\n    \"\"\"\n    Returns the information of the config (e.g. the input_image_size)\n    The whole path of the information must be given:\n    info_path = [\"datasets\", \"data_description\", \"input_image_size\"]\n    \"\"\"\n    config_dict: Dict[str, Any] = self.get_config_dict()\n    cur_info_path = info_path.copy()\n    file = cur_info_path.pop(0)\n    sub_config_dict = {\n        key: value for key, value in config_dict.items() if file in key\n    }\n    if len(sub_config_dict) == 1:\n        return extract_info_from_dict(\n            list(sub_config_dict.values())[0], cur_info_path\n        )\n    if len(sub_config_dict) &gt; 1:\n        exact_sub_config_dict = {\n            key: value\n            for key, value in sub_config_dict.items()\n            if file == basename(key)\n        }\n        if len(exact_sub_config_dict) == 1:\n            return extract_info_from_dict(\n                list(exact_sub_config_dict.values())[0], cur_info_path\n            )\n    raise InfoNotFoundError(\n        f\"Information: {info_path} not found at {info_path[0]} in {self.exp_info.short_id}\"\n    )\n</code></pre>"},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.ExperimentData.get_exp_prefix","title":"get_exp_prefix","text":"<pre><code>get_exp_prefix()\n</code></pre> <p>get prefix of experiment</p> Source code in <code>niceml/experiments/experimentdata.py</code> <pre><code>def get_exp_prefix(self) -&gt; str:\n    \"\"\"get prefix of experiment\"\"\"\n    return self.exp_info.experiment_prefix\n</code></pre>"},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.ExperimentData.get_experiment_path","title":"get_experiment_path","text":"<pre><code>get_experiment_path()\n</code></pre> <p>get path to experiment</p> Source code in <code>niceml/experiments/experimentdata.py</code> <pre><code>def get_experiment_path(self):\n    \"\"\"get path to experiment\"\"\"\n    return self.exp_info.exp_filepath\n</code></pre>"},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.ExperimentData.get_file_paths","title":"get_file_paths","text":"<pre><code>get_file_paths(subfolder_name, suffix)\n</code></pre> <p>Get a list of files in a subfolder with a specified <code>suffix</code> Args:     subfolder_name: Name of the subfolder     suffix: Suffix or list of suffixes that must be part of the file path to be returned</p> <p>Returns:</p> <ul> <li> <code>List[str]</code>         \u2013          <p>list of filepaths as strings</p> </li> </ul> Source code in <code>niceml/experiments/experimentdata.py</code> <pre><code>def get_file_paths(\n    self, subfolder_name: str, suffix: Union[str, List[str]]\n) -&gt; List[str]:\n    \"\"\"\n    Get a list of files in a subfolder with a specified `suffix`\n    Args:\n        subfolder_name: Name of the subfolder\n        suffix: Suffix or list of suffixes that must be part of the file path to be returned\n\n    Returns:\n        list of filepaths as strings\n\n    \"\"\"\n\n    filtered_paths = [\n        file_paths\n        for file_paths in self.all_exp_files\n        if subfolder_name in file_paths\n    ]\n    if isinstance(suffix, str):\n        suffix = [suffix]\n    return [\n        join(self.exp_info.exp_filepath, filtered_path)\n        for filtered_path in filtered_paths\n        if any(ext in filtered_path for ext in suffix)\n    ]\n</code></pre>"},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.ExperimentData.get_in_memory_usage","title":"get_in_memory_usage","text":"<pre><code>get_in_memory_usage()\n</code></pre> <p>get memory usage of experiment</p> Source code in <code>niceml/experiments/experimentdata.py</code> <pre><code>def get_in_memory_usage(self) -&gt; str:\n    \"\"\"get memory usage of experiment\"\"\"\n    return human_readable_size(self)\n</code></pre>"},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.ExperimentData.get_instantiated_data_description","title":"get_instantiated_data_description","text":"<pre><code>get_instantiated_data_description(class_renamings=None)\n</code></pre> <p>Instantiates the DataDescription stored with the experiment If the name of the class has changed meanwhile, you can specify this in the class_renamings</p> Source code in <code>niceml/experiments/experimentdata.py</code> <pre><code>def get_instantiated_data_description(\n    self, class_renamings: Optional[Dict[str, str]] = None\n) -&gt; DataDescription:\n    \"\"\"Instantiates the DataDescription stored with the experiment\n    If the name of the class has changed meanwhile, you can specify this in the class_renamings\n    \"\"\"\n    class_renamings = class_renamings or {}\n    data_description_yaml = self.get_config_information([\"data_description\"])\n    cur_target = data_description_yaml[\"_target_\"]\n    data_description_yaml[\"_target_\"] = class_renamings.get(cur_target, cur_target)\n    data_description = instantiate(data_description_yaml)\n    return check_instance(data_description, DataDescription)\n</code></pre>"},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.ExperimentData.get_loaded_yaml","title":"get_loaded_yaml","text":"<pre><code>get_loaded_yaml(file)\n</code></pre> <p>gets a loaded yaml file</p> Source code in <code>niceml/experiments/experimentdata.py</code> <pre><code>def get_loaded_yaml(self, file: str) -&gt; Union[dict, list]:\n    \"\"\"gets a loaded yaml file\"\"\"\n    if splitext(file)[1] in [\".yaml\", \".yml\"]:\n        file = splitext(file)[0]\n    if file in self.exp_dict_data:\n        return self.exp_dict_data[file]\n    matching_files = [x for x in self.exp_dict_data.keys() if file == basename(x)]\n    if len(matching_files) == 0:\n        raise FileNotFoundError(f\"loaded_yaml: {self.get_short_id()} - {file}\")\n    if len(matching_files) == 1:\n        return self.exp_dict_data[matching_files[0]]\n    raise AmbigousFilenameError(\n        f\"Multiple files are matching: {file}, \"\n        f\"{matching_files}, expid: {self.get_short_id()}\"\n    )\n</code></pre>"},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.ExperimentData.get_log_for_metric","title":"get_log_for_metric","text":"<pre><code>get_log_for_metric(metric_name)\n</code></pre> <p>Returns log information for given metric</p> Source code in <code>niceml/experiments/experimentdata.py</code> <pre><code>def get_log_for_metric(self, metric_name: str) -&gt; pd.DataFrame:\n    \"\"\"Returns log information for given metric\"\"\"\n    series_epoch = self._get_epoch_series()\n    try:\n        series_metrics = self.log_data[metric_name]\n    except KeyError as error:\n        raise LogEmptyError(\n            f\"Log of experiment is empty: {self.exp_info.short_id}\"\n        ) from error\n    series_name = pd.Series(data=[self.exp_info.short_id] * len(series_epoch))\n    log_data = pd.DataFrame(\n        {\"epoch\": series_epoch, metric_name: series_metrics, \"name\": series_name}\n    )\n\n    return log_data\n</code></pre>"},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.ExperimentData.get_metrics","title":"get_metrics","text":"<pre><code>get_metrics()\n</code></pre> <p>get experiment metrics</p> Source code in <code>niceml/experiments/experimentdata.py</code> <pre><code>def get_metrics(self) -&gt; List[str]:\n    \"\"\"get experiment metrics\"\"\"\n    metrics = list(self.log_data.columns)\n    try:\n        metrics.remove(\"epoch\")\n        metrics.remove(\"Unnamed: 0\")\n    except ValueError:\n        pass\n    return metrics\n</code></pre>"},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.ExperimentData.get_model_path","title":"get_model_path","text":"<pre><code>get_model_path(epoch=None, relative_path=True)\n</code></pre> <p>Get the model path for the desired model. :param epoch: epoch as int if not given the latest is returned</p> Source code in <code>niceml/experiments/experimentdata.py</code> <pre><code>def get_model_path(self, epoch: int = None, relative_path: bool = True) -&gt; str:\n    \"\"\"\n    Get the model path for the desired model.\n    :param epoch: epoch as int if not given the latest is returned\n    \"\"\"\n    ret_model = None\n    model_files = self.get_all_model_files()\n    if len(model_files) == 0:\n        raise ModelNotFoundError(\n            f\"No model found for this experiment: {self.exp_info.short_id}\"\n        )\n\n    if epoch is None:\n        ret_model = model_files[-1]\n    else:\n        ep_str = ExperimentFilenames.EPOCHS_FORMATTING.format(epoch)\n        for model_files in model_files:\n            if ep_str in model_files:\n                ret_model = model_files\n\n    if ret_model is None:\n        raise ModelNotFoundError(\n            f\"Model from epoch: {epoch} not found in exp: \"\n            f\"{self.exp_info.short_id}\"\n        )\n\n    if relative_path:\n        return ret_model\n\n    return join(self.exp_info.exp_filepath, ret_model)\n</code></pre>"},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.ExperimentData.get_prediction_path","title":"get_prediction_path","text":"<pre><code>get_prediction_path()\n</code></pre> <p>get path to prediction folder</p> Source code in <code>niceml/experiments/experimentdata.py</code> <pre><code>def get_prediction_path(self) -&gt; str:\n    \"\"\"get path to prediction folder\"\"\"\n    return join(self.get_experiment_path(), ExperimentFilenames.PREDICTION_FOLDER)\n</code></pre>"},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.ExperimentData.get_rel_file_exp_path","title":"get_rel_file_exp_path","text":"<pre><code>get_rel_file_exp_path(file)\n</code></pre> <p>Returns the filepath of the given file relative to the experiment folder. Parameters</p> <p>file: str     Relative path from the experiment without or with extension.     If the name is unique its enough to specify the basename of the file. Returns</p> <p>str: filepath of the dataframe file</p> Source code in <code>niceml/experiments/experimentdata.py</code> <pre><code>def get_rel_file_exp_path(self, file: str) -&gt; str:\n    \"\"\"\n    Returns the filepath of the given file relative to the experiment folder.\n    Parameters\n    ----------\n    file: str\n        Relative path from the experiment without or with extension.\n        If the name is unique its enough to specify the basename of the file.\n    Returns\n    -------\n    str: filepath of the dataframe file\n    \"\"\"\n    if file in self.all_exp_files:\n        return file\n    file_name, file_ext = splitext(file)\n    if file_ext == \"\":\n        target_files = self.all_exp_files\n    else:\n        target_files = [x for x in self.all_exp_files if file_ext == splitext(x)[1]]\n\n    matching_files = [\n        x for x in target_files if basename(file_name) == basename(splitext(x)[0])\n    ]\n    if len(matching_files) == 0:\n        raise FileNotFoundError(f\"loaded_df: {self.get_short_id()} - {file}\")\n    if len(matching_files) == 1:\n        return matching_files[0]\n    raise AmbigousFilenameError(\n        f\"Multiple files are matching: {file}, \"\n        f\"{matching_files}, expid: {self.get_short_id()}\"\n    )\n</code></pre>"},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.ExperimentData.get_run_date","title":"get_run_date","text":"<pre><code>get_run_date()\n</code></pre> <p>get date of experiment run</p> Source code in <code>niceml/experiments/experimentdata.py</code> <pre><code>def get_run_date(self) -&gt; datetime.datetime:\n    \"\"\"get date of experiment run\"\"\"\n    return parse_datetime(self.get_run_id())\n</code></pre>"},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.ExperimentData.get_run_id","title":"get_run_id","text":"<pre><code>get_run_id()\n</code></pre> <p>get id of experiment run</p> Source code in <code>niceml/experiments/experimentdata.py</code> <pre><code>def get_run_id(self) -&gt; str:\n    \"\"\"get id of experiment run\"\"\"\n    return self.exp_info.run_id\n</code></pre>"},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.ExperimentData.get_short_id","title":"get_short_id","text":"<pre><code>get_short_id()\n</code></pre> <p>get short id of experiment run</p> Source code in <code>niceml/experiments/experimentdata.py</code> <pre><code>def get_short_id(self) -&gt; str:\n    \"\"\"get short id of experiment run\"\"\"\n    return self.exp_info.short_id\n</code></pre>"},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.ExperimentData.get_trained_epochs","title":"get_trained_epochs","text":"<pre><code>get_trained_epochs()\n</code></pre> <p>Uses the logfile to determine how many epochs have been trained</p> Source code in <code>niceml/experiments/experimentdata.py</code> <pre><code>def get_trained_epochs(self) -&gt; int:\n    \"\"\"Uses the logfile to determine how many epochs have been trained\"\"\"\n    try:\n        epochs = len(self._get_epoch_series())\n    except LogEmptyError:\n        epochs = 0\n    return epochs\n</code></pre>"},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.ExperimentData.get_yaml_information","title":"get_yaml_information","text":"<pre><code>get_yaml_information(info_path)\n</code></pre> <p>get info from yaml file at given info_path</p> Source code in <code>niceml/experiments/experimentdata.py</code> <pre><code>def get_yaml_information(self, info_path: List[str]):\n    \"\"\"get info from yaml file at given info_path\"\"\"\n    cur_info_path = info_path.copy()\n    file = cur_info_path.pop(0)\n    sub_info_dict = {\n        key: value for key, value in self.exp_dict_data.items() if file in key\n    }\n    if len(sub_info_dict) == 1:\n        return extract_info_from_dict(\n            list(sub_info_dict.values())[0], cur_info_path\n        )\n    raise InfoNotFoundError(\n        f\"Information: {info_path} not found at {info_path[0]} in {self.exp_info.short_id}\"\n    )\n</code></pre>"},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.ExperimentData.has_metric","title":"has_metric","text":"<pre><code>has_metric(metric_name)\n</code></pre> <p>checks if given metric is available for the experiment run</p> Source code in <code>niceml/experiments/experimentdata.py</code> <pre><code>def has_metric(self, metric_name: str) -&gt; bool:\n    \"\"\"checks if given metric is available for the experiment run\"\"\"\n    return metric_name in self.get_metrics()\n</code></pre>"},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.ExperimentData.is_empty","title":"is_empty","text":"<pre><code>is_empty()\n</code></pre> <p>Determines whether the exp has trained epochs</p> Source code in <code>niceml/experiments/experimentdata.py</code> <pre><code>def is_empty(self) -&gt; bool:\n    \"\"\"Determines whether the exp has trained epochs\"\"\"\n    return self.get_trained_epochs() == 0\n</code></pre>"},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.ExperimentData.load_df","title":"load_df","text":"<pre><code>load_df(file)\n</code></pre> <p>Loads a dataframe file Parameters</p> <p>file: str     Relative path from the experiment without extension.     If the name is unique its enough to specify the basename of the file. Returns</p> <p>pd.DataFrame: dataframe</p> Source code in <code>niceml/experiments/experimentdata.py</code> <pre><code>def load_df(self, file: str) -&gt; pd.DataFrame:\n    \"\"\"\n    Loads a dataframe file\n    Parameters\n    ----------\n    file: str\n        Relative path from the experiment without extension.\n        If the name is unique its enough to specify the basename of the file.\n    Returns\n    -------\n    pd.DataFrame: dataframe\n    \"\"\"\n    file_path = self.get_rel_file_exp_path(file)\n    if self.df_loader is None:\n        raise Exception(\"No df loader is set\")\n    return self.df_loader.load_df(file_path)\n</code></pre>"},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.ExperimentData.set_loaders","title":"set_loaders","text":"<pre><code>set_loaders(*, df_loader=None, image_loader=None)\n</code></pre> <p>set loaders for experiment</p> Source code in <code>niceml/experiments/experimentdata.py</code> <pre><code>def set_loaders(\n    self,\n    *,\n    df_loader: Optional[DfLoader] = None,\n    image_loader: Optional[ImageLoader] = None,\n):\n    \"\"\"set loaders for experiment\"\"\"\n    if df_loader is not None:\n        self.df_loader = check_instance(df_loader, DfLoader)\n    if image_loader is not None:\n        self.image_loader = check_instance(image_loader, ImageLoader)\n</code></pre>"},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.MetricValue","title":"MetricValue  <code>dataclass</code>","text":"<p>abstact implementation of MetricValue</p>"},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata-functions","title":"Functions","text":""},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.extract_info_from_dict","title":"extract_info_from_dict","text":"<pre><code>extract_info_from_dict(info, info_path)\n</code></pre> <p>Extracts information from a dict at given path</p> Source code in <code>niceml/experiments/experimentdata.py</code> <pre><code>def extract_info_from_dict(info: dict, info_path: List[Union[str, int]]) -&gt; Any:\n    \"\"\"Extracts information from a dict at given path\"\"\"\n    for key in info_path:\n        try:\n            info = info[key]\n        except (IndexError, KeyError) as excep:\n            raise InfoNotFoundError(\n                f\"Information: {info_path} not found at {key}\"\n            ) from excep\n    return info\n</code></pre>"},{"location":"reference/experiments/experimentdata/#niceml.experiments.experimentdata.load_loggings","title":"load_loggings","text":"<pre><code>load_loggings(logging_file)\n</code></pre> <p>loads loggings from csv file</p> Source code in <code>niceml/experiments/experimentdata.py</code> <pre><code>def load_loggings(logging_file: str) -&gt; pd.DataFrame:\n    \"\"\"loads loggings from csv file\"\"\"\n    return pd.read_csv(logging_file)\n</code></pre>"},{"location":"reference/experiments/experimentdownloader/","title":"experimentdownloader","text":""},{"location":"reference/experiments/experimentdownloader/#niceml.experiments.experimentdownloader","title":"experimentdownloader","text":"<p>module of experiment downloader</p>"},{"location":"reference/experiments/experimentdownloader/#niceml.experiments.experimentdownloader-classes","title":"Classes","text":""},{"location":"reference/experiments/experimentdownloader/#niceml.experiments.experimentdownloader.Download","title":"Download","text":"<pre><code>Download(source_file, target_file, storage_interface)\n</code></pre> <p>Download class for the dashboard</p> Source code in <code>niceml/experiments/experimentdownloader.py</code> <pre><code>def __init__(\n    self, source_file: str, target_file: str, storage_interface: StorageInterface\n):\n    self.source_file = source_file\n    self.target_file = target_file\n    self.storage_interface = storage_interface\n</code></pre>"},{"location":"reference/experiments/experimentdownloader/#niceml.experiments.experimentdownloader.ExperimentDownloader","title":"ExperimentDownloader","text":"<pre><code>ExperimentDownloader(\n    experiments,\n    storage_interface,\n    local_store_path,\n    remote_exp_path,\n)\n</code></pre> <p>Class to download experiment data</p> Source code in <code>niceml/experiments/experimentdownloader.py</code> <pre><code>def __init__(\n    self,\n    experiments: List[ExperimentData],\n    storage_interface: StorageInterface,\n    local_store_path: str,\n    remote_exp_path: str,\n):\n    self.experiments = experiments\n    self.storage_interface = storage_interface\n    self.local_store_path = local_store_path\n    self.remote_exp_path = remote_exp_path\n</code></pre>"},{"location":"reference/experiments/experimenterrors/","title":"experimenterrors","text":""},{"location":"reference/experiments/experimenterrors/#niceml.experiments.experimenterrors","title":"experimenterrors","text":"<p>Module for all experiment errors</p>"},{"location":"reference/experiments/experimenterrors/#niceml.experiments.experimenterrors-classes","title":"Classes","text":""},{"location":"reference/experiments/experimenterrors/#niceml.experiments.experimenterrors.AmbigousFilenameError","title":"AmbigousFilenameError","text":"<p>             Bases: <code>Exception</code></p> <p>Filename can be interpreted in multiple ways</p>"},{"location":"reference/experiments/experimenterrors/#niceml.experiments.experimenterrors.EmptyExperimentError","title":"EmptyExperimentError","text":"<p>             Bases: <code>Exception</code></p> <p>Error when the experiment is empty</p>"},{"location":"reference/experiments/experimenterrors/#niceml.experiments.experimenterrors.ExperimentNotFoundError","title":"ExperimentNotFoundError","text":"<p>             Bases: <code>Exception</code></p> <p>Error when the path doesn't contain an experiment</p>"},{"location":"reference/experiments/experimenterrors/#niceml.experiments.experimenterrors.InfoNotFoundError","title":"InfoNotFoundError","text":"<p>             Bases: <code>Exception</code></p> <p>Error when the experiment info is not found</p>"},{"location":"reference/experiments/experimenterrors/#niceml.experiments.experimenterrors.LogEmptyError","title":"LogEmptyError","text":"<p>             Bases: <code>Exception</code></p> <p>Error when the train logs are empty</p>"},{"location":"reference/experiments/experimenterrors/#niceml.experiments.experimenterrors.MetricNotAvailableError","title":"MetricNotAvailableError","text":"<p>             Bases: <code>Exception</code></p> <p>Error when a metric is not available</p>"},{"location":"reference/experiments/experimenterrors/#niceml.experiments.experimenterrors.ModelNotFoundError","title":"ModelNotFoundError","text":"<p>             Bases: <code>Exception</code></p> <p>Error when experiment has no model</p>"},{"location":"reference/experiments/experimenterrors/#niceml.experiments.experimenterrors.MultipleExperimentsFoundError","title":"MultipleExperimentsFoundError","text":"<p>             Bases: <code>Exception</code></p> <p>Error when the path contain multiple experiment with a given id</p>"},{"location":"reference/experiments/experimentinfo/","title":"experimentinfo","text":""},{"location":"reference/experiments/experimentinfo/#niceml.experiments.experimentinfo","title":"experimentinfo","text":"<p>Module for experimentinfo</p>"},{"location":"reference/experiments/experimentinfo/#niceml.experiments.experimentinfo-classes","title":"Classes","text":""},{"location":"reference/experiments/experimentinfo/#niceml.experiments.experimentinfo.ExpIdNotFoundError","title":"ExpIdNotFoundError","text":"<p>             Bases: <code>Exception</code></p> <p>Exception which is raised when an experiment id is not found</p>"},{"location":"reference/experiments/experimentinfo/#niceml.experiments.experimentinfo.ExperimentInfo","title":"ExperimentInfo  <code>dataclass</code>","text":"<p>Dataclass which holds information about an experiment but not the data</p>"},{"location":"reference/experiments/experimentinfo/#niceml.experiments.experimentinfo.ExperimentInfo-functions","title":"Functions","text":""},{"location":"reference/experiments/experimentinfo/#niceml.experiments.experimentinfo.ExperimentInfo.as_save_dict","title":"as_save_dict","text":"<pre><code>as_save_dict()\n</code></pre> <p>Returns a dictionary which can be saved to a yaml file</p> Source code in <code>niceml/experiments/experimentinfo.py</code> <pre><code>def as_save_dict(self) -&gt; dict:\n    \"\"\"Returns a dictionary which can be saved to a yaml file\"\"\"\n    return {\n        EXP_NAME_KEY: self.experiment_name,\n        EXP_PREFIX_KEY: self.experiment_prefix,\n        EXP_TYPE_KEY: self.experiment_type,\n        RUN_ID_KEY: self.run_id,\n        SHORT_ID_KEY: self.short_id,\n        ENVIRONMENT_KEY: self.environment,\n        DESCRIPTION_KEY: self.description,\n        EXP_DIR_KEY: self.exp_dir,\n        LAST_MODIFIED_KEY: self.last_modified,\n    }\n</code></pre>"},{"location":"reference/experiments/experimentinfo/#niceml.experiments.experimentinfo.ExperimentInfo.is_modified","title":"is_modified","text":"<pre><code>is_modified(other)\n</code></pre> <p>Checks if the other experiment info is modified</p> Source code in <code>niceml/experiments/experimentinfo.py</code> <pre><code>def is_modified(self, other) -&gt; bool:\n    \"\"\"Checks if the other experiment info is modified\"\"\"\n    return self.last_modified != other.last_modified\n</code></pre>"},{"location":"reference/experiments/experimentinfo/#niceml.experiments.experimentinfo-functions","title":"Functions","text":""},{"location":"reference/experiments/experimentinfo/#niceml.experiments.experimentinfo.experiment_info_factory","title":"experiment_info_factory","text":"<pre><code>experiment_info_factory(data, path=None)\n</code></pre> <p>Creates an experiment info from a dictionary</p> Source code in <code>niceml/experiments/experimentinfo.py</code> <pre><code>def experiment_info_factory(data: dict, path: Optional[str] = None) -&gt; ExperimentInfo:\n    \"\"\"Creates an experiment info from a dictionary\"\"\"\n    return ExperimentInfo(\n        experiment_name=data[EXP_NAME_KEY],\n        experiment_prefix=data[EXP_PREFIX_KEY],\n        experiment_type=data.get(EXP_TYPE_KEY, \"\"),\n        run_id=data[RUN_ID_KEY],\n        short_id=data[SHORT_ID_KEY],\n        environment=data.get(ENVIRONMENT_KEY, \"\"),\n        description=data.get(DESCRIPTION_KEY, \"\"),\n        exp_dir=data.get(EXP_DIR_KEY, \"\"),\n        exp_filepath=path,\n        last_modified=data.get(LAST_MODIFIED_KEY, None),\n    )\n</code></pre>"},{"location":"reference/experiments/experimentinfo/#niceml.experiments.experimentinfo.get_exp_id_from_name","title":"get_exp_id_from_name","text":"<pre><code>get_exp_id_from_name(input_name)\n</code></pre> <p>Returns a 4 digit alphanumeric string with the experiment id. The id follows after 'id_' and follow with a non alphanumeric char.</p> Source code in <code>niceml/experiments/experimentinfo.py</code> <pre><code>def get_exp_id_from_name(input_name: str) -&gt; str:\n    \"\"\"\n    Returns a 4 digit alphanumeric string with the experiment id.\n    The id follows after 'id_' and follow with a non alphanumeric char.\n    \"\"\"\n    input_name = basename(input_name)\n    index = input_name.rfind(\"id_\")\n    if index == -1:\n        raise ExpIdNotFoundError(\n            f\"ID not found anywhere starting with 'id_': {input_name}\"\n        )\n    cur_id = input_name[index + 3 : index + 7]\n    if len(cur_id) != 4:  # noqa: PLR2004\n        raise ExpIdNotFoundError(f\"ID not complete: {input_name}\")\n    if any((x not in ALPHANUMERICLIST for x in cur_id)):\n        raise ExpIdNotFoundError(\n            f\"ID shouldn't have any non alphanumeric chars: {cur_id}\"\n        )\n    return cur_id\n</code></pre>"},{"location":"reference/experiments/experimentinfo/#niceml.experiments.experimentinfo.load_exp_info","title":"load_exp_info","text":"<pre><code>load_exp_info(exp_info_file, file_system=None)\n</code></pre> <p>Loads an experiment info from a yaml file</p> Source code in <code>niceml/experiments/experimentinfo.py</code> <pre><code>def load_exp_info(\n    exp_info_file, file_system: Optional[AbstractFileSystem] = None\n) -&gt; ExperimentInfo:\n    \"\"\"Loads an experiment info from a yaml file\"\"\"\n    file_system = file_system or LocalFileSystem()\n    data = read_yaml(exp_info_file, file_system)\n\n    exp_info = experiment_info_factory(data)\n    return exp_info\n</code></pre>"},{"location":"reference/experiments/experimentmanager/","title":"experimentmanager","text":""},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager","title":"experimentmanager","text":"<p>Module for the experimentmanager</p>"},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager-classes","title":"Classes","text":""},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager.ExperimentManager","title":"ExperimentManager","text":"<pre><code>ExperimentManager(experiments=None)\n</code></pre> <p>             Bases: <code>object</code></p> <p>Class for managing experiments</p> <p>Manages a list of experiments</p> Source code in <code>niceml/experiments/experimentmanager.py</code> <pre><code>def __init__(self, experiments: List[ExperimentData] = None):\n    \"\"\"Manages a list of experiments\"\"\"\n    self.experiments = [] if experiments is None else experiments\n    self.exp_dict = {exp.get_short_id(): exp for exp in self.experiments}\n    self.exp_dict.update({exp.get_run_id(): exp for exp in self.experiments})\n</code></pre>"},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager.ExperimentManager-functions","title":"Functions","text":""},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager.ExperimentManager.__contains__","title":"__contains__","text":"<pre><code>__contains__(exp_id)\n</code></pre> <p>Checks if the experiment is in the manager</p> Source code in <code>niceml/experiments/experimentmanager.py</code> <pre><code>def __contains__(self, exp_id: Union[str, ExperimentInfo]):\n    \"\"\"Checks if the experiment is in the manager\"\"\"\n    if type(exp_id) == ExperimentInfo:\n        exp_id = exp_id.short_id\n    for experiment in self.experiments:\n        if exp_id.endswith(experiment.get_short_id()):\n            return True\n    return False\n</code></pre>"},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager.ExperimentManager.add_experiment","title":"add_experiment","text":"<pre><code>add_experiment(experiment)\n</code></pre> <p>Adds an experiment to the manager</p> Source code in <code>niceml/experiments/experimentmanager.py</code> <pre><code>def add_experiment(self, experiment: ExperimentData):\n    \"\"\"Adds an experiment to the manager\"\"\"\n    self.experiments.append(experiment)\n    self.exp_dict[experiment.get_short_id()] = experiment\n    self.exp_dict[experiment.get_run_id()] = experiment\n</code></pre>"},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager.ExperimentManager.get_best_experiments","title":"get_best_experiments","text":"<pre><code>get_best_experiments(metric_name, mode, number_of_exps)\n</code></pre> <p>Finds the best experiments according to given metric. Parameters</p> <p>metric_name: str     name of the metric mode: str     use 'max' for maximum and 'min' for minimum values number_of_exps     number of experiments which should be included Returns</p> <pre><code>A list of Tuple[str, ExperimentData].\nThe str is a readable representation of the value and the\nexperiment id\n</code></pre> Source code in <code>niceml/experiments/experimentmanager.py</code> <pre><code>def get_best_experiments(\n    self, metric_name: str, mode: str, number_of_exps: int\n) -&gt; List[Tuple[str, ExperimentData]]:\n    \"\"\"\n    Finds the best experiments according to given metric.\n    Parameters\n    ----------\n    metric_name: str\n        name of the metric\n    mode: str\n        use 'max' for maximum and 'min' for minimum values\n    number_of_exps\n        number of experiments which should be included\n    Returns\n    -------\n        A list of Tuple[str, ExperimentData].\n        The str is a readable representation of the value and the\n        experiment id\n    \"\"\"\n    if mode not in [\"max\", \"min\"]:\n        raise Exception(f\"mode is not max or min but : {mode}\")\n    exp_list = self.experiments\n    number_of_exps = min(number_of_exps, len(exp_list))\n    value_exps = [\n        (exp, exp.get_best_metric_value(metric_name, mode))\n        for exp in exp_list\n        if exp.has_metric(metric_name)\n    ]\n    reversed = True if mode == \"max\" else False\n    value_exps = sorted(value_exps, reverse=reversed, key=lambda x: x[1].value)\n    value_exps = value_exps[:number_of_exps]\n\n    return [\n        (f\"{exp.exp_info.short_id} - {value.value:0.2f}\", exp)\n        for exp, value in value_exps\n    ]\n</code></pre>"},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager.ExperimentManager.get_dataset","title":"get_dataset","text":"<pre><code>get_dataset(exp)\n</code></pre> <p>Returns the dataset of the given experiment</p> Source code in <code>niceml/experiments/experimentmanager.py</code> <pre><code>def get_dataset(self, exp: ExperimentData) -&gt; str:\n    \"\"\"Returns the dataset of the given experiment\"\"\"\n    dataset = exp.get_experiment_path().split(\"/\")[0]\n    return dataset\n</code></pre>"},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager.ExperimentManager.get_datasets","title":"get_datasets","text":"<pre><code>get_datasets()\n</code></pre> <p>Returns a list of all datasets used in the experiments</p> Source code in <code>niceml/experiments/experimentmanager.py</code> <pre><code>def get_datasets(self) -&gt; List[str]:\n    \"\"\"Returns a list of all datasets used in the experiments\"\"\"\n    dataset_set: Set[str] = set()\n    for cur_exp in self.experiments:\n        dataset_set.add(cur_exp.get_experiment_path().split(\"/\")[0])\n\n    return sorted(list(dataset_set))\n</code></pre>"},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager.ExperimentManager.get_datasets_information_dict","title":"get_datasets_information_dict","text":"<pre><code>get_datasets_information_dict()\n</code></pre> <p>Returns a dict with information about the datasets</p> Source code in <code>niceml/experiments/experimentmanager.py</code> <pre><code>def get_datasets_information_dict(self) -&gt; Dict[str, List[str]]:\n    \"\"\"Returns a dict with information about the datasets\"\"\"\n    datasets_information_dict = defaultdict(list)\n    for exp in self.experiments:\n        dataset = exp.get_experiment_path().split(\"/\")[0]\n        datasets_information_dict[dataset].append(exp.get_short_id())\n    return datasets_information_dict\n</code></pre>"},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager.ExperimentManager.get_date_information_dict","title":"get_date_information_dict","text":"<pre><code>get_date_information_dict()\n</code></pre> <p>Returns a dict with information about the dates</p> Source code in <code>niceml/experiments/experimentmanager.py</code> <pre><code>def get_date_information_dict(self) -&gt; Dict[date, List[str]]:\n    \"\"\"Returns a dict with information about the dates\"\"\"\n    date_information_dict = defaultdict(list)\n    for exp in self.experiments:\n        date_string = exp.exp_info.run_id.split(\"T\")[0]\n        date = datetime.strptime(date_string, \"%Y-%m-%d\").date()\n        date_information_dict[date].append(exp.get_short_id())\n    return date_information_dict\n</code></pre>"},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager.ExperimentManager.get_empty_exps","title":"get_empty_exps","text":"<pre><code>get_empty_exps(id_list=None)\n</code></pre> <p>Finds all experiments which are empty</p> Source code in <code>niceml/experiments/experimentmanager.py</code> <pre><code>def get_empty_exps(\n    self, id_list: Optional[List[str]] = None\n) -&gt; List[ExperimentData]:\n    \"\"\"Finds all experiments which are empty\"\"\"\n    if id_list is None:\n        id_list = [x.get_short_id() for x in self.experiments]\n    exp_list = [self.exp_dict[x] for x in id_list]\n    empty_list = [x for x in exp_list if x.is_empty()]\n    return empty_list\n</code></pre>"},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager.ExperimentManager.get_epochs_information_dict","title":"get_epochs_information_dict","text":"<pre><code>get_epochs_information_dict()\n</code></pre> <p>Returns a dict with information about the trained epochs</p> Source code in <code>niceml/experiments/experimentmanager.py</code> <pre><code>def get_epochs_information_dict(self) -&gt; Dict[int, List[str]]:\n    \"\"\"Returns a dict with information about the trained epochs\"\"\"\n    epochs_information_dict = defaultdict(list)\n    for exp in self.experiments:\n        epochs_information_dict[exp.get_trained_epochs()].append(exp.get_short_id())\n    return epochs_information_dict\n</code></pre>"},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager.ExperimentManager.get_exp_by_id","title":"get_exp_by_id","text":"<pre><code>get_exp_by_id(exp_id)\n</code></pre> <p>Returns the experiment with the given id</p>"},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager.ExperimentManager.get_exp_by_id--parameters","title":"Parameters","text":"<p>exp_id: str     alphanumeric str with 4 digits of the desired experiment     OR 'latest' for the newest experiment</p>"},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager.ExperimentManager.get_exp_by_id--returns","title":"Returns","text":"<p>experiment: ExperimentData</p>"},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager.ExperimentManager.get_exp_by_id--raises","title":"Raises","text":"<p>KeyError     If the experiment id does not exist</p> Source code in <code>niceml/experiments/experimentmanager.py</code> <pre><code>def get_exp_by_id(self, exp_id: str) -&gt; ExperimentData:\n    \"\"\"\n    Returns the experiment with the given id\n\n    Parameters\n    ----------\n    exp_id: str\n        alphanumeric str with 4 digits of the desired experiment\n        OR 'latest' for the newest experiment\n\n    Returns\n    -------\n    experiment: ExperimentData\n\n    Raises\n    ------\n    KeyError\n        If the experiment id does not exist\n    \"\"\"\n    if exp_id.lower() == \"latest\":\n        ret_exp = sorted(\n            self.experiments, reverse=True, key=lambda x: x.get_run_id()\n        )[0]\n    else:\n        ret_exp = self.exp_dict[exp_id]\n    return ret_exp\n</code></pre>"},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager.ExperimentManager.get_exp_count","title":"get_exp_count","text":"<pre><code>get_exp_count()\n</code></pre> <p>Returns the number of experiments</p> Source code in <code>niceml/experiments/experimentmanager.py</code> <pre><code>def get_exp_count(self) -&gt; int:\n    \"\"\"Returns the number of experiments\"\"\"\n    return len(self.experiments)\n</code></pre>"},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager.ExperimentManager.get_exp_prefix","title":"get_exp_prefix","text":"<pre><code>get_exp_prefix(exp_id)\n</code></pre> <p>extracts the prefix from the target exp data</p> Source code in <code>niceml/experiments/experimentmanager.py</code> <pre><code>def get_exp_prefix(self, exp_id) -&gt; str:\n    \"\"\"extracts the prefix from the target exp data\"\"\"\n    exp_data: ExperimentData = self.get_exp_by_id(exp_id)\n    return exp_data.exp_info.experiment_prefix\n</code></pre>"},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager.ExperimentManager.get_experiment_type","title":"get_experiment_type","text":"<pre><code>get_experiment_type(experiment)\n</code></pre> <p>Returns the experiment type of the given experiment</p> Source code in <code>niceml/experiments/experimentmanager.py</code> <pre><code>def get_experiment_type(self, experiment: ExperimentData) -&gt; str:\n    \"\"\"Returns the experiment type of the given experiment\"\"\"\n    return experiment.get_experiment_path().split(\"/\")[-1].split(\"-\")[0]\n</code></pre>"},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager.ExperimentManager.get_experiment_type_information_dict","title":"get_experiment_type_information_dict","text":"<pre><code>get_experiment_type_information_dict()\n</code></pre> <p>Returns a dict with information about the experiment types</p> Source code in <code>niceml/experiments/experimentmanager.py</code> <pre><code>def get_experiment_type_information_dict(self) -&gt; Dict[str, List[str]]:\n    \"\"\"Returns a dict with information about the experiment types\"\"\"\n    experiment_type_information_dict = defaultdict(list)\n    for exp in self.experiments:\n        experiment_type = exp.get_experiment_path().split(\"/\")[-1].split(\"-\")[0]\n        experiment_type_information_dict[experiment_type].append(exp.get_short_id())\n    return experiment_type_information_dict\n</code></pre>"},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager.ExperimentManager.get_experiment_types","title":"get_experiment_types","text":"<pre><code>get_experiment_types()\n</code></pre> <p>Returns a list of all experiment types</p> Source code in <code>niceml/experiments/experimentmanager.py</code> <pre><code>def get_experiment_types(self) -&gt; List[str]:\n    \"\"\"Returns a list of all experiment types\"\"\"\n    experiment_type_set: Set[str] = set()\n    for cur_exp in self.experiments:\n        experiment_type_set.add(self.get_experiment_type(cur_exp))\n\n    return sorted(list(experiment_type_set))\n</code></pre>"},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager.ExperimentManager.get_experiments","title":"get_experiments","text":"<pre><code>get_experiments()\n</code></pre> <p>Returns a sorted list of all experiments (newest first)</p> Source code in <code>niceml/experiments/experimentmanager.py</code> <pre><code>def get_experiments(self) -&gt; List[ExperimentData]:\n    \"\"\"Returns a sorted list of all experiments (newest first)\"\"\"\n    return sorted(self.experiments, reverse=True, key=lambda x: x.get_run_id())\n</code></pre>"},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager.ExperimentManager.get_max_trained_epochs","title":"get_max_trained_epochs","text":"<pre><code>get_max_trained_epochs()\n</code></pre> <p>Returns the max epochs of all trained experiments</p> Source code in <code>niceml/experiments/experimentmanager.py</code> <pre><code>def get_max_trained_epochs(self) -&gt; int:\n    \"\"\"Returns the max epochs of all trained experiments\"\"\"\n    max_epochs = 0\n    for exp in self.experiments:\n        max_epochs = max(max_epochs, exp.get_trained_epochs())\n    return max_epochs\n</code></pre>"},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager.ExperimentManager.get_metrics","title":"get_metrics","text":"<pre><code>get_metrics(experiments=None)\n</code></pre> <p>Returns a list of all metrics used in the experiments</p> Source code in <code>niceml/experiments/experimentmanager.py</code> <pre><code>def get_metrics(self, experiments: Optional[List[str]] = None) -&gt; List[str]:\n    \"\"\"Returns a list of all metrics used in the experiments\"\"\"\n    metric_set: Set[str] = set()\n    for cur_exp in self.experiments:\n        if experiments is not None and cur_exp.get_short_id() not in experiments:\n            continue\n        metric_set.update(cur_exp.get_metrics())\n\n    return sorted(list(metric_set))\n</code></pre>"},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager.ExperimentManager.get_metrics_visu_df","title":"get_metrics_visu_df","text":"<pre><code>get_metrics_visu_df(metric_names, exp_id_list)\n</code></pre> <p>Returns a dataframe for the metrics visu, containing the min, max value for each metric and each experiment</p> Source code in <code>niceml/experiments/experimentmanager.py</code> <pre><code>def get_metrics_visu_df(\n    self, metric_names: List[str], exp_id_list: List[str]\n) -&gt; pd.DataFrame:\n    \"\"\"Returns a dataframe for the metrics visu, containing the min, max value for\n    each metric and each experiment\"\"\"\n    mode_dict: Dict[str, str] = {\n        \"accuracy\": \"max\",\n        \"loss\": \"min\",\n        \"iou\": \"max\",\n        \"precision\": \"max\",\n        \"recall\": \"max\",\n    }\n    metrics_data = pd.DataFrame()\n    for met in metric_names:\n        if not met.startswith(\"val_\"):\n            val_met = f\"val_{met}\"\n            cur_df = self.get_visu_df(met, list(exp_id_list))\n            cur_val_df = self.get_visu_df(val_met, list(exp_id_list))\n            if cur_df is None or cur_val_df is None:\n                continue\n            min_met = []\n            min_val_met = []\n            max_met = []\n            max_val_met = []\n            experiment_names = []\n            for experiment in list(exp_id_list):\n                experiment_names.append(experiment)\n                experiment_df = cur_df[cur_df[\"name\"] == experiment]\n                experiment_val_df = cur_val_df[cur_val_df[\"name\"] == experiment]\n                if experiment_df.empty or experiment_val_df.empty:\n                    if experiment_df.empty:\n                        min_met.append(np.nan)\n                        max_met.append(np.nan)\n                    if experiment_val_df.empty:\n                        min_val_met.append(np.nan)\n                        max_val_met.append(np.nan)\n                    continue\n                min_met.append(min(cur_df[cur_df[\"name\"] == experiment][met]))\n                max_met.append(max(cur_df[cur_df[\"name\"] == experiment][met]))\n                min_val_met.append(\n                    min(cur_val_df[cur_val_df[\"name\"] == experiment][val_met])\n                )\n                max_val_met.append(\n                    max(cur_val_df[cur_val_df[\"name\"] == experiment][val_met])\n                )\n            metrics_data[\"Experiment\"] = experiment_names\n            add_min, add_max = get_add_min_max(met, mode_dict)\n            if add_min:\n                metrics_data[f\"{met}_min\"] = min_met\n                metrics_data[f\"{val_met}_min\"] = min_val_met\n            if add_max:\n                metrics_data[f\"{met}_max\"] = max_met\n                metrics_data[f\"{val_met}_max\"] = max_val_met\n    return metrics_data\n</code></pre>"},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager.ExperimentManager.get_value_information_dict","title":"get_value_information_dict","text":"<pre><code>get_value_information_dict(\n    info_path, list_connection_str=\"x\"\n)\n</code></pre> <p>Returns a dict with information about the values</p> Source code in <code>niceml/experiments/experimentmanager.py</code> <pre><code>def get_value_information_dict(\n    self, info_path: List[str], list_connection_str: str = \"x\"\n) -&gt; Dict[Any, List[str]]:\n    \"\"\"Returns a dict with information about the values\"\"\"\n    value_information_dict = defaultdict(list)\n    for exp in self.experiments:\n        try:\n            exp_info = exp.get_config_information(info_path)\n            if type(exp_info) is list:\n                exp_info = list_connection_str.join([str(x) for x in exp_info])\n            value_information_dict[exp_info].append(exp.exp_info.short_id)\n        except InfoNotFoundError:\n            pass\n\n    return value_information_dict\n</code></pre>"},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager.ExperimentManager.get_visu_df","title":"get_visu_df","text":"<pre><code>get_visu_df(metric_name, exp_id_list)\n</code></pre> <p>Returns a dataframe for the metric and experiments</p> Source code in <code>niceml/experiments/experimentmanager.py</code> <pre><code>def get_visu_df(self, metric_name: str, exp_id_list: List[str]) -&gt; pd.DataFrame:\n    \"\"\"Returns a dataframe for the metric and experiments\"\"\"\n    df = None\n    for exp_id in exp_id_list:\n        exp = self.get_exp_by_id(exp_id)\n        try:\n            cur_df = exp.get_log_for_metric(metric_name)\n        except LogEmptyError:\n            continue\n        if df is None:\n            df = cur_df\n        else:\n            df = pd.concat([df, cur_df])\n\n    return df\n</code></pre>"},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager.ExperimentManager.is_exp_modified","title":"is_exp_modified","text":"<pre><code>is_exp_modified(exp_id, new_time_str)\n</code></pre> <p>Checks if the experiment has been modified</p> Source code in <code>niceml/experiments/experimentmanager.py</code> <pre><code>def is_exp_modified(self, exp_id: str, new_time_str: str) -&gt; bool:\n    \"\"\"Checks if the experiment has been modified\"\"\"\n    if exp_id not in self.exp_dict:\n        return True\n    exp = self.get_exp_by_id(exp_id)\n    return exp.exp_info.is_modified(new_time_str)\n</code></pre>"},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager-functions","title":"Functions","text":""},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager.get_add_min_max","title":"get_add_min_max","text":"<pre><code>get_add_min_max(metric_name, mode_dict)\n</code></pre> <p>Returns if min and max should be added</p> Source code in <code>niceml/experiments/experimentmanager.py</code> <pre><code>def get_add_min_max(metric_name: str, mode_dict: Dict[str, str]) -&gt; Tuple[bool, bool]:\n    \"\"\"Returns if min and max should be added\"\"\"\n    add_min: bool = True\n    add_max: bool = True\n    for key, mode in mode_dict.items():\n        if key in metric_name:\n            if mode == \"max\":\n                add_min = False\n            if mode == \"min\":\n                add_max = False\n    return add_min, add_max\n</code></pre>"},{"location":"reference/experiments/experimentmanager/#niceml.experiments.experimentmanager.local_exp_manager_factory","title":"local_exp_manager_factory","text":"<pre><code>local_exp_manager_factory(path)\n</code></pre> <p>Creates a local experiment manager</p> Source code in <code>niceml/experiments/experimentmanager.py</code> <pre><code>def local_exp_manager_factory(path: str) -&gt; ExperimentManager:\n    \"\"\"Creates a local experiment manager\"\"\"\n    experiments: List[ExperimentData] = []\n    for path in [f.path for f in os.scandir(path) if f.is_dir()]:\n        try:\n            experiments.append(create_expdata_from_local_storage(path))\n        except EmptyExperimentError:\n            logging.getLogger(__name__).info(f\"Empty Experiment at: {path}\")\n\n    return ExperimentManager(experiments)\n</code></pre>"},{"location":"reference/experiments/expfilenames/","title":"expfilenames","text":""},{"location":"reference/experiments/expfilenames/#niceml.experiments.expfilenames","title":"expfilenames","text":"<p>List of experiment filenames</p>"},{"location":"reference/experiments/expfilenames/#niceml.experiments.expfilenames-classes","title":"Classes","text":""},{"location":"reference/experiments/expfilenames/#niceml.experiments.expfilenames.AdditionalExperimentFilenames","title":"AdditionalExperimentFilenames","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> <p>Experiment filenames used dataset specific</p>"},{"location":"reference/experiments/expfilenames/#niceml.experiments.expfilenames.AdditionalExperimentFilenames-functions","title":"Functions","text":""},{"location":"reference/experiments/expfilenames/#niceml.experiments.expfilenames.AdditionalExperimentFilenames.get_complete_name","title":"get_complete_name","text":"<pre><code>get_complete_name(dataset_name)\n</code></pre> <p>Replaces {dataset} with the specific datasetname and returns the string</p> Source code in <code>niceml/experiments/expfilenames.py</code> <pre><code>def get_complete_name(self, dataset_name: str) -&gt; str:\n    \"\"\"Replaces {dataset} with the specific datasetname and returns the string\"\"\"\n    return self.value.format(dataset=dataset_name)\n</code></pre>"},{"location":"reference/experiments/expfilenames/#niceml.experiments.expfilenames.AdditionalExperimentFilenames.get_formatted_basename","title":"get_formatted_basename","text":"<pre><code>get_formatted_basename(dataset_name)\n</code></pre> <p>returns only the basename from the complete_name</p> Source code in <code>niceml/experiments/expfilenames.py</code> <pre><code>def get_formatted_basename(self, dataset_name: str) -&gt; str:\n    \"\"\"returns only the basename from the complete_name\"\"\"\n    return basename(self.get_complete_name(dataset_name))\n</code></pre>"},{"location":"reference/experiments/expfilenames/#niceml.experiments.expfilenames.ExpEvalCopyNames","title":"ExpEvalCopyNames","text":"<pre><code>ExpEvalCopyNames(exclude_files=None)\n</code></pre> <p>Class for determining whether a file should be copied during eval job</p> <p>Class for determining whether a file should be copied during eval job</p> Source code in <code>niceml/experiments/expfilenames.py</code> <pre><code>def __init__(self, exclude_files: Optional[List[str]] = None):\n    \"\"\"Class for determining whether a file should be copied during eval job\"\"\"\n\n    self.exclude_files = exclude_files or [\n        ExperimentFilenames.ANALYSIS_FOLDER,\n        ExperimentFilenames.PREDICTION_FOLDER,\n    ]\n</code></pre>"},{"location":"reference/experiments/expfilenames/#niceml.experiments.expfilenames.ExpEvalCopyNames-functions","title":"Functions","text":""},{"location":"reference/experiments/expfilenames/#niceml.experiments.expfilenames.ExpEvalCopyNames.__contains__","title":"__contains__","text":"<pre><code>__contains__(key)\n</code></pre> <p>The contains function is used to check if a key is in the dictionary. This function will be called when using the 'in' keyword.</p> <p>Parameters:</p> <ul> <li> <code>key</code>             (<code>str</code>)         \u2013          <p>str: Check if the key (<code>file</code>) starts with an excluded file</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>         \u2013          <p>False, if the key (<code>file</code>) starts with an excluded file</p> </li> </ul> Source code in <code>niceml/experiments/expfilenames.py</code> <pre><code>def __contains__(self, key: str) -&gt; bool:\n    \"\"\"\n    The __contains__ function is used to check if a key is in the dictionary.\n    This function will be called when using the 'in' keyword.\n\n    Args:\n        key: str: Check if the key (`file`) starts with an excluded file\n\n    Returns:\n        False, if the key (`file`) starts with an excluded file\n    \"\"\"\n    for ex_file in self.exclude_files:\n        if key.startswith(ex_file):\n            return False\n    return True\n</code></pre>"},{"location":"reference/experiments/expfilenames/#niceml.experiments.expfilenames.ExperimentFilenames","title":"ExperimentFilenames","text":"<p>Available experiment filenames</p>"},{"location":"reference/experiments/expfilenames/#niceml.experiments.expfilenames.OpNames","title":"OpNames","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> <p>Names of the ops</p>"},{"location":"reference/experiments/expfilenames/#niceml.experiments.expfilenames-functions","title":"Functions","text":""},{"location":"reference/experiments/expfilenames/#niceml.experiments.expfilenames.filter_for_exp_info_files","title":"filter_for_exp_info_files","text":"<pre><code>filter_for_exp_info_files(file_list)\n</code></pre> <p>Returns all files which are named like the EXP_INFO file</p> Source code in <code>niceml/experiments/expfilenames.py</code> <pre><code>def filter_for_exp_info_files(file_list: List[str]) -&gt; List[str]:\n    \"\"\"Returns all files which are named like the EXP_INFO file\"\"\"\n    return [x for x in file_list if basename(x) in [ExperimentFilenames.EXP_INFO]]\n</code></pre>"},{"location":"reference/experiments/expfilenames/#niceml.experiments.expfilenames.get_load_parq_files","title":"get_load_parq_files","text":"<pre><code>get_load_parq_files()\n</code></pre> <p>returns the files which should be loaded</p> Source code in <code>niceml/experiments/expfilenames.py</code> <pre><code>def get_load_parq_files() -&gt; List[str]:\n    \"\"\"returns the files which should be loaded\"\"\"\n    cur_exp_fn: AdditionalExperimentFilenames  # ruff: noqa: F842\n    load_parq_files = [\n        cur_exp_fn.get_complete_name(y)\n        for cur_exp_fn in AdditionalExperimentFilenames\n        for y in get_eval_save_names()\n    ]\n    return load_parq_files\n</code></pre>"},{"location":"reference/experiments/expoutinitializer/","title":"expoutinitializer","text":""},{"location":"reference/experiments/expoutinitializer/#niceml.experiments.expoutinitializer","title":"expoutinitializer","text":"<p>Module for expout initializer</p>"},{"location":"reference/experiments/expoutinitializer/#niceml.experiments.expoutinitializer-classes","title":"Classes","text":""},{"location":"reference/experiments/expoutinitializer/#niceml.experiments.expoutinitializer.ExpOutInitializer","title":"ExpOutInitializer","text":"<pre><code>ExpOutInitializer(\n    git_dirs=None,\n    git_modules=None,\n    copy_info=None,\n    environment=None,\n    exp_name=None,\n    exp_prefix=None,\n    description=None,\n    exp_type=None,\n)\n</code></pre> <p>This class creates the first folder and files for an experiment</p> Source code in <code>niceml/experiments/expoutinitializer.py</code> <pre><code>def __init__(\n    self,\n    git_dirs: List[str] = None,\n    git_modules: List[str] = None,\n    copy_info: Optional[CopyInfo] = None,\n    environment: Optional[dict] = None,\n    exp_name: Optional[str] = None,\n    exp_prefix: Optional[str] = None,\n    description: Optional[str] = None,\n    exp_type: Optional[str] = None,\n):\n    self.copy_info = copy_info\n    self.git_dirs: List[str] = git_dirs or []\n    self.git_modules: List[str] = git_modules or []\n    self.environment = environment or {}\n    self.description = description or \"\"\n    self.exp_name: str = exp_name or \"\"\n    self.exp_prefix: str = exp_prefix or \"\"\n    self.exp_type: str = exp_type or \"\"\n</code></pre>"},{"location":"reference/experiments/expoutinitializer/#niceml.experiments.expoutinitializer-functions","title":"Functions","text":""},{"location":"reference/experiments/expoutinitializer/#niceml.experiments.expoutinitializer.produce_exp_info","title":"produce_exp_info","text":"<pre><code>produce_exp_info(\n    exp_context,\n    filepath,\n    environment,\n    description,\n    short_id,\n    run_id,\n    exp_name,\n    experiment_type=\"\",\n    exp_prefix=None,\n)\n</code></pre> <p>This function creates the experiment info file and stores it within the experiment folder</p> Source code in <code>niceml/experiments/expoutinitializer.py</code> <pre><code>def produce_exp_info(  # pylint: disable=too-many-arguments\n    exp_context: ExperimentContext,\n    filepath: str,\n    environment: dict,\n    description: str,\n    short_id: str,\n    run_id: str,\n    exp_name: str,\n    experiment_type: str = \"\",\n    exp_prefix: Optional[str] = None,\n):\n    \"\"\"This function creates the experiment info file\n    and stores it within the experiment folder\"\"\"\n    exp_info = ExperimentInfo(\n        experiment_name=exp_name,\n        experiment_prefix=exp_prefix,\n        experiment_type=experiment_type,\n        run_id=run_id,\n        short_id=short_id,\n        environment=environment,\n        description=description,\n        exp_dir=basename(dirname(filepath)),\n    )\n    out_dict = exp_info.as_save_dict()\n    exp_context.write_yaml(out_dict, filepath)\n</code></pre>"},{"location":"reference/experiments/exppathfinder/","title":"exppathfinder","text":""},{"location":"reference/experiments/exppathfinder/#niceml.experiments.exppathfinder","title":"exppathfinder","text":"<p>This module contains functions to find experiment paths.</p>"},{"location":"reference/experiments/exppathfinder/#niceml.experiments.exppathfinder-classes","title":"Classes","text":""},{"location":"reference/experiments/exppathfinder/#niceml.experiments.exppathfinder-functions","title":"Functions","text":""},{"location":"reference/experiments/exppathfinder/#niceml.experiments.exppathfinder.get_exp_filepath","title":"get_exp_filepath","text":"<pre><code>get_exp_filepath(fs_path_config, exp_id)\n</code></pre> <p>Searches for the experimentpath with the given id. <code>latest</code> returns the newest experiment.</p> Source code in <code>niceml/experiments/exppathfinder.py</code> <pre><code>def get_exp_filepath(fs_path_config: LocationConfig, exp_id: str):\n    \"\"\"Searches for the experimentpath with the given id.\n    `latest` returns the newest experiment.\"\"\"\n    storage = FSSpecStorage(fs_path_config)\n    exp_id_list: List[ExperimentInfo] = storage.list_experiments()\n    exp_id_list = sorted(exp_id_list, key=lambda x: x.run_id)\n    if exp_id == \"latest\":\n        return exp_id_list[-1].exp_filepath\n    exps_w_id = [cur_exp for cur_exp in exp_id_list if cur_exp.short_id == exp_id]\n    if len(exps_w_id) == 0:\n        raise ExperimentNotFoundError(\n            f\"Experiment with id: {exp_id} not found in path: {fs_path_config.uri}\"\n        )\n    if len(exps_w_id) &gt; 1:\n        raise MultipleExperimentsFoundError(\n            f\"Multiple experiments with id: {exp_id} found in path: {fs_path_config.uri}\"\n        )\n    return exps_w_id[0].exp_filepath\n</code></pre>"},{"location":"reference/experiments/loaddatafunctions/","title":"loaddatafunctions","text":""},{"location":"reference/experiments/loaddatafunctions/#niceml.experiments.loaddatafunctions","title":"loaddatafunctions","text":"<p>Module for LoadDataFunctions</p>"},{"location":"reference/experiments/loaddatafunctions/#niceml.experiments.loaddatafunctions-classes","title":"Classes","text":""},{"location":"reference/experiments/loaddatafunctions/#niceml.experiments.loaddatafunctions.LoadCsvFile","title":"LoadCsvFile","text":"<p>             Bases: <code>LoadDataFunc</code></p> <p>Loads csv data from a cloud storage</p>"},{"location":"reference/experiments/loaddatafunctions/#niceml.experiments.loaddatafunctions.LoadDataFunc","title":"LoadDataFunc","text":"<p>             Bases: <code>ABC</code></p> <p>Abstract class to load arbitrary data via a storages</p>"},{"location":"reference/experiments/loaddatafunctions/#niceml.experiments.loaddatafunctions.LoadDataFunc-functions","title":"Functions","text":""},{"location":"reference/experiments/loaddatafunctions/#niceml.experiments.loaddatafunctions.LoadDataFunc.load_data","title":"load_data  <code>abstractmethod</code>","text":"<pre><code>load_data(file_path, storage)\n</code></pre> <p>loads data from cloud storage</p> Source code in <code>niceml/experiments/loaddatafunctions.py</code> <pre><code>@abstractmethod\ndef load_data(self, file_path: str, storage: StorageInterface) -&gt; Any:\n    \"\"\"loads data from cloud storage\"\"\"\n</code></pre>"},{"location":"reference/experiments/loaddatafunctions/#niceml.experiments.loaddatafunctions.LoadImageFile","title":"LoadImageFile","text":"<pre><code>LoadImageFile(target_size, output_dtype=np.uint8)\n</code></pre> <p>             Bases: <code>LoadDataFunc</code></p> <p>Loads image data from a cloud storage</p> Source code in <code>niceml/experiments/loaddatafunctions.py</code> <pre><code>def __init__(self, target_size: ImageSize, output_dtype=np.uint8):\n    self.target_size = target_size\n    self.output_dtype = output_dtype\n</code></pre>"},{"location":"reference/experiments/loaddatafunctions/#niceml.experiments.loaddatafunctions.LoadParquetFile","title":"LoadParquetFile","text":"<p>             Bases: <code>LoadDataFunc</code></p> <p>Loads parquet data from a cloud storage</p>"},{"location":"reference/experiments/loaddatafunctions/#niceml.experiments.loaddatafunctions.LoadYamlFile","title":"LoadYamlFile","text":"<p>             Bases: <code>LoadDataFunc</code></p> <p>Loads yaml data from a cloud storage</p>"},{"location":"reference/experiments/loadexpinfo/","title":"loadexpinfo","text":""},{"location":"reference/experiments/loadexpinfo/#niceml.experiments.loadexpinfo","title":"loadexpinfo","text":"<p>Module for loading experiment info</p>"},{"location":"reference/experiments/loadexpinfo/#niceml.experiments.loadexpinfo-classes","title":"Classes","text":""},{"location":"reference/experiments/loadexpinfo/#niceml.experiments.loadexpinfo-functions","title":"Functions","text":""},{"location":"reference/experiments/loadexpinfo/#niceml.experiments.loadexpinfo.load_exp_info","title":"load_exp_info","text":"<pre><code>load_exp_info(storage, exp_path)\n</code></pre> <p>Loads the experiment info file</p> Source code in <code>niceml/experiments/loadexpinfo.py</code> <pre><code>def load_exp_info(storage: StorageInterface, exp_path: str) -&gt; ExperimentInfo:\n    \"\"\"Loads the experiment info file\"\"\"\n    if len(exp_path) == 0:\n        target_path = ExperimentFilenames.EXP_INFO\n    else:\n        target_path = storage.join_paths(exp_path, ExperimentFilenames.EXP_INFO)\n    yaml_data = LoadYamlFile().load_data(target_path, storage)\n    if yaml_data is None:\n        raise FileNotFoundError(f\"Info File {exp_path} is empty!\")\n    return experiment_info_factory(yaml_data, path=exp_path)\n</code></pre>"},{"location":"reference/experiments/localexperimentcache/","title":"localexperimentcache","text":""},{"location":"reference/experiments/localexperimentcache/#niceml.experiments.localexperimentcache","title":"localexperimentcache","text":"<p>Implementation of the ExperimentCache interface for local experiments.</p>"},{"location":"reference/experiments/localexperimentcache/#niceml.experiments.localexperimentcache-classes","title":"Classes","text":""},{"location":"reference/experiments/localexperimentcache/#niceml.experiments.localexperimentcache.ExperimentCache","title":"ExperimentCache","text":"<p>             Bases: <code>ABC</code></p> <p>Interface for the experiment cache</p>"},{"location":"reference/experiments/localexperimentcache/#niceml.experiments.localexperimentcache.ExperimentCache-functions","title":"Functions","text":""},{"location":"reference/experiments/localexperimentcache/#niceml.experiments.localexperimentcache.ExperimentCache.__contains__","title":"__contains__  <code>abstractmethod</code>","text":"<pre><code>__contains__(exp_id)\n</code></pre> <p>Checks if the experiment is in the cache</p> Source code in <code>niceml/experiments/localexperimentcache.py</code> <pre><code>@abstractmethod\ndef __contains__(self, exp_id: str) -&gt; bool:\n    \"\"\"Checks if the experiment is in the cache\"\"\"\n</code></pre>"},{"location":"reference/experiments/localexperimentcache/#niceml.experiments.localexperimentcache.ExperimentCache.get_exp_count_in_cache","title":"get_exp_count_in_cache  <code>abstractmethod</code>","text":"<pre><code>get_exp_count_in_cache()\n</code></pre> <p>Returns the amount of cached experiments</p> Source code in <code>niceml/experiments/localexperimentcache.py</code> <pre><code>@abstractmethod\ndef get_exp_count_in_cache(self) -&gt; int:\n    \"\"\"Returns the amount of cached experiments\"\"\"\n</code></pre>"},{"location":"reference/experiments/localexperimentcache/#niceml.experiments.localexperimentcache.ExperimentCache.load_exp_info","title":"load_exp_info  <code>abstractmethod</code>","text":"<pre><code>load_exp_info(exp_id)\n</code></pre> <p>Loads the experiment info from the cache</p> Source code in <code>niceml/experiments/localexperimentcache.py</code> <pre><code>@abstractmethod\ndef load_exp_info(self, exp_id: str) -&gt; ExperimentInfo:\n    \"\"\"Loads the experiment info from the cache\"\"\"\n</code></pre>"},{"location":"reference/experiments/localexperimentcache/#niceml.experiments.localexperimentcache.ExperimentCache.load_experiment","title":"load_experiment  <code>abstractmethod</code>","text":"<pre><code>load_experiment(exp_id, image_loader=None, df_loader=None)\n</code></pre> <p>Loads the experiment from the cache</p> Source code in <code>niceml/experiments/localexperimentcache.py</code> <pre><code>@abstractmethod\ndef load_experiment(\n    self,\n    exp_id: str,\n    image_loader: Optional[ImageLoader] = None,\n    df_loader: Optional[DfLoader] = None,\n) -&gt; ExperimentData:\n    \"\"\"Loads the experiment from the cache\"\"\"\n</code></pre>"},{"location":"reference/experiments/localexperimentcache/#niceml.experiments.localexperimentcache.ExperimentCache.save_experiment","title":"save_experiment  <code>abstractmethod</code>","text":"<pre><code>save_experiment(exp_data)\n</code></pre> <p>Saves the experiment to the cache</p> Source code in <code>niceml/experiments/localexperimentcache.py</code> <pre><code>@abstractmethod\ndef save_experiment(self, exp_data: ExperimentData):\n    \"\"\"Saves the experiment to the cache\"\"\"\n</code></pre>"},{"location":"reference/experiments/localexperimentcache/#niceml.experiments.localexperimentcache.ExperimentCache.should_reload","title":"should_reload","text":"<pre><code>should_reload(experiment_info)\n</code></pre> <p>Checks if the experiment should be reloaded</p> Source code in <code>niceml/experiments/localexperimentcache.py</code> <pre><code>def should_reload(self, experiment_info: ExperimentInfo) -&gt; bool:\n    \"\"\"Checks if the experiment should be reloaded\"\"\"\n    if experiment_info.short_id not in self:\n        return True\n    loaded_exp_info = self.load_exp_info(experiment_info.short_id)\n    return experiment_info.is_modified(loaded_exp_info)\n</code></pre>"},{"location":"reference/experiments/localexperimentcache/#niceml.experiments.localexperimentcache.LocalExperimentCache","title":"LocalExperimentCache","text":"<pre><code>LocalExperimentCache(store_folder)\n</code></pre> <p>             Bases: <code>ExperimentCache</code></p> <p>Implementation of the ExperimentCache interface for local disk experiments.</p> <p>Factory method for the local experiment cache</p> Source code in <code>niceml/experiments/localexperimentcache.py</code> <pre><code>def __init__(self, store_folder: str):\n    \"\"\"Factory method for the local experiment cache\"\"\"\n    self.store_folder = store_folder\n    if not isdir(self.store_folder):\n        makedirs(self.store_folder, exist_ok=True)\n</code></pre>"},{"location":"reference/experiments/localexperimentcache/#niceml.experiments.localexperimentcache.LocalExperimentCache-functions","title":"Functions","text":""},{"location":"reference/experiments/localexperimentcache/#niceml.experiments.localexperimentcache.LocalExperimentCache.__contains__","title":"__contains__","text":"<pre><code>__contains__(exp_id)\n</code></pre> <p>Checks if the experiment is in the cache</p> Source code in <code>niceml/experiments/localexperimentcache.py</code> <pre><code>def __contains__(self, exp_id: str) -&gt; bool:\n    \"\"\"Checks if the experiment is in the cache\"\"\"\n    try:\n        self.find_folder_name_of_exp_id(exp_id)\n        return True\n    except ExpIdNotFoundError:\n        return False\n</code></pre>"},{"location":"reference/experiments/localexperimentcache/#niceml.experiments.localexperimentcache.LocalExperimentCache.find_folder_name_of_exp_id","title":"find_folder_name_of_exp_id","text":"<pre><code>find_folder_name_of_exp_id(exp_id)\n</code></pre> <p>Finds the folder name of the experiment id</p> Source code in <code>niceml/experiments/localexperimentcache.py</code> <pre><code>def find_folder_name_of_exp_id(self, exp_id) -&gt; Optional[str]:\n    \"\"\"Finds the folder name of the experiment id\"\"\"\n\n    for folder_name in get_exp_folder_list(self.store_folder):\n        if exp_id in folder_name and isdir(join(self.store_folder, folder_name)):\n            return folder_name\n    raise ExpIdNotFoundError(f\"Experiment with id: {exp_id} not in Cache\")\n</code></pre>"},{"location":"reference/experiments/localexperimentcache/#niceml.experiments.localexperimentcache.LocalExperimentCache.get_exp_count_in_cache","title":"get_exp_count_in_cache","text":"<pre><code>get_exp_count_in_cache()\n</code></pre> <p>Returns the amount of cached experiments</p> Source code in <code>niceml/experiments/localexperimentcache.py</code> <pre><code>def get_exp_count_in_cache(self):\n    \"\"\"Returns the amount of cached experiments\"\"\"\n    return len(get_exp_folder_list(self.store_folder))\n</code></pre>"},{"location":"reference/experiments/localexperimentcache/#niceml.experiments.localexperimentcache.LocalExperimentCache.load_exp_info","title":"load_exp_info","text":"<pre><code>load_exp_info(exp_id)\n</code></pre> <p>Loads the experiment info from the cache</p> Source code in <code>niceml/experiments/localexperimentcache.py</code> <pre><code>def load_exp_info(self, exp_id: str) -&gt; ExperimentInfo:\n    \"\"\"Loads the experiment info from the cache\"\"\"\n    exp_folder = self.find_folder_name_of_exp_id(exp_id)\n    exp_info_file = join(\n        self.store_folder, exp_folder, ExperimentFilenames.EXP_INFO\n    )\n    exp_info = load_exp_info(exp_info_file)\n\n    return exp_info\n</code></pre>"},{"location":"reference/experiments/localexperimentcache/#niceml.experiments.localexperimentcache.LocalExperimentCache.load_experiment","title":"load_experiment","text":"<pre><code>load_experiment(exp_id, image_loader=None, df_loader=None)\n</code></pre> <p>Loads the experiment from the cache</p> Source code in <code>niceml/experiments/localexperimentcache.py</code> <pre><code>def load_experiment(\n    self,\n    exp_id: str,\n    image_loader: Optional[ImageLoader] = None,\n    df_loader: Optional[DfLoader] = None,\n) -&gt; ExperimentData:\n    \"\"\"Loads the experiment from the cache\"\"\"\n    exp_folder = self.find_folder_name_of_exp_id(exp_id)\n    storage = LocalStorage(self.store_folder)\n    return create_expdata_from_storage(\n        exp_folder, storage, image_loader=image_loader, df_loader=df_loader\n    )\n</code></pre>"},{"location":"reference/experiments/localexperimentcache/#niceml.experiments.localexperimentcache.LocalExperimentCache.save_experiment","title":"save_experiment","text":"<pre><code>save_experiment(exp_data)\n</code></pre> <p>Saves the experiment to the cache</p> Source code in <code>niceml/experiments/localexperimentcache.py</code> <pre><code>def save_experiment(self, exp_data: ExperimentData):\n    \"\"\"Saves the experiment to the cache\"\"\"\n    if self.store_folder is None:\n        return\n    self._create_output_folders(exp_data=exp_data)\n\n    exp_files_df = create_exp_file_df(exp_data=exp_data)\n\n    for key, value in exp_data.exp_dict_data.items():\n        with open(\n            join(\n                self.store_folder,\n                exp_data.get_experiment_path(),\n                key + \".yaml\",\n            ),\n            \"w\",\n            encoding=\"utf-8\",\n        ) as exp_data_path:\n            yaml.dump(value, exp_data_path, indent=2)\n\n    exp_data.log_data.to_csv(\n        join(\n            self.store_folder,\n            exp_data.get_experiment_path(),\n            ExperimentFilenames.TRAIN_LOGS,\n        )\n    )\n\n    write_parquet(\n        exp_files_df,\n        join(\n            self.store_folder,\n            exp_data.get_experiment_path(),\n            ExperimentFilenames.EXP_FILES_FILE,\n        ),\n    )\n</code></pre>"},{"location":"reference/experiments/localexperimentcache/#niceml.experiments.localexperimentcache-functions","title":"Functions","text":""},{"location":"reference/experiments/localexperimentcache/#niceml.experiments.localexperimentcache.create_exp_file_df","title":"create_exp_file_df","text":"<pre><code>create_exp_file_df(exp_data)\n</code></pre> <p>Creates a dataframe with the experiment files</p> Source code in <code>niceml/experiments/localexperimentcache.py</code> <pre><code>def create_exp_file_df(exp_data: ExperimentData) -&gt; pd.DataFrame:\n    \"\"\"Creates a dataframe with the experiment files\"\"\"\n    exp_files = []\n    for exp_file in exp_data.all_exp_files:\n        ext = splitext(exp_file)[1]\n\n        if len(ext) &gt; 0:\n            if ext == \".yml\":\n                ext = \".yaml\"\n            exp_files.append(\n                {\n                    ExperimentFilenames.EXP_FILES_COL: splitext(exp_file)[0] + ext,\n                    \"suffix\": ext,\n                }\n            )\n    return pd.DataFrame(exp_files)\n</code></pre>"},{"location":"reference/experiments/localexperimentcache/#niceml.experiments.localexperimentcache.get_exp_folder_list","title":"get_exp_folder_list","text":"<pre><code>get_exp_folder_list(folder, root_folder=None)\n</code></pre> <pre><code>Creates a list with names of experiment folders, which also includes parent\n directories if they exist\n</code></pre> <p>Args:     folder: folder to search in     root_folder: param for saving the first <code>folder</code> attribute due to a recursive function call</p> <p>Returns:</p> <ul> <li> <code>List[str]</code>         \u2013          <p>List of experiment folder names</p> </li> </ul> Source code in <code>niceml/experiments/localexperimentcache.py</code> <pre><code>def get_exp_folder_list(folder: str, root_folder: Optional[str] = None) -&gt; List[str]:\n    \"\"\"\n        Creates a list with names of experiment folders, which also includes parent\n         directories if they exist\n    Args:\n        folder: folder to search in\n        root_folder: param for saving the first `folder` attribute due to a recursive function call\n\n    Returns:\n        List of experiment folder names\n\n    \"\"\"\n    if check_exp_name(folder):\n        return [folder]\n\n    folders = (\n        list_dir(folder) if root_folder is None else list_dir(join(root_folder, folder))\n    )\n    if root_folder is None:\n        root_folder = folder\n    if not all(check_exp_name(split(path)[-1]) for path in folders):\n        sub_folders = [\n            get_exp_folder_list(path, root_folder)\n            for path in folders\n            if isdir(join(root_folder, path))\n        ]\n        sub_folders = sum(sub_folders, [])\n        return sub_folders\n    return (\n        [join(folder, sub_folder) for sub_folder in folders]\n        if folder != root_folder\n        else folders\n    )\n</code></pre>"},{"location":"reference/experiments/metafunctions/","title":"metafunctions","text":""},{"location":"reference/experiments/metafunctions/#niceml.experiments.metafunctions","title":"metafunctions","text":""},{"location":"reference/experiments/metafunctions/#niceml.experiments.metafunctions-classes","title":"Classes","text":""},{"location":"reference/experiments/metainfotables/","title":"metainfotables","text":""},{"location":"reference/experiments/metainfotables/#niceml.experiments.metainfotables","title":"metainfotables","text":""},{"location":"reference/experiments/metainfotables/#niceml.experiments.metainfotables-classes","title":"Classes","text":""},{"location":"reference/experiments/metalists/","title":"metalists","text":""},{"location":"reference/experiments/metalists/#niceml.experiments.metalists","title":"metalists","text":""},{"location":"reference/experiments/metalists/#niceml.experiments.metalists-classes","title":"Classes","text":""},{"location":"reference/experiments/metalists/#niceml.experiments.metalists-functions","title":"Functions","text":""},{"location":"reference/experiments/metalists/#niceml.experiments.metalists.get_augmentation_list","title":"get_augmentation_list","text":"<pre><code>get_augmentation_list(max_augmentators=5)\n</code></pre> <p>Includes ID and all augmentations when used with genericdatagenerator</p> Source code in <code>niceml/experiments/metalists.py</code> <pre><code>def get_augmentation_list(max_augmentators: int = 5) -&gt; List[MetaFunction]:\n    \"\"\"Includes ID and all augmentations when used with genericdatagenerator\"\"\"\n    meta_functions = [ExperimentIdExtraction()]\n    for idx in range(max_augmentators):\n        cur_aug_conf_path = AUGMENTATIONS_CONFIG_PATH + [idx]\n        meta_functions.append(\n            ConfigInfoExtractor(\n                f\"augmentation_{idx}\",\n                cur_aug_conf_path,\n                info_format_func=hydra_instance_format,\n            )\n        )\n    return meta_functions\n</code></pre>"},{"location":"reference/experiments/metatablefactory/","title":"metatablefactory","text":""},{"location":"reference/experiments/metatablefactory/#niceml.experiments.metatablefactory","title":"metatablefactory","text":""},{"location":"reference/experiments/experimenttests/__init__/","title":"experimenttests","text":""},{"location":"reference/experiments/experimenttests/__init__/#niceml.experiments.experimenttests","title":"experimenttests","text":""},{"location":"reference/experiments/experimenttests/checkfilesfolderstest/","title":"checkfilesfolderstest","text":""},{"location":"reference/experiments/experimenttests/checkfilesfolderstest/#niceml.experiments.experimenttests.checkfilesfolderstest","title":"checkfilesfolderstest","text":"<p>Module for CheckFilesFoldersTest</p>"},{"location":"reference/experiments/experimenttests/checkfilesfolderstest/#niceml.experiments.experimenttests.checkfilesfolderstest-classes","title":"Classes","text":""},{"location":"reference/experiments/experimenttests/checkfilesfolderstest/#niceml.experiments.experimenttests.checkfilesfolderstest.CheckFilesFoldersTest","title":"CheckFilesFoldersTest","text":"<pre><code>CheckFilesFoldersTest(files=None, folders=None)\n</code></pre> <p>             Bases: <code>ExperimentTest</code></p> <p>ExperimentTest if files and folders are located in the experiment Parameters</p> <p>files: Optional[List[str]], default None     All required files with relative path to experiment root folders: Optional[List[str]], default None     All required folders with relative path to experiment root</p> Source code in <code>niceml/experiments/experimenttests/checkfilesfolderstest.py</code> <pre><code>def __init__(\n    self, files: Optional[List[str]] = None, folders: Optional[List[str]] = None\n):\n    \"\"\"\n    ExperimentTest if files and folders are located in the experiment\n    Parameters\n    ----------\n    files: Optional[List[str]], default None\n        All required files with relative path to experiment root\n    folders: Optional[List[str]], default None\n        All required folders with relative path to experiment root\n    \"\"\"\n    self.files = [] if files is None else files\n    self.folders = [] if folders is None else folders\n</code></pre>"},{"location":"reference/experiments/experimenttests/checkfilesfolderstest/#niceml.experiments.experimenttests.checkfilesfolderstest.CheckFilesFoldersTest-functions","title":"Functions","text":""},{"location":"reference/experiments/experimenttests/exptests/","title":"exptests","text":""},{"location":"reference/experiments/experimenttests/exptests/#niceml.experiments.experimenttests.exptests","title":"exptests","text":"<p>Module for exptests</p>"},{"location":"reference/experiments/experimenttests/exptests/#niceml.experiments.experimenttests.exptests-classes","title":"Classes","text":""},{"location":"reference/experiments/experimenttests/exptests/#niceml.experiments.experimenttests.exptests.ExpTestResult","title":"ExpTestResult  <code>dataclass</code>","text":"<p>             Bases: <code>object</code></p> <p>Result of an experiment test</p>"},{"location":"reference/experiments/experimenttests/exptests/#niceml.experiments.experimenttests.exptests.ExperimentTest","title":"ExperimentTest","text":"<p>             Bases: <code>ABC</code></p> <p>Abstract class for an experiment test</p>"},{"location":"reference/experiments/experimenttests/metriccheck/","title":"metriccheck","text":""},{"location":"reference/experiments/experimenttests/metriccheck/#niceml.experiments.experimenttests.metriccheck","title":"metriccheck","text":""},{"location":"reference/experiments/experimenttests/metriccheck/#niceml.experiments.experimenttests.metriccheck-classes","title":"Classes","text":""},{"location":"reference/experiments/experimenttests/metriccheck/#niceml.experiments.experimenttests.metriccheck-functions","title":"Functions","text":""},{"location":"reference/experiments/experimenttests/testinitializer/","title":"testinitializer","text":""},{"location":"reference/experiments/experimenttests/testinitializer/#niceml.experiments.experimenttests.testinitializer","title":"testinitializer","text":"<p>Module for testinitializer</p>"},{"location":"reference/experiments/experimenttests/testinitializer/#niceml.experiments.experimenttests.testinitializer-classes","title":"Classes","text":""},{"location":"reference/experiments/experimenttests/testinitializer/#niceml.experiments.experimenttests.testinitializer.ExpTestProcess","title":"ExpTestProcess","text":"<pre><code>ExpTestProcess(\n    test_list,\n    csv_out_name=\"exp_tests.csv\",\n    raise_exception=True,\n    store_results=True,\n)\n</code></pre> <p>             Bases: <code>object</code></p> <p>Class to execute a list of ExperimentTests</p> <p>Initialize the ExpTestProcess</p> Source code in <code>niceml/experiments/experimenttests/testinitializer.py</code> <pre><code>def __init__(\n    self,\n    test_list: List[ExperimentTest],\n    csv_out_name: str = \"exp_tests.csv\",\n    raise_exception: bool = True,\n    store_results: bool = True,\n):\n    \"\"\"Initialize the ExpTestProcess\"\"\"\n    self.test_list = test_list\n    self.csv_out_name = csv_out_name\n    self.raise_exception = raise_exception\n    self.store_results = store_results\n</code></pre>"},{"location":"reference/experiments/experimenttests/testinitializer/#niceml.experiments.experimenttests.testinitializer.ExpTestProcess-functions","title":"Functions","text":""},{"location":"reference/experiments/experimenttests/testinitializer/#niceml.experiments.experimenttests.testinitializer.ExpTestProcess.__call__","title":"__call__","text":"<pre><code>__call__(\n    input_folder, output_folder=None, file_system=None\n)\n</code></pre> <p>Execute the list of tests and return a list of ExpTestResults</p> Source code in <code>niceml/experiments/experimenttests/testinitializer.py</code> <pre><code>def __call__(\n    self,\n    input_folder: str,\n    output_folder: Optional[str] = None,\n    file_system: Optional[AbstractFileSystem] = None,\n):\n    \"\"\"Execute the list of tests and return a list of ExpTestResults\"\"\"\n    file_system = file_system or LocalFileSystem()\n    if output_folder is None:\n        output_folder = input_folder\n    test_result_list: List[ExpTestResult] = []\n    failed: List[ExpTestResult] = []\n    for test_obj in self.test_list:\n        test_result = test_obj(input_folder, file_system)\n        if test_result.status == TestStatus.FAILED:\n            failed.append(test_result)\n        test_result_list.append(test_result)\n\n    out_path = join(output_folder, self.csv_out_name)\n    if self.store_results:\n        dataframe: pd.DataFrame = pd.DataFrame(\n            [x.to_dict() for x in test_result_list]\n        )\n        write_csv(\n            dataframe, out_path, file_system=file_system, sep=\";\", decimal=\",\"\n        )\n        df_dict = dataframe.to_dict(orient=\"records\")\n        mlflow.log_dict(df_dict, \"exp_tests.yaml\")\n\n    if len(failed) &gt; 0 and self.raise_exception:\n        for failed_exp in failed:\n            logging.getLogger(__name__).error(str(failed_exp))\n        raise ExperimentTestFailedError(\n            f\"Experiment Tests Failed: {failed} Info at: {out_path}\"\n        )\n</code></pre>"},{"location":"reference/experiments/experimenttests/testinitializer/#niceml.experiments.experimenttests.testinitializer.ExperimentTestFailedError","title":"ExperimentTestFailedError","text":"<p>             Bases: <code>Exception</code></p> <p>Exception for when an experiment test fails</p>"},{"location":"reference/experiments/experimenttests/testinitializer/#niceml.experiments.experimenttests.testinitializer-functions","title":"Functions","text":""},{"location":"reference/experiments/experimenttests/validateexps/","title":"validateexps","text":""},{"location":"reference/experiments/experimenttests/validateexps/#niceml.experiments.experimenttests.validateexps","title":"validateexps","text":""},{"location":"reference/experiments/experimenttests/validateexps/#niceml.experiments.experimenttests.validateexps-classes","title":"Classes","text":""},{"location":"reference/experiments/experimenttests/validateexps/#niceml.experiments.experimenttests.validateexps-functions","title":"Functions","text":""},{"location":"reference/experiments/filters/__init__/","title":"filters","text":""},{"location":"reference/experiments/filters/__init__/#niceml.experiments.filters","title":"filters","text":""},{"location":"reference/experiments/filters/datefilter/","title":"datefilter","text":""},{"location":"reference/experiments/filters/datefilter/#niceml.experiments.filters.datefilter","title":"datefilter","text":"<p>Module for date filter</p>"},{"location":"reference/experiments/filters/datefilter/#niceml.experiments.filters.datefilter-classes","title":"Classes","text":""},{"location":"reference/experiments/filters/datefilter/#niceml.experiments.filters.datefilter.DateFilter","title":"DateFilter","text":"<pre><code>DateFilter(days_ago=14, min_shown_exp=5)\n</code></pre> <p>             Bases: <code>ExperimentFilter</code></p> <p>Datefilter for selecting experiments</p> Source code in <code>niceml/experiments/filters/datefilter.py</code> <pre><code>def __init__(self, days_ago: int = 14, min_shown_exp: int = 5):\n    self.days_ago = days_ago\n    self.selected_values = None\n    self.min_shown_exp = min_shown_exp\n</code></pre>"},{"location":"reference/experiments/filters/datefilter/#niceml.experiments.filters.datefilter.DateFilter-functions","title":"Functions","text":""},{"location":"reference/experiments/filters/datefilter/#niceml.experiments.filters.datefilter.DateFilter.filter","title":"filter","text":"<pre><code>filter(exp_list)\n</code></pre> <p>filters the experiments which are inside the selected date range</p> Source code in <code>niceml/experiments/filters/datefilter.py</code> <pre><code>def filter(self, exp_list: List[ExperimentData]) -&gt; List[ExperimentData]:\n    \"\"\"filters the experiments which are inside the selected date range\"\"\"\n    try:\n        start_date, end_date = self.selected_values\n    except ValueError:\n        start_date = self.selected_values[0]\n        end_date = date.today()\n    date_filtered_list: List[ExperimentData] = []\n    not_included_list: List[ExperimentData] = []\n    for exp_data in exp_list:\n        run_date = exp_data.get_run_date().date()\n        if start_date &lt;= run_date &lt;= end_date:\n            date_filtered_list.append(exp_data)\n        else:\n            not_included_list.append(exp_data)\n    if len(date_filtered_list) &lt; self.min_shown_exp:\n        date_filtered_list += not_included_list[\n            : self.min_shown_exp - len(date_filtered_list)\n        ]\n\n    date_filtered_list = sorted(\n        date_filtered_list, key=lambda x: x.get_run_id(), reverse=True\n    )\n    return date_filtered_list\n</code></pre>"},{"location":"reference/experiments/filters/datefilter/#niceml.experiments.filters.datefilter.DateFilter.render","title":"render","text":"<pre><code>render(exp_list)\n</code></pre> <p>Shows the date selection and stores its values</p> Source code in <code>niceml/experiments/filters/datefilter.py</code> <pre><code>def render(self, exp_list: List[ExperimentData]):\n    \"\"\"Shows the date selection and stores its values\"\"\"\n    start_date = datetime.now() - timedelta(days=self.days_ago)\n    end_date = datetime.now()\n    self.selected_values = st.sidebar.date_input(\n        label=\"date selection\", value=(start_date, end_date)\n    )\n</code></pre>"},{"location":"reference/experiments/filters/experimentfilter/","title":"experimentfilter","text":""},{"location":"reference/experiments/filters/experimentfilter/#niceml.experiments.filters.experimentfilter","title":"experimentfilter","text":"<p>Module for class ExperimentFilter</p>"},{"location":"reference/experiments/filters/experimentfilter/#niceml.experiments.filters.experimentfilter-classes","title":"Classes","text":""},{"location":"reference/experiments/filters/experimentfilter/#niceml.experiments.filters.experimentfilter.ExperimentFilter","title":"ExperimentFilter","text":"<p>             Bases: <code>ABC</code></p> <p>This class allows to filter and render experiments</p>"},{"location":"reference/experiments/filters/experimentfilter/#niceml.experiments.filters.experimentfilter.ExperimentFilter-functions","title":"Functions","text":""},{"location":"reference/experiments/filters/experimentfilter/#niceml.experiments.filters.experimentfilter.ExperimentFilter.filter","title":"filter  <code>abstractmethod</code>","text":"<pre><code>filter(exp_list)\n</code></pre> <p>Filters list and returns left over experiments</p> Source code in <code>niceml/experiments/filters/experimentfilter.py</code> <pre><code>@abstractmethod\ndef filter(self, exp_list: List[ExperimentData]) -&gt; List[ExperimentData]:\n    \"\"\"Filters list and returns left over experiments\"\"\"\n</code></pre>"},{"location":"reference/experiments/filters/experimentfilter/#niceml.experiments.filters.experimentfilter.ExperimentFilter.render","title":"render  <code>abstractmethod</code>","text":"<pre><code>render(exp_list)\n</code></pre> <p>render in streamlit e.g. checkbox or slider</p> Source code in <code>niceml/experiments/filters/experimentfilter.py</code> <pre><code>@abstractmethod\ndef render(self, exp_list: List[ExperimentData]):\n    \"\"\"render in streamlit e.g. checkbox or slider\"\"\"\n</code></pre>"},{"location":"reference/experiments/filters/expselectionfilter/","title":"expselectionfilter","text":""},{"location":"reference/experiments/filters/expselectionfilter/#niceml.experiments.filters.expselectionfilter","title":"expselectionfilter","text":"<p>Module for experiment selection filters</p>"},{"location":"reference/experiments/filters/expselectionfilter/#niceml.experiments.filters.expselectionfilter-classes","title":"Classes","text":""},{"location":"reference/experiments/filters/expselectionfilter/#niceml.experiments.filters.expselectionfilter.ExpCheckboxSelectionFilter","title":"ExpCheckboxSelectionFilter","text":"<pre><code>ExpCheckboxSelectionFilter(default_selected=3)\n</code></pre> <p>             Bases: <code>ExperimentFilter</code></p> <p>Filters experiments with checkboxes</p> Source code in <code>niceml/experiments/filters/expselectionfilter.py</code> <pre><code>def __init__(self, default_selected: int = 3):\n    self.default_selected = default_selected\n</code></pre>"},{"location":"reference/experiments/filters/expselectionfilter/#niceml.experiments.filters.expselectionfilter.ExpCheckboxSelectionFilter-functions","title":"Functions","text":""},{"location":"reference/experiments/filters/expselectionfilter/#niceml.experiments.filters.expselectionfilter.ExpCheckboxSelectionFilter.filter","title":"filter","text":"<pre><code>filter(exp_list)\n</code></pre> <p>Filters experiments with checkboxes</p> Source code in <code>niceml/experiments/filters/expselectionfilter.py</code> <pre><code>def filter(self, exp_list: List[ExperimentData]) -&gt; List[ExperimentData]:\n    \"\"\"Filters experiments with checkboxes\"\"\"\n    exp_out_list: List[ExperimentData] = []\n    st.sidebar.markdown(\"Experiments:\")\n    for idx, exp_data in enumerate(exp_list):\n        if st.sidebar.checkbox(\n            exp_format_func(exp_data), value=(idx &lt; self.default_selected)\n        ):\n            exp_out_list.append(exp_data)\n    return exp_out_list\n</code></pre>"},{"location":"reference/experiments/filters/expselectionfilter/#niceml.experiments.filters.expselectionfilter.ExpCheckboxSelectionFilter.render","title":"render","text":"<pre><code>render(exp_list)\n</code></pre> <p>Not required because experiments should be filtered at the end</p> Source code in <code>niceml/experiments/filters/expselectionfilter.py</code> <pre><code>def render(self, exp_list: List[ExperimentData]):\n    \"\"\"Not required because experiments should be filtered at the end\"\"\"\n    pass\n</code></pre>"},{"location":"reference/experiments/filters/expselectionfilter/#niceml.experiments.filters.expselectionfilter.ExpMultiSelectFilter","title":"ExpMultiSelectFilter","text":"<pre><code>ExpMultiSelectFilter(default_selected=3)\n</code></pre> <p>             Bases: <code>ExperimentFilter</code></p> <p>Filters experiments with multiselect</p> Source code in <code>niceml/experiments/filters/expselectionfilter.py</code> <pre><code>def __init__(self, default_selected: int = 3):\n    self.default_selected = default_selected\n</code></pre>"},{"location":"reference/experiments/filters/expselectionfilter/#niceml.experiments.filters.expselectionfilter.ExpMultiSelectFilter-functions","title":"Functions","text":""},{"location":"reference/experiments/filters/expselectionfilter/#niceml.experiments.filters.expselectionfilter.ExpMultiSelectFilter.filter","title":"filter","text":"<pre><code>filter(exp_list)\n</code></pre> <p>Filters experiments with multiselect</p> Source code in <code>niceml/experiments/filters/expselectionfilter.py</code> <pre><code>def filter(self, exp_list: List[ExperimentData]) -&gt; List[ExperimentData]:\n    \"\"\"Filters experiments with multiselect\"\"\"\n    id_dict = {exp_format_func(x): x for x in exp_list}\n    id_list = list(id_dict.keys())\n    default_values = id_list[: self.default_selected]\n    selects = st.sidebar.multiselect(\n        label=\"Experiments\", options=id_list, default=default_values\n    )\n    return [id_dict[cur_id] for cur_id in selects]\n</code></pre>"},{"location":"reference/experiments/filters/expselectionfilter/#niceml.experiments.filters.expselectionfilter.ExpMultiSelectFilter.render","title":"render","text":"<pre><code>render(exp_list)\n</code></pre> <p>Not required because experiments should be filtered at the end</p> Source code in <code>niceml/experiments/filters/expselectionfilter.py</code> <pre><code>def render(self, exp_list: List[ExperimentData]):\n    \"\"\"Not required because experiments should be filtered at the end\"\"\"\n    pass\n</code></pre>"},{"location":"reference/experiments/filters/expselectionfilter/#niceml.experiments.filters.expselectionfilter-functions","title":"Functions","text":""},{"location":"reference/experiments/filters/expselectionfilter/#niceml.experiments.filters.expselectionfilter.exp_format_func","title":"exp_format_func","text":"<pre><code>exp_format_func(exp_data)\n</code></pre> <p>default formatting for experiments in the dashboard</p> Source code in <code>niceml/experiments/filters/expselectionfilter.py</code> <pre><code>def exp_format_func(exp_data: ExperimentData) -&gt; str:\n    \"\"\"default formatting for experiments in the dashboard\"\"\"\n    out_str: str = (\n        f\"{exp_data.exp_info.experiment_prefix}-\"\n        f\"{exp_data.get_short_id()}-{exp_data.get_run_date().date()}\"\n    )\n    return out_str\n</code></pre>"},{"location":"reference/experiments/filters/selectboxfilter/","title":"selectboxfilter","text":""},{"location":"reference/experiments/filters/selectboxfilter/#niceml.experiments.filters.selectboxfilter","title":"selectboxfilter","text":"<p>Module for selectboxfilter</p>"},{"location":"reference/experiments/filters/selectboxfilter/#niceml.experiments.filters.selectboxfilter-classes","title":"Classes","text":""},{"location":"reference/experiments/filters/selectboxfilter/#niceml.experiments.filters.selectboxfilter.SelectBoxFilter","title":"SelectBoxFilter","text":"<pre><code>SelectBoxFilter(\n    meta_function, default=None, allow_all=True\n)\n</code></pre> <p>             Bases: <code>ExperimentFilter</code></p> <p>Filters experiments for a specific value</p> Source code in <code>niceml/experiments/filters/selectboxfilter.py</code> <pre><code>def __init__(\n    self,\n    meta_function: MetaFunction,\n    default: Optional[str] = None,\n    allow_all: bool = True,\n):\n    self.meta_function = meta_function\n    self.selected_value = None\n    self.allow_all = allow_all\n    self.default = default\n</code></pre>"},{"location":"reference/experiments/filters/selectboxfilter/#niceml.experiments.filters.selectboxfilter.SelectBoxFilter-functions","title":"Functions","text":""},{"location":"reference/experiments/filters/selectboxfilter/#niceml.experiments.filters.selectboxfilter.SelectBoxFilter.filter","title":"filter","text":"<pre><code>filter(exp_list)\n</code></pre> <p>filters experiments according to the settings</p> Source code in <code>niceml/experiments/filters/selectboxfilter.py</code> <pre><code>def filter(self, exp_list: List[ExperimentData]) -&gt; List[ExperimentData]:\n    \"\"\"filters experiments according to the settings\"\"\"\n    if self.allow_all and self.selected_value == SHOW_ALL_KEY:\n        return exp_list\n    return [\n        exp for exp in exp_list if self.selected_value == self.meta_function(exp)\n    ]\n</code></pre>"},{"location":"reference/experiments/filters/selectboxfilter/#niceml.experiments.filters.selectboxfilter.SelectBoxFilter.render","title":"render","text":"<pre><code>render(exp_list)\n</code></pre> <p>renders the component in the streamlit sidebar and stores the selected result</p> Source code in <code>niceml/experiments/filters/selectboxfilter.py</code> <pre><code>def render(self, exp_list: List[ExperimentData]):\n    \"\"\"\n    renders the component in the streamlit sidebar and\n    stores the selected result\n    \"\"\"\n    values = list(set((self.meta_function(exp) for exp in exp_list)))\n    if self.allow_all:\n        values = [SHOW_ALL_KEY] + values\n    index: int = 0\n    if self.default is not None:\n        if self.default in values:\n            index = values.index(self.default)\n        else:\n            logging.getLogger(__name__).warning(\n                f\"Default cannot be find: {self.default} \"\n                f\"in {self.meta_function.get_name()}\"\n            )\n    self.selected_value = st.sidebar.selectbox(\n        self.meta_function.get_name(), values, index=index\n    )\n</code></pre>"},{"location":"reference/experiments/filters/sliderfilter/","title":"sliderfilter","text":""},{"location":"reference/experiments/filters/sliderfilter/#niceml.experiments.filters.sliderfilter","title":"sliderfilter","text":"<p>Module contains the filter with a slider</p>"},{"location":"reference/experiments/filters/sliderfilter/#niceml.experiments.filters.sliderfilter-classes","title":"Classes","text":""},{"location":"reference/experiments/filters/sliderfilter/#niceml.experiments.filters.sliderfilter.SliderFilter","title":"SliderFilter","text":"<pre><code>SliderFilter(\n    meta_function,\n    default_min=None,\n    default_max=None,\n    mode=\"min\",\n)\n</code></pre> <p>             Bases: <code>ExperimentFilter</code></p> <p>Filter for experiments which uses a slider</p> Source code in <code>niceml/experiments/filters/sliderfilter.py</code> <pre><code>def __init__(\n    self,\n    meta_function: MetaFunction,\n    default_min: Optional[Any] = None,\n    default_max: Optional[Any] = None,\n    mode: str = \"min\",\n):\n    super().__init__()\n    self.meta_function = meta_function\n    self.default_min = default_min\n    self.default_max = default_max\n    self.mode = mode\n    self.selected_value = None\n    if self.mode not in MODE_STR:\n        raise UnsupportedModeError(\n            f\"Mode: {self.mode}\" f\"is not supported!\" f\"Supported modes: {MODE_STR}\"\n        )\n</code></pre>"},{"location":"reference/experiments/filters/sliderfilter/#niceml.experiments.filters.sliderfilter.SliderFilter-functions","title":"Functions","text":""},{"location":"reference/experiments/filters/sliderfilter/#niceml.experiments.filters.sliderfilter.SliderFilter.filter","title":"filter","text":"<pre><code>filter(exp_list)\n</code></pre> <p>filters experiments according to the settings</p> Source code in <code>niceml/experiments/filters/sliderfilter.py</code> <pre><code>def filter(self, exp_list: List[ExperimentData]) -&gt; List[ExperimentData]:\n    \"\"\"filters experiments according to the settings\"\"\"\n    out_exp_list: List[ExperimentData] = []\n    for exp_data in exp_list:\n        val = self.meta_function(exp_data)\n        if self.mode == MODE_STR[0] and self.selected_value &lt;= val:\n            out_exp_list.append(exp_data)\n        elif self.mode == MODE_STR[1] and self.selected_value &gt;= val:\n            out_exp_list.append(exp_data)\n        elif self.mode == MODE_STR[2]:\n            sel_min, sel_max = self.selected_value\n            if sel_min &lt;= val &lt;= sel_max:\n                out_exp_list.append(exp_data)\n\n    return out_exp_list\n</code></pre>"},{"location":"reference/experiments/filters/sliderfilter/#niceml.experiments.filters.sliderfilter.SliderFilter.render","title":"render","text":"<pre><code>render(exp_list)\n</code></pre> <p>renders the component in the streamlit sidebar and stores the selected result</p> Source code in <code>niceml/experiments/filters/sliderfilter.py</code> <pre><code>def render(self, exp_list: List[ExperimentData]):\n    \"\"\"renders the component in the streamlit sidebar\n    and stores the selected result\"\"\"\n    values = [self.meta_function(exp_data) for exp_data in exp_list]\n    min_value = min(values)\n    if self.default_min is not None:\n        min_value = min(min_value, self.default_min)\n    max_value = max(values)\n    if self.default_max is not None:\n        max_value = max(max_value, self.default_max)\n    if self.mode == MODE_STR[0]:\n        value = min_value\n    elif self.mode == MODE_STR[1]:\n        value = max_value\n    else:\n        value = (min_value, max_value)\n    self.selected_value = st.sidebar.slider(\n        label=self.meta_function.get_name(),\n        min_value=min_value,\n        max_value=max_value,\n        value=value,\n    )\n</code></pre>"},{"location":"reference/experiments/filters/sliderfilter/#niceml.experiments.filters.sliderfilter.UnsupportedModeError","title":"UnsupportedModeError","text":"<p>             Bases: <code>Exception</code></p> <p>Error when the mode is not supported</p>"},{"location":"reference/experiments/schemas/__init__/","title":"schemas","text":""},{"location":"reference/experiments/schemas/__init__/#niceml.experiments.schemas","title":"schemas","text":""},{"location":"reference/experiments/schemas/baseexpschema/","title":"baseexpschema","text":""},{"location":"reference/experiments/schemas/baseexpschema/#niceml.experiments.schemas.baseexpschema","title":"baseexpschema","text":"<p>Module containing the base experiment schema</p>"},{"location":"reference/experiments/schemas/baseexpschema/#niceml.experiments.schemas.baseexpschema-classes","title":"Classes","text":""},{"location":"reference/experiments/schemas/baseexpschema/#niceml.experiments.schemas.baseexpschema.BaseExperimentSchema","title":"BaseExperimentSchema","text":"<p>base experiment schema for subclassing</p>"},{"location":"reference/experiments/schemas/defaultexpschema/","title":"defaultexpschema","text":""},{"location":"reference/experiments/schemas/defaultexpschema/#niceml.experiments.schemas.defaultexpschema","title":"defaultexpschema","text":"<p>Module containing the default experiment schema</p>"},{"location":"reference/experiments/schemas/defaultexpschema/#niceml.experiments.schemas.defaultexpschema-classes","title":"Classes","text":""},{"location":"reference/experiments/schemas/defaultexpschema/#niceml.experiments.schemas.defaultexpschema.DefaultExperimentSchema","title":"DefaultExperimentSchema","text":"<p>             Bases: <code>BaseExperimentSchema</code></p> <p>default experiment schema for subclassing</p>"},{"location":"reference/experiments/schemas/expdocstring/","title":"expdocstring","text":""},{"location":"reference/experiments/schemas/expdocstring/#niceml.experiments.schemas.expdocstring","title":"expdocstring","text":"<p>Module for the experiment_docstring</p>"},{"location":"reference/experiments/schemas/expdocstring/#niceml.experiments.schemas.expdocstring-classes","title":"Classes","text":""},{"location":"reference/experiments/schemas/expdocstring/#niceml.experiments.schemas.expdocstring-functions","title":"Functions","text":""},{"location":"reference/experiments/schemas/expdocstring/#niceml.experiments.schemas.expdocstring.experiment_docstring","title":"experiment_docstring","text":"<pre><code>experiment_docstring(cls)\n</code></pre> <p>extends the docstring of a experiment class with its attributes</p> Source code in <code>niceml/experiments/schemas/expdocstring.py</code> <pre><code>def experiment_docstring(cls):\n    \"\"\"extends the docstring of a experiment class with its attributes\"\"\"\n    cur_doc: str = cls.__doc__ or \"\"\n    cur_doc = f\"{cls.__name__}\\n{'#'*len(cls.__name__)}\\n\\n\" + cur_doc + \"\\n\\n\"\n    exp_member_list: List[ExpMember] = get_expmembers_from_class(cls)\n    for member in sorted(exp_member_list):\n        cur_doc += f\"{member.get_docstring()}\\n\\n\"\n    cls.__doc__ = cur_doc\n    return cls\n</code></pre>"},{"location":"reference/experiments/schemas/expmember/","title":"expmember","text":""},{"location":"reference/experiments/schemas/expmember/#niceml.experiments.schemas.expmember","title":"expmember","text":"<p>Module for a base ExpMember</p>"},{"location":"reference/experiments/schemas/expmember/#niceml.experiments.schemas.expmember-classes","title":"Classes","text":""},{"location":"reference/experiments/schemas/expmember/#niceml.experiments.schemas.expmember.ExpMember","title":"ExpMember  <code>dataclass</code>","text":"<p>ExpMember class to describe and validate experiments</p>"},{"location":"reference/experiments/schemas/expmember/#niceml.experiments.schemas.expmember.ExpMember-functions","title":"Functions","text":""},{"location":"reference/experiments/schemas/expmember/#niceml.experiments.schemas.expmember.ExpMember.__lt__","title":"__lt__","text":"<pre><code>__lt__(other)\n</code></pre> <p>ExpMembers without folders come first otherwise sort after name</p> Source code in <code>niceml/experiments/schemas/expmember.py</code> <pre><code>def __lt__(self, other):\n    \"\"\"ExpMembers without folders come first\n    otherwise sort after name\"\"\"\n    own_paths = self.path.rsplit(\"/\", maxsplit=1)\n    other_paths = other.path.rsplit(\"/\", maxsplit=1)\n    if len(own_paths) &lt; len(other_paths):\n        return True\n    if len(own_paths) &gt; len(other_paths):\n        return False\n    return self.path &lt; other.path\n</code></pre>"},{"location":"reference/experiments/schemas/expmember/#niceml.experiments.schemas.expmember.ExpMember.get_docstring","title":"get_docstring","text":"<pre><code>get_docstring()\n</code></pre> <p>Returns a docstring for an ExpMember</p> Source code in <code>niceml/experiments/schemas/expmember.py</code> <pre><code>def get_docstring(self) -&gt; str:\n    \"\"\"Returns a docstring for an ExpMember\"\"\"\n    doc_str = f\"**File:** ``{self.path}``\\n\\n\"\n    doc_str += f\":type: {self.member_type}\\n\"\n    doc_str += f\":required: {self.required}\\n\"\n    doc_str += f\":description: {self.description}\\n\"\n    return doc_str\n</code></pre>"},{"location":"reference/experiments/schemas/expmember/#niceml.experiments.schemas.expmember.ExpMember.validate","title":"validate","text":"<pre><code>validate(exp_data)\n</code></pre> <p>validates the experiment given the ExperimentData</p> Source code in <code>niceml/experiments/schemas/expmember.py</code> <pre><code>def validate(self, exp_data: ExperimentData) -&gt; bool:\n    \"\"\"validates the experiment given the ExperimentData\"\"\"\n    return self.path in exp_data.all_exp_files\n</code></pre>"},{"location":"reference/experiments/schemas/expmember/#niceml.experiments.schemas.expmember.FolderMember","title":"FolderMember","text":"<pre><code>FolderMember(\n    path,\n    required,\n    description,\n    min_required_files=0,\n    extensions=None,\n)\n</code></pre> <p>             Bases: <code>ExpMember</code></p> <p>This member is a folder containing arbitrary files with specific extensions</p> <p>Initialize a member that is a folder containing arbitrary files with specific extensions</p> Source code in <code>niceml/experiments/schemas/expmember.py</code> <pre><code>def __init__(  # ruff: noqa: PLR0913\n    self,\n    path: str,\n    required: bool,\n    description: str,\n    min_required_files: int = 0,\n    extensions: Optional[List[str]] = None,\n):\n    \"\"\"Initialize a member that is a folder containing arbitrary files\n    with specific extensions\"\"\"\n\n    super().__init__(\n        path=path, required=required, description=description, member_type=\"folder\"\n    )\n    self.min_required_files = min_required_files\n    self.extensions = extensions\n</code></pre>"},{"location":"reference/experiments/schemas/expmember/#niceml.experiments.schemas.expmember.FolderMember-functions","title":"Functions","text":""},{"location":"reference/experiments/schemas/expmember/#niceml.experiments.schemas.expmember.FolderMember.get_docstring","title":"get_docstring","text":"<pre><code>get_docstring()\n</code></pre> <p>The get_docstring function is used to generate the docstring for an instance of <code>FolderMember</code>. The function takes no arguments and returns a string containing the ReST formatted docstring.</p> <p>Returns:</p> <ul> <li> <code>str</code>         \u2013          <p>A docstring for an instance of <code>FolderMember</code></p> </li> </ul> Source code in <code>niceml/experiments/schemas/expmember.py</code> <pre><code>def get_docstring(self) -&gt; str:\n    \"\"\"\n    The get_docstring function is used to generate the docstring for an instance of\n    `FolderMember`. The function takes no arguments and returns a string\n    containing the ReST formatted docstring.\n\n    Returns:\n        A docstring for an instance of `FolderMember`\n    \"\"\"\n    doc_str = super().get_docstring()\n    doc_str += f\":min_required_files: {self.min_required_files}\\n\"\n    if self.extensions is not None:\n        ext_str = \",\".join(self.extensions)\n        doc_str += f\":extensions: {ext_str}\"\n    return doc_str\n</code></pre>"},{"location":"reference/experiments/schemas/expmember/#niceml.experiments.schemas.expmember.LogCsvMember","title":"LogCsvMember","text":"<pre><code>LogCsvMember()\n</code></pre> <p>             Bases: <code>ExpMember</code></p> <p>Specific member of the experiment containing the train logs</p> <p>Initialize a specific member of the experiment containing the train logs</p> Source code in <code>niceml/experiments/schemas/expmember.py</code> <pre><code>def __init__(self):\n    \"\"\"Initialize a specific member of the experiment containing the train logs\"\"\"\n\n    super().__init__(\n        path=ExperimentFilenames.TRAIN_LOGS,\n        required=True,\n        description=\"This file contains all logs generated during the training\",\n        member_type=\"csv-file\",\n    )\n</code></pre>"},{"location":"reference/experiments/schemas/expmember/#niceml.experiments.schemas.expmember.LogCsvMember-functions","title":"Functions","text":""},{"location":"reference/experiments/schemas/objdetexpschema/","title":"objdetexpschema","text":""},{"location":"reference/experiments/schemas/objdetexpschema/#niceml.experiments.schemas.objdetexpschema","title":"objdetexpschema","text":"<p>Module for object detection experiment schema</p>"},{"location":"reference/experiments/schemas/objdetexpschema/#niceml.experiments.schemas.objdetexpschema-classes","title":"Classes","text":""},{"location":"reference/experiments/schemas/objdetexpschema/#niceml.experiments.schemas.objdetexpschema.ObjDetExpSchema","title":"ObjDetExpSchema","text":"<p>             Bases: <code>DefaultExperimentSchema</code></p> <p>This is the experiment for object detection</p>"},{"location":"reference/experiments/schemas/parquetframeexpmember/","title":"parquetframeexpmember","text":""},{"location":"reference/experiments/schemas/parquetframeexpmember/#niceml.experiments.schemas.parquetframeexpmember","title":"parquetframeexpmember","text":"<p>Module for parquetexpmember</p>"},{"location":"reference/experiments/schemas/parquetframeexpmember/#niceml.experiments.schemas.parquetframeexpmember-classes","title":"Classes","text":""},{"location":"reference/experiments/schemas/parquetframeexpmember/#niceml.experiments.schemas.parquetframeexpmember.ParquetMember","title":"ParquetMember","text":"<pre><code>ParquetMember(path, required, description, df_schema=None)\n</code></pre> <p>             Bases: <code>ExpMember</code></p> <p>parquet-file which is member of the experiment</p> Source code in <code>niceml/experiments/schemas/parquetframeexpmember.py</code> <pre><code>def __init__(\n    self,\n    path: str,\n    required: bool,\n    description: str,\n    df_schema: Optional[pa.DataFrameSchema] = None,\n):\n    super().__init__(\n        path=path,\n        required=required,\n        description=description,\n        member_type=\"parquet-file\",\n    )\n    self.df_schema: Optional[pa.DataFrameSchema] = df_schema\n</code></pre>"},{"location":"reference/experiments/schemas/sampleexpschemas/","title":"sampleexpschemas","text":""},{"location":"reference/experiments/schemas/sampleexpschemas/#niceml.experiments.schemas.sampleexpschemas","title":"sampleexpschemas","text":"<p>Module containing classes which describe the sample experiments</p>"},{"location":"reference/experiments/schemas/sampleexpschemas/#niceml.experiments.schemas.sampleexpschemas-classes","title":"Classes","text":""},{"location":"reference/experiments/schemas/sampleexpschemas/#niceml.experiments.schemas.sampleexpschemas.NumRegExpSchema","title":"NumRegExpSchema","text":"<p>             Bases: <code>DefaultExperimentSchema</code></p> <p>This is the experiment for regression</p>"},{"location":"reference/experiments/schemas/schemalist/","title":"schemalist","text":""},{"location":"reference/experiments/schemas/schemalist/#niceml.experiments.schemas.schemalist","title":"schemalist","text":"<p>Module to get all exp schemas</p>"},{"location":"reference/experiments/schemas/schemalist/#niceml.experiments.schemas.schemalist-classes","title":"Classes","text":""},{"location":"reference/experiments/schemas/schemalist/#niceml.experiments.schemas.schemalist-functions","title":"Functions","text":""},{"location":"reference/experiments/schemas/schemalist/#niceml.experiments.schemas.schemalist.get_all_schemas","title":"get_all_schemas","text":"<pre><code>get_all_schemas()\n</code></pre> <p>Returns a list of all exp schemas</p> Source code in <code>niceml/experiments/schemas/schemalist.py</code> <pre><code>def get_all_schemas():\n    \"\"\"Returns a list of all exp schemas\"\"\"\n    return [BaseExperimentSchema, NumRegExpSchema, ObjDetExpSchema]\n</code></pre>"},{"location":"reference/experiments/schemas/schemavalidation/","title":"schemavalidation","text":""},{"location":"reference/experiments/schemas/schemavalidation/#niceml.experiments.schemas.schemavalidation","title":"schemavalidation","text":"<p>Module for the validating schemas</p>"},{"location":"reference/experiments/schemas/schemavalidation/#niceml.experiments.schemas.schemavalidation-classes","title":"Classes","text":""},{"location":"reference/experiments/schemas/schemavalidation/#niceml.experiments.schemas.schemavalidation-functions","title":"Functions","text":""},{"location":"reference/experiments/schemas/schemavalidation/#niceml.experiments.schemas.schemavalidation.get_expmembers_from_class","title":"get_expmembers_from_class","text":"<pre><code>get_expmembers_from_class(cls)\n</code></pre> <p>Returns all ExpMember from a given class</p> Source code in <code>niceml/experiments/schemas/schemavalidation.py</code> <pre><code>def get_expmembers_from_class(cls) -&gt; List[ExpMember]:\n    \"\"\"Returns all ExpMember from a given class\"\"\"\n    exp_member_list: List[ExpMember] = [\n        getattr(cls, member_name)\n        for member_name in dir(cls)\n        if isinstance(getattr(cls, member_name), ExpMember)\n    ]\n    return exp_member_list\n</code></pre>"},{"location":"reference/experiments/schemas/schemavalidation/#niceml.experiments.schemas.schemavalidation.validate_schema","title":"validate_schema","text":"<pre><code>validate_schema(exp_data, schema)\n</code></pre> <p>validates the instance with the given schema</p> Source code in <code>niceml/experiments/schemas/schemavalidation.py</code> <pre><code>def validate_schema(exp_data: ExperimentData, schema) -&gt; bool:\n    \"\"\"validates the instance with the given schema\"\"\"\n    exp_member_list: List[ExpMember] = get_expmembers_from_class(schema)\n    is_valid_list = [x.validate(exp_data) for x in exp_member_list]\n    return all(is_valid_list)\n</code></pre>"},{"location":"reference/experiments/schemas/yamlexpmember/","title":"yamlexpmember","text":""},{"location":"reference/experiments/schemas/yamlexpmember/#niceml.experiments.schemas.yamlexpmember","title":"yamlexpmember","text":"<p>Module for yaml exp members</p>"},{"location":"reference/experiments/schemas/yamlexpmember/#niceml.experiments.schemas.yamlexpmember-classes","title":"Classes","text":""},{"location":"reference/experiments/schemas/yamlexpmember/#niceml.experiments.schemas.yamlexpmember.ExpInfoMember","title":"ExpInfoMember","text":"<pre><code>ExpInfoMember()\n</code></pre> <p>             Bases: <code>YamlMember</code></p> <p>Specific member of the experiment containing the experiment info</p> <p>Constructor of ExpInfoMember</p> Source code in <code>niceml/experiments/schemas/yamlexpmember.py</code> <pre><code>def __init__(self):\n    \"\"\"Constructor of ExpInfoMember\"\"\"\n    short_id_len = 4\n    run_id_len = 24\n    exp_schema = schema.Schema(\n        {\n            envc.EXP_NAME_KEY: str,\n            envc.ENVIRONMENT_KEY: dict,\n            envc.DESCRIPTION_KEY: str,\n            envc.EXP_PREFIX_KEY: str,\n            envc.SHORT_ID_KEY: lambda val: isinstance(val, str)\n            and len(val) == short_id_len,\n            envc.RUN_ID_KEY: lambda val: isinstance(val, str)\n            and len(val) == run_id_len,\n            envc.EXP_TYPE_KEY: str,\n            envc.EXP_DIR_KEY: str,\n            schema.Optional(envc.LAST_MODIFIED_KEY): str,\n        }\n    )\n    super().__init__(\n        path=ExperimentFilenames.EXP_INFO,\n        required=True,\n        description=\"This file contains experiment info like id, environment and runtime\",\n        yaml_schema=exp_schema,\n    )\n</code></pre>"},{"location":"reference/experiments/schemas/yamlexpmember/#niceml.experiments.schemas.yamlexpmember.ExpInfoMember-functions","title":"Functions","text":""},{"location":"reference/experiments/schemas/yamlexpmember/#niceml.experiments.schemas.yamlexpmember.YamlMember","title":"YamlMember","text":"<pre><code>YamlMember(path, required, description, yaml_schema=None)\n</code></pre> <p>             Bases: <code>ExpMember</code></p> <p>yaml-file which is member of the experiment</p> <p>Constructor of YamlMember</p> Source code in <code>niceml/experiments/schemas/yamlexpmember.py</code> <pre><code>def __init__(\n    self,\n    path: str,\n    required: bool,\n    description: str,\n    yaml_schema: Optional[schema.Schema] = None,\n):\n    \"\"\"Constructor of YamlMember\"\"\"\n    super().__init__(\n        path=path,\n        required=required,\n        description=description,\n        member_type=\"yaml-file\",\n    )\n    self.yaml_schema: Optional[schema.Schema] = yaml_schema\n</code></pre>"},{"location":"reference/experiments/schemas/yamlexpmember/#niceml.experiments.schemas.yamlexpmember.YamlMember-functions","title":"Functions","text":""},{"location":"reference/experiments/schemas/yamlexpmember/#niceml.experiments.schemas.yamlexpmember.YamlMember.validate","title":"validate","text":"<pre><code>validate(exp_data)\n</code></pre> <p>Validates the yaml file</p> Source code in <code>niceml/experiments/schemas/yamlexpmember.py</code> <pre><code>def validate(self, exp_data: ExperimentData) -&gt; bool:\n    \"\"\"Validates the yaml file\"\"\"\n    result = super().validate(exp_data)\n    val_data = exp_data.get_loaded_yaml(self.path)\n    val_result = self._validate_schema(val_data)\n    return result and val_result\n</code></pre>"},{"location":"reference/filechecksumprocessors/__init__/","title":"filechecksumprocessors","text":""},{"location":"reference/filechecksumprocessors/__init__/#niceml.filechecksumprocessors","title":"filechecksumprocessors","text":""},{"location":"reference/filechecksumprocessors/filechecksumprocessor/","title":"filechecksumprocessor","text":""},{"location":"reference/filechecksumprocessors/filechecksumprocessor/#niceml.filechecksumprocessors.filechecksumprocessor","title":"filechecksumprocessor","text":"<p>Module for abstract implementation of FileChecksumProcessor</p>"},{"location":"reference/filechecksumprocessors/filechecksumprocessor/#niceml.filechecksumprocessors.filechecksumprocessor-classes","title":"Classes","text":""},{"location":"reference/filechecksumprocessors/filechecksumprocessor/#niceml.filechecksumprocessors.filechecksumprocessor.FileChecksumProcessor","title":"FileChecksumProcessor","text":"<pre><code>FileChecksumProcessor(\n    input_location,\n    output_location,\n    lockfile_location,\n    lock_file_name=\"lock.yaml\",\n    debug=False,\n    process_count=8,\n    batch_size=16,\n)\n</code></pre> <p>             Bases: <code>ABC</code></p> <p>FileChecksumProcessor that can be used as part of a pipeline to process files based on the checksum</p> <p>FileChecksumProcessor that can be used as part of a pipeline to process files based on the checksum. Args:     input_location: Input location of the Processor     output_location: Output location of the Processor     lockfile_location: Location of the checksum lockfile     debug: Flag to activate the debug mode     process_count: Amount of processes for parallel execution     batch_size: Size of a batch</p> Source code in <code>niceml/filechecksumprocessors/filechecksumprocessor.py</code> <pre><code>def __init__(\n    self,\n    input_location: Union[dict, LocationConfig],\n    output_location: Union[dict, LocationConfig],\n    lockfile_location: Union[dict, LocationConfig],\n    lock_file_name: str = \"lock.yaml\",\n    debug: bool = False,\n    process_count: int = 8,\n    batch_size: int = 16,\n):\n    \"\"\"\n    FileChecksumProcessor that can be used as part of a pipeline to process\n    files based on the checksum.\n    Args:\n        input_location: Input location of the Processor\n        output_location: Output location of the Processor\n        lockfile_location: Location of the checksum lockfile\n        debug: Flag to activate the debug mode\n        process_count: Amount of processes for parallel execution\n        batch_size: Size of a batch\n    \"\"\"\n    self.lock_file_name = lock_file_name\n    self.input_location = input_location\n    self.output_location = output_location\n    self.lockfile_location = lockfile_location\n    self.debug = debug\n    self.process_count = process_count\n    self.lock_data: Dict[str, dict] = defaultdict(dict)\n    self.batch_size = batch_size\n</code></pre>"},{"location":"reference/filechecksumprocessors/filechecksumprocessor/#niceml.filechecksumprocessors.filechecksumprocessor.FileChecksumProcessor-functions","title":"Functions","text":""},{"location":"reference/filechecksumprocessors/filechecksumprocessor/#niceml.filechecksumprocessors.filechecksumprocessor.FileChecksumProcessor.find_changed_files","title":"find_changed_files","text":"<pre><code>find_changed_files(\n    input_file_list, output_file_list, checksum_dict\n)\n</code></pre> <p>Filters input and output files that are not required to be reprocessed</p> Source code in <code>niceml/filechecksumprocessors/filechecksumprocessor.py</code> <pre><code>def find_changed_files(\n    self,\n    input_file_list: List[str],\n    output_file_list: List[str],\n    checksum_dict: Dict[str, Dict[str, str]],\n) -&gt; Dict[str, Dict[str, bool]]:\n    \"\"\"Filters input and output files that are not required to be reprocessed\"\"\"\n    input_files_changed = check_files_changed(\n        self.input_location,\n        input_file_list,\n        checksum_dict[\"inputs\"] if \"inputs\" in checksum_dict else None,\n    )\n    output_files_changed = check_files_changed(\n        self.output_location,\n        output_file_list,\n        checksum_dict[\"outputs\"] if \"outputs\" in checksum_dict else None,\n    )\n\n    return dict(inputs=input_files_changed, outputs=output_files_changed)\n</code></pre>"},{"location":"reference/filechecksumprocessors/filechecksumprocessor/#niceml.filechecksumprocessors.filechecksumprocessor.FileChecksumProcessor.generate_batches","title":"generate_batches  <code>abstractmethod</code>","text":"<pre><code>generate_batches(\n    input_file_list,\n    changed_files_dict,\n    output_file_list=None,\n    force=False,\n)\n</code></pre> <p>Generates batches of input and output files and returns them as a list</p> Source code in <code>niceml/filechecksumprocessors/filechecksumprocessor.py</code> <pre><code>@abstractmethod\ndef generate_batches(\n    self,\n    input_file_list: List[str],\n    changed_files_dict: Dict[str, Dict[str, bool]],\n    output_file_list: Optional[List[str]] = None,\n    force: bool = False,\n) -&gt; List[Any]:\n    \"\"\"Generates batches of input and output files\n    and returns them as a list\"\"\"\n</code></pre>"},{"location":"reference/filechecksumprocessors/filechecksumprocessor/#niceml.filechecksumprocessors.filechecksumprocessor.FileChecksumProcessor.list_files","title":"list_files  <code>abstractmethod</code>","text":"<pre><code>list_files()\n</code></pre> <p>Lists input and output files and returns them as lists of strings</p> Source code in <code>niceml/filechecksumprocessors/filechecksumprocessor.py</code> <pre><code>@abstractmethod\ndef list_files(self) -&gt; Tuple[List[str], List[str]]:\n    \"\"\"Lists input and output files and\n    returns them as lists of strings\"\"\"\n</code></pre>"},{"location":"reference/filechecksumprocessors/filechecksumprocessor/#niceml.filechecksumprocessors.filechecksumprocessor.FileChecksumProcessor.load_checksums","title":"load_checksums","text":"<pre><code>load_checksums()\n</code></pre> <p>Loads checksums from lockfile</p> Source code in <code>niceml/filechecksumprocessors/filechecksumprocessor.py</code> <pre><code>def load_checksums(self) -&gt; Dict[str, Dict[str, str]]:\n    \"\"\"Loads checksums from lockfile\"\"\"\n    with open_location(self.lockfile_location) as (lockfile_fs, lockfile_path):\n        try:\n            checksum_dict = read_yaml(\n                join_fs_path(lockfile_fs, lockfile_path, self.lock_file_name),\n                file_system=lockfile_fs,\n            )\n        except FileNotFoundError:\n            checksum_dict = defaultdict(dict)\n    return checksum_dict\n</code></pre>"},{"location":"reference/filechecksumprocessors/filechecksumprocessor/#niceml.filechecksumprocessors.filechecksumprocessor.FileChecksumProcessor.process","title":"process  <code>abstractmethod</code>","text":"<pre><code>process(batch)\n</code></pre> <p>Processes a batch of files. Returns a dict of input and output files with the updated checksums e.g. {\"inputs\":{\"filename\":\"checksum\"}, \"outputs\":{\"filename\":\"checksum\"}}</p> Source code in <code>niceml/filechecksumprocessors/filechecksumprocessor.py</code> <pre><code>@abstractmethod\ndef process(self, batch: Any) -&gt; Dict[str, Any]:\n    \"\"\"\n    Processes a batch of files.\n    Returns a dict of input and output files with the updated checksums\n    e.g. {\"inputs\":{\"filename\":\"checksum\"}, \"outputs\":{\"filename\":\"checksum\"}}\n    \"\"\"\n</code></pre>"},{"location":"reference/filechecksumprocessors/filechecksumprocessor/#niceml.filechecksumprocessors.filechecksumprocessor.FileChecksumProcessor.remove_not_required_outputs","title":"remove_not_required_outputs","text":"<pre><code>remove_not_required_outputs(output_file_list)\n</code></pre> <p>Removes output files that are not required anymore</p> Source code in <code>niceml/filechecksumprocessors/filechecksumprocessor.py</code> <pre><code>def remove_not_required_outputs(self, output_file_list: List[str]) -&gt; None:\n    \"\"\"Removes output files that are not required anymore\"\"\"\n    with open_location(self.output_location) as (output_fs, output_root):\n        files_in_output_location = list_dir(path=output_root, file_system=output_fs)\n        files_in_output_location = [\n            join_fs_path(output_fs, output_root, output_file)\n            for output_file in files_in_output_location\n        ]\n        file_diff = list(set(files_in_output_location) - set(output_file_list))\n        for file in file_diff:\n            output_fs.rm_file(join_fs_path(output_fs, output_root, file))\n</code></pre>"},{"location":"reference/filechecksumprocessors/filechecksumprocessor/#niceml.filechecksumprocessors.filechecksumprocessor.FileChecksumProcessor.run_process","title":"run_process","text":"<pre><code>run_process(force=False)\n</code></pre> <p>Processes files</p> Source code in <code>niceml/filechecksumprocessors/filechecksumprocessor.py</code> <pre><code>def run_process(self, force: bool = False) -&gt; None:\n    \"\"\"Processes files\"\"\"\n    checksum_dict = self.load_checksums()\n    input_file_list, output_file_list = self.list_files()\n\n    self.remove_not_required_outputs(output_file_list)\n    checksum_dict = remove_deleted_checksums(\n        input_file_list=input_file_list,\n        output_file_list=output_file_list,\n        checksum_dict=checksum_dict,\n    )\n\n    changed_files_dict = (\n        self.find_changed_files(  # TODO right place or better in line 82\n            input_file_list, output_file_list, checksum_dict\n        )\n    )\n\n    processing_list = self.generate_batches(\n        input_file_list, changed_files_dict, force=force\n    )\n\n    def _process_result(result, index: int):\n        if result is not None:\n            self.lock_data = deep_update(self.lock_data, result)\n        if (index % 10 == 0) or (len(processing_list) == (index + 1)):\n            with open_location(self.lockfile_location) as (\n                lockfile_fs,\n                lockfile_root,\n            ):\n                write_yaml(\n                    dict(self.lock_data),\n                    join_fs_path(lockfile_fs, lockfile_root, self.lock_file_name),\n                    file_system=lockfile_fs,\n                )\n\n    if self.debug:\n        for idx, batch in enumerate(processing_list):\n            process_result = self.process(batch)\n            _process_result(process_result, idx)\n    else:\n        with Pool(self.process_count) as pool:\n            for idx, process_result in enumerate(\n                tqdm(\n                    pool.imap_unordered(self.process, processing_list),\n                    total=len(processing_list),\n                    desc=\"Process batches\",\n                )\n            ):\n                _process_result(process_result, idx)\n</code></pre>"},{"location":"reference/filechecksumprocessors/filechecksumprocessor/#niceml.filechecksumprocessors.filechecksumprocessor-functions","title":"Functions","text":""},{"location":"reference/filechecksumprocessors/filechecksumprocessor/#niceml.filechecksumprocessors.filechecksumprocessor.check_files_changed","title":"check_files_changed","text":"<pre><code>check_files_changed(\n    location, file_list, checksum_dict=None\n)\n</code></pre> <p>Checks if files in a location have changed</p> Source code in <code>niceml/filechecksumprocessors/filechecksumprocessor.py</code> <pre><code>def check_files_changed(\n    location: Union[dict, LocationConfig],\n    file_list: List[str],\n    checksum_dict: Optional[Dict[str, str]] = None,\n) -&gt; Dict[str, bool]:\n    \"\"\"Checks if files in a location have changed\"\"\"\n    changed_checksums_dict = {}\n    with open_location(location) as (location_fs, location_root):\n        for file_path in file_list:\n            if checksum_dict is not None:\n                if file_path in checksum_dict.keys():\n                    if (\n                        md5_from_file(file_path=file_path, file_system=location_fs)\n                        == checksum_dict[file_path]\n                    ):\n                        changed_checksums_dict[file_path] = False\n                        continue\n\n            changed_checksums_dict[file_path] = True\n\n    return changed_checksums_dict\n</code></pre>"},{"location":"reference/filechecksumprocessors/filechecksumprocessor/#niceml.filechecksumprocessors.filechecksumprocessor.remove_deleted_checksums","title":"remove_deleted_checksums","text":"<pre><code>remove_deleted_checksums(\n    input_file_list, output_file_list, checksum_dict\n)\n</code></pre> <p>Takes in a list of input files, a list of output files, and a dictionary containing the checksums for all the files. It returns an updated version of that dictionary with only those keys corresponding to either input or output file names.</p> <p>Parameters:</p> <ul> <li> <code>input_file_list</code>             (<code>List[str]</code>)         \u2013          <p>List[str]: Specify the input files</p> </li> <li> <code>output_file_list</code>             (<code>List[str]</code>)         \u2013          <p>List[str]: Specify the output files</p> </li> <li> <code>checksum_dict</code>             (<code>Dict[str, Dict[str, str]]</code>)         \u2013          <p>Dict[str,Dict[str,str]]: Dictionary with the checksums             of the input and output files</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dict[str, Dict[str, str]]</code>         \u2013          <p>A dictionary of dictionaries with the updated checksums of the input and output files</p> </li> </ul> Source code in <code>niceml/filechecksumprocessors/filechecksumprocessor.py</code> <pre><code>def remove_deleted_checksums(\n    input_file_list: List[str],\n    output_file_list: List[str],\n    checksum_dict: Dict[str, Dict[str, str]],\n) -&gt; Dict[str, Dict[str, str]]:\n    \"\"\"\n    Takes in a list of input files, a list of output files, and\n    a dictionary containing the checksums for all the files. It returns an updated version of that\n    dictionary with only those keys corresponding to either input or output file names.\n\n    Args:\n        input_file_list: List[str]: Specify the input files\n        output_file_list: List[str]: Specify the output files\n        checksum_dict: Dict[str,Dict[str,str]]: Dictionary with the checksums\n                        of the input and output files\n\n    Returns:\n        A dictionary of dictionaries with the updated checksums of the input and output files\n    \"\"\"\n    existing_checksums = defaultdict(dict)\n    existing_checksums[\"inputs\"] = {\n        key: value\n        for key, value in checksum_dict[\"inputs\"].items()\n        if key in input_file_list\n    }\n    existing_checksums[\"outputs\"] = {\n        key: value\n        for key, value in checksum_dict[\"outputs\"].items()\n        if key in output_file_list\n    }\n    return existing_checksums\n</code></pre>"},{"location":"reference/filechecksumprocessors/zippedcsvtoparqprocessor/","title":"zippedcsvtoparqprocessor","text":""},{"location":"reference/filechecksumprocessors/zippedcsvtoparqprocessor/#niceml.filechecksumprocessors.zippedcsvtoparqprocessor","title":"zippedcsvtoparqprocessor","text":"<p>Module for implementation of ZippedCsvToParqProcessor</p>"},{"location":"reference/filechecksumprocessors/zippedcsvtoparqprocessor/#niceml.filechecksumprocessors.zippedcsvtoparqprocessor-classes","title":"Classes","text":""},{"location":"reference/filechecksumprocessors/zippedcsvtoparqprocessor/#niceml.filechecksumprocessors.zippedcsvtoparqprocessor.ZippedCsvToParqProcessor","title":"ZippedCsvToParqProcessor","text":"<pre><code>ZippedCsvToParqProcessor(\n    input_location,\n    output_location,\n    lockfile_location,\n    lock_file_name=\"lock.yaml\",\n    debug=False,\n    process_count=8,\n    batch_size=16,\n    csv_seperator=\";\",\n    clear=False,\n    recursive=False,\n)\n</code></pre> <p>             Bases: <code>FileChecksumProcessor</code></p> <p>Implementation of a FileChecksumProcessor to convert zip archives with csv files into parquet files</p> <p>FileChecksumProcessor that can be used as part of a pipeline to process files based on the checksum. Args:     input_location: Input location of the Processor     output_location: Output location of the Processor     lockfile_location: Location of the checksum lockfile     debug: Flag to activate the debug mode     process_count: Amount of processes for parallel execution     batch_size: Size of a batch     csv_seperator: Seperator character for the csv files.     clear: Flag to clear the output location when initialize the Processor     recursive: Flag indicating whether the input location should be                 searched for files recursively</p> Source code in <code>niceml/filechecksumprocessors/zippedcsvtoparqprocessor.py</code> <pre><code>def __init__(\n    self,\n    input_location: Union[dict, LocationConfig],\n    output_location: Union[dict, LocationConfig],\n    lockfile_location: Union[dict, LocationConfig],\n    lock_file_name: str = \"lock.yaml\",\n    debug: bool = False,\n    process_count: int = 8,\n    batch_size: int = 16,\n    csv_seperator: str = \";\",\n    clear: bool = False,\n    recursive: bool = False,\n):\n    \"\"\"\n    FileChecksumProcessor that can be used as part of a pipeline to\n    process files based on the checksum.\n    Args:\n        input_location: Input location of the Processor\n        output_location: Output location of the Processor\n        lockfile_location: Location of the checksum lockfile\n        debug: Flag to activate the debug mode\n        process_count: Amount of processes for parallel execution\n        batch_size: Size of a batch\n        csv_seperator: Seperator character for the csv files.\n        clear: Flag to clear the output location when initialize the Processor\n        recursive: Flag indicating whether the input location should be\n                    searched for files recursively\n    \"\"\"\n    super().__init__(\n        input_location=input_location,\n        output_location=output_location,\n        lockfile_location=lockfile_location,\n        debug=debug,\n        process_count=process_count,\n        batch_size=batch_size,\n        lock_file_name=lock_file_name,\n    )\n    self.recursive = recursive\n    self.clear = clear\n    self.csv_seperator = csv_seperator\n\n    if self.clear:\n        clear_folder(self.output_location)\n</code></pre>"},{"location":"reference/filechecksumprocessors/zippedcsvtoparqprocessor/#niceml.filechecksumprocessors.zippedcsvtoparqprocessor.ZippedCsvToParqProcessor-functions","title":"Functions","text":""},{"location":"reference/filechecksumprocessors/zippedcsvtoparqprocessor/#niceml.filechecksumprocessors.zippedcsvtoparqprocessor.ZippedCsvToParqProcessor.generate_batches","title":"generate_batches","text":"<pre><code>generate_batches(\n    input_file_list,\n    changed_files_dict,\n    output_file_list=None,\n    force=False,\n)\n</code></pre> <p>The generate_batches function is responsible for generating a list of batches, where each batch is a dictionary with <code>inputs</code> as a key, followed by a list of file paths</p> <p>Parameters:</p> <ul> <li> <code>input_file_list</code>             (<code>List[str]</code>)         \u2013          <p>List[str]: A list of input file names</p> </li> <li> <code>changed_files_dict</code>             (<code>Dict[str, Dict[str, bool]]</code>)         \u2013          <p>Dict[str: Dict[str:bool]]: Dictionary with the information</p> </li> <li> <code>output_file_list</code>             (<code>Optional[List[str]]</code>, default:                 <code>None</code> )         \u2013          <p>List[str]: A optional list of output file names</p> </li> <li> <code>force</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>bool: Force the generation of batches even if no files have changed</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>List[Dict[str, List[str]]]</code>         \u2013          <p>A list of batches, each batch is a dictionary with one key <code>inputs</code></p> </li> <li> <code>List[Dict[str, List[str]]]</code>         \u2013          <p>and the value is a list of file paths</p> </li> </ul> Source code in <code>niceml/filechecksumprocessors/zippedcsvtoparqprocessor.py</code> <pre><code>def generate_batches(\n    self,\n    input_file_list: List[str],\n    changed_files_dict: Dict[str, Dict[str, bool]],\n    output_file_list: Optional[List[str]] = None,\n    force: bool = False,\n) -&gt; List[Dict[str, List[str]]]:\n    \"\"\"\n    The generate_batches function is responsible for generating a list of batches,\n    where each batch is a dictionary with `inputs` as a key, followed by a list of file paths\n\n    Args:\n        input_file_list: List[str]: A list of input file names\n        changed_files_dict: Dict[str: Dict[str:bool]]: Dictionary with the information\n        which files have changed\n        output_file_list: List[str]: A optional list of output file names\n        force: bool: Force the generation of batches even if no files have changed\n\n    Returns:\n        A list of batches, each batch is a dictionary with one key `inputs`\n        and the value is a list of file paths\n    \"\"\"\n    if not force:\n        input_file_list = [\n            file_name\n            for file_name, changed in changed_files_dict[\"inputs\"].items()\n            if changed\n        ]\n    batches = []\n    for batch_pos in range(0, len(input_file_list), self.batch_size):\n        batches.append(\n            {\"inputs\": input_file_list[batch_pos : batch_pos + self.batch_size]}\n        )\n    return batches\n</code></pre>"},{"location":"reference/filechecksumprocessors/zippedcsvtoparqprocessor/#niceml.filechecksumprocessors.zippedcsvtoparqprocessor.ZippedCsvToParqProcessor.list_files","title":"list_files","text":"<pre><code>list_files()\n</code></pre> Returns a tuple of two lists <ol> <li>A list of all files in the input location</li> <li>A list of all files in the output location</li> </ol> <p>Returns:</p> <ul> <li> <code>Tuple[List[str], List[str]]</code>         \u2013          <p>A tuple of two lists</p> </li> </ul> Source code in <code>niceml/filechecksumprocessors/zippedcsvtoparqprocessor.py</code> <pre><code>def list_files(self) -&gt; Tuple[List[str], List[str]]:\n    \"\"\"\n    Returns a tuple of two lists:\n        1. A list of all files in the input location\n        2. A list of all files in the output location\n\n    Returns:\n        A tuple of two lists\n    \"\"\"\n    with open_location(self.input_location) as (input_fs, input_path):\n        input_files = list_dir(\n            path=input_path,\n            recursive=self.recursive,\n            file_system=input_fs,\n            filter_ext=[\".zip\"],\n        )\n        input_files = [\n            join_fs_path(input_fs, input_path, input_file)\n            for input_file in input_files\n        ]\n    with open_location(self.output_location) as (output_fs, output_path):\n        output_fs.makedirs(output_path, exist_ok=True)\n        output_files = list_dir(\n            path=output_path,\n            recursive=self.recursive,\n            file_system=output_fs,\n            filter_ext=[\".parq\"],\n        )\n        output_files = [\n            join_fs_path(output_fs, output_path, output_file)\n            for output_file in output_files\n        ]\n\n    return input_files, output_files\n</code></pre>"},{"location":"reference/filechecksumprocessors/zippedcsvtoparqprocessor/#niceml.filechecksumprocessors.zippedcsvtoparqprocessor.ZippedCsvToParqProcessor.process","title":"process","text":"<pre><code>process(batch)\n</code></pre> <p>The process function takes a batch of files and converts them from CSV to Parquet.</p> <p>Parameters:</p> <ul> <li> <code>self</code>         \u2013          <p>Access the class attributes</p> </li> <li> <code>batch</code>             (<code>Dict[str, List[str]]</code>)         \u2013          <p>Dict[str: Pass in the batch of files to be processed</p> </li> <li> <code>List[str]]</code>         \u2013          <p>Pass in the list of files that are to be processed</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dict[str, Dict[str, str]]</code>         \u2013          <p>A dictionary of checksums for each file in <code>self.output_location</code></p> </li> <li> <code>Dict[str, Dict[str, str]]</code>         \u2013          <p>(key = <code>outputs</code>) and <code>self.input_location</code> (key = <code>inputs</code>)</p> </li> </ul> Source code in <code>niceml/filechecksumprocessors/zippedcsvtoparqprocessor.py</code> <pre><code>def process(self, batch: Dict[str, List[str]]) -&gt; Dict[str, Dict[str, str]]:\n    \"\"\"\n    The process function takes a batch of files and converts them from CSV to Parquet.\n\n    Args:\n        self: Access the class attributes\n        batch: Dict[str: Pass in the batch of files to be processed\n        List[str]]: Pass in the list of files that are to be processed\n\n    Returns:\n        A dictionary of checksums for each file in `self.output_location`\n        (key = `outputs`) and `self.input_location` (key = `inputs`)\n    \"\"\"\n    checksums = defaultdict(dict)\n\n    with open_location(self.input_location) as (input_file_system, input_root):\n        for zip_file in tqdm(\n            batch[\"inputs\"], desc=\"Extract zip files of current batch\"\n        ):\n            with input_file_system.open(zip_file) as opened_zip_file:\n                checksums[\"inputs\"][zip_file] = md5_from_file(\n                    file_path=zip_file, file_system=input_file_system\n                )\n\n                zf = zipfile.ZipFile(opened_zip_file)\n                csv_files = zf.namelist()\n                for csv_file in csv_files:\n                    with zf.open(csv_file, mode=\"r\") as opened_csv_file:\n                        df = pd.read_csv(\n                            opened_csv_file,\n                            sep=self.csv_seperator,\n                            low_memory=False,\n                        )\n                    parq_name = basename(splitext(csv_file)[0]) + \".parq\"\n                    output_df_location = join_location_w_path(\n                        self.output_location, parq_name\n                    )\n                    with open_location(output_df_location) as (\n                        output_file_system,\n                        output_df_path,\n                    ):\n                        write_parquet(\n                            df, output_df_path, file_system=output_file_system\n                        )\n                        checksums[\"outputs\"][output_df_path] = md5_from_file(\n                            file_path=output_df_path, file_system=output_file_system\n                        )\n    return checksums\n</code></pre>"},{"location":"reference/filechecksumprocessors/zippedcsvtoparqprocessor/#niceml.filechecksumprocessors.zippedcsvtoparqprocessor-functions","title":"Functions","text":""},{"location":"reference/mkdocs/__init__/","title":"mkdocs","text":""},{"location":"reference/mkdocs/__init__/#niceml.mkdocs","title":"mkdocs","text":""},{"location":"reference/mkdocs/mdgraph/","title":"mdgraph","text":""},{"location":"reference/mkdocs/mdgraph/#niceml.mkdocs.mdgraph","title":"mdgraph","text":"<p>Module for generating a graph in mkdocs</p>"},{"location":"reference/mkdocs/mdgraph/#niceml.mkdocs.mdgraph-functions","title":"Functions","text":""},{"location":"reference/mkdocs/mdgraph/#niceml.mkdocs.mdgraph.get_graph_md","title":"get_graph_md","text":"<pre><code>get_graph_md(job)\n</code></pre> <p>Creates a graph as str with material for mkdocs</p> Source code in <code>niceml/mkdocs/mdgraph.py</code> <pre><code>def get_graph_md(job: JobDefinition) -&gt; str:\n    \"\"\"Creates a graph as str with material for mkdocs\"\"\"\n    deps = job.graph.dependencies\n    graph_str = \"\"\n    for node, node_dependencies in deps.items():\n        for _, dependencies in node_dependencies.items():\n            if isinstance(dependencies, DependencyDefinition):\n                graph_str += f\"  {dependencies.node} --&gt; {node.name};\\n\"\n            elif isinstance(dependencies, MultiDependencyDefinition):\n                for dependency in dependencies.dependencies:\n                    graph_str += f\"  {dependency.node} --&gt; {node.name};\\n\"\n            else:\n                raise AttributeError(\"'dependencies' is not of expected type.\")\n    if len(graph_str) == 0:\n        return \"\"\n\n    graph_str = \"``` mermaid\\ngraph LR\\n\" + graph_str\n    graph_str += \"```\"\n    return graph_str\n</code></pre>"},{"location":"reference/mkdocs/mdjob/","title":"mdjob","text":""},{"location":"reference/mkdocs/mdjob/#niceml.mkdocs.mdjob","title":"mdjob","text":"<p>Module for generating mkdocs str for jobs</p>"},{"location":"reference/mkdocs/mdjob/#niceml.mkdocs.mdjob-functions","title":"Functions","text":""},{"location":"reference/mkdocs/mdjob/#niceml.mkdocs.mdjob.get_job_md","title":"get_job_md","text":"<pre><code>get_job_md(job, include_graph=True)\n</code></pre> <p>creates the job markdown</p> Source code in <code>niceml/mkdocs/mdjob.py</code> <pre><code>def get_job_md(job: JobDefinition, include_graph: bool = True) -&gt; str:\n    \"\"\"creates the job markdown\"\"\"\n    job_md: str = f\"## Job: `{job.name}`\\n\\n\"\n\n    job_md += job.__doc__ + \"\\n\\n\"\n    if include_graph:\n        graph_md = get_graph_md(job)\n        if len(graph_md) &gt; 0:\n            job_md += graph_md + \"\\n\\n\"\n    op_list: List[OpDefinition] = get_ops_from_job(job)\n    for cur_op in op_list:\n        job_md += get_md_op(cur_op)\n\n    return job_md\n</code></pre>"},{"location":"reference/mkdocs/mdjob/#niceml.mkdocs.mdjob.get_ops_from_job","title":"get_ops_from_job","text":"<pre><code>get_ops_from_job(job)\n</code></pre> <p>Returns all ops from job</p> Source code in <code>niceml/mkdocs/mdjob.py</code> <pre><code>def get_ops_from_job(job: JobDefinition) -&gt; List[OpDefinition]:\n    \"\"\"Returns all ops from job\"\"\"\n    return job.all_node_defs\n</code></pre>"},{"location":"reference/mkdocs/mdop/","title":"mdop","text":""},{"location":"reference/mkdocs/mdop/#niceml.mkdocs.mdop","title":"mdop","text":"<p>Module for generating markdown strings for dagster ops</p>"},{"location":"reference/mkdocs/mdop/#niceml.mkdocs.mdop-functions","title":"Functions","text":""},{"location":"reference/mkdocs/mdop/#niceml.mkdocs.mdop.get_md_op","title":"get_md_op","text":"<pre><code>get_md_op(op_def)\n</code></pre> <p>generates markdown strings for dagster ops</p> Source code in <code>niceml/mkdocs/mdop.py</code> <pre><code>def get_md_op(op_def: OpDefinition) -&gt; str:\n    \"\"\"generates markdown strings for dagster ops\"\"\"\n    col_widths: List[int] = [80, 120]\n    op_fields = get_op_fields(op_def)\n    headings: List[str] = [\"ConfigKey\", \"Description\"]\n    cur_md: str = f\"### Op: `{op_def.name}`\\n\\n\"\n    if op_def.description is not None:\n        cur_md += op_def.description + \"\\n\\n\"\n    contents: List[List[str]] = []\n    for config_key in sorted(op_fields):\n        desc = op_fields[config_key].description or \"\"\n        contents.append([f\"`{config_key}`\", desc.replace(\"\\n\", \" \")])\n    cur_md += get_md_table(headings, col_widths, contents)\n    cur_md += \"\\n\\n\"\n    return cur_md\n</code></pre>"},{"location":"reference/mkdocs/mdop/#niceml.mkdocs.mdop.get_op_fields","title":"get_op_fields","text":"<pre><code>get_op_fields(op_def)\n</code></pre> <p>returns fields from OpDefinition</p> Source code in <code>niceml/mkdocs/mdop.py</code> <pre><code>def get_op_fields(op_def: OpDefinition) -&gt; Dict[str, Field]:\n    \"\"\"returns fields from OpDefinition\"\"\"\n    try:\n        return op_def.config_schema.config_type.fields\n    except AttributeError:\n        return dict()\n</code></pre>"},{"location":"reference/mkdocs/mdtable/","title":"mdtable","text":""},{"location":"reference/mkdocs/mdtable/#niceml.mkdocs.mdtable","title":"mdtable","text":"<p>Module for markdowntable</p>"},{"location":"reference/mkdocs/mdtable/#niceml.mkdocs.mdtable-functions","title":"Functions","text":""},{"location":"reference/mkdocs/mdtable/#niceml.mkdocs.mdtable.get_char_line","title":"get_char_line","text":"<pre><code>get_char_line(col_widths, used_char='-')\n</code></pre> <p>Returns one row line with the same char (used_char)</p> Source code in <code>niceml/mkdocs/mdtable.py</code> <pre><code>def get_char_line(col_widths: List[int], used_char: str = \"-\"):\n    \"\"\"Returns one row line with the same char (used_char)\"\"\"\n    assert len(used_char) == 1\n    line: str = \"|\"\n    for cur_col_width in col_widths:\n        line += used_char * (cur_col_width + 2) + \"|\"\n    return line + \"\\n\"\n</code></pre>"},{"location":"reference/mkdocs/mdtable/#niceml.mkdocs.mdtable.get_md_table","title":"get_md_table","text":"<pre><code>get_md_table(headings, col_widths, contents)\n</code></pre> <p>Creates a markdown table as str</p> Source code in <code>niceml/mkdocs/mdtable.py</code> <pre><code>def get_md_table(\n    headings: List[str], col_widths: List[int], contents: List[List[str]]\n) -&gt; str:\n    \"\"\"Creates a markdown table as str\"\"\"\n    table_str = get_table_line(col_widths, headings)\n    table_str += get_char_line(col_widths)\n    for cur_content in contents:\n        table_str += get_table_line(col_widths, cur_content)\n    return table_str\n</code></pre>"},{"location":"reference/mkdocs/mdtable/#niceml.mkdocs.mdtable.get_table_line","title":"get_table_line","text":"<pre><code>get_table_line(col_widths, contents)\n</code></pre> <p>Creates one line in an mdtable</p> Source code in <code>niceml/mkdocs/mdtable.py</code> <pre><code>def get_table_line(col_widths: List[int], contents: List[str]) -&gt; str:\n    \"\"\"Creates one line in an mdtable\"\"\"\n    line: str = \"|\"\n    for index, cur_col_width in enumerate(col_widths):\n        cur_content: str = \"\"\n        if len(contents) &gt; index:\n            cur_content = contents[index]\n        line += (\n            \" \"\n            + cur_content[:cur_col_width]\n            + \" \" * max(0, cur_col_width - len(cur_content))\n            + \" |\"\n        )\n    return line + \"\\n\"\n</code></pre>"},{"location":"reference/mkdocs/schemadocgeneration/","title":"schemadocgeneration","text":""},{"location":"reference/mkdocs/schemadocgeneration/#niceml.mkdocs.schemadocgeneration","title":"schemadocgeneration","text":"<p>Module for generating markdown docs for schemas</p>"},{"location":"reference/mkdocs/schemadocgeneration/#niceml.mkdocs.schemadocgeneration-classes","title":"Classes","text":""},{"location":"reference/mkdocs/schemadocgeneration/#niceml.mkdocs.schemadocgeneration-functions","title":"Functions","text":""},{"location":"reference/mkdocs/schemadocgeneration/#niceml.mkdocs.schemadocgeneration.expschema_to_markdown","title":"expschema_to_markdown","text":"<pre><code>expschema_to_markdown(exp_schema_cls, col_widths)\n</code></pre> <p>Converts an expschema to a markdown table</p> Source code in <code>niceml/mkdocs/schemadocgeneration.py</code> <pre><code>def expschema_to_markdown(exp_schema_cls, col_widths: List[int]) -&gt; str:\n    \"\"\"Converts an expschema to a markdown table\"\"\"\n    cur_md: str = f\"## `{exp_schema_cls.__name__}`\\n\\n\"\n    cur_md += exp_schema_cls.__doc__ + \"\\n\\n\" or \"\"\n    exp_member_list: List[ExpMember] = get_expmembers_from_class(exp_schema_cls)\n    headings: List[str] = [\"File\", \"Description\"]\n    contents: List[List[str]] = []\n    for member in sorted(exp_member_list):\n        icon = get_icon(member)\n        contents.append([f\"{icon} `{member.path}`\", member.description])\n    cur_md += get_md_table(headings, col_widths, contents)\n    return cur_md\n</code></pre>"},{"location":"reference/mkdocs/schemadocgeneration/#niceml.mkdocs.schemadocgeneration.get_all_expschema_markdowns","title":"get_all_expschema_markdowns","text":"<pre><code>get_all_expschema_markdowns(col_widths)\n</code></pre> <p>Returns all schemas as md str</p> Source code in <code>niceml/mkdocs/schemadocgeneration.py</code> <pre><code>def get_all_expschema_markdowns(col_widths: List[int]) -&gt; str:\n    \"\"\"Returns all schemas as md str\"\"\"\n    mk_str = \"\"\n    for exp_schema in get_all_schemas():\n        mk_str += expschema_to_markdown(exp_schema, col_widths) + \"\\n\\n\"\n\n    return mk_str\n</code></pre>"},{"location":"reference/mkdocs/schemadocgeneration/#niceml.mkdocs.schemadocgeneration.get_icon","title":"get_icon","text":"<pre><code>get_icon(member)\n</code></pre> <p>Returns an icon according the member type</p> Source code in <code>niceml/mkdocs/schemadocgeneration.py</code> <pre><code>def get_icon(member: ExpMember) -&gt; str:\n    \"\"\"Returns an icon according the member type\"\"\"\n    if isinstance(member, FolderMember):\n        return \":file_folder:\"\n    return \":material-file:\"\n</code></pre>"},{"location":"reference/mlcomponents/__init__/","title":"mlcomponents","text":""},{"location":"reference/mlcomponents/__init__/#niceml.mlcomponents","title":"mlcomponents","text":""},{"location":"reference/mlcomponents/callbacks/__init__/","title":"callbacks","text":""},{"location":"reference/mlcomponents/callbacks/__init__/#niceml.mlcomponents.callbacks","title":"callbacks","text":""},{"location":"reference/mlcomponents/callbacks/callbackinitializer/","title":"callbackinitializer","text":""},{"location":"reference/mlcomponents/callbacks/callbackinitializer/#niceml.mlcomponents.callbacks.callbackinitializer","title":"callbackinitializer","text":"<p>Module for CallbackInitializer</p>"},{"location":"reference/mlcomponents/callbacks/callbackinitializer/#niceml.mlcomponents.callbacks.callbackinitializer-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/callbacks/callbackinitializer/#niceml.mlcomponents.callbacks.callbackinitializer.CallbackInitializer","title":"CallbackInitializer","text":"<pre><code>CallbackInitializer(callback_list=None, callback_dict=None)\n</code></pre> <p>Initializes callbacks with ExperimentContext</p> <p>Constructor for CallbackInitializer Args:     callback_list: A list of callback factories     callback_dict: A dict of callback factories</p> Source code in <code>niceml/mlcomponents/callbacks/callbackinitializer.py</code> <pre><code>def __init__(\n    self,\n    callback_list: Optional[List[CallbackFactory]] = None,\n    callback_dict: Optional[Dict[str, CallbackFactory]] = None,\n):\n    \"\"\"\n    Constructor for CallbackInitializer\n    Args:\n        callback_list: A list of callback factories\n        callback_dict: A dict of callback factories\n    \"\"\"\n    self.callback_list = callback_list or []\n    self.callback_dict = callback_dict or {}\n</code></pre>"},{"location":"reference/mlcomponents/callbacks/callbackinitializer/#niceml.mlcomponents.callbacks.callbackinitializer.CallbackInitializer-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/callbacks/callbackinitializer/#niceml.mlcomponents.callbacks.callbackinitializer.CallbackInitializer.__call__","title":"__call__","text":"<pre><code>__call__(exp_context)\n</code></pre> <p>Initializes the callbacks</p> Source code in <code>niceml/mlcomponents/callbacks/callbackinitializer.py</code> <pre><code>def __call__(self, exp_context: ExperimentContext) -&gt; List:\n    \"\"\"Initializes the callbacks\"\"\"\n    callback_list = self.callback_list + list(self.callback_dict.values())\n    cb_init_list = [cur_cb.create_callback(exp_context) for cur_cb in callback_list]\n    return cb_init_list\n</code></pre>"},{"location":"reference/mlcomponents/learners/__init__/","title":"learners","text":""},{"location":"reference/mlcomponents/learners/__init__/#niceml.mlcomponents.learners","title":"learners","text":""},{"location":"reference/mlcomponents/learners/fitgenerators/","title":"fitgenerators","text":""},{"location":"reference/mlcomponents/learners/fitgenerators/#niceml.mlcomponents.learners.fitgenerators","title":"fitgenerators","text":"<p>Module for fit generator</p>"},{"location":"reference/mlcomponents/learners/fitgenerators/#niceml.mlcomponents.learners.fitgenerators-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/learners/fitgenerators/#niceml.mlcomponents.learners.fitgenerators-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/learners/fitgenerators/#niceml.mlcomponents.learners.fitgenerators.fit_generator","title":"fit_generator","text":"<pre><code>fit_generator(\n    exp_context,\n    learner,\n    model,\n    train_set,\n    validation_set,\n    train_params,\n    data_description,\n)\n</code></pre> <p>Function to fit the generator with the learner</p> Source code in <code>niceml/mlcomponents/learners/fitgenerators.py</code> <pre><code>def fit_generator(  # noqa: PLR0913\n    exp_context: ExperimentContext,\n    learner: Learner,\n    model: ModelFactory,\n    train_set,\n    validation_set,\n    train_params: TrainParams,\n    data_description: DataDescription,\n):\n    \"\"\"Function to fit the generator with the learner\"\"\"\n    if train_params.validation_steps is not None:\n        print(f\"Validation steps: {train_params.validation_steps}\")\n    if train_params.steps_per_epoch is not None:\n        print(f\"Steps per epoch: {train_params.steps_per_epoch}\")\n\n    learner.run_training(\n        exp_context,\n        model,\n        train_set,\n        validation_set,\n        train_params,\n        data_description,\n    )\n</code></pre>"},{"location":"reference/mlcomponents/learners/learner/","title":"learner","text":""},{"location":"reference/mlcomponents/learners/learner/#niceml.mlcomponents.learners.learner","title":"learner","text":"<p>Module for learner</p>"},{"location":"reference/mlcomponents/learners/learner/#niceml.mlcomponents.learners.learner-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/learners/learner/#niceml.mlcomponents.learners.learner.Learner","title":"Learner","text":"<p>             Bases: <code>ABC</code></p> <p>Wrapper to do the training</p>"},{"location":"reference/mlcomponents/learners/learner/#niceml.mlcomponents.learners.learner.Learner-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/learners/learner/#niceml.mlcomponents.learners.learner.Learner.run_training","title":"run_training  <code>abstractmethod</code>","text":"<pre><code>run_training(\n    exp_context,\n    model_factory,\n    train_set,\n    validation_set,\n    train_params,\n    data_description,\n)\n</code></pre> <p>Runs the training</p> Source code in <code>niceml/mlcomponents/learners/learner.py</code> <pre><code>@abstractmethod\ndef run_training(  # noqa: PLR0913\n    self,\n    exp_context: ExperimentContext,\n    model_factory: ModelFactory,\n    train_set: Dataset,\n    validation_set: Dataset,\n    train_params: TrainParams,\n    data_description: DataDescription,\n):\n    \"\"\"Runs the training\"\"\"\n</code></pre>"},{"location":"reference/mlcomponents/modelcompiler/__init__/","title":"modelcompiler","text":""},{"location":"reference/mlcomponents/modelcompiler/__init__/#niceml.mlcomponents.modelcompiler","title":"modelcompiler","text":""},{"location":"reference/mlcomponents/modelcompiler/modelcompiler/","title":"modelcompiler","text":""},{"location":"reference/mlcomponents/modelcompiler/modelcompiler/#niceml.mlcomponents.modelcompiler.modelcompiler","title":"modelcompiler","text":"<p>Module for ABC ModelCompiler</p>"},{"location":"reference/mlcomponents/modelcompiler/modelcompiler/#niceml.mlcomponents.modelcompiler.modelcompiler-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/modelcompiler/modelcompiler/#niceml.mlcomponents.modelcompiler.modelcompiler.ModelCompiler","title":"ModelCompiler","text":"<p>             Bases: <code>ABC</code></p> <p>Prepares a model for training</p>"},{"location":"reference/mlcomponents/modelcompiler/modelcompiler/#niceml.mlcomponents.modelcompiler.modelcompiler.ModelCompiler-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/modelcompiler/modelcompiler/#niceml.mlcomponents.modelcompiler.modelcompiler.ModelCompiler.compile","title":"compile  <code>abstractmethod</code>","text":"<pre><code>compile(model_factory, data_description)\n</code></pre> <p>Converts a ModelFactory to a ModelBundle</p> Source code in <code>niceml/mlcomponents/modelcompiler/modelcompiler.py</code> <pre><code>@abstractmethod\ndef compile(\n    self, model_factory: ModelFactory, data_description: DataDescription\n) -&gt; ModelBundle:\n    \"\"\"Converts a ModelFactory to a ModelBundle\"\"\"\n</code></pre>"},{"location":"reference/mlcomponents/modelcompiler/modelcustomloadobjects/","title":"modelcustomloadobjects","text":""},{"location":"reference/mlcomponents/modelcompiler/modelcustomloadobjects/#niceml.mlcomponents.modelcompiler.modelcustomloadobjects","title":"modelcustomloadobjects","text":"<p>Module for ModelCustomLoadObjects</p>"},{"location":"reference/mlcomponents/modelcompiler/modelcustomloadobjects/#niceml.mlcomponents.modelcompiler.modelcustomloadobjects-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/modelcompiler/modelcustomloadobjects/#niceml.mlcomponents.modelcompiler.modelcustomloadobjects.ModelCustomLoadObjects","title":"ModelCustomLoadObjects  <code>dataclass</code>","text":"<p>Only used to import modules required for the model (e.g. tensorflow)</p>"},{"location":"reference/mlcomponents/modelloader/__init__/","title":"modelloader","text":""},{"location":"reference/mlcomponents/modelloader/__init__/#niceml.mlcomponents.modelloader","title":"modelloader","text":""},{"location":"reference/mlcomponents/modelloader/modelloader/","title":"modelloader","text":""},{"location":"reference/mlcomponents/modelloader/modelloader/#niceml.mlcomponents.modelloader.modelloader","title":"modelloader","text":"<p>Module for AVC ModelLoader</p>"},{"location":"reference/mlcomponents/modelloader/modelloader/#niceml.mlcomponents.modelloader.modelloader-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/modelloader/modelloader/#niceml.mlcomponents.modelloader.modelloader.ModelLoader","title":"ModelLoader","text":"<p>             Bases: <code>ABC</code></p> <p>Callable that loads models</p>"},{"location":"reference/mlcomponents/modelloader/modelloader/#niceml.mlcomponents.modelloader.modelloader.ModelLoader-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/modelloader/modelloader/#niceml.mlcomponents.modelloader.modelloader.ModelLoader.__call__","title":"__call__  <code>abstractmethod</code>","text":"<pre><code>__call__(model_path, file_system=None)\n</code></pre> <p>Loads the model at the given path</p> Source code in <code>niceml/mlcomponents/modelloader/modelloader.py</code> <pre><code>@abstractmethod\ndef __call__(\n    self,\n    model_path: str,\n    file_system: Optional[AbstractFileSystem] = None,\n) -&gt; Any:\n    \"\"\"Loads the model at the given path\"\"\"\n</code></pre>"},{"location":"reference/mlcomponents/models/__init__/","title":"models","text":""},{"location":"reference/mlcomponents/models/__init__/#niceml.mlcomponents.models","title":"models","text":""},{"location":"reference/mlcomponents/models/modelbundle/","title":"modelbundle","text":""},{"location":"reference/mlcomponents/models/modelbundle/#niceml.mlcomponents.models.modelbundle","title":"modelbundle","text":""},{"location":"reference/mlcomponents/models/modelfactory/","title":"modelfactory","text":""},{"location":"reference/mlcomponents/models/modelfactory/#niceml.mlcomponents.models.modelfactory","title":"modelfactory","text":"<p>Module for ModelFactory</p>"},{"location":"reference/mlcomponents/models/modelfactory/#niceml.mlcomponents.models.modelfactory-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/models/modelfactory/#niceml.mlcomponents.models.modelfactory.ModelFactory","title":"ModelFactory","text":"<p>             Bases: <code>ABC</code></p> <p>ABC for model factories. Used to create the model before training</p>"},{"location":"reference/mlcomponents/models/modelfactory/#niceml.mlcomponents.models.modelfactory.ModelFactory-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/models/modelfactory/#niceml.mlcomponents.models.modelfactory.ModelFactory.create_model","title":"create_model  <code>abstractmethod</code>","text":"<pre><code>create_model(data_description)\n</code></pre> <p>Creates a model for training according to the data_description</p> Source code in <code>niceml/mlcomponents/models/modelfactory.py</code> <pre><code>@abstractmethod\ndef create_model(self, data_description: DataDescription) -&gt; Any:\n    \"\"\"Creates a model for training according to the data_description\"\"\"\n</code></pre>"},{"location":"reference/mlcomponents/objdet/__init__/","title":"objdet","text":""},{"location":"reference/mlcomponents/objdet/__init__/#niceml.mlcomponents.objdet","title":"objdet","text":""},{"location":"reference/mlcomponents/objdet/anchorencoding/","title":"anchorencoding","text":""},{"location":"reference/mlcomponents/objdet/anchorencoding/#niceml.mlcomponents.objdet.anchorencoding","title":"anchorencoding","text":"<p>Module for anchor encoding</p>"},{"location":"reference/mlcomponents/objdet/anchorencoding/#niceml.mlcomponents.objdet.anchorencoding-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/objdet/anchorencoding/#niceml.mlcomponents.objdet.anchorencoding.AnchorEncoder","title":"AnchorEncoder","text":"<p>             Bases: <code>ABC</code></p> <p>Abstract AnchorEncoder</p>"},{"location":"reference/mlcomponents/objdet/anchorencoding/#niceml.mlcomponents.objdet.anchorencoding.AnchorEncoder-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/objdet/anchorencoding/#niceml.mlcomponents.objdet.anchorencoding.AnchorEncoder.decode_anchors","title":"decode_anchors  <code>abstractmethod</code>","text":"<pre><code>decode_anchors(anchor_list, encodings)\n</code></pre> <p>\"Decodes an anchor list with corresponding labels to a numpy array</p> Source code in <code>niceml/mlcomponents/objdet/anchorencoding.py</code> <pre><code>@abstractmethod\ndef decode_anchors(self, anchor_list: List[BoundingBox], encodings: np.ndarray):\n    \"\"\" \"Decodes an anchor list with corresponding labels to a numpy array\"\"\"\n</code></pre>"},{"location":"reference/mlcomponents/objdet/anchorencoding/#niceml.mlcomponents.objdet.anchorencoding.AnchorEncoder.encode_anchors","title":"encode_anchors  <code>abstractmethod</code>","text":"<pre><code>encode_anchors(\n    anchor_list, gt_labels, num_classes, box_variance\n)\n</code></pre> <p>Encodes an anchor list with corresponding labels to a numpy array</p> Source code in <code>niceml/mlcomponents/objdet/anchorencoding.py</code> <pre><code>@abstractmethod\ndef encode_anchors(\n    self,\n    anchor_list: List[BoundingBox],\n    gt_labels: List[ObjDetInstanceLabel],\n    num_classes: int,\n    box_variance: List[float],\n) -&gt; np.ndarray:\n    \"\"\"Encodes an anchor list with corresponding labels to a numpy array\"\"\"\n</code></pre>"},{"location":"reference/mlcomponents/objdet/anchorencoding/#niceml.mlcomponents.objdet.anchorencoding.OptimizedAnchorEncoder","title":"OptimizedAnchorEncoder  <code>dataclass</code>","text":"<p>             Bases: <code>AnchorEncoder</code></p> <p>Class to encode anchors before model optimization</p>"},{"location":"reference/mlcomponents/objdet/anchorencoding/#niceml.mlcomponents.objdet.anchorencoding.OptimizedAnchorEncoder-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/objdet/anchorencoding/#niceml.mlcomponents.objdet.anchorencoding.OptimizedAnchorEncoder.decode_anchors","title":"decode_anchors","text":"<pre><code>decode_anchors(anchor_list, encodings)\n</code></pre> <p>Decodes encoded bounding boxes in an optimized way Args:     anchor_list: List of bounding boxes representing the anchors     encodings: 2D array with at least the four coordinates     of the bounding boxes in xywh format.     This is optionally followed by a mask flag (POSITIVE,NEGATIVE,IGNORE)     and a one-hot encoded class vector</p> <p>Returns:</p> <ul> <li>         \u2013          <p>Same as encodings but with decoded bounding box coordinates</p> </li> </ul> Source code in <code>niceml/mlcomponents/objdet/anchorencoding.py</code> <pre><code>def decode_anchors(self, anchor_list: List[BoundingBox], encodings: np.ndarray):\n    \"\"\"\n    Decodes encoded bounding boxes in an optimized way\n    Args:\n        anchor_list: List of bounding boxes representing the anchors\n        encodings: 2D array with at least the four coordinates\n        of the bounding boxes in xywh format.\n        This is optionally followed by a mask flag (POSITIVE,NEGATIVE,IGNORE)\n        and a one-hot encoded class vector\n\n    Returns:\n        Same as encodings but with decoded bounding box coordinates\n\n    \"\"\"\n\n    if (\n        self.anchor_array_stored_xywh is None\n        or len(anchor_list) != self.anchor_array_stored_xywh.shape[0]\n    ):\n        self.anchor_array_stored_xywh = np.array(\n            [box.get_absolute_ullr() for box in anchor_list]\n        )\n\n    box_variance = self.box_variance  # pylint: disable=no-member\n    decoded_boxes = decode_boxes(\n        anchor_boxes_xywh=self.anchor_array_stored_xywh,\n        encoded_array_xywh=encodings[:, :4],\n        box_variances=np.array(box_variance),\n    )\n\n    encodings[:, :4] = decoded_boxes\n\n    return encodings\n</code></pre>"},{"location":"reference/mlcomponents/objdet/anchorencoding/#niceml.mlcomponents.objdet.anchorencoding.OptimizedAnchorEncoder.encode_anchors","title":"encode_anchors","text":"<pre><code>encode_anchors(\n    anchor_list, gt_labels, num_classes, box_variance\n)\n</code></pre> <p>Encodes an anchor list to a numpy array</p> Source code in <code>niceml/mlcomponents/objdet/anchorencoding.py</code> <pre><code>def encode_anchors(\n    self,\n    anchor_list: List[BoundingBox],\n    gt_labels: List[ObjDetInstanceLabel],\n    num_classes: int,\n    box_variance: List[float],\n) -&gt; np.ndarray:\n    \"\"\"Encodes an anchor list to a numpy array\"\"\"\n    box: BoundingBox\n    label: ObjDetInstanceLabel\n    if (\n        self.anchor_array_stored_ullr is None\n        or len(anchor_list) != self.anchor_array_stored_ullr.shape[0]\n    ):\n        self.anchor_array_stored_ullr = np.array(\n            [box.get_absolute_ullr() for box in anchor_list]\n        )\n\n    if len(gt_labels) == 0:\n        anchor_shape = self.anchor_array_stored_ullr.shape\n        target_array = np.zeros(\n            (anchor_shape[0], anchor_shape[1] + 1 + num_classes)\n        )\n        target_array[:, anchor_shape[1]] = NEGATIVE_MASK_VALUE\n        return target_array\n\n    gt_box_array = np.array(\n        [label.bounding_box.get_absolute_ullr() for label in gt_labels]\n    )\n    iou_matrix = compute_iou_matrix(self.anchor_array_stored_ullr, gt_box_array)\n    class_index_array = np.array([label.class_index for label in gt_labels])\n    target_array = compute_target_gt_array(\n        self.anchor_array_stored_ullr,\n        gt_box_array,\n        iou_matrix=iou_matrix,\n        box_variances=np.array(box_variance),\n        class_index_array=class_index_array,\n        match_iou=self.match_iou,\n        ignore_iou=self.ignore_iou,\n        num_classes=num_classes,\n    )\n    return target_array\n</code></pre>"},{"location":"reference/mlcomponents/objdet/anchorencoding/#niceml.mlcomponents.objdet.anchorencoding.SimpleAnchorEncoder","title":"SimpleAnchorEncoder  <code>dataclass</code>","text":"<p>             Bases: <code>AnchorEncoder</code></p> <p>Class to encode anchors before model optimization</p>"},{"location":"reference/mlcomponents/objdet/anchorencoding/#niceml.mlcomponents.objdet.anchorencoding.SimpleAnchorEncoder-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/objdet/anchorencoding/#niceml.mlcomponents.objdet.anchorencoding.SimpleAnchorEncoder.decode_anchors","title":"decode_anchors","text":"<pre><code>decode_anchors(anchor_list, encodings)\n</code></pre> <p>Decodes encoded bounding boxes Args:     anchor_list: List of bounding boxes representing the anchors     encodings: 2D array with at least the four coordinates     of the bounding boxes in xywh format.     This is optionally followed by a mask flag (POSITIVE,NEGATIVE,IGNORE)     and a one-hot encoded class vector</p> <p>Returns:</p> <ul> <li> <code>ndarray</code>         \u2013          <p>Same as encodings but with decoded bounding box coordinates</p> </li> </ul> Source code in <code>niceml/mlcomponents/objdet/anchorencoding.py</code> <pre><code>def decode_anchors(\n    self, anchor_list: List[BoundingBox], encodings: np.ndarray\n) -&gt; np.ndarray:\n    \"\"\"\n    Decodes encoded bounding boxes\n    Args:\n        anchor_list: List of bounding boxes representing the anchors\n        encodings: 2D array with at least the four coordinates\n        of the bounding boxes in xywh format.\n        This is optionally followed by a mask flag (POSITIVE,NEGATIVE,IGNORE)\n        and a one-hot encoded class vector\n\n    Returns:\n        Same as encodings but with decoded bounding box coordinates\n\n    \"\"\"\n    decoded_box_predictions: List[np.ndarray] = []\n\n    for anchor, prediction in zip(anchor_list, encodings):\n        box_variance = self.box_variance  # pylint: disable=no-member\n        decoded_box = anchor.decode(\n            predicted_values=list(prediction[:4]), box_variance=box_variance\n        )\n\n        decoded_box_predictions.append(\n            np.array(list(decoded_box.get_absolute_ullr()))\n        )\n    decoded_box_prediction_array = np.array(decoded_box_predictions)\n    encodings[:, :4] = decoded_box_prediction_array\n\n    return encodings\n</code></pre>"},{"location":"reference/mlcomponents/objdet/anchorencoding/#niceml.mlcomponents.objdet.anchorencoding.SimpleAnchorEncoder.encode_anchors","title":"encode_anchors","text":"<pre><code>encode_anchors(\n    anchor_list, gt_labels, num_classes, box_variance\n)\n</code></pre> <p>Encodes an anchor list to a numpy array</p> Source code in <code>niceml/mlcomponents/objdet/anchorencoding.py</code> <pre><code>def encode_anchors(  # pylint: disable=too-many-locals\n    self,\n    anchor_list: List[BoundingBox],\n    gt_labels: List[ObjDetInstanceLabel],\n    num_classes: int,\n    box_variance: List[float],\n) -&gt; np.ndarray:\n    \"\"\"Encodes an anchor list to a numpy array\"\"\"\n    encoded_feature_list: List[List[float]] = []\n\n    for anchor in anchor_list:\n        if len(gt_labels) == 0:\n            target_bbox = anchor\n            target_label = None\n            prediction_flag = NEGATIVE_MASK_VALUE\n        else:\n            max_iou = 0\n            target_bbox = gt_labels[0].bounding_box\n            target_label = None\n            prediction_flag = NEGATIVE_MASK_VALUE\n\n            for label_instance in gt_labels:\n                gt_bbox = label_instance.bounding_box\n                iou = anchor.calc_iou(gt_bbox)\n\n                if iou &gt; max_iou:\n                    max_iou = iou\n                    target_bbox = gt_bbox\n                    target_label = label_instance.class_index\n                    prediction_flag = POSITIVE_MASK_VALUE\n\n            if self.match_iou &gt; max_iou &gt; self.ignore_iou:\n                target_label = None\n                prediction_flag = IGNORE_MASK_VALUE\n\n            elif max_iou &lt; self.ignore_iou:\n                target_label = None\n                prediction_flag = NEGATIVE_MASK_VALUE\n\n        cur_encoding = anchor.encode(target_bbox, box_variance)\n        cur_encoding.append(prediction_flag)\n        target_label_vector = [0] * num_classes\n        if target_label is not None:\n            target_label_vector[target_label] = 1\n        cur_encoding += target_label_vector\n        encoded_feature_list.append(cur_encoding)\n\n    target_bbox_array = np.array(encoded_feature_list)\n    return target_bbox_array\n</code></pre>"},{"location":"reference/mlcomponents/objdet/anchorencoding/#niceml.mlcomponents.objdet.anchorencoding-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/objdet/anchorgenerator/","title":"anchorgenerator","text":""},{"location":"reference/mlcomponents/objdet/anchorgenerator/#niceml.mlcomponents.objdet.anchorgenerator","title":"anchorgenerator","text":"<p>Module for the anchorgenerator</p>"},{"location":"reference/mlcomponents/objdet/anchorgenerator/#niceml.mlcomponents.objdet.anchorgenerator-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/objdet/anchorgenerator/#niceml.mlcomponents.objdet.anchorgenerator.AnchorGenerator","title":"AnchorGenerator","text":"<p>Class for generating anchors for object detection</p>"},{"location":"reference/mlcomponents/objdet/anchorgenerator/#niceml.mlcomponents.objdet.anchorgenerator.AnchorGenerator-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/objdet/anchorgenerator/#niceml.mlcomponents.objdet.anchorgenerator.AnchorGenerator.gen_anchors_for_featuremap","title":"gen_anchors_for_featuremap","text":"<pre><code>gen_anchors_for_featuremap(\n    image_size,\n    scale,\n    aspect_ratios,\n    anchor_scales,\n    base_area_side,\n)\n</code></pre> <p>Generates anchors for one featuremap</p> Source code in <code>niceml/mlcomponents/objdet/anchorgenerator.py</code> <pre><code>def gen_anchors_for_featuremap(  # pylint: disable=too-many-locals,too-many-arguments\n    self,\n    image_size: ImageSize,\n    scale: int,\n    aspect_ratios: List[float],\n    anchor_scales: List[float],\n    base_area_side: float,\n) -&gt; List[BoundingBox]:\n    \"\"\"Generates anchors for one featuremap\"\"\"\n\n    steps_width = image_size.width // scale\n    steps_height = image_size.height // scale\n    area: float = (base_area_side * scale) ** 2\n\n    width_height_list = calculate_anchor_width_height_list(\n        aspect_ratios, anchor_scales, area\n    )\n    bbox_list: List[BoundingBox] = []\n    for y_pos in range(steps_height):\n        for x_pos in range(steps_width):\n            center_x = (x_pos + 0.5) * scale\n            center_y = (y_pos + 0.5) * scale\n            for cur_width, cur_height in width_height_list:\n                bounding_box: BoundingBox = bounding_box_from_absolute_cxcywh(\n                    center_x, center_y, cur_width, cur_height\n                )\n                bbox_list.append(bounding_box)\n    return bbox_list\n</code></pre>"},{"location":"reference/mlcomponents/objdet/anchorgenerator/#niceml.mlcomponents.objdet.anchorgenerator.AnchorGenerator.generate_anchors","title":"generate_anchors","text":"<pre><code>generate_anchors(data_description)\n</code></pre> <p>Generate anchors for all feature maps and appends them</p> Source code in <code>niceml/mlcomponents/objdet/anchorgenerator.py</code> <pre><code>def generate_anchors(\n    self, data_description: OutputObjDetDataDescription\n) -&gt; List[BoundingBox]:\n    \"\"\"Generate anchors for all feature maps and appends them\"\"\"\n    out_anchors = []\n    for feature_map_scale in data_description.get_featuremap_scales():\n        out_anchors += self.gen_anchors_for_featuremap(\n            image_size=data_description.get_input_image_size(),\n            scale=feature_map_scale,\n            aspect_ratios=data_description.get_anchor_aspect_ratios(),\n            anchor_scales=data_description.get_anchor_scales(),\n            base_area_side=data_description.get_base_area_side(),\n        )\n    return out_anchors\n</code></pre>"},{"location":"reference/mlcomponents/objdet/anchorgenerator/#niceml.mlcomponents.objdet.anchorgenerator-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/objdet/anchorgenerator/#niceml.mlcomponents.objdet.anchorgenerator.calculate_anchor_width_height_list","title":"calculate_anchor_width_height_list","text":"<pre><code>calculate_anchor_width_height_list(\n    aspect_ratios, anchor_scales, area\n)\n</code></pre> <p>calculates the widths and heights for one featuremap</p> Source code in <code>niceml/mlcomponents/objdet/anchorgenerator.py</code> <pre><code>def calculate_anchor_width_height_list(\n    aspect_ratios: List[float], anchor_scales: List[float], area: float\n) -&gt; List[Tuple[float, float]]:\n    \"\"\"calculates the widths and heights for one featuremap\"\"\"\n    width_height_list = []\n    for cur_ratio in aspect_ratios:\n        anchor_height = sqrt(area / cur_ratio)\n        anchor_width = area / anchor_height\n        for cur_scale in anchor_scales:\n            width_height_list.append(\n                (anchor_width * cur_scale, anchor_height * cur_scale)\n            )\n\n    return width_height_list\n</code></pre>"},{"location":"reference/mlcomponents/predictionfunction/__init__/","title":"predictionfunction","text":""},{"location":"reference/mlcomponents/predictionfunction/__init__/#niceml.mlcomponents.predictionfunction","title":"predictionfunction","text":""},{"location":"reference/mlcomponents/predictionfunction/predictionfunction/","title":"predictionfunction","text":""},{"location":"reference/mlcomponents/predictionfunction/predictionfunction/#niceml.mlcomponents.predictionfunction.predictionfunction","title":"predictionfunction","text":"<p>Abstract class for prediction functions</p>"},{"location":"reference/mlcomponents/predictionfunction/predictionfunction/#niceml.mlcomponents.predictionfunction.predictionfunction-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/predictionfunction/predictionfunction/#niceml.mlcomponents.predictionfunction.predictionfunction.PredictionFunction","title":"PredictionFunction","text":"<p>             Bases: <code>ABC</code></p> <p>Abstract class for prediction functions</p>"},{"location":"reference/mlcomponents/predictionfunction/predictionfunction/#niceml.mlcomponents.predictionfunction.predictionfunction.PredictionFunction-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/predictionfunction/predictionfunction/#niceml.mlcomponents.predictionfunction.predictionfunction.PredictionFunction.predict","title":"predict  <code>abstractmethod</code>","text":"<pre><code>predict(model, data_x)\n</code></pre> <p>Predicts the given data with the given model</p> Source code in <code>niceml/mlcomponents/predictionfunction/predictionfunction.py</code> <pre><code>@abstractmethod\ndef predict(self, model, data_x) -&gt; Any:\n    \"\"\"Predicts the given data with the given model\"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"reference/mlcomponents/predictionhandlers/__init__/","title":"predictionhandlers","text":""},{"location":"reference/mlcomponents/predictionhandlers/__init__/#niceml.mlcomponents.predictionhandlers","title":"predictionhandlers","text":""},{"location":"reference/mlcomponents/predictionhandlers/combinationpredictionhandler/","title":"combinationpredictionhandler","text":""},{"location":"reference/mlcomponents/predictionhandlers/combinationpredictionhandler/#niceml.mlcomponents.predictionhandlers.combinationpredictionhandler","title":"combinationpredictionhandler","text":"<p>Module of the MultiPredictionHandler</p>"},{"location":"reference/mlcomponents/predictionhandlers/combinationpredictionhandler/#niceml.mlcomponents.predictionhandlers.combinationpredictionhandler-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/predictionhandlers/combinationpredictionhandler/#niceml.mlcomponents.predictionhandlers.combinationpredictionhandler.CombinationPredictionHandler","title":"CombinationPredictionHandler","text":"<pre><code>CombinationPredictionHandler(handlers)\n</code></pre> <p>             Bases: <code>PredictionHandler</code></p> <p>Prediction Handler that combines a list of <code>PredictionHandler</code>s</p> Source code in <code>niceml/mlcomponents/predictionhandlers/combinationpredictionhandler.py</code> <pre><code>def __init__(self, handlers: List[PredictionHandler]):\n    super().__init__()\n    self.handler_list: List[PredictionHandler] = handlers\n</code></pre>"},{"location":"reference/mlcomponents/predictionhandlers/objdetpredictionhandler/","title":"objdetpredictionhandler","text":""},{"location":"reference/mlcomponents/predictionhandlers/objdetpredictionhandler/#niceml.mlcomponents.predictionhandlers.objdetpredictionhandler","title":"objdetpredictionhandler","text":"<p>Module with a prediction handler for object detection and also supportive functions</p>"},{"location":"reference/mlcomponents/predictionhandlers/objdetpredictionhandler/#niceml.mlcomponents.predictionhandlers.objdetpredictionhandler-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/predictionhandlers/objdetpredictionhandler/#niceml.mlcomponents.predictionhandlers.objdetpredictionhandler.ObjDetPredictionHandler","title":"ObjDetPredictionHandler","text":"<pre><code>ObjDetPredictionHandler(\n    prediction_filter,\n    prediction_prefix=\"pred\",\n    pred_identifier=\"image_location\",\n    detection_idx_col=DETECTION_INDEX_COLUMN_NAME,\n    apply_sigmoid=True,\n)\n</code></pre> <p>             Bases: <code>PredictionHandler</code></p> <p>Prediction handler for object detection predictions (BoundingBox, class prediction)</p> <p>Initializes the ObjDetPredictionHandler</p> Source code in <code>niceml/mlcomponents/predictionhandlers/objdetpredictionhandler.py</code> <pre><code>def __init__(  # noqa: PLR0913\n    self,\n    prediction_filter: PredictionFilter,\n    prediction_prefix: str = \"pred\",\n    pred_identifier: str = \"image_location\",\n    detection_idx_col: str = DETECTION_INDEX_COLUMN_NAME,\n    apply_sigmoid: bool = True,\n):\n    \"\"\"Initializes the ObjDetPredictionHandler\"\"\"\n    super().__init__()\n    self.prediction_filter = prediction_filter\n    self.prediction_prefix = prediction_prefix\n    self.apply_sigmoid = apply_sigmoid\n    self.pred_identifier = pred_identifier\n    self.detection_idx_col = detection_idx_col\n    self.data = None\n    self.data_columns = [pred_identifier, detection_idx_col]\n    self.data_columns += list(asdict(BoundingBox(0, 0, 0, 0)).keys())\n\n    self.anchor_generator = AnchorGenerator()\n    self.anchors = None\n    self.anchor_array = None\n</code></pre>"},{"location":"reference/mlcomponents/predictionhandlers/objdetpredictionhandler/#niceml.mlcomponents.predictionhandlers.objdetpredictionhandler.ObjDetPredictionHandler-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/predictionhandlers/objdetpredictionhandler/#niceml.mlcomponents.predictionhandlers.objdetpredictionhandler.ObjDetPredictionHandler.__enter__","title":"__enter__","text":"<pre><code>__enter__()\n</code></pre> <p>Init <code>self.data</code> after the context is entered</p> Source code in <code>niceml/mlcomponents/predictionhandlers/objdetpredictionhandler.py</code> <pre><code>def __enter__(self):\n    \"\"\"Init `self.data` after the context is entered\"\"\"\n    self.data = []\n    if isinstance(self.data_description, OutputObjDetDataDescription):\n        for class_count in range(self.data_description.get_output_class_count()):\n            self.data_columns.append(f\"{self.prediction_prefix}_{class_count:04d}\")\n    return self\n</code></pre>"},{"location":"reference/mlcomponents/predictionhandlers/objdetpredictionhandler/#niceml.mlcomponents.predictionhandlers.objdetpredictionhandler.ObjDetPredictionHandler.__exit__","title":"__exit__","text":"<pre><code>__exit__(exc_type, exc_value, exc_traceback)\n</code></pre> <p>Save the data in <code>self.data</code> as a parquet file</p> Source code in <code>niceml/mlcomponents/predictionhandlers/objdetpredictionhandler.py</code> <pre><code>def __exit__(self, exc_type, exc_value, exc_traceback):\n    \"\"\"Save the data in `self.data` as a parquet file\"\"\"\n    if self.data is None:\n        logging.getLogger(__name__).warning(\n            \"PredictionHandler: %s has no data to write!\",\n            self.filename,\n        )\n    else:\n        data_frame: pd.DataFrame = pd.DataFrame(self.data)\n        self.exp_context.write_parquet(\n            data_frame,\n            join(ExperimentFilenames.PREDICTION_FOLDER, self.filename + \".parq\"),\n        )\n</code></pre>"},{"location":"reference/mlcomponents/predictionhandlers/objdetpredictionhandler/#niceml.mlcomponents.predictionhandlers.objdetpredictionhandler.ObjDetPredictionHandler.add_prediction","title":"add_prediction","text":"<pre><code>add_prediction(data_info_list, prediction_batch)\n</code></pre> <p>Gets the results of an object detection model, de</p> Source code in <code>niceml/mlcomponents/predictionhandlers/objdetpredictionhandler.py</code> <pre><code>def add_prediction(\n    self, data_info_list: List[ObjDetDataInfo], prediction_batch: np.ndarray\n):\n    \"\"\"Gets the results of an object detection model, de\"\"\"\n    output_dd: OutputObjDetDataDescription = check_instance(\n        self.data_description, OutputObjDetDataDescription\n    )\n    for curr_batch, curr_data_info in zip(prediction_batch, data_info_list):\n        decoded_box_predictions = self._decode_box_predictions(\n            box_predictions=curr_batch\n        )\n\n        if self.apply_sigmoid:\n            decoded_box_predictions = apply_sigmoid_on_cls_predictions(\n                decoded_box_predictions,\n                output_dd.get_coordinates_count(),\n            )\n\n        filtered_box_predictions = self.prediction_filter.filter(\n            decoded_box_predictions\n        )\n\n        if len(filtered_box_predictions) &gt; 0:\n            for curr_index, prediction in enumerate(filtered_box_predictions):\n                self._add_data(\n                    identifier=curr_data_info.get_identifier(),\n                    prediction=prediction,\n                    detection_index=curr_index,\n                )\n        else:\n            prediction = np.zeros(\n                (\n                    output_dd.get_coordinates_count()\n                    + output_dd.get_output_class_count(),\n                )\n            )\n            self._add_data(\n                curr_data_info.get_identifier(),\n                prediction=prediction,\n                detection_index=NO_PREDICTIONS_DETECTION_VALUE,\n            )\n</code></pre>"},{"location":"reference/mlcomponents/predictionhandlers/objdetpredictionhandler/#niceml.mlcomponents.predictionhandlers.objdetpredictionhandler.ObjDetPredictionHandler.initialize","title":"initialize","text":"<pre><code>initialize()\n</code></pre> <p>Initializes the prediction handler</p> Source code in <code>niceml/mlcomponents/predictionhandlers/objdetpredictionhandler.py</code> <pre><code>def initialize(self):\n    \"\"\"Initializes the prediction handler\"\"\"\n    self.anchors: List[BoundingBox] = self.anchor_generator.generate_anchors(\n        data_description=self.data_description\n    )\n    self.anchor_array = np.array([box.get_absolute_xywh() for box in self.anchors])\n    self.prediction_filter.initialize(data_description=self.data_description)\n</code></pre>"},{"location":"reference/mlcomponents/predictionhandlers/objdetpredictionhandler/#niceml.mlcomponents.predictionhandlers.objdetpredictionhandler-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/predictionhandlers/objdetpredictionhandler/#niceml.mlcomponents.predictionhandlers.objdetpredictionhandler.apply_sigmoid_on_cls_predictions","title":"apply_sigmoid_on_cls_predictions","text":"<pre><code>apply_sigmoid_on_cls_predictions(\n    box_predictions, coordinates_count\n)\n</code></pre> <p>Applies sigmoid only on the classification part</p> Source code in <code>niceml/mlcomponents/predictionhandlers/objdetpredictionhandler.py</code> <pre><code>def apply_sigmoid_on_cls_predictions(\n    box_predictions: np.ndarray, coordinates_count: int\n) -&gt; np.ndarray:\n    \"\"\"Applies sigmoid only on the classification part\"\"\"\n    box_predictions[:, coordinates_count:] = 1 / (\n        1 + np.exp(-box_predictions[:, coordinates_count:])\n    )\n    return box_predictions\n</code></pre>"},{"location":"reference/mlcomponents/predictionhandlers/predictionhandler/","title":"predictionhandler","text":""},{"location":"reference/mlcomponents/predictionhandlers/predictionhandler/#niceml.mlcomponents.predictionhandlers.predictionhandler","title":"predictionhandler","text":"<p>Module for the abstract PredictionHandler</p>"},{"location":"reference/mlcomponents/predictionhandlers/predictionhandler/#niceml.mlcomponents.predictionhandlers.predictionhandler-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/predictionhandlers/predictionhandler/#niceml.mlcomponents.predictionhandlers.predictionhandler.PredictionHandler","title":"PredictionHandler","text":"<pre><code>PredictionHandler()\n</code></pre> <p>             Bases: <code>ABC</code></p> <p>Abstract PredictionHandler class to implement your own prediction handler</p> Source code in <code>niceml/mlcomponents/predictionhandlers/predictionhandler.py</code> <pre><code>def __init__(self):\n    self.exp_context = None\n    self.filename = None\n    self.data_description = None\n</code></pre>"},{"location":"reference/mlcomponents/predictionhandlers/predictionhandler/#niceml.mlcomponents.predictionhandlers.predictionhandler.PredictionHandler-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/predictionhandlers/predictionhandler/#niceml.mlcomponents.predictionhandlers.predictionhandler.PredictionHandler.add_prediction","title":"add_prediction  <code>abstractmethod</code>","text":"<pre><code>add_prediction(data_info_list, prediction_batch)\n</code></pre> <p>Consumes a prediction batch and handles the predicted data to create an experiment output</p> Source code in <code>niceml/mlcomponents/predictionhandlers/predictionhandler.py</code> <pre><code>@abstractmethod\ndef add_prediction(self, data_info_list: List[DataInfo], prediction_batch):\n    \"\"\"Consumes a prediction batch and handles the predicted data\n    to create an experiment output\"\"\"\n</code></pre>"},{"location":"reference/mlcomponents/predictionhandlers/predictionhandler/#niceml.mlcomponents.predictionhandlers.predictionhandler.PredictionHandler.initialize","title":"initialize","text":"<pre><code>initialize(*args, **kwargs)\n</code></pre> <p>This method can be implemented if some initialization steps need values that are specified in set_params Returns:</p> Source code in <code>niceml/mlcomponents/predictionhandlers/predictionhandler.py</code> <pre><code>def initialize(self, *args, **kwargs):\n    \"\"\"\n    This method can be implemented if some initialization steps need\n    values that are specified in set_params\n    Returns:\n\n    \"\"\"\n</code></pre>"},{"location":"reference/mlcomponents/predictionhandlers/semsegpredictionhandler/","title":"semsegpredictionhandler","text":""},{"location":"reference/mlcomponents/predictionhandlers/semsegpredictionhandler/#niceml.mlcomponents.predictionhandlers.semsegpredictionhandler","title":"semsegpredictionhandler","text":"<p>module for semseg prediction handlers</p>"},{"location":"reference/mlcomponents/predictionhandlers/semsegpredictionhandler/#niceml.mlcomponents.predictionhandlers.semsegpredictionhandler-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/predictionhandlers/semsegpredictionhandler/#niceml.mlcomponents.predictionhandlers.semsegpredictionhandler.SemSegBBoxPredictionHandler","title":"SemSegBBoxPredictionHandler","text":"<pre><code>SemSegBBoxPredictionHandler(\n    instance_finder,\n    prediction_prefix=\"pred\",\n    pred_identifier=\"image_filepath\",\n    detection_idx_col=DETECTION_INDEX_COLUMN_NAME,\n)\n</code></pre> <p>             Bases: <code>PredictionHandler</code></p> <p>Prediction handler to convert a tensor to bounding box information corresponding to <code>ObjDetPredictionHandler</code> based on found instances in a prediction mask.</p> <p>Initialize SemSegBBoxPredictionHandler. Takes a list of arguments, which are passed to it when an object of this type is created.</p> <p>Parameters:</p> <ul> <li> <code>instance_finder</code>             (<code>InstanceFinder</code>)         \u2013          <p>InstanceFinder for prediction identification</p> </li> <li> <code>prediction_prefix</code>             (<code>str</code>, default:                 <code>'pred'</code> )         \u2013          <p>Prefix the column names of the predictions</p> </li> <li> <code>pred_identifier</code>             (<code>str</code>, default:                 <code>'image_filepath'</code> )         \u2013          <p>Specify the column name of the image filepaths</p> </li> <li> <code>detection_idx_col</code>             (<code>str</code>, default:                 <code>DETECTION_INDEX_COLUMN_NAME</code> )         \u2013          <p>Specify the name of the column in which detection indices are stored</p> </li> </ul> Source code in <code>niceml/mlcomponents/predictionhandlers/semsegpredictionhandler.py</code> <pre><code>def __init__(\n    self,\n    instance_finder: InstanceFinder,\n    prediction_prefix: str = \"pred\",\n    pred_identifier: str = \"image_filepath\",\n    detection_idx_col: str = DETECTION_INDEX_COLUMN_NAME,\n):\n    \"\"\"\n    Initialize SemSegBBoxPredictionHandler. Takes a list of\n    arguments, which are passed to it when an object of this type is\n    created.\n\n    Args:\n        instance_finder: InstanceFinder for prediction identification\n        prediction_prefix: Prefix the column names of the predictions\n        pred_identifier: Specify the column name of the image filepaths\n        detection_idx_col: Specify the name of the column in which detection indices are stored\n    \"\"\"\n    super().__init__()\n    self.prediction_prefix = prediction_prefix\n    self.instance_finder = instance_finder\n    self.pred_identifier = pred_identifier\n    self.detection_idx_col = detection_idx_col\n    self.data = None\n    self.data_columns = [pred_identifier, detection_idx_col]\n    self.data_columns += get_bounding_box_attributes()\n</code></pre>"},{"location":"reference/mlcomponents/predictionhandlers/semsegpredictionhandler/#niceml.mlcomponents.predictionhandlers.semsegpredictionhandler.SemSegBBoxPredictionHandler-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/predictionhandlers/semsegpredictionhandler/#niceml.mlcomponents.predictionhandlers.semsegpredictionhandler.SemSegBBoxPredictionHandler.__enter__","title":"__enter__","text":"<pre><code>__enter__()\n</code></pre> <p>Enter SemSegBBoxPredictionHandler</p> Source code in <code>niceml/mlcomponents/predictionhandlers/semsegpredictionhandler.py</code> <pre><code>def __enter__(self):\n    \"\"\"Enter SemSegBBoxPredictionHandler\"\"\"\n    self.data = []\n    if isinstance(self.data_description, OutputImageDataDescription):\n        for class_count in range(self.data_description.get_output_channel_count()):\n            self.data_columns.append(f\"{self.prediction_prefix}_{class_count:04d}\")\n    return self\n</code></pre>"},{"location":"reference/mlcomponents/predictionhandlers/semsegpredictionhandler/#niceml.mlcomponents.predictionhandlers.semsegpredictionhandler.SemSegBBoxPredictionHandler.__exit__","title":"__exit__","text":"<pre><code>__exit__(exc_type, exc_value, exc_traceback)\n</code></pre> <p>Save the data in <code>self.data</code> as a parquet file</p> Source code in <code>niceml/mlcomponents/predictionhandlers/semsegpredictionhandler.py</code> <pre><code>def __exit__(self, exc_type, exc_value, exc_traceback):\n    \"\"\"Save the data in `self.data` as a parquet file\"\"\"\n    if self.data is None:\n        logging.getLogger(__name__).warning(\n            \"PredictionHandler: %s has no data to write!\",\n            self.filename,\n        )\n    else:\n        data_frame: pd.DataFrame = pd.DataFrame(self.data)\n        self.exp_context.write_parquet(\n            data_frame,\n            join(ExperimentFilenames.PREDICTION_FOLDER, self.filename + \".parq\"),\n        )\n</code></pre>"},{"location":"reference/mlcomponents/predictionhandlers/semsegpredictionhandler/#niceml.mlcomponents.predictionhandlers.semsegpredictionhandler.SemSegBBoxPredictionHandler.add_prediction","title":"add_prediction","text":"<pre><code>add_prediction(data_info_list, prediction_batch)\n</code></pre> <p>After each prediction, this is processed to find instances in a mask and create bounding box coordinates from the found instances</p> Source code in <code>niceml/mlcomponents/predictionhandlers/semsegpredictionhandler.py</code> <pre><code>def add_prediction(self, data_info_list: List[DataInfo], prediction_batch):\n    \"\"\"After each prediction, this is processed to find instances in a mask\n    and create bounding box coordinates from the found instances\"\"\"\n\n    expected_shape_dimensions = 4\n    if (\n        len(prediction_batch.shape) &lt; expected_shape_dimensions\n    ):  # If the batch size is 1, an additional dimension is necessary and added below\n        prediction_batch = np.expand_dims(prediction_batch, 0)\n\n    output_data_description: OutputImageDataDescription = check_instance(\n        self.data_description, OutputImageDataDescription\n    )\n\n    for prediction, data_info in zip(prediction_batch, data_info_list):\n        if output_data_description.get_use_void_class():\n            # remove background class from prediction array\n            prediction = prediction[:, :, :-1]\n        values = np.max(prediction, axis=2)\n\n        value_idxes = np.argmax(prediction, axis=2)\n\n        prediction_container = SemSegPredictionContainer(\n            image_id=None,\n            max_prediction_idxes=value_idxes,\n            max_prediction_values=values,\n        )\n\n        mask_instances: List[MaskInstance] = self.instance_finder.analyse_datapoint(\n            data_key=\"\",\n            data_predicted=prediction_container,\n            data_loaded=None,\n            additional_data={},\n        )\n\n        bbox_pred_data = create_bbox_prediction_from_mask_instances(\n            prediction=prediction,\n            mask_instances=mask_instances,\n        )\n        for detection_idx, predictions in bbox_pred_data:\n            self._add_data(\n                identifier=data_info.get_identifier(),\n                predictions=predictions,\n                detection_index=detection_idx,\n            )\n</code></pre>"},{"location":"reference/mlcomponents/predictionhandlers/semsegpredictionhandler/#niceml.mlcomponents.predictionhandlers.semsegpredictionhandler.SemSegBBoxPredictionHandler.set_params","title":"set_params","text":"<pre><code>set_params(exp_context, filename, data_description)\n</code></pre> <p>The set_params function is called by the ExperimentContext object when it is time to set up a new experiment.</p> <p>Parameters:</p> <ul> <li> <code>exp_context</code>             (<code>ExperimentContext</code>)         \u2013          <p>experiment context to pass to the instance finder</p> </li> <li> <code>filename</code>             (<code>str</code>)         \u2013          <p>Specifies the name of the dataset</p> </li> <li> <code>data_description</code>             (<code>DataDescription</code>)         \u2013          <p>Stores the data description of the dataset</p> </li> </ul> Source code in <code>niceml/mlcomponents/predictionhandlers/semsegpredictionhandler.py</code> <pre><code>def set_params(\n    self,\n    exp_context: ExperimentContext,\n    filename: str,\n    data_description: DataDescription,\n):\n    \"\"\"\n    The set_params function is called by the ExperimentContext object when it\n    is time to set up a new experiment.\n\n    Args:\n        exp_context: experiment context to pass to the instance finder\n        filename: Specifies the name of the dataset\n        data_description: Stores the data description of the dataset\n    \"\"\"\n    super().set_params(exp_context, filename, data_description)\n    self.instance_finder.initialize(\n        data_description=data_description,\n        exp_context=exp_context,\n        dataset_name=filename,\n    )\n</code></pre>"},{"location":"reference/mlcomponents/predictionhandlers/semsegpredictionhandler/#niceml.mlcomponents.predictionhandlers.semsegpredictionhandler.SemSegMaskPredictionHandler","title":"SemSegMaskPredictionHandler","text":"<pre><code>SemSegMaskPredictionHandler(\n    img_extension=\".png\", prediction_suffix=\"_pred\"\n)\n</code></pre> <p>             Bases: <code>PredictionHandler</code></p> <p>Prediction handler to convert a tensor to channel images for SemSeg</p> <p>This prediction handler converts a tensor to the maximum prediction image</p> <p>Parameters:</p> <ul> <li> <code>img_extension</code>             (<code>str</code>, default:                 <code>'.png'</code> )         \u2013          <p>Type of the images to write</p> </li> <li> <code>prediction_suffix</code>             (<code>str</code>, default:                 <code>'_pred'</code> )         \u2013          <p>Suffix for prediction columns</p> </li> </ul> Source code in <code>niceml/mlcomponents/predictionhandlers/semsegpredictionhandler.py</code> <pre><code>def __init__(self, img_extension: str = \".png\", prediction_suffix: str = \"_pred\"):\n    \"\"\"\n    This prediction handler converts a tensor to the maximum prediction image\n\n    Args:\n        img_extension: Type of the images to write\n        prediction_suffix: Suffix for prediction columns\n    \"\"\"\n    super().__init__()\n    self.img_extension = img_extension\n    self.prediction_suffix = prediction_suffix\n</code></pre>"},{"location":"reference/mlcomponents/predictionhandlers/semsegpredictionhandler/#niceml.mlcomponents.predictionhandlers.semsegpredictionhandler.SemSegMaskPredictionHandler-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/predictionhandlers/semsegpredictionhandler/#niceml.mlcomponents.predictionhandlers.semsegpredictionhandler.SemSegMaskPredictionHandler.__enter__","title":"__enter__","text":"<pre><code>__enter__()\n</code></pre> <p>Enter SemSegMaskPredictionHandler</p> Source code in <code>niceml/mlcomponents/predictionhandlers/semsegpredictionhandler.py</code> <pre><code>def __enter__(self):\n    \"\"\"Enter SemSegMaskPredictionHandler\"\"\"\n    return self\n</code></pre>"},{"location":"reference/mlcomponents/predictionhandlers/semsegpredictionhandler/#niceml.mlcomponents.predictionhandlers.semsegpredictionhandler.SemSegMaskPredictionHandler.__exit__","title":"__exit__","text":"<pre><code>__exit__(exc_type, exc_value, exc_traceback)\n</code></pre> <p>Exit SemSegMaskPredictionHandler</p> Source code in <code>niceml/mlcomponents/predictionhandlers/semsegpredictionhandler.py</code> <pre><code>def __exit__(self, exc_type, exc_value, exc_traceback):\n    \"\"\"Exit SemSegMaskPredictionHandler\"\"\"\n    pass\n</code></pre>"},{"location":"reference/mlcomponents/predictionhandlers/semsegpredictionhandler/#niceml.mlcomponents.predictionhandlers.semsegpredictionhandler.SemSegMaskPredictionHandler.add_prediction","title":"add_prediction","text":"<pre><code>add_prediction(data_info_list, prediction_batch)\n</code></pre> <p>After each prediction this is processed to store the images.</p> Source code in <code>niceml/mlcomponents/predictionhandlers/semsegpredictionhandler.py</code> <pre><code>def add_prediction(self, data_info_list: List[DataInfo], prediction_batch):\n    \"\"\"After each prediction this is processed to store the images.\"\"\"\n\n    output_data_description: OutputImageDataDescription = check_instance(\n        self.data_description, OutputImageDataDescription\n    )\n\n    expected_shape_dimensions = 4\n    if (\n        len(prediction_batch.shape) &lt; expected_shape_dimensions\n    ):  # If the batch size is 1, an additional dimension is necessary and added below\n        prediction_batch = np.expand_dims(prediction_batch, 0)\n    for prediction, data_info in zip(prediction_batch, data_info_list):\n        if output_data_description.get_use_void_class():\n            # remove background class from prediction array\n            prediction = prediction[:, :, :-1]\n        values = np.max(prediction, axis=2) * 255\n        value_idxes = np.argmax(prediction, axis=2)\n        target_array = np.stack(\n            (values, value_idxes, np.zeros_like(values)), axis=2\n        ).astype(dtype=np.uint8)\n        target_image = Image.fromarray(target_array)\n        self.exp_context.write_image(\n            target_image,\n            join(\n                ExperimentFilenames.PREDICTION_FOLDER,\n                self.filename,\n                f\"{data_info.get_identifier()}{self.prediction_suffix}{self.img_extension}\",\n            ),\n        )\n</code></pre>"},{"location":"reference/mlcomponents/predictionhandlers/semsegpredictionhandler/#niceml.mlcomponents.predictionhandlers.semsegpredictionhandler-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/predictionhandlers/semsegpredictionhandler/#niceml.mlcomponents.predictionhandlers.semsegpredictionhandler.create_bbox_prediction_from_mask_instances","title":"create_bbox_prediction_from_mask_instances","text":"<pre><code>create_bbox_prediction_from_mask_instances(\n    prediction, mask_instances\n)\n</code></pre> <p>Creates a prepared list of bounding box prediction information based on the result of a semantic segmentation Args:     prediction: raw prediction data with the shape                 (image_width, image_height, channel_count)     mask_instances: found instances of a mask</p> <p>Returns:</p> <ul> <li> <code>List[Tuple[int, List[float]]]</code>         \u2013          <p>List of Tuples (detection_index, list of prediction data</p> </li> <li> <code>List[Tuple[int, List[float]]]</code>         \u2013          <p>(bbox coordinates and prediction scores of each output channel))</p> </li> </ul> Source code in <code>niceml/mlcomponents/predictionhandlers/semsegpredictionhandler.py</code> <pre><code>def create_bbox_prediction_from_mask_instances(\n    prediction: np.ndarray,\n    mask_instances: List[MaskInstance],\n) -&gt; List[Tuple[int, List[float]]]:\n    \"\"\"\n    Creates a prepared list of bounding box prediction information\n    based on the result of a semantic segmentation\n    Args:\n        prediction: raw prediction data with the shape\n                    (image_width, image_height, channel_count)\n        mask_instances: found instances of a mask\n\n    Returns:\n        List of Tuples (detection_index, list of prediction data\n        (bbox coordinates and prediction scores of each output channel))\n\n    \"\"\"\n    detection_idx_count: int = 0\n    bbox_prediction_data: List[Tuple[int, List[float]]] = []\n\n    if (\n        len(mask_instances) == 0\n        and sum(len(error_info.instance_contours) for error_info in mask_instances) == 0\n    ):\n        bbox_prediction_data.append(\n            (-1, [0.0 for _ in range(4 + prediction.shape[-1])])\n        )\n\n    for error_info in mask_instances:\n        # pylint: disable = no-member\n        for error in error_info.instance_contours:\n            poly = cv2.approxPolyDP(error.contour, epsilon=1, closed=True)\n            # epsilon is the approximation accuracy\n            # (max difference between the original and the approximation)\n\n            x_pos, y_pos, width, height = cv2.boundingRect(poly)\n            predictions_of_error = prediction[\n                y_pos : y_pos + height, x_pos : x_pos + width, :\n            ]\n            bbox_prediction_data.append(\n                (\n                    detection_idx_count,\n                    [float(coord) for coord in [x_pos, y_pos, width, height]]\n                    + list(np.max(predictions_of_error, axis=(0, 1))),\n                )\n            )\n            detection_idx_count += 1\n    return bbox_prediction_data\n</code></pre>"},{"location":"reference/mlcomponents/predictionhandlers/tensorpredictionhandler/","title":"tensorpredictionhandler","text":""},{"location":"reference/mlcomponents/predictionhandlers/tensorpredictionhandler/#niceml.mlcomponents.predictionhandlers.tensorpredictionhandler","title":"tensorpredictionhandler","text":"<p>Module for TensorPredictionHandler</p>"},{"location":"reference/mlcomponents/predictionhandlers/tensorpredictionhandler/#niceml.mlcomponents.predictionhandlers.tensorpredictionhandler-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/predictionhandlers/tensorpredictionhandler/#niceml.mlcomponents.predictionhandlers.tensorpredictionhandler.TensorPredictionHandler","title":"TensorPredictionHandler","text":"<pre><code>TensorPredictionHandler(\n    immediately_write=False, round_decimals=None\n)\n</code></pre> <p>             Bases: <code>PredictionHandler</code></p> <p>Gets tensors and stores them numpy compressed files</p> Source code in <code>niceml/mlcomponents/predictionhandlers/tensorpredictionhandler.py</code> <pre><code>def __init__(\n    self,\n    immediately_write: bool = False,\n    round_decimals: int = None,\n):\n    super().__init__()\n    self.immediately_write = immediately_write\n    self.should_round = round_decimals is not None\n    self.round_decimals = round_decimals\n    self.data = None\n</code></pre>"},{"location":"reference/mlcomponents/predictionhandlers/tensorpredictionhandler/#niceml.mlcomponents.predictionhandlers.tensorpredictionhandler.TensorPredictionHandler-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/predictionhandlers/tensorpredictionhandler/#niceml.mlcomponents.predictionhandlers.tensorpredictionhandler.TensorPredictionHandler.add_prediction","title":"add_prediction","text":"<pre><code>add_prediction(data_info_list, prediction_batch)\n</code></pre> <p>adds a prediction after processed by the net</p> Source code in <code>niceml/mlcomponents/predictionhandlers/tensorpredictionhandler.py</code> <pre><code>def add_prediction(self, data_info_list: List[DataInfo], prediction_batch):\n    \"\"\"adds a prediction after processed by the net\"\"\"\n    if self.should_round:\n        prediction_batch = np.round(prediction_batch, self.round_decimals)\n    for idx, data_info in enumerate(data_info_list):\n        cur_pred = prediction_batch[idx, :]\n        if self.immediately_write:\n            with open_location(self.exp_context.fs) as (exp_fs, exp_path):\n                with exp_fs.open(\n                    join(\n                        exp_path,\n                        ExperimentFilenames.PREDICTION_FOLDER,\n                        self.filename + \".npy\",\n                    ),\n                    \"wb\",\n                ) as file:\n                    np.save(\n                        file,\n                        cur_pred,\n                    )\n        else:\n            self.data[data_info.get_identifier()] = cur_pred\n</code></pre>"},{"location":"reference/mlcomponents/predictionhandlers/tensorpredictionhandler/#niceml.mlcomponents.predictionhandlers.tensorpredictionhandler.TensorPredictionHandlerZarr","title":"TensorPredictionHandlerZarr","text":"<pre><code>TensorPredictionHandlerZarr(\n    key_seperator=\"\", scale_to_int=False, save_as_int=False\n)\n</code></pre> <p>             Bases: <code>TensorPredictionHandler</code></p> <p>Saves tensors in da compressed Zarr directory. Each tensor is compressed with gzip.</p>"},{"location":"reference/mlcomponents/predictionhandlers/tensorpredictionhandler/#niceml.mlcomponents.predictionhandlers.tensorpredictionhandler.TensorPredictionHandlerZarr--parameters","title":"Parameters","text":"<p>key_seperator: str default \"\"     string which seperates image_location and output type scale_to_int: bool, default False     If true data is multiplied by 255 save_as_int: bool, default False     If true dtype of data is converted to uint8 to save space</p> Source code in <code>niceml/mlcomponents/predictionhandlers/tensorpredictionhandler.py</code> <pre><code>def __init__(\n    self,\n    key_seperator: str = \"\",\n    scale_to_int: bool = False,\n    save_as_int: bool = False,\n):\n    super().__init__()\n    self.save_as_int = save_as_int\n    self.scale_to_int = scale_to_int\n    self.key_seperator = key_seperator\n    self.data = None\n</code></pre>"},{"location":"reference/mlcomponents/predictionhandlers/tensorpredictionhandler/#niceml.mlcomponents.predictionhandlers.tensorpredictionhandler.TensorPredictionHandlerZarr-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/predictionhandlers/tensorpredictionhandler/#niceml.mlcomponents.predictionhandlers.tensorpredictionhandler.TensorPredictionHandlerZarr.add_prediction","title":"add_prediction","text":"<pre><code>add_prediction(data_info_list, prediction_batch)\n</code></pre> <p>adds a prediction after processed by the net</p> Source code in <code>niceml/mlcomponents/predictionhandlers/tensorpredictionhandler.py</code> <pre><code>def add_prediction(self, data_info_list: List[DataInfo], prediction_batch):\n    \"\"\"adds a prediction after processed by the net\"\"\"\n    if isinstance(prediction_batch, list):\n        pred_list = zip(prediction_batch, self.data_description.get_output_names())\n    else:\n        pred_list = [(prediction_batch, \"\")]\n\n    for prediction, suffix in pred_list:\n        if self.scale_to_int:\n            prediction = prediction * 255\n        if self.save_as_int:\n            prediction = prediction.astype(np.uint8)\n        for idx, data_info in enumerate(data_info_list):\n            cur_pred: np.ndarray = prediction[idx, :]\n            # self.data[data_info.file_id] = cur_instance\n            dataset = self.data.create(\n                data_info.get_identifier() + self.key_seperator + suffix,\n                shape=cur_pred.shape,\n                dtype=cur_pred.dtype,\n                compressor=GZip(level=7),\n                chunks=False,\n            )\n            dataset[:] = cur_pred\n</code></pre>"},{"location":"reference/mlcomponents/predictionhandlers/tensorpredictionhandler/#niceml.mlcomponents.predictionhandlers.tensorpredictionhandler-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/predictionhandlers/vectorpredictionhandler/","title":"vectorpredictionhandler","text":""},{"location":"reference/mlcomponents/predictionhandlers/vectorpredictionhandler/#niceml.mlcomponents.predictionhandlers.vectorpredictionhandler","title":"vectorpredictionhandler","text":""},{"location":"reference/mlcomponents/predictionhandlers/vectorpredictionhandler/#niceml.mlcomponents.predictionhandlers.vectorpredictionhandler-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/resultanalyzers/__init__/","title":"resultanalyzers","text":""},{"location":"reference/mlcomponents/resultanalyzers/__init__/#niceml.mlcomponents.resultanalyzers","title":"resultanalyzers","text":""},{"location":"reference/mlcomponents/resultanalyzers/analyzer/","title":"analyzer","text":""},{"location":"reference/mlcomponents/resultanalyzers/analyzer/#niceml.mlcomponents.resultanalyzers.analyzer","title":"analyzer","text":"<p>Module for the ABC ResultAnalyzer</p>"},{"location":"reference/mlcomponents/resultanalyzers/analyzer/#niceml.mlcomponents.resultanalyzers.analyzer-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/resultanalyzers/analyzer/#niceml.mlcomponents.resultanalyzers.analyzer.ResultAnalyzer","title":"ResultAnalyzer","text":"<pre><code>ResultAnalyzer()\n</code></pre> <p>             Bases: <code>ABC</code></p> <p>After the prediction is done all data can be analyzed with a specific implementation of the ResultAnalyzer</p> Source code in <code>niceml/mlcomponents/resultanalyzers/analyzer.py</code> <pre><code>def __init__(self):\n    self.data_description = None\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/analyzer/#niceml.mlcomponents.resultanalyzers.analyzer.ResultAnalyzer-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/resultanalyzers/analyzer/#niceml.mlcomponents.resultanalyzers.analyzer.ResultAnalyzer.__call__","title":"__call__  <code>abstractmethod</code>","text":"<pre><code>__call__(dataset, exp_context, dataset_name)\n</code></pre> <p>Method to analyze one dataset</p> Source code in <code>niceml/mlcomponents/resultanalyzers/analyzer.py</code> <pre><code>@abstractmethod\ndef __call__(\n    self, dataset: Dataset, exp_context: ExperimentContext, dataset_name: str\n):\n    \"\"\"Method to analyze one dataset\"\"\"\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/analyzer/#niceml.mlcomponents.resultanalyzers.analyzer.ResultAnalyzer.initialize","title":"initialize","text":"<pre><code>initialize(data_description)\n</code></pre> <p>Initializes the resultanalyzer and adds the data description</p> Source code in <code>niceml/mlcomponents/resultanalyzers/analyzer.py</code> <pre><code>def initialize(self, data_description: DataDescription):\n    \"\"\"Initializes the resultanalyzer and adds the data description\"\"\"\n    self.data_description = data_description\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/multiresultanalyzer/","title":"multiresultanalyzer","text":""},{"location":"reference/mlcomponents/resultanalyzers/multiresultanalyzer/#niceml.mlcomponents.resultanalyzers.multiresultanalyzer","title":"multiresultanalyzer","text":"<p>Module for MultiResultAnalyzer</p>"},{"location":"reference/mlcomponents/resultanalyzers/multiresultanalyzer/#niceml.mlcomponents.resultanalyzers.multiresultanalyzer-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/resultanalyzers/multiresultanalyzer/#niceml.mlcomponents.resultanalyzers.multiresultanalyzer.MultiResultAnalyzer","title":"MultiResultAnalyzer","text":"<pre><code>MultiResultAnalyzer(analyzers)\n</code></pre> <p>             Bases: <code>ResultAnalyzer</code></p> <p>contains multiple ResultAnalyzer which are called consequently</p> Source code in <code>niceml/mlcomponents/resultanalyzers/multiresultanalyzer.py</code> <pre><code>def __init__(self, analyzers: List[ResultAnalyzer]):\n    super().__init__()\n    self.analyzers: List[ResultAnalyzer] = analyzers\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/dataframes/__init__/","title":"dataframes","text":""},{"location":"reference/mlcomponents/resultanalyzers/dataframes/__init__/#niceml.mlcomponents.resultanalyzers.dataframes","title":"dataframes","text":""},{"location":"reference/mlcomponents/resultanalyzers/dataframes/clsmetric/","title":"clsmetric","text":""},{"location":"reference/mlcomponents/resultanalyzers/dataframes/clsmetric/#niceml.mlcomponents.resultanalyzers.dataframes.clsmetric","title":"clsmetric","text":"<p>Module for clsmetric</p>"},{"location":"reference/mlcomponents/resultanalyzers/dataframes/clsmetric/#niceml.mlcomponents.resultanalyzers.dataframes.clsmetric-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/resultanalyzers/dataframes/clsmetric/#niceml.mlcomponents.resultanalyzers.dataframes.clsmetric.ClsMetric","title":"ClsMetric","text":"<pre><code>ClsMetric(\n    source_col,\n    target_cols_prefix,\n    function=\"accuracy\",\n    name_suffix=\"\",\n    use_multitarget=False,\n    use_probabilities=False,\n)\n</code></pre> <p>             Bases: <code>DfMetric</code></p> <p>Let's use calculate arbitrary classification metrics as part of the DataframeAnalyzer(ResultAnalyzer).</p>"},{"location":"reference/mlcomponents/resultanalyzers/dataframes/clsmetric/#niceml.mlcomponents.resultanalyzers.dataframes.clsmetric.ClsMetric--parameters","title":"Parameters","text":"<p>source_col: str     name of the column with the class     index or indexes (multitarget) target_cols_prefix: str     starting name of the columns     containing the output of the model function: str or dict, default \"accuracy\"     function to calculate the metric.     If str is given it must be a key of the <code>cl_metric_dict</code>.     Otherwise the given dict is initialized with     <code>init_object</code> and additional the key <code>name</code>     must be available to define the     output name in the result dict. name_suffix: str, default \"\"     can be used to add a str to the dict     output name (e.g. if the same metric should be applied     to multiple columns) use_multitarget: bool, default false     allows to be more than one class present per sample use_probabilities: bool, default false     if this is set true then the values are     not binarized before calculating the metric function</p> Source code in <code>niceml/mlcomponents/resultanalyzers/dataframes/clsmetric.py</code> <pre><code>def __init__(\n    self,\n    source_col: str,\n    target_cols_prefix: str,\n    function: Union[str, dict] = \"accuracy\",\n    name_suffix: str = \"\",\n    use_multitarget: bool = False,\n    use_probabilities: bool = False,\n):\n    \"\"\"\n    Let's use calculate arbitrary classification\n    metrics as part of the DataframeAnalyzer(ResultAnalyzer).\n\n    Parameters\n    ----------\n    source_col: str\n        name of the column with the class\n        index or indexes (multitarget)\n    target_cols_prefix: str\n        starting name of the columns\n        containing the output of the model\n    function: str or dict, default \"accuracy\"\n        function to calculate the metric.\n        If str is given it must be a key of the `cl_metric_dict`.\n        Otherwise the given dict is initialized with\n        `init_object` and additional the key `name`\n        must be available to define the\n        output name in the result dict.\n    name_suffix: str, default \"\"\n        can be used to add a str to the dict\n        output name (e.g. if the same metric should be applied\n        to multiple columns)\n    use_multitarget: bool, default false\n        allows to be more than one class present per sample\n    use_probabilities: bool, default false\n        if this is set true then the values are\n        not binarized before calculating the metric function\n    \"\"\"\n    self.source_col = source_col\n    self.target_cols_prefix = target_cols_prefix\n    self.multi_target = use_multitarget\n    self.name_suffix = name_suffix\n    self.use_probabilities = use_probabilities\n    if type(function) is str:\n        self.func_name = function\n        try:\n            self.function = cl_metric_dict[function]\n        except KeyError as e:\n            raise Exception(\n                f\"Function with name {function} not \"\n                f\"supported! Available: {list(cl_metric_dict.keys())}\"\n            ) from e\n    else:\n        self.func_name = function[\"name\"]\n        self.function = function[\"target\"]\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/dataframes/clsmetric/#niceml.mlcomponents.resultanalyzers.dataframes.clsmetric.ClsMetric-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/resultanalyzers/dataframes/dfanalyzer/","title":"dfanalyzer","text":""},{"location":"reference/mlcomponents/resultanalyzers/dataframes/dfanalyzer/#niceml.mlcomponents.resultanalyzers.dataframes.dfanalyzer","title":"dfanalyzer","text":"<p>Module for DataframeAnalyzer and DfMetric</p>"},{"location":"reference/mlcomponents/resultanalyzers/dataframes/dfanalyzer/#niceml.mlcomponents.resultanalyzers.dataframes.dfanalyzer-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/resultanalyzers/dataframes/dfanalyzer/#niceml.mlcomponents.resultanalyzers.dataframes.dfanalyzer.DataframeAnalyzer","title":"DataframeAnalyzer","text":"<pre><code>DataframeAnalyzer(metrics, parq_file_prefix='')\n</code></pre> <p>             Bases: <code>ResultAnalyzer</code></p> <p>Result analyzer for dataframes</p> <p>Initialize a result analyzer for dataframes</p> Source code in <code>niceml/mlcomponents/resultanalyzers/dataframes/dfanalyzer.py</code> <pre><code>def __init__(\n    self,\n    metrics: List[DfMetric],\n    parq_file_prefix: str = \"\",\n):\n    \"\"\"Initialize a result analyzer for dataframes\"\"\"\n\n    super().__init__()\n    self.parq_file_prefix = parq_file_prefix\n    self.df_metrics: List[DfMetric] = metrics\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/dataframes/dfanalyzer/#niceml.mlcomponents.resultanalyzers.dataframes.dfanalyzer.DataframeAnalyzer-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/resultanalyzers/dataframes/dfanalyzer/#niceml.mlcomponents.resultanalyzers.dataframes.dfanalyzer.DataframeAnalyzer.__call__","title":"__call__","text":"<pre><code>__call__(dataset, exp_context, subset_name)\n</code></pre> <p>Calculate values of the metrics in <code>self.metrics</code> and save them into a csv file.</p> <p>Parameters:</p> <ul> <li> <code>dataset</code>         \u2013          <p>Dataset of the experiment. Not used in this function</p> </li> <li> <code>exp_context</code>             (<code>ExperimentContext</code>)         \u2013          <p>Current <code>ExperimentContext</code> to read and write files</p> </li> <li> <code>subset_name</code>             (<code>str</code>)         \u2013          <p>Name the subset</p> </li> </ul> Source code in <code>niceml/mlcomponents/resultanalyzers/dataframes/dfanalyzer.py</code> <pre><code>def __call__(self, dataset, exp_context: ExperimentContext, subset_name: str):\n    \"\"\"\n    Calculate values of the metrics in `self.metrics` and save them into a csv file.\n\n    Args:\n        dataset: Dataset of the experiment. Not used in this function\n        exp_context: Current `ExperimentContext` to read and write files\n        subset_name: Name the subset\n\n    \"\"\"\n    input_file: str = join(\n        ExperimentFilenames.PREDICTION_FOLDER,\n        f\"{self.parq_file_prefix}{subset_name}.parq\",\n    )\n    data_frame = exp_context.read_parquet(input_file)\n\n    output_file = join(\n        ExperimentFilenames.ANALYSIS_FOLDER,\n        ExperimentFilenames.ANALYSIS_FILE.format(subset_name=subset_name),\n    )\n\n    out_dict = {}\n    for met in self.df_metrics:\n        out_dict.update(met(data_frame, exp_context, subset_name))\n\n    log_str = f\"{basename(output_file)}\\n\" f\"========================\\n\"\n\n    log_str += get_logstr_from_dict(out_dict)\n    logging.getLogger(__name__).info(log_str)\n\n    mlflow.log_dict(out_dict, output_file)\n    exp_context.write_yaml(out_dict, output_file)\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/dataframes/dfanalyzer/#niceml.mlcomponents.resultanalyzers.dataframes.dfanalyzer.DataframeAnalyzer.initialize","title":"initialize","text":"<pre><code>initialize(data_description)\n</code></pre> <p>The initialize function initialized the metrics in <code>self.metrics</code> This function is called once before the first call to the evaluate function. It can be used to initialize any variables that are needed for evaluation. The data_description parameter contains information about the data set, such as number of classes and feature names.</p> <p>Parameters:</p> <ul> <li> <code>data_description</code>             (<code>DataDescription</code>)         \u2013          <p><code>DataDescription</code> used to initialize instances of                 this class and the metrics</p> </li> </ul> Source code in <code>niceml/mlcomponents/resultanalyzers/dataframes/dfanalyzer.py</code> <pre><code>def initialize(self, data_description: DataDescription):\n    \"\"\"\n    The initialize function initialized the metrics in `self.metrics`\n    This function is called once before the first call to the\n    evaluate function. It can be used to initialize any variables that are needed\n    for evaluation. The data_description parameter contains information about the\n    data set, such as number of classes and feature names.\n\n    Args:\n        data_description: `DataDescription` used to initialize instances of\n                            this class and the metrics\n    \"\"\"\n    super().initialize(data_description)\n    for cur_metric in self.df_metrics:\n        cur_metric.initialize(data_description)\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/dataframes/dfanalyzer/#niceml.mlcomponents.resultanalyzers.dataframes.dfanalyzer.DfMetric","title":"DfMetric","text":"<p>             Bases: <code>ABC</code></p> <p>metric of a dataframe</p>"},{"location":"reference/mlcomponents/resultanalyzers/dataframes/dfanalyzer/#niceml.mlcomponents.resultanalyzers.dataframes.dfanalyzer.DfMetric-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/resultanalyzers/dataframes/dfanalyzer/#niceml.mlcomponents.resultanalyzers.dataframes.dfanalyzer.DfMetric.__call__","title":"__call__  <code>abstractmethod</code>","text":"<pre><code>__call__(data, exp_context, dataset_name)\n</code></pre> <p>Calculates the metric for the given data and returns a dict with the results</p> Source code in <code>niceml/mlcomponents/resultanalyzers/dataframes/dfanalyzer.py</code> <pre><code>@abstractmethod\ndef __call__(\n    self, data: pd.DataFrame, exp_context: ExperimentContext, dataset_name: str\n) -&gt; dict:\n    \"\"\"Calculates the metric for the given data and returns a dict with the results\"\"\"\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/dataframes/dfanalyzer/#niceml.mlcomponents.resultanalyzers.dataframes.dfanalyzer.DfMetric.initialize","title":"initialize","text":"<pre><code>initialize(data_description)\n</code></pre> <p>Initializes the metric with a data_description</p> Source code in <code>niceml/mlcomponents/resultanalyzers/dataframes/dfanalyzer.py</code> <pre><code>def initialize(self, data_description: DataDescription):\n    \"\"\"Initializes the metric with a data_description\"\"\"\n    self.data_description = data_description\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/dataframes/dfanalyzer/#niceml.mlcomponents.resultanalyzers.dataframes.dfanalyzer-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/resultanalyzers/dataframes/multilabeltobinary/","title":"multilabeltobinary","text":""},{"location":"reference/mlcomponents/resultanalyzers/dataframes/multilabeltobinary/#niceml.mlcomponents.resultanalyzers.dataframes.multilabeltobinary","title":"multilabeltobinary","text":""},{"location":"reference/mlcomponents/resultanalyzers/dataframes/multilabeltobinary/#niceml.mlcomponents.resultanalyzers.dataframes.multilabeltobinary-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/resultanalyzers/dataframes/multilabeltobinary/#niceml.mlcomponents.resultanalyzers.dataframes.multilabeltobinary.MultilabelBinaryMetric","title":"MultilabelBinaryMetric","text":"<pre><code>MultilabelBinaryMetric(\n    source_col,\n    target_cols_prefix,\n    positive_indexes,\n    lower_thres=0.5,\n    function=\"accuracy\",\n    name_suffix=\"\",\n)\n</code></pre> <p>             Bases: <code>DfMetric</code></p> <p>Converts a multilabel classification problem to a binary. Uses the <code>positive_indexes</code> class as positive class. If any of these class indexes is higher than <code>threshold</code> it is counted as positive class and negative otherwise.</p>"},{"location":"reference/mlcomponents/resultanalyzers/dataframes/multilabeltobinary/#niceml.mlcomponents.resultanalyzers.dataframes.multilabeltobinary.MultilabelBinaryMetric--parameters","title":"Parameters","text":"<p>source_col: str     name of the column with the class index or indexes (multitarget) target_cols_prefix: str     starting name of the columns containing the output of the model positive_indexes: List[int]     indexes of the positive classes.     Has to be match with the index in <code>classes</code> in the     datasets.yml -&gt; data_description lower_thres: float, default 0.5     lower threshold for the positive classes to be counted as true function: str or dict, default \"accuracy\"     function to calculate the metric.     If str is given it must be a key of the <code>cl_metric_dict</code>.     Otherwise the given dict is initialized with <code>init_object</code>     and additional the key <code>name</code>     must be available to define the output     name in the result dict. name_suffix: str, default \"\"     can be used to add a str to the dict output name     (e.g. if the same metric should be applied     to multiple columns)</p> Source code in <code>niceml/mlcomponents/resultanalyzers/dataframes/multilabeltobinary.py</code> <pre><code>def __init__(\n    self,\n    source_col: str,\n    target_cols_prefix: str,\n    positive_indexes: List[int],\n    lower_thres: float = 0.5,\n    function: Union[str, dict] = \"accuracy\",\n    name_suffix: str = \"\",\n):\n    \"\"\"\n    Converts a multilabel classification problem to a binary.\n    Uses the `positive_indexes` class as positive class.\n    If any of these class indexes is higher than `threshold`\n    it is counted as positive class and negative otherwise.\n\n    Parameters\n    ----------\n    source_col: str\n        name of the column with the class index or indexes (multitarget)\n    target_cols_prefix: str\n        starting name of the columns containing the output of the model\n    positive_indexes: List[int]\n        indexes of the positive classes.\n        Has to be match with the index in `classes` in the\n        datasets.yml -&gt; data_description\n    lower_thres: float, default 0.5\n        lower threshold for the positive classes to be counted as true\n    function: str or dict, default \"accuracy\"\n        function to calculate the metric.\n        If str is given it must be a key of the `cl_metric_dict`.\n        Otherwise the given dict is initialized with `init_object`\n        and additional the key `name`\n        must be available to define the output\n        name in the result dict.\n    name_suffix: str, default \"\"\n        can be used to add a str to the dict output name\n        (e.g. if the same metric should be applied\n        to multiple columns)\n    \"\"\"\n    self.source_col = source_col\n    self.target_cols_prefix = target_cols_prefix\n    self.name_suffix = name_suffix\n    self.positive_indexes = positive_indexes\n    self.lower_thres = lower_thres\n    if type(function) is str:\n        self.func_name = function\n        try:\n            self.function = cl_metric_dict[function]\n        except KeyError as e:\n            raise Exception(\n                f\"Function with name {function} not supported!\"\n                f\" Available: {list(cl_metric_dict.keys())}\"\n            ) from e\n    else:\n        self.func_name = function[\"name\"]\n        self.function = function[\"target\"]\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/dataframes/multilabeltobinary/#niceml.mlcomponents.resultanalyzers.dataframes.multilabeltobinary.MultilabelBinaryMetric-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/resultanalyzers/dataframes/regmetric/","title":"regmetric","text":""},{"location":"reference/mlcomponents/resultanalyzers/dataframes/regmetric/#niceml.mlcomponents.resultanalyzers.dataframes.regmetric","title":"regmetric","text":"<p>Module for regression metric</p>"},{"location":"reference/mlcomponents/resultanalyzers/dataframes/regmetric/#niceml.mlcomponents.resultanalyzers.dataframes.regmetric-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/resultanalyzers/dataframes/regmetric/#niceml.mlcomponents.resultanalyzers.dataframes.regmetric.RegMetric","title":"RegMetric","text":"<pre><code>RegMetric(\n    source_col,\n    target_col,\n    function_name,\n    function,\n    normalization_file=\"external_infos/normalization_info.yml\",\n)\n</code></pre> <p>             Bases: <code>DfMetric</code></p> <p>Regression metric for dataframes</p> <p>This class let's you calculate arbitrary regression metrics. It could be integrated as DfMetric in the DataframeAnalyzer(ResultAnalyzer).</p>"},{"location":"reference/mlcomponents/resultanalyzers/dataframes/regmetric/#niceml.mlcomponents.resultanalyzers.dataframes.regmetric.RegMetric--parameters","title":"Parameters","text":"<p>source_col: str     column name in the dataframe where the ground truth is stored. target_col: str     column name where the predictions are stored function: str or dict     function to calculate the metric.     If str is given it must be a key of the metric dict.     Otherwise the given dict is initialized with <code>init_object</code>      and additional the key <code>name</code>     must be available to define the     output name in the result dict. function_name: str     Name of the function normalization_file: str, default \"normalization_info.yml\"     This is a image_location relative to the experiment     output folder. If a key exists with the same     name as <code>source_col</code> the metric result is     normalized and additionaly stored.</p> Source code in <code>niceml/mlcomponents/resultanalyzers/dataframes/regmetric.py</code> <pre><code>def __init__(  # pylint: disable = too-many-arguments\n    self,\n    source_col: str,\n    target_col: str,\n    function_name: str,\n    function: Union[str, Callable],\n    normalization_file: str = \"external_infos/normalization_info.yml\",\n):\n    \"\"\"\n    This class let's you calculate arbitrary\n    regression metrics. It could be integrated\n    as DfMetric in the DataframeAnalyzer(ResultAnalyzer).\n\n    Parameters\n    ----------\n    source_col: str\n        column name in the dataframe where the ground truth is stored.\n    target_col: str\n        column name where the predictions are stored\n    function: str or dict\n        function to calculate the metric.\n        If str is given it must be a key of the metric dict.\n        Otherwise the given dict is initialized with `init_object`\n         and additional the key `name`\n        must be available to define the\n        output name in the result dict.\n    function_name: str\n        Name of the function\n    normalization_file: str, default \"normalization_info.yml\"\n        This is a image_location relative to the experiment\n        output folder. If a key exists with the same\n        name as `source_col` the metric result is\n        normalized and additionaly stored.\n    \"\"\"\n    self.source_col = source_col\n    self.target_col = target_col\n    self.normalization_file: str = normalization_file\n    self.func_name = function_name\n    if isinstance(function, str):\n        try:\n            self.function = metric_dict[function]\n        except KeyError as error:\n            raise Exception(\n                f\"Function with name {function}\"\n                f\" not supported! Available: {list(metric_dict.keys())}\"\n            ) from error\n    else:\n        self.function = function\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/dataframes/regmetric/#niceml.mlcomponents.resultanalyzers.dataframes.regmetric.RegMetric-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/resultanalyzers/instancefinders/__init__/","title":"instancefinders","text":""},{"location":"reference/mlcomponents/resultanalyzers/instancefinders/__init__/#niceml.mlcomponents.resultanalyzers.instancefinders","title":"instancefinders","text":""},{"location":"reference/mlcomponents/resultanalyzers/instancefinders/instancecontour/","title":"instancecontour","text":""},{"location":"reference/mlcomponents/resultanalyzers/instancefinders/instancecontour/#niceml.mlcomponents.resultanalyzers.instancefinders.instancecontour","title":"instancecontour","text":"<p>Module for data classes representing the found error instances in a predicted image</p>"},{"location":"reference/mlcomponents/resultanalyzers/instancefinders/instancecontour/#niceml.mlcomponents.resultanalyzers.instancefinders.instancecontour-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/resultanalyzers/instancefinders/instancecontour/#niceml.mlcomponents.resultanalyzers.instancefinders.instancecontour.InstanceContour","title":"InstanceContour  <code>dataclass</code>","text":"<p>Dataclass that represents a instance contour.</p>"},{"location":"reference/mlcomponents/resultanalyzers/instancefinders/instancecontour/#niceml.mlcomponents.resultanalyzers.instancefinders.instancecontour.InstanceContour-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/resultanalyzers/instancefinders/instancecontour/#niceml.mlcomponents.resultanalyzers.instancefinders.instancecontour.InstanceContour.get_contour_mask","title":"get_contour_mask","text":"<pre><code>get_contour_mask(target_shape)\n</code></pre> <p>Creates a Mask from <code>self.contour with</code>target_shape` Args:     target_shape: Shape of the mask</p> <p>Returns:</p> <ul> <li> <code>ndarray</code>         \u2013          <p>Mask with <code>self.contour</code> on it and the form <code>target_shape</code>.</p> </li> </ul> Source code in <code>niceml/mlcomponents/resultanalyzers/instancefinders/instancecontour.py</code> <pre><code>def get_contour_mask(\n    self, target_shape: Union[ImageSize, Tuple[int, int]]\n) -&gt; np.ndarray:\n    \"\"\"\n    Creates a Mask from `self.contour with `target_shape`\n    Args:\n        target_shape: Shape of the mask\n\n    Returns:\n        Mask with `self.contour` on it and the form `target_shape`.\n    \"\"\"\n\n    target_shape = (\n        target_shape.to_numpy_shape()\n        if isinstance(target_shape, ImageSize)\n        else target_shape\n    )\n    mask = np.zeros(shape=target_shape)\n    mask = cv2.drawContours(\n        mask,\n        [self.contour],\n        -1,\n        color=(255,),\n        thickness=cv2.FILLED,\n    )\n    return mask\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/instancefinders/instancecontour/#niceml.mlcomponents.resultanalyzers.instancefinders.instancecontour.InstanceContour.intersects_mask","title":"intersects_mask","text":"<pre><code>intersects_mask(mask)\n</code></pre> <p>Check if <code>self.contour</code> intersect with <code>mask</code>.</p> <p>Parameters:</p> <ul> <li> <code>mask</code>             (<code>ndarray</code>)         \u2013          <p>mask to check for intersection</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>bool</code>         \u2013          <p>True if there is an intersection</p> </li> </ul> Source code in <code>niceml/mlcomponents/resultanalyzers/instancefinders/instancecontour.py</code> <pre><code>def intersects_mask(self, mask: np.ndarray) -&gt; bool:\n    \"\"\"\n    Check if `self.contour` intersect with `mask`.\n\n    Args:\n        mask: mask to check for intersection\n\n    Returns:\n        True if there is an intersection\n\n    \"\"\"\n\n    defect_mask = np.zeros_like(mask)\n    cv2.drawContours(\n        defect_mask, [self.contour], -1, color=(1,), thickness=cv2.FILLED\n    )\n    intersect = np.logical_and(mask, defect_mask)\n    return np.any(intersect)\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/instancefinders/instancefinder/","title":"instancefinder","text":""},{"location":"reference/mlcomponents/resultanalyzers/instancefinders/instancefinder/#niceml.mlcomponents.resultanalyzers.instancefinders.instancefinder","title":"instancefinder","text":"<p>Module of the abstract InstanceFinder</p>"},{"location":"reference/mlcomponents/resultanalyzers/instancefinders/instancefinder/#niceml.mlcomponents.resultanalyzers.instancefinders.instancefinder-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/resultanalyzers/instancefinders/instancefinder/#niceml.mlcomponents.resultanalyzers.instancefinders.instancefinder.InstanceFinder","title":"InstanceFinder","text":"<pre><code>InstanceFinder(key, min_area, max_area, threshold)\n</code></pre> <p>             Bases: <code>TensorMetric</code>, <code>ABC</code></p> <p>Abstract class of an instance finder that finds error instances in a mask.</p> Source code in <code>niceml/mlcomponents/resultanalyzers/instancefinders/instancefinder.py</code> <pre><code>def __init__(\n    self,\n    key: str,\n    min_area: int,\n    max_area: int,\n    threshold: float,\n):\n    super().__init__(key=key)\n    self.threshold = threshold\n    self.max_area = max_area\n    self.min_area = min_area\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/instancefinders/maskinstance/","title":"maskinstance","text":""},{"location":"reference/mlcomponents/resultanalyzers/instancefinders/maskinstance/#niceml.mlcomponents.resultanalyzers.instancefinders.maskinstance","title":"maskinstance","text":"<p>Module of the MaskInstance that represents an error instance derived from a prediction mask</p>"},{"location":"reference/mlcomponents/resultanalyzers/instancefinders/maskinstance/#niceml.mlcomponents.resultanalyzers.instancefinders.maskinstance-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/resultanalyzers/instancefinders/maskinstance/#niceml.mlcomponents.resultanalyzers.instancefinders.maskinstance.MaskInstance","title":"MaskInstance  <code>dataclass</code>","text":"<p>Dataclass with infos about an error (instance) found on a predicted image.</p>"},{"location":"reference/mlcomponents/resultanalyzers/instancefinders/maskinstance/#niceml.mlcomponents.resultanalyzers.instancefinders.maskinstance.MaskInstance-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/resultanalyzers/instancefinders/maskinstance/#niceml.mlcomponents.resultanalyzers.instancefinders.maskinstance.MaskInstance.to_semseg_instance_label","title":"to_semseg_instance_label","text":"<pre><code>to_semseg_instance_label(data_description)\n</code></pre> <p>Transform this <code>MaskInstance</code> into a <code>SemSegInstanceLabel</code> Args:     data_description: Data description to get the class name of <code>self.instance_class_idx</code></p> <p>Returns:</p> <ul> <li> <code>List[SemSegInstanceLabel]</code>         \u2013          <p>Created <code>SemSegInstanceLabel</code></p> </li> </ul> Source code in <code>niceml/mlcomponents/resultanalyzers/instancefinders/maskinstance.py</code> <pre><code>def to_semseg_instance_label(\n    self, data_description: OutputImageDataDescription\n) -&gt; List[SemSegInstanceLabel]:\n    \"\"\"\n    Transform this `MaskInstance` into a `SemSegInstanceLabel`\n    Args:\n        data_description: Data description to get the class name of `self.instance_class_idx`\n\n    Returns:\n        Created `SemSegInstanceLabel`\n    \"\"\"\n    if self.instance_class_idx is None:\n        raise ValueError(\"self.instance_class_idx is None\")\n\n    instance_labels = [\n        SemSegInstanceLabel(\n            class_name=data_description.get_output_channel_names()[\n                self.instance_class_idx\n            ],\n            class_index=self.instance_class_idx,\n            mask=error.get_contour_mask(\n                target_shape=data_description.get_output_image_size()\n            ),\n        )\n        for error in self.instance_contours\n    ]\n    return instance_labels\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/instancefinders/multichannelinstancefinder/","title":"multichannelinstancefinder","text":""},{"location":"reference/mlcomponents/resultanalyzers/instancefinders/multichannelinstancefinder/#niceml.mlcomponents.resultanalyzers.instancefinders.multichannelinstancefinder","title":"multichannelinstancefinder","text":"<p>Module for the multichannel instance finder</p>"},{"location":"reference/mlcomponents/resultanalyzers/instancefinders/multichannelinstancefinder/#niceml.mlcomponents.resultanalyzers.instancefinders.multichannelinstancefinder-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/resultanalyzers/instancefinders/multichannelinstancefinder/#niceml.mlcomponents.resultanalyzers.instancefinders.multichannelinstancefinder.MultiChannelInstanceFinder","title":"MultiChannelInstanceFinder","text":"<pre><code>MultiChannelInstanceFinder(\n    key=\"multichannelinstancefinder\",\n    min_area=10,\n    max_area=2000000,\n    threshold=0.5,\n)\n</code></pre> <p>             Bases: <code>InstanceFinder</code></p> <p>Instance finder for SemSeg predictions with more than one channel (classes).</p> Source code in <code>niceml/mlcomponents/resultanalyzers/instancefinders/multichannelinstancefinder.py</code> <pre><code>def __init__(\n    self,\n    key: str = \"multichannelinstancefinder\",\n    min_area: int = 10,\n    max_area: int = 2000000,\n    threshold: float = 0.5,\n):\n    super().__init__(\n        key=key,\n        min_area=min_area,\n        max_area=max_area,\n        threshold=threshold,\n    )\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/instancefinders/multichannelinstancefinder/#niceml.mlcomponents.resultanalyzers.instancefinders.multichannelinstancefinder.MultiChannelInstanceFinder-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/resultanalyzers/instancefinders/multichannelinstancefinder/#niceml.mlcomponents.resultanalyzers.instancefinders.multichannelinstancefinder.MultiChannelInstanceFinder.analyse_datapoint","title":"analyse_datapoint","text":"<pre><code>analyse_datapoint(\n    data_key,\n    data_predicted,\n    data_loaded=None,\n    additional_data=None,\n    dyn_threshold=None,\n    **kwargs\n)\n</code></pre> <p>extract information about multiple predicted errors (instances) from multichannel image. The dynamic threshold can be used to override the threshold</p> Source code in <code>niceml/mlcomponents/resultanalyzers/instancefinders/multichannelinstancefinder.py</code> <pre><code>def analyse_datapoint(\n    self,\n    data_key: str,\n    data_predicted: SemSegPredictionContainer,\n    data_loaded: Optional[DataInfo] = None,\n    additional_data: Optional[dict] = None,\n    dyn_threshold: Optional[float] = None,\n    **kwargs,\n) -&gt; Optional[Any]:\n    \"\"\"extract information about multiple predicted errors\n    (instances) from multichannel image.\n    The dynamic threshold can be used to override the threshold\"\"\"\n\n    dyn_threshold = dyn_threshold or self.threshold\n    binarize_multichannel_images, _ = binarize_multichannel_image(\n        image_index=data_predicted.max_prediction_idxes,\n        image_scores=data_predicted.max_prediction_values,\n        threshold=dyn_threshold,\n    )\n    mask_instances: List[MaskInstance] = []\n\n    for class_idx, curr_binary_img in binarize_multichannel_images.items():\n        instance_contours = find_contours_in_binary_image(\n            binary_image=curr_binary_img.astype(np.uint8),\n            min_area=self.min_area,\n            max_area=self.max_area,\n        )\n        instance_contours = [\n            InstanceContour(\n                contour=error_contour,\n                class_idx=int(float(class_idx)),\n            )\n            for error_contour in instance_contours\n        ]\n        mask_instance = MaskInstance(\n            mask=curr_binary_img,\n            instance_contours=instance_contours,\n            instance_class_idx=int(float(class_idx)),\n        )\n        mask_instances.append(mask_instance)\n\n    return mask_instances\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/instancefinders/multichannelinstancefinder/#niceml.mlcomponents.resultanalyzers.instancefinders.multichannelinstancefinder.MultiChannelInstanceFinder.get_final_metric","title":"get_final_metric","text":"<pre><code>get_final_metric()\n</code></pre> <p>returns empty dict</p> Source code in <code>niceml/mlcomponents/resultanalyzers/instancefinders/multichannelinstancefinder.py</code> <pre><code>def get_final_metric(self) -&gt; Optional[dict]:\n    \"\"\"returns empty dict\"\"\"\n    return {}\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/instancefinders/multichannelinstancefinder/#niceml.mlcomponents.resultanalyzers.instancefinders.multichannelinstancefinder-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/resultanalyzers/tensors/__init__/","title":"tensors","text":""},{"location":"reference/mlcomponents/resultanalyzers/tensors/__init__/#niceml.mlcomponents.resultanalyzers.tensors","title":"tensors","text":""},{"location":"reference/mlcomponents/resultanalyzers/tensors/semsegdataiterator/","title":"semsegdataiterator","text":""},{"location":"reference/mlcomponents/resultanalyzers/tensors/semsegdataiterator/#niceml.mlcomponents.resultanalyzers.tensors.semsegdataiterator","title":"semsegdataiterator","text":"<p>Module for semseg prediction container and data handler</p>"},{"location":"reference/mlcomponents/resultanalyzers/tensors/semsegdataiterator/#niceml.mlcomponents.resultanalyzers.tensors.semsegdataiterator-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/resultanalyzers/tensors/semsegdataiterator/#niceml.mlcomponents.resultanalyzers.tensors.semsegdataiterator.SemSegDataIterator","title":"SemSegDataIterator","text":"<pre><code>SemSegDataIterator(\n    supported_extensions=None, prediction_suffix=\"_pred\"\n)\n</code></pre> <p>             Bases: <code>TensordataIterator</code></p> <p>Data Iterator for SemSeg</p> Source code in <code>niceml/mlcomponents/resultanalyzers/tensors/semsegdataiterator.py</code> <pre><code>def __init__(\n    self,\n    supported_extensions: Optional[List[str]] = None,\n    prediction_suffix: str = \"_pred\",\n):\n    if supported_extensions is None:\n        self.supported_extensions = [\".png\", \".jpg\", \".jpeg\", \".tiff\", \".bmp\"]\n    self.data: Optional[dict] = None\n    self.prediction_suffix = prediction_suffix\n    self.file_system: Optional[AbstractFileSystem] = None\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/tensors/semsegdataiterator/#niceml.mlcomponents.resultanalyzers.tensors.semsegdataiterator.SemSegPredictionContainer","title":"SemSegPredictionContainer  <code>dataclass</code>","text":"<p>Contains information about maximum prediction of an image</p>"},{"location":"reference/mlcomponents/resultanalyzers/tensors/semsegdataiterator/#niceml.mlcomponents.resultanalyzers.tensors.semsegdataiterator-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensordataiterators/","title":"tensordataiterators","text":""},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensordataiterators/#niceml.mlcomponents.resultanalyzers.tensors.tensordataiterators","title":"tensordataiterators","text":"<p>Module for tensordataiterator</p>"},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensordataiterators/#niceml.mlcomponents.resultanalyzers.tensors.tensordataiterators-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensordataiterators/#niceml.mlcomponents.resultanalyzers.tensors.tensordataiterators.TensordataIterator","title":"TensordataIterator","text":"<p>             Bases: <code>ABC</code></p> <p>TensordataIterators are used in the tensoranalyser to load and iterate over the data.</p>"},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensordataiterators/#niceml.mlcomponents.resultanalyzers.tensors.tensordataiterators.TensordataIterator-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensordataiterators/#niceml.mlcomponents.resultanalyzers.tensors.tensordataiterators.TensordataIterator.__getitem__","title":"__getitem__  <code>abstractmethod</code>","text":"<pre><code>__getitem__(item)\n</code></pre> <p>Access to an specific item</p> Source code in <code>niceml/mlcomponents/resultanalyzers/tensors/tensordataiterators.py</code> <pre><code>@abstractmethod\ndef __getitem__(self, item):\n    \"\"\"Access to an specific item\"\"\"\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensordataiterators/#niceml.mlcomponents.resultanalyzers.tensors.tensordataiterators.TensordataIterator.__iter__","title":"__iter__  <code>abstractmethod</code>","text":"<pre><code>__iter__()\n</code></pre> <p>Returning an iterator</p> Source code in <code>niceml/mlcomponents/resultanalyzers/tensors/tensordataiterators.py</code> <pre><code>@abstractmethod\ndef __iter__(self):\n    \"\"\"Returning an iterator\"\"\"\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensordataiterators/#niceml.mlcomponents.resultanalyzers.tensors.tensordataiterators.TensordataIterator.open","title":"open  <code>abstractmethod</code>","text":"<pre><code>open(path, file_system=None)\n</code></pre> <p>Method to start with before using the iterator</p> Source code in <code>niceml/mlcomponents/resultanalyzers/tensors/tensordataiterators.py</code> <pre><code>@abstractmethod\ndef open(self, path: str, file_system: Optional[AbstractFileSystem] = None):\n    \"\"\"Method to start with before using the iterator\"\"\"\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensordfmetricwrapper/","title":"tensordfmetricwrapper","text":""},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensordfmetricwrapper/#niceml.mlcomponents.resultanalyzers.tensors.tensordfmetricwrapper","title":"tensordfmetricwrapper","text":"<p>Module for TensorDfMetricWrapper</p>"},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensordfmetricwrapper/#niceml.mlcomponents.resultanalyzers.tensors.tensordfmetricwrapper-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensordfmetricwrapper/#niceml.mlcomponents.resultanalyzers.tensors.tensordfmetricwrapper.TensorDfMetricWrapper","title":"TensorDfMetricWrapper","text":"<pre><code>TensorDfMetricWrapper(\n    key, df_metric_list, parquet_filename\n)\n</code></pre> <p>             Bases: <code>TensorMetric</code></p> <p>Wrapper for TensorMetric to include dataframe metrics</p> Source code in <code>niceml/mlcomponents/resultanalyzers/tensors/tensordfmetricwrapper.py</code> <pre><code>def __init__(self, key: str, df_metric_list: List[DfMetric], parquet_filename: str):\n    super().__init__(key=key)\n    self.df_metric_list = df_metric_list\n\n    if \".\" in parquet_filename:\n        module_name, class_name, filename = parquet_filename.rsplit(\".\", 2)\n        module_name_object = importlib.import_module(module_name)\n        parquet_filename = getattr(\n            getattr(module_name_object, class_name), filename\n        ).value\n    if \".parq\" not in parquet_filename:\n        parquet_filename = f\"{parquet_filename}.parq\"\n\n    self.parquet_filename = parquet_filename\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensordfmetricwrapper/#niceml.mlcomponents.resultanalyzers.tensors.tensordfmetricwrapper.TensorDfMetricWrapper-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensordfmetricwrapper/#niceml.mlcomponents.resultanalyzers.tensors.tensordfmetricwrapper.TensorDfMetricWrapper.analyse_datapoint","title":"analyse_datapoint","text":"<pre><code>analyse_datapoint(\n    data_key,\n    data_predicted,\n    data_loaded,\n    additional_data,\n    **kwargs\n)\n</code></pre> <p>Not required due to dataframe analysis</p> Source code in <code>niceml/mlcomponents/resultanalyzers/tensors/tensordfmetricwrapper.py</code> <pre><code>def analyse_datapoint(\n    self,\n    data_key: str,\n    data_predicted,\n    data_loaded,\n    additional_data: dict,\n    **kwargs,\n) -&gt; Optional[Any]:\n    \"\"\"Not required due to dataframe analysis\"\"\"\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensordfmetricwrapper/#niceml.mlcomponents.resultanalyzers.tensors.tensordfmetricwrapper.TensorDfMetricWrapper.get_final_metric","title":"get_final_metric","text":"<pre><code>get_final_metric()\n</code></pre> <p>Reads the parquet file and runs the dataframe metrics on it</p> Source code in <code>niceml/mlcomponents/resultanalyzers/tensors/tensordfmetricwrapper.py</code> <pre><code>def get_final_metric(self) -&gt; Optional[dict]:\n    \"\"\"Reads the parquet file and runs the dataframe metrics on it\"\"\"\n    cur_df: pd.DataFrame = self.exp_context.read_parquet(\n        join(\n            ExperimentFilenames.ANALYSIS_FOLDER,\n            self.parquet_filename.format(subset=self.dataset_name),\n        )\n    )\n\n    outdict = {}\n    for df_metric in self.df_metric_list:\n        cur_out_dict = df_metric(cur_df, self.exp_context, self.dataset_name)\n        if cur_out_dict is not None:\n            outdict.update(cur_out_dict)\n    return outdict\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensorgraphanalyzer/","title":"tensorgraphanalyzer","text":""},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensorgraphanalyzer/#niceml.mlcomponents.resultanalyzers.tensors.tensorgraphanalyzer","title":"tensorgraphanalyzer","text":"<p>Module for tensorgraphanalyzer</p>"},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensorgraphanalyzer/#niceml.mlcomponents.resultanalyzers.tensors.tensorgraphanalyzer-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensorgraphanalyzer/#niceml.mlcomponents.resultanalyzers.tensors.tensorgraphanalyzer.TensorGraphAnalyzer","title":"TensorGraphAnalyzer","text":"<pre><code>TensorGraphAnalyzer(\n    metrics, dataiterator, zarr_file_prefix=\"\"\n)\n</code></pre> <p>             Bases: <code>ResultAnalyzer</code></p> <p>Resultanalyzer for analyzing datapoints seperately. Results from a previous applied TensorMetric are accessible in the following TensorMetrics. For access the <code>key</code> attribute is used in each tensormetric.</p> <p>Initializes the TensorGraphAnalyzer</p> Source code in <code>niceml/mlcomponents/resultanalyzers/tensors/tensorgraphanalyzer.py</code> <pre><code>def __init__(\n    self,\n    metrics: List[TensorMetric],\n    dataiterator: TensordataIterator,\n    zarr_file_prefix: str = \"\",\n):\n    \"\"\"Initializes the TensorGraphAnalyzer\"\"\"\n    super().__init__()\n    self.zarr_file_prefix = zarr_file_prefix\n    self.df_metrics: List[TensorMetric] = metrics\n    self.dataiterator: TensordataIterator = dataiterator\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensorgraphanalyzer/#niceml.mlcomponents.resultanalyzers.tensors.tensorgraphanalyzer.TensorGraphAnalyzer-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensorgraphanalyzer/#niceml.mlcomponents.resultanalyzers.tensors.tensorgraphanalyzer.TensorGraphAnalyzer.__call__","title":"__call__","text":"<pre><code>__call__(dataset, exp_context, dataset_name)\n</code></pre> <p>Analyzes the dataset with the given metrics</p> Source code in <code>niceml/mlcomponents/resultanalyzers/tensors/tensorgraphanalyzer.py</code> <pre><code>def __call__(\n    self, dataset: Dataset, exp_context: ExperimentContext, dataset_name: str\n):  # pylint: disable=too-many-locals\n    \"\"\"Analyzes the dataset with the given metrics\"\"\"\n    with open_location(exp_context.fs_config) as (exp_fs, exp_root):\n        input_file: str = join(\n            exp_root,\n            ExperimentFilenames.PREDICTION_FOLDER,\n            f\"{self.zarr_file_prefix}{dataset_name}\",\n        )\n        self.dataiterator.open(input_file, file_system=exp_fs)\n\n    cur_metric: TensorMetric\n    for cur_metric in self.df_metrics:\n        cur_metric.initialize(\n            data_description=self.data_description,\n            exp_context=exp_context,\n            dataset_name=dataset_name,\n        )\n        cur_metric.start_analysis()\n\n    for data_key in self.dataiterator:\n        cur_data: dict = {}\n        data_predicted = self.dataiterator[data_key]\n        data_loaded = dataset.get_data_by_key(data_key)\n        for cur_metric in self.df_metrics:\n            ret_value = cur_metric.analyse_datapoint(\n                data_key, data_predicted, data_loaded, cur_data\n            )\n            if ret_value is not None:\n                cur_data[cur_metric.key] = ret_value\n\n    out_dict = {}\n    for cur_met in self.df_metrics:\n        final_metric = cur_met.get_final_metric()\n        if final_metric is not None:\n            out_dict.update(final_metric)\n\n    output_file = join(\n        ExperimentFilenames.ANALYSIS_FOLDER,\n        ExperimentFilenames.ANALYSIS_FILE.format(subset_name=dataset_name),\n    )\n    mlflow_metrics_dict = metrics_dict_to_mlflow_metrics_dict(metrics_dict=out_dict)\n    mlflow.log_metrics(mlflow_metrics_dict)\n    exp_context.write_yaml(out_dict, output_file)\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensorgraphanalyzer/#niceml.mlcomponents.resultanalyzers.tensors.tensorgraphanalyzer-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensorgraphanalyzer/#niceml.mlcomponents.resultanalyzers.tensors.tensorgraphanalyzer.metrics_dict_to_mlflow_metrics_dict","title":"metrics_dict_to_mlflow_metrics_dict","text":"<pre><code>metrics_dict_to_mlflow_metrics_dict(metrics_dict)\n</code></pre> <p>Converts a nested metrics dictionary to a flat dictionary suitable for MLflow logging.</p> <p>Parameters:</p> <ul> <li> <code>metrics_dict</code>             (<code>dict</code>)         \u2013          <p>A dictionary containing metrics, possibly nested.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code> (            <code>dict</code> )        \u2013          <p>A flat dictionary suitable for logging metrics in MLflow.</p> </li> </ul> <p>Raises:</p> <ul> <li> <code>ValueError</code>           \u2013          <p>If a metric is not of type float, dict or list.</p> </li> </ul> Example <p>Given the input metrics_dict: {     'accuracy': 0.85,     'precision': {         'class_0': 0.90,         'class_1': 0.78     },     'loss': [0.5, 0.3, 0.2],     'confusion_matrix': [         [50, 5],         [10, 80]     ] }</p> <p>The output mlflow_metrics_dict will be: {     'accuracy': 0.85,     'precision_class_0': 0.90,     'precision_class_1': 0.78,     'loss_0': 0.5,     'loss_1': 0.3,     'loss_2': 0.2,     'confusion_matrix_0_0': 50.0,     'confusion_matrix_0_1': 5.0,     'confusion_matrix_1_0': 10.0,     'confusion_matrix_1_1': 80.0 }</p> Source code in <code>niceml/mlcomponents/resultanalyzers/tensors/tensorgraphanalyzer.py</code> <pre><code>def metrics_dict_to_mlflow_metrics_dict(metrics_dict: dict) -&gt; dict:\n    \"\"\"\n    Converts a nested metrics dictionary to a flat dictionary suitable\n    for MLflow logging.\n\n    Args:\n        metrics_dict: A dictionary containing metrics, possibly nested.\n\n    Returns:\n        dict: A flat dictionary suitable for logging metrics in MLflow.\n\n    Raises:\n        ValueError: If a metric is not of type float, dict or list.\n\n    Example:\n        Given the input metrics_dict:\n        {\n            'accuracy': 0.85,\n            'precision': {\n                'class_0': 0.90,\n                'class_1': 0.78\n            },\n            'loss': [0.5, 0.3, 0.2],\n            'confusion_matrix': [\n                [50, 5],\n                [10, 80]\n            ]\n        }\n\n        The output mlflow_metrics_dict will be:\n        {\n            'accuracy': 0.85,\n            'precision_class_0': 0.90,\n            'precision_class_1': 0.78,\n            'loss_0': 0.5,\n            'loss_1': 0.3,\n            'loss_2': 0.2,\n            'confusion_matrix_0_0': 50.0,\n            'confusion_matrix_0_1': 5.0,\n            'confusion_matrix_1_0': 10.0,\n            'confusion_matrix_1_1': 80.0\n        }\n    \"\"\"\n    mlflow_metrics_dict = defaultdict(float)\n\n    for key, metric in metrics_dict.items():\n        try:\n            if isinstance(metric, (float, int)):\n                mlflow_metrics_dict[key] = float(metric)\n            elif isinstance(metric, tuple):\n                mlflow_metrics_dict[f\"{key}_0\"] = float(metric[0])\n                mlflow_metrics_dict[f\"{key}_1\"] = float(metric[1])\n            elif isinstance(metric, dict):\n                for metric_key, metric_value in metric.items():\n                    mlflow_metrics_dict[f\"{key}_{metric_key}\"] = float(metric_value)\n            elif isinstance(metric, list):\n                for idx, metric_value in enumerate(metric):\n                    if isinstance(metric_value, list):\n                        for inner_idx, inner_metric_value in enumerate(metric_value):\n                            mlflow_metrics_dict[f\"{key}_{idx}_{inner_idx}\"] = float(\n                                inner_metric_value\n                            )\n                        continue\n                    mlflow_metrics_dict[f\"{key}_{idx}\"] = float(metric_value)\n            else:\n                raise ValueError(\n                    f\"Metric ({key}) should be of type int, float, dict, tuple, or list.\"\n                )\n        except (ValueError, TypeError) as error:\n            raise TypeError(\n                f\"Metrics ({key}) of type dict, tuple or list must have values that \"\n                f\"can be parsed to float.\"\n            ) from error\n    return mlflow_metrics_dict\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensoriou/","title":"tensoriou","text":""},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensoriou/#niceml.mlcomponents.resultanalyzers.tensors.tensoriou","title":"tensoriou","text":"<p>Module for TensorIou TensorMetric</p>"},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensoriou/#niceml.mlcomponents.resultanalyzers.tensors.tensoriou-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensoriou/#niceml.mlcomponents.resultanalyzers.tensors.tensoriou.TensorIoU","title":"TensorIoU","text":"<pre><code>TensorIoU(key, threshold=0.5)\n</code></pre> <p>             Bases: <code>TensorMetric</code></p> <p>TensorMetric for calculating the IoU</p> Source code in <code>niceml/mlcomponents/resultanalyzers/tensors/tensoriou.py</code> <pre><code>def __init__(\n    self,\n    key: str,\n    threshold: float = 0.5,\n):\n    super().__init__(key)\n    self.threshold = threshold\n    self.data_description = None\n    self.intersection_sum = None\n    self.union_sum = None\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensormetric/","title":"tensormetric","text":""},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensormetric/#niceml.mlcomponents.resultanalyzers.tensors.tensormetric","title":"tensormetric","text":"<p>Module for TensorMetric</p>"},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensormetric/#niceml.mlcomponents.resultanalyzers.tensors.tensormetric-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensormetric/#niceml.mlcomponents.resultanalyzers.tensors.tensormetric.TensorMetric","title":"TensorMetric","text":"<pre><code>TensorMetric(key)\n</code></pre> <p>             Bases: <code>ABC</code></p> <p>The tensormetric is used in the tensorgraphanalyzer</p> Source code in <code>niceml/mlcomponents/resultanalyzers/tensors/tensormetric.py</code> <pre><code>def __init__(self, key: str):\n    self.output_folder = None\n    self.dataset_name = None\n    self.data_description = None\n    self.exp_context = None\n    self.key = key\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensormetric/#niceml.mlcomponents.resultanalyzers.tensors.tensormetric.TensorMetric-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensormetric/#niceml.mlcomponents.resultanalyzers.tensors.tensormetric.TensorMetric.analyse_datapoint","title":"analyse_datapoint  <code>abstractmethod</code>","text":"<pre><code>analyse_datapoint(\n    data_key,\n    data_predicted,\n    data_loaded,\n    additional_data,\n    **kwargs\n)\n</code></pre> <p>Abstract method to analyze one datapoint</p> Source code in <code>niceml/mlcomponents/resultanalyzers/tensors/tensormetric.py</code> <pre><code>@abstractmethod\ndef analyse_datapoint(\n    self,\n    data_key: str,\n    data_predicted,\n    data_loaded,\n    additional_data: dict,\n    **kwargs,\n) -&gt; Optional[Any]:\n    \"\"\"Abstract method to analyze one datapoint\"\"\"\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensormetric/#niceml.mlcomponents.resultanalyzers.tensors.tensormetric.TensorMetric.get_final_metric","title":"get_final_metric  <code>abstractmethod</code>","text":"<pre><code>get_final_metric()\n</code></pre> <p>This method is executed after all datapoints are processed</p> Source code in <code>niceml/mlcomponents/resultanalyzers/tensors/tensormetric.py</code> <pre><code>@abstractmethod\ndef get_final_metric(self) -&gt; Optional[dict]:\n    \"\"\"This method is executed after all datapoints are processed\"\"\"\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensormetric/#niceml.mlcomponents.resultanalyzers.tensors.tensormetric.TensorMetric.initialize","title":"initialize","text":"<pre><code>initialize(data_description, exp_context, dataset_name)\n</code></pre> <p>required parameters for initialization</p> Source code in <code>niceml/mlcomponents/resultanalyzers/tensors/tensormetric.py</code> <pre><code>def initialize(\n    self,\n    data_description: DataDescription,\n    exp_context: ExperimentContext,\n    dataset_name: str,\n):\n    \"\"\"required parameters for initialization\"\"\"\n    self.data_description = data_description\n    self.exp_context = exp_context\n    self.dataset_name = dataset_name\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensormetric/#niceml.mlcomponents.resultanalyzers.tensors.tensormetric.TensorMetric.start_analysis","title":"start_analysis","text":"<pre><code>start_analysis()\n</code></pre> <p>everything that needs to be done before the analysis</p> Source code in <code>niceml/mlcomponents/resultanalyzers/tensors/tensormetric.py</code> <pre><code>def start_analysis(self):\n    \"\"\"everything that needs to be done before the analysis\"\"\"\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensorvisualizer/","title":"tensorvisualizer","text":""},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensorvisualizer/#niceml.mlcomponents.resultanalyzers.tensors.tensorvisualizer","title":"tensorvisualizer","text":"<p>Module for tensorvisualizer</p>"},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensorvisualizer/#niceml.mlcomponents.resultanalyzers.tensors.tensorvisualizer-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensorvisualizer/#niceml.mlcomponents.resultanalyzers.tensors.tensorvisualizer.ColorInfo","title":"ColorInfo  <code>dataclass</code>","text":"<p>ColorInfo used for visualization</p>"},{"location":"reference/mlcomponents/resultanalyzers/tensors/tensorvisualizer/#niceml.mlcomponents.resultanalyzers.tensors.tensorvisualizer.TensorVisualizer","title":"TensorVisualizer","text":"<pre><code>TensorVisualizer(key, colormap)\n</code></pre> <p>             Bases: <code>TensorMetric</code></p> <p>TensorMetric used for visualization e.g. SemSeg</p> Source code in <code>niceml/mlcomponents/resultanalyzers/tensors/tensorvisualizer.py</code> <pre><code>def __init__(self, key: str, colormap: List[dict]):\n    super().__init__(key)\n    color_list: List[ColorInfo] = [ColorInfo(**x) for x in colormap]\n    c_info: ColorInfo\n    self.colormap = {c_info.index: c_info.color for c_info in color_list}\n    self.thresholds = {c_info.index: c_info.threshold for c_info in color_list}\n    self.img_count = 0\n    self.store_folder: str = \"\"\n</code></pre>"},{"location":"reference/mlcomponents/resultanalyzers/tensors/zarrdataiterator/","title":"zarrdataiterator","text":""},{"location":"reference/mlcomponents/resultanalyzers/tensors/zarrdataiterator/#niceml.mlcomponents.resultanalyzers.tensors.zarrdataiterator","title":"zarrdataiterator","text":""},{"location":"reference/mlcomponents/resultanalyzers/tensors/zarrdataiterator/#niceml.mlcomponents.resultanalyzers.tensors.zarrdataiterator-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/resultanalyzers/tensors/zarrdataiterator/#niceml.mlcomponents.resultanalyzers.tensors.zarrdataiterator.ZarrDataIterator","title":"ZarrDataIterator","text":"<pre><code>ZarrDataIterator(\n    scale_int_to_float=False, use_key_splits=None\n)\n</code></pre> <p>             Bases: <code>TensordataIterator</code></p> <p>This iterator allows to iterate over a zarr data file.</p>"},{"location":"reference/mlcomponents/resultanalyzers/tensors/zarrdataiterator/#niceml.mlcomponents.resultanalyzers.tensors.zarrdataiterator.ZarrDataIterator--parameters","title":"Parameters","text":"<p>scale_int_to_float: bool, default False     Divides all values by 255 use_key_splits: Optional[str], default None     if not none it uses this to combine multiple files to one key.</p> Source code in <code>niceml/mlcomponents/resultanalyzers/tensors/zarrdataiterator.py</code> <pre><code>def __init__(\n    self, scale_int_to_float: bool = False, use_key_splits: Optional[str] = None\n):\n    self.scale_int_to_float = scale_int_to_float\n    self.data = None\n    self.data_info: Optional[dict] = None\n    self.use_key_splits: Optional[str] = use_key_splits\n</code></pre>"},{"location":"reference/mlcomponents/targettransformer/__init__/","title":"targettransformer","text":""},{"location":"reference/mlcomponents/targettransformer/__init__/#niceml.mlcomponents.targettransformer","title":"targettransformer","text":""},{"location":"reference/mlcomponents/targettransformer/imageinputtransformer/","title":"imageinputtransformer","text":""},{"location":"reference/mlcomponents/targettransformer/imageinputtransformer/#niceml.mlcomponents.targettransformer.imageinputtransformer","title":"imageinputtransformer","text":"<p>Module for ImageInputTransformer</p>"},{"location":"reference/mlcomponents/targettransformer/imageinputtransformer/#niceml.mlcomponents.targettransformer.imageinputtransformer-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/targettransformer/imageinputtransformer/#niceml.mlcomponents.targettransformer.imageinputtransformer.ImageInputTransformer","title":"ImageInputTransformer","text":"<pre><code>ImageInputTransformer(image_attr_name='image')\n</code></pre> <p>             Bases: <code>NetInputTransformer</code></p> <p>Input transformer for object detection</p> Source code in <code>niceml/mlcomponents/targettransformer/imageinputtransformer.py</code> <pre><code>def __init__(self, image_attr_name: str = \"image\"):\n    self.image_attr_name = image_attr_name\n</code></pre>"},{"location":"reference/mlcomponents/targettransformer/objdettargettransformer/","title":"objdettargettransformer","text":""},{"location":"reference/mlcomponents/targettransformer/objdettargettransformer/#niceml.mlcomponents.targettransformer.objdettargettransformer","title":"objdettargettransformer","text":"<p>Module for the input and target transformers used for object detection</p>"},{"location":"reference/mlcomponents/targettransformer/objdettargettransformer/#niceml.mlcomponents.targettransformer.objdettargettransformer-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/targettransformer/objdettargettransformer/#niceml.mlcomponents.targettransformer.objdettargettransformer.ObjDetTargetTransformer","title":"ObjDetTargetTransformer","text":"<pre><code>ObjDetTargetTransformer(anchor_generator, anchor_encoder)\n</code></pre> <p>             Bases: <code>NetTargetTransformer</code></p> <p>Target transformer for object detection</p> Source code in <code>niceml/mlcomponents/targettransformer/objdettargettransformer.py</code> <pre><code>def __init__(\n    self, anchor_generator: AnchorGenerator, anchor_encoder: AnchorEncoder\n):\n    self.anchor_encoder = anchor_encoder\n    self.anchor_generator = anchor_generator\n    self.anchors = None\n</code></pre>"},{"location":"reference/mlcomponents/targettransformer/semsegtargettransformer/","title":"semsegtargettransformer","text":""},{"location":"reference/mlcomponents/targettransformer/semsegtargettransformer/#niceml.mlcomponents.targettransformer.semsegtargettransformer","title":"semsegtargettransformer","text":"<p>Module for SemSegTargetTransformer</p>"},{"location":"reference/mlcomponents/targettransformer/semsegtargettransformer/#niceml.mlcomponents.targettransformer.semsegtargettransformer-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/targettransformer/semsegtargettransformer/#niceml.mlcomponents.targettransformer.semsegtargettransformer.SemSegTargetTransformer","title":"SemSegTargetTransformer","text":"<pre><code>SemSegTargetTransformer(default_value=255)\n</code></pre> <p>             Bases: <code>NetTargetTransformer</code></p> <p>transforms classification net targets for Lens Defect SemSeg</p> Source code in <code>niceml/mlcomponents/targettransformer/semsegtargettransformer.py</code> <pre><code>def __init__(self, default_value: int = 255):\n    self.default_value = default_value\n</code></pre>"},{"location":"reference/mlcomponents/targettransformer/semsegtargettransformer/#niceml.mlcomponents.targettransformer.semsegtargettransformer.SemSegTargetTransformer-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/targettransformer/semsegtargettransformer/#niceml.mlcomponents.targettransformer.semsegtargettransformer.SemSegTargetTransformer.get_single_target","title":"get_single_target","text":"<pre><code>get_single_target(semseg_data)\n</code></pre> <p>returns mask array of one lens</p> Source code in <code>niceml/mlcomponents/targettransformer/semsegtargettransformer.py</code> <pre><code>def get_single_target(self, semseg_data: SemSegData) -&gt; np.ndarray:\n    \"\"\"returns mask array of one lens\"\"\"\n    out_dd: OutputImageDataDescription = check_instance(\n        self.data_description, OutputImageDataDescription\n    )\n    input_dd: InputImageDataDescription = check_instance(\n        self.data_description, InputImageDataDescription\n    )\n    input_image_size: ImageSize = input_dd.get_input_image_size()\n    output_image_size: ImageSize = out_dd.get_output_image_size()\n    class_count: int = out_dd.get_output_channel_count()\n    mask_image = semseg_data.mask_image\n    output_array = np.zeros(out_dd.get_output_tensor_shape())\n    if out_dd.get_output_image_size().np_array_has_same_size(mask_image):\n        output_array[\n            mask_image != self.default_value,\n            mask_image[mask_image &lt; class_count],\n        ] = 1\n    else:\n        ds_masked_hist = get_downscaled_masked_histogram(\n            mask_image=mask_image,\n            num_classes=class_count,\n            default_value=self.default_value,\n            ds_factor=int(input_image_size.get_division_factor(output_image_size)),\n        )\n        output_array[ds_masked_hist &gt; 0] = 1\n    return output_array\n</code></pre>"},{"location":"reference/mlcomponents/targettransformer/semsegtargettransformer/#niceml.mlcomponents.targettransformer.semsegtargettransformer-functions","title":"Functions","text":""},{"location":"reference/mlcomponents/targettransformer/targettransformer/","title":"targettransformer","text":""},{"location":"reference/mlcomponents/targettransformer/targettransformer/#niceml.mlcomponents.targettransformer.targettransformer","title":"targettransformer","text":""},{"location":"reference/mlcomponents/targettransformer/targettransformer/#niceml.mlcomponents.targettransformer.targettransformer-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/targettransformer/targettransformercls/","title":"targettransformercls","text":""},{"location":"reference/mlcomponents/targettransformer/targettransformercls/#niceml.mlcomponents.targettransformer.targettransformercls","title":"targettransformercls","text":"<p>Module for TargetTransformerClassification</p>"},{"location":"reference/mlcomponents/targettransformer/targettransformercls/#niceml.mlcomponents.targettransformer.targettransformercls-classes","title":"Classes","text":""},{"location":"reference/mlcomponents/targettransformer/targettransformercls/#niceml.mlcomponents.targettransformer.targettransformercls.TargetTransformerClassification","title":"TargetTransformerClassification","text":"<pre><code>TargetTransformerClassification()\n</code></pre> <p>             Bases: <code>NetTargetTransformer</code></p> <p>NetTargetTransformer for Classification</p> Source code in <code>niceml/mlcomponents/targettransformer/targettransformercls.py</code> <pre><code>def __init__(self):\n    super().__init__()\n    self.use_binary: bool = False\n    self.multi_label_binarizer = None\n</code></pre>"},{"location":"reference/mlcomponents/targettransformer/targettransformercls/#niceml.mlcomponents.targettransformer.targettransformercls-functions","title":"Functions","text":""},{"location":"reference/scripts/__init__/","title":"scripts","text":""},{"location":"reference/scripts/__init__/#niceml.scripts","title":"scripts","text":""},{"location":"reference/scripts/hydraconfreader/","title":"hydraconfreader","text":""},{"location":"reference/scripts/hydraconfreader/#niceml.scripts.hydraconfreader","title":"hydraconfreader","text":"<p>Module to load hydra configurations</p>"},{"location":"reference/scripts/hydraconfreader/#niceml.scripts.hydraconfreader-functions","title":"Functions","text":""},{"location":"reference/scripts/hydraconfreader/#niceml.scripts.hydraconfreader.load_hydra_conf","title":"load_hydra_conf","text":"<pre><code>load_hydra_conf(\n    conf_path,\n    additional_dict=None,\n    remove_globals_after_resolving=True,\n)\n</code></pre> <p>The load_hydra_conf function is a wrapper around the Hydra library. It loads a configuration file and returns it as a dictionary. The function also allows for additional parameters to be passed in,  which will override any conflicting values in the config file.</p> <p>Parameters:</p> <ul> <li> <code>conf_path</code>             (<code>str</code>)         \u2013          <p>Specify the path to the configuration file</p> </li> <li> <code>additional_dict</code>             (<code>Optional[Dict[str, str]]</code>, default:                 <code>None</code> )         \u2013          <p>Parameters which should be overwritten in the output dictionary</p> </li> <li> <code>remove_globals_after_resolving</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Choose to remove globals from config after resolving the configuration. Removing is only applied if 'additional_dict' is given</p> </li> </ul> <p>Returns     A dictionary of loaded configurations</p> Source code in <code>niceml/scripts/hydraconfreader.py</code> <pre><code>def load_hydra_conf(\n    conf_path: str,\n    additional_dict: Optional[Dict[str, str]] = None,\n    remove_globals_after_resolving: bool = True,\n) -&gt; dict:\n    \"\"\"\n    The load_hydra_conf function is a wrapper around the Hydra library.\n    It loads a configuration file and returns it as a dictionary.\n    The function also allows for additional parameters to be passed in,\n     which will override any conflicting values in the config file.\n\n    Args:\n        conf_path: Specify the path to the configuration file\n        additional_dict: Parameters which should be overwritten in the\n            output dictionary\n        remove_globals_after_resolving: Choose to remove globals from\n            config after resolving the configuration. Removing is only\n            applied if 'additional_dict' is given\n    Returns\n        A dictionary of loaded configurations\n    \"\"\"\n    conf_dir = abspath(dirname(conf_path))\n    config_file = basename(conf_path)\n    with initialize_config_dir(config_dir=conf_dir, version_base=\"1.1\"):\n        cfg = compose(config_name=config_file)\n        if additional_dict is not None:\n            cfg = OmegaConf.to_container(cfg)\n            globals_dict = {\"globals\": additional_dict}\n            cfg = OmegaConf.merge(cfg, globals_dict)\n            cfg = OmegaConf.to_container(cfg, resolve=True)\n            if remove_globals_after_resolving:\n                del cfg[\"globals\"]\n        else:\n            OmegaConf.resolve(cfg)\n            cfg = OmegaConf.to_container(cfg)\n    return cfg\n</code></pre>"},{"location":"reference/scripts/hydraconfreader/#niceml.scripts.hydraconfreader.load_hydra_conf_cmd","title":"load_hydra_conf_cmd","text":"<pre><code>load_hydra_conf_cmd(conf_path)\n</code></pre> <p>Command to load hydra configurations from file Args:     conf_path: path to config file</p> Source code in <code>niceml/scripts/hydraconfreader.py</code> <pre><code>@click.command()\n@click.argument(\"conf_path\")\ndef load_hydra_conf_cmd(conf_path: str):\n    \"\"\"\n    Command to load hydra configurations from file\n    Args:\n        conf_path: path to config file\n    \"\"\"\n    load_hydra_conf(conf_path)\n</code></pre>"},{"location":"reference/scripts/rundatatests/","title":"rundatatests","text":""},{"location":"reference/scripts/rundatatests/#niceml.scripts.rundatatests","title":"rundatatests","text":"<p>Module for data tests</p>"},{"location":"reference/scripts/rundatatests/#niceml.scripts.rundatatests-functions","title":"Functions","text":""},{"location":"reference/scripts/rundatatests/#niceml.scripts.rundatatests.run_datatests","title":"run_datatests","text":"<pre><code>run_datatests(config_file, data_folder)\n</code></pre> <p>Run data tests</p> <p>Parameters:</p> <ul> <li> <code>config_file</code>             (<code>str</code>)         \u2013          <p>path to file with data test configuration</p> </li> <li> <code>data_folder</code>             (<code>str</code>)         \u2013          <p>data to test</p> </li> </ul> Source code in <code>niceml/scripts/rundatatests.py</code> <pre><code>def run_datatests(config_file: str, data_folder: str):\n    \"\"\"\n    Run data tests\n\n    Args:\n        config_file: path to file with data test configuration\n        data_folder: data to test\n    \"\"\"\n    with open(config_file, \"r\") as file:\n        config = yaml.load(file, Loader=yaml.SafeLoader)\n\n    test_process = config[\"tests\"]\n    test_process(data_folder, data_folder)\n</code></pre>"},{"location":"reference/scripts/rundatatests/#niceml.scripts.rundatatests.run_datatests_cmd","title":"run_datatests_cmd","text":"<pre><code>run_datatests_cmd(config_file, data_folder)\n</code></pre> <p>Command to run data tests</p> Source code in <code>niceml/scripts/rundatatests.py</code> <pre><code>@click.command()\n@click.argument(\"config_file\")\n@click.argument(\"data_folder\")\ndef run_datatests_cmd(config_file: str, data_folder: str):\n    \"\"\"Command to run data tests\"\"\"\n    run_datatests(config_file, data_folder)\n</code></pre>"},{"location":"reference/scripts/splitdatasetindex/","title":"splitdatasetindex","text":""},{"location":"reference/scripts/splitdatasetindex/#niceml.scripts.splitdatasetindex","title":"splitdatasetindex","text":"<p>Split dataset index module</p>"},{"location":"reference/scripts/splitdatasetindex/#niceml.scripts.splitdatasetindex-classes","title":"Classes","text":""},{"location":"reference/scripts/splitdatasetindex/#niceml.scripts.splitdatasetindex-functions","title":"Functions","text":""},{"location":"reference/scripts/splitdatasetindex/#niceml.scripts.splitdatasetindex.get_set","title":"get_set","text":"<pre><code>get_set(file_id, set_infos)\n</code></pre> <p>Chooses a set for a file according to the given sets with their probability. If you run get_set with the same arguments multiple times, you will always get back the same result.</p> <p>Parameters:</p> <ul> <li> <code>file_id</code>             (<code>str</code>)         \u2013          <p>file id</p> </li> <li> <code>set_infos</code>             (<code>List[DataSetInfo]</code>)         \u2013          <p>list of DataSetInfos including set names and their probability</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>         \u2013          <p>Name of the chosen set</p> </li> </ul> Source code in <code>niceml/scripts/splitdatasetindex.py</code> <pre><code>def get_set(file_id: str, set_infos: List[DataSetInfo]) -&gt; str:\n    \"\"\"\n    Chooses a set for a file according to the given sets with their probability.\n    If you run get_set with the same arguments multiple times,\n    you will always get back the same result.\n\n    Args:\n        file_id: file id\n        set_infos: list of DataSetInfos including set names and their probability\n\n    Returns:\n        Name of the chosen set\n    \"\"\"\n    identifier = \"\".join([x for x in file_id if x in ALPHANUMERICLIST])\n    cur_seed = int(identifier, base=len(ALPHANUMERICLIST)) % (2**32 - 1)\n    rng = np.random.default_rng(cur_seed)\n    tmp_list: List[Tuple[str, float]] = [\n        (dsf.set_name, dsf.probability) for dsf in set_infos\n    ]\n    names, probs = zip(*tmp_list)\n    return rng.choice(list(names), 1, p=list(probs))[0]\n</code></pre>"},{"location":"reference/scripts/splitdatasetindex/#niceml.scripts.splitdatasetindex.split_dataset_index","title":"split_dataset_index","text":"<pre><code>split_dataset_index(\n    index_file, output_folder, set_infos, index_col_name\n)\n</code></pre> <p>Split dataset index into subsets</p> Source code in <code>niceml/scripts/splitdatasetindex.py</code> <pre><code>def split_dataset_index(\n    index_file: str,\n    output_folder: str,\n    set_infos: List[DataSetInfo],\n    index_col_name: str,\n):\n    \"\"\"Split dataset index into subsets\"\"\"\n    index_df: pd.DataFrame = fastparquet.ParquetFile(index_file).to_pandas()\n    set_row_dict: Dict[str, list] = defaultdict(list)\n    for _, cur_row in index_df.iterrows():\n        target_set = get_set(cur_row[index_col_name], set_infos)\n        set_row_dict[target_set].append(cur_row)\n\n    if not isdir(output_folder):\n        makedirs(output_folder)\n    for set_name, row_list in set_row_dict.items():\n        cur_df = pd.DataFrame(row_list)\n        fastparquet.write(join(output_folder, f\"{set_name}.parq\"), cur_df)\n</code></pre>"},{"location":"reference/scripts/splitdatasetindex/#niceml.scripts.splitdatasetindex.split_dataset_index_cmd","title":"split_dataset_index_cmd","text":"<pre><code>split_dataset_index_cmd(\n    index_file, output_folder, index_col_name, set_infos\n)\n</code></pre> <p>Split dataset index command</p> Source code in <code>niceml/scripts/splitdatasetindex.py</code> <pre><code>@click.command()\n@click.argument(\"index_file\")\n@click.argument(\"output_location\")\n@click.argument(\"index_col_name\")\n@click.argument(\"set_infos\", nargs=-1)\ndef split_dataset_index_cmd(\n    index_file: str, output_folder: str, index_col_name: str, set_infos: List[str]\n):\n    \"\"\"Split dataset index command\"\"\"\n    set_prob_infos: List[DataSetInfo] = [init_dataset_info(x) for x in set_infos]\n    split_dataset_index(index_file, output_folder, set_prob_infos, index_col_name)\n</code></pre>"},{"location":"reference/storages/__init__/","title":"storages","text":""},{"location":"reference/storages/__init__/#niceml.storages","title":"storages","text":""},{"location":"reference/storages/abs/","title":"abs","text":""},{"location":"reference/storages/abs/#niceml.storages.abs","title":"abs","text":""},{"location":"reference/storages/abs/#niceml.storages.abs-classes","title":"Classes","text":""},{"location":"reference/storages/abs/#niceml.storages.abs-functions","title":"Functions","text":""},{"location":"reference/storages/abs/#niceml.storages.abs.get_files_to_download","title":"get_files_to_download","text":"<pre><code>get_files_to_download(cloud_interface, source, dest)\n</code></pre> <p>Download a file or directory to a path on the local filesystem</p> <p>Parameters:</p> <ul> <li> <code>cloud_interface</code>             (<code>StorageInterface</code>)         \u2013          <p>interface to load data</p> </li> <li> <code>source</code>             (<code>str</code>)         \u2013          <p>Source path in the container</p> </li> <li> <code>dest</code>             (<code>str</code>)         \u2013          <p>Local destination path</p> </li> </ul> Source code in <code>niceml/storages/abs.py</code> <pre><code>def get_files_to_download(cloud_interface: StorageInterface, source: str, dest: str):\n    \"\"\"\n    Download a file or directory to a path on the local filesystem\n\n    Args:\n        cloud_interface: interface to load data\n        source: Source path in the container\n        dest: Local destination path\n    \"\"\"\n    logger = logging.getLogger(\"abs_logger\")\n    logger.disabled = True\n    return list_download_files(cloud_interface, source, dest)\n</code></pre>"},{"location":"reference/storages/abs/#niceml.storages.abs.list_download_files","title":"list_download_files","text":"<pre><code>list_download_files(\n    cloud_interface, bucket_path, local_path\n)\n</code></pre> <p>List all files that need to be downloaded from the given source and the resulting destination paths. Args:     cloud_interface: interface to load data     bucket_path: Source path in the container     local_path: Local destination path</p> <p>Returns:</p> <ul> <li> <code>Dict[str, str]</code>         \u2013          <p>Dictionary with the blob path as key and the local path as value</p> </li> </ul> Source code in <code>niceml/storages/abs.py</code> <pre><code>def list_download_files(\n    cloud_interface: StorageInterface, bucket_path: str, local_path: str\n) -&gt; Dict[str, str]:\n    \"\"\"\n    List all files that need to be downloaded from the given source and\n    the resulting destination paths.\n    Args:\n        cloud_interface: interface to load data\n        bucket_path: Source path in the container\n        local_path: Local destination path\n\n    Returns:\n        Dictionary with the blob path as key and the local path as value\n    \"\"\"\n    blobs = cloud_interface.list_data(bucket_path)\n    download_dict = {}\n    if blobs:\n        for blob_path in blobs:\n            file_path = os.path.relpath(blob_path, bucket_path)\n            if not file_path.startswith(local_path):\n                file_path = os.path.join(local_path, file_path)\n            if not os.path.exists(file_path):\n                download_dict[blob_path] = file_path\n    else:\n        download_dict[bucket_path] = local_path\n    return download_dict\n</code></pre>"},{"location":"reference/utilities/__init__/","title":"utilities","text":""},{"location":"reference/utilities/__init__/#niceml.utilities","title":"utilities","text":""},{"location":"reference/utilities/chartutils/","title":"chartutils","text":""},{"location":"reference/utilities/chartutils/#niceml.utilities.chartutils","title":"chartutils","text":""},{"location":"reference/utilities/chartutils/#niceml.utilities.chartutils-functions","title":"Functions","text":""},{"location":"reference/utilities/chartutils/#niceml.utilities.chartutils.generate_hover_charts","title":"generate_hover_charts","text":"<pre><code>generate_hover_charts(\n    source,\n    x_name,\n    text_name,\n    base_chart,\n    width,\n    height,\n    additional_layers=None,\n    text_type=\"Q\",\n)\n</code></pre> <p>Generates Altair Charts, with hover functionality</p> Source code in <code>niceml/utilities/chartutils.py</code> <pre><code>def generate_hover_charts(  # QUEST: still in use?\n    source,\n    x_name: str,\n    text_name: str,\n    base_chart,\n    width: int,\n    height: int,\n    additional_layers: Optional[List[altair.Chart]] = None,\n    text_type: str = \"Q\",\n):\n    \"\"\"Generates Altair Charts, with hover functionality\"\"\"\n    if additional_layers is None:\n        additional_layers = []\n    # Create a selection that chooses the nearest point &amp; selects based on x-value\n    nearest = altair.selection(\n        type=\"single\", nearest=True, on=\"mouseover\", fields=[x_name], empty=\"none\"\n    )\n\n    # Transparent selectors across the chart. This is what tells us\n    # the x-value of the cursor\n    selectors = (\n        altair.Chart(source)\n        .mark_point()\n        .encode(\n            x=x_name,\n            opacity=altair.value(0),\n        )\n        .add_selection(nearest)\n    )\n\n    # Draw points on the line, and highlight based on selection\n    points = base_chart.mark_point().encode(\n        opacity=altair.condition(nearest, altair.value(1), altair.value(0))\n    )\n\n    # Draw text labels near the points, and highlight based on selection\n    text = base_chart.mark_text(align=\"left\", dx=5, dy=-5).encode(\n        text=altair.condition(nearest, f\"{text_name}:{text_type}\", altair.value(\" \"))\n    )\n\n    # Draw a rule at the location of the selection\n    rules = (\n        altair.Chart(source)\n        .mark_rule(color=\"gray\")\n        .encode(x=f\"{x_name}:Q\")\n        .transform_filter(nearest)\n    )\n\n    return altair.layer(\n        base_chart, selectors, points, rules, text, *additional_layers\n    ).properties(width=width, height=height)\n</code></pre>"},{"location":"reference/utilities/checksums/","title":"checksums","text":""},{"location":"reference/utilities/checksums/#niceml.utilities.checksums","title":"checksums","text":"<p>Module for calculating checksums</p>"},{"location":"reference/utilities/checksums/#niceml.utilities.checksums-functions","title":"Functions","text":""},{"location":"reference/utilities/checksums/#niceml.utilities.checksums.combine_checksums","title":"combine_checksums","text":"<pre><code>combine_checksums(first_hash, second_hash)\n</code></pre> <p>Combines two checksums</p> Source code in <code>niceml/utilities/checksums.py</code> <pre><code>def combine_checksums(first_hash, second_hash) -&gt; str:\n    \"\"\"Combines two checksums\"\"\"\n    if first_hash is None:\n        return second_hash\n    if second_hash is None:\n        return first_hash\n    value = int(first_hash, 16) ^ int(second_hash, 16)\n    return hex_leading_zeros(value)\n</code></pre>"},{"location":"reference/utilities/checksums/#niceml.utilities.checksums.gen_hash_command","title":"gen_hash_command","text":"<pre><code>gen_hash_command(output_file, file_list)\n</code></pre> <p>Command line interface for file hash calculation</p> Source code in <code>niceml/utilities/checksums.py</code> <pre><code>@click.command()\n@click.argument(\"output_file\")\n@click.argument(\"file_list\", nargs=-1)\n@click.option(\"--fileservice\", default=None)\ndef gen_hash_command(output_file, file_list):\n    \"\"\"Command line interface for file hash calculation\"\"\"\n    file_list = list(file_list) if isinstance(file_list, tuple) else [file_list]\n    gen_hash_main(output_file, file_list)\n</code></pre>"},{"location":"reference/utilities/checksums/#niceml.utilities.checksums.gen_hash_main","title":"gen_hash_main","text":"<pre><code>gen_hash_main(output_file, file_list)\n</code></pre> <p>Main function for file hash calculation</p> Source code in <code>niceml/utilities/checksums.py</code> <pre><code>def gen_hash_main(output_file, file_list):\n    \"\"\"Main function for file hash calculation\"\"\"\n    md5_hash = md5_from_filelist_or_dir(file_list)\n    with open(output_file, \"w\") as file:  # pylint: disable=unspecified-encoding\n        file.write(md5_hash)\n</code></pre>"},{"location":"reference/utilities/checksums/#niceml.utilities.checksums.hex_leading_zeros","title":"hex_leading_zeros","text":"<pre><code>hex_leading_zeros(value, length=32)\n</code></pre> <p>Returns a hex string with leading zeros of given length</p> Source code in <code>niceml/utilities/checksums.py</code> <pre><code>def hex_leading_zeros(value, length=32) -&gt; str:\n    \"\"\"Returns a hex string with leading zeros of given length\"\"\"\n    return f\"{value:#0{length}x}\"\n</code></pre>"},{"location":"reference/utilities/checksums/#niceml.utilities.checksums.md5_from_file","title":"md5_from_file","text":"<pre><code>md5_from_file(file_path, file_system=None)\n</code></pre> <p>Calculates the md5 hash of a file Args:     file_path: path to file to hash     file_system: filesystem where the file is stored</p> <p>Returns:</p> <ul> <li> <code>str</code>         \u2013          <p>hash of file</p> </li> </ul> Source code in <code>niceml/utilities/checksums.py</code> <pre><code>def md5_from_file(\n    file_path: str, file_system: Optional[AbstractFileSystem] = None\n) -&gt; str:\n    \"\"\"\n    Calculates the md5 hash of a file\n    Args:\n        file_path: path to file to hash\n        file_system: filesystem where the file is stored\n\n    Returns:\n        hash of file\n    \"\"\"\n    cur_fs = file_system or LocalFileSystem()\n    with cur_fs.open(file_path, \"rb\") as file:\n        data = file.read()\n    return hashlib.md5(data).hexdigest()\n</code></pre>"},{"location":"reference/utilities/checksums/#niceml.utilities.checksums.md5_from_filelist_or_dir","title":"md5_from_filelist_or_dir","text":"<pre><code>md5_from_filelist_or_dir(file_list, file_system=None)\n</code></pre> <p>Calculates the md5 hash of a list of files or a directory</p> <p>Parameters:</p> <ul> <li> <code>file_list</code>             (<code>Union[list, str]</code>)         \u2013          <p>List of files to hash or directory of files to hash</p> </li> <li> <code>file_system</code>             (<code>Optional[AbstractFileSystem]</code>, default:                 <code>None</code> )         \u2013          <p>Filesystem where the files are stored; Default = local</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>         \u2013          <p>A hash of one or more files</p> </li> </ul> Source code in <code>niceml/utilities/checksums.py</code> <pre><code>def md5_from_filelist_or_dir(\n    file_list: Union[list, str], file_system: Optional[AbstractFileSystem] = None\n) -&gt; str:\n    \"\"\"\n    Calculates the md5 hash of a list of files or a directory\n\n    Args:\n        file_list: List of files to hash or directory of files to hash\n        file_system: Filesystem where the files are stored; Default = local\n\n    Returns:\n        A hash of one or more files\n    \"\"\"\n    cur_fs = file_system or LocalFileSystem()\n    if isinstance(file_list, list):\n        md5_hash = hex_leading_zeros(0)\n        for file in file_list:\n            if isdir(file):\n                cur_hash = md5_from_filelist_or_dir(\n                    [\n                        os.path.join(file, f)\n                        for f in sorted(list_dir(file, return_full_path=True))\n                    ],\n                    file_system=cur_fs,\n                )\n            else:\n                cur_hash = md5_from_filelist_or_dir(file, file_system=cur_fs)\n            md5_hash = combine_checksums(cur_hash, md5_hash)\n        return md5_hash\n    if isinstance(file_list, str):\n        return md5_from_file(file_list, file_system=cur_fs)\n\n    raise Exception(f\"Unknown type: {type(file_list)}\")\n</code></pre>"},{"location":"reference/utilities/colorutils/","title":"colorutils","text":""},{"location":"reference/utilities/colorutils/#niceml.utilities.colorutils","title":"colorutils","text":"<p>Module for all color functions and variables</p>"},{"location":"reference/utilities/colorutils/#niceml.utilities.colorutils-classes","title":"Classes","text":""},{"location":"reference/utilities/colorutils/#niceml.utilities.colorutils.Color","title":"Color","text":"<p>             Bases: <code>tuple</code>, <code>Enum</code></p> <p>Enum for RGB color tuples used for visualization</p>"},{"location":"reference/utilities/colorutils/#niceml.utilities.colorutils-functions","title":"Functions","text":""},{"location":"reference/utilities/colorutils/#niceml.utilities.colorutils.get_color","title":"get_color","text":"<pre><code>get_color(idx)\n</code></pre> <p>returns a color tuple with len 3 for a color between 0 and 1</p> Source code in <code>niceml/utilities/colorutils.py</code> <pre><code>def get_color(idx: int) -&gt; Tuple[float, float, float]:\n    \"\"\"returns a color tuple with len 3 for a color between 0 and 1\"\"\"\n    return COLORS[idx % len(COLORS)]\n</code></pre>"},{"location":"reference/utilities/colorutils/#niceml.utilities.colorutils.get_color_array","title":"get_color_array","text":"<pre><code>get_color_array(classes_array)\n</code></pre> <p>Returns an array with colors for each class</p> <p>Parameters:</p> <ul> <li> <code>classes_array</code>             (<code>List</code>)         \u2013          <p>List of classes to generate colors for</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>         \u2013          <p>Array of one color per class</p> </li> </ul> Source code in <code>niceml/utilities/colorutils.py</code> <pre><code>def get_color_array(classes_array: List) -&gt; np.ndarray:\n    \"\"\"\n    Returns an array with colors for each class\n\n    Args:\n        classes_array: List of classes to generate colors for\n\n    Returns:\n        Array of one color per class\n    \"\"\"\n    color_list = [get_color(color) for color in classes_array]\n    return np.array(color_list)\n</code></pre>"},{"location":"reference/utilities/colorutils/#niceml.utilities.colorutils.get_color_array_uint","title":"get_color_array_uint","text":"<pre><code>get_color_array_uint()\n</code></pre> <p>returns a color array with shape (len(COLORS),3) with values between 0 and 255</p> Source code in <code>niceml/utilities/colorutils.py</code> <pre><code>def get_color_array_uint() -&gt; np.ndarray:\n    \"\"\"returns a color array with shape (len(COLORS),3) with values between\n    0 and 255\"\"\"\n    color_list = [get_color(idx) for idx in range(len(COLORS))]\n    color_array = np.array(color_list)\n    color_array = (color_array * 255).astype(np.uint8)\n    return color_array\n</code></pre>"},{"location":"reference/utilities/colorutils/#niceml.utilities.colorutils.get_color_uint","title":"get_color_uint","text":"<pre><code>get_color_uint(idx)\n</code></pre> <p>returns a color tuple with len 3 for a color between 0 and 255</p> Source code in <code>niceml/utilities/colorutils.py</code> <pre><code>def get_color_uint(idx: int) -&gt; Tuple[int, int, int]:\n    \"\"\"returns a color tuple with len 3 for a color between 0 and 255\"\"\"\n    color = [int(x * 255) for x in get_color(idx)]\n    return tuple(color)\n</code></pre>"},{"location":"reference/utilities/commonutils/","title":"commonutils","text":""},{"location":"reference/utilities/commonutils/#niceml.utilities.commonutils","title":"commonutils","text":"<p>Module for common utils</p>"},{"location":"reference/utilities/commonutils/#niceml.utilities.commonutils-functions","title":"Functions","text":""},{"location":"reference/utilities/commonutils/#niceml.utilities.commonutils.check_instance","title":"check_instance","text":"<pre><code>check_instance(obj_instance, class_type)\n</code></pre> <p>Checks whether 'obj_instance' is an instance of 'class_type'. Returns 'obj_instance' if True. Raises TypeError if not.</p> <p>Parameters:</p> <ul> <li> <code>obj_instance</code>             (<code>Any</code>)         \u2013          <p>Object to check the instance type for</p> </li> <li> <code>class_type</code>             (<code>Any</code>)         \u2013          <p>instance type which is expected</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Any</code>         \u2013          <p>'obj_instance' if the type is correct</p> </li> </ul> Source code in <code>niceml/utilities/commonutils.py</code> <pre><code>def check_instance(obj_instance: Any, class_type: Any) -&gt; Any:\n    \"\"\"\n    Checks whether 'obj_instance' is an instance of 'class_type'.\n    Returns 'obj_instance' if True. Raises TypeError if not.\n\n    Args:\n        obj_instance: Object to check the instance type for\n        class_type: instance type which is expected\n\n    Returns:\n        'obj_instance' if the type is correct\n    \"\"\"\n    if isinstance(obj_instance, class_type):\n        return obj_instance\n    raise TypeError(\n        f\"Object of class {type(obj_instance)} \"\n        f\"is not instance of class: {class_type}\"\n    )\n</code></pre>"},{"location":"reference/utilities/commonutils/#niceml.utilities.commonutils.human_readable_size","title":"human_readable_size","text":"<pre><code>human_readable_size(obj)\n</code></pre> <p>Returns human-readable size in bytes of an object as string</p> <p>Parameters:</p> <ul> <li> <code>obj</code>             (<code>Any</code>)         \u2013          <p>object to check the size for</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>str</code>         \u2013          <p>Size of the object in bytes; e.g. \"1.23 GB\"</p> </li> </ul> Source code in <code>niceml/utilities/commonutils.py</code> <pre><code>def human_readable_size(obj: Any) -&gt; str:\n    \"\"\"\n    Returns human-readable size in bytes of an object as string\n\n    Args:\n        obj: object to check the size for\n\n    Returns:\n        Size of the object in bytes; e.g. \"1.23 GB\"\n    \"\"\"\n    size = asizeof.asizeof(obj)\n    if size &lt; 1024:\n        return f\"{size} bytes\"\n    if 1024 &lt;= size &lt; 1024**2:\n        size_kb = size / 1024\n        return f\"{size_kb:.2f} KB\"\n    if 1024**2 &lt;= size &lt; 1024**3:\n        size_mb = size / 1024**2\n        return f\"{size_mb:.2f} MB\"\n\n    size_gb = size / 1024**3\n    return f\"{size_gb:.2f} GB\"\n</code></pre>"},{"location":"reference/utilities/commonutils/#niceml.utilities.commonutils.items_from_shuffled_list","title":"items_from_shuffled_list","text":"<pre><code>items_from_shuffled_list(item_list, count)\n</code></pre> <p>Generates a shuffled list of 'item_list', where 'count' is the number of items in that list. The order is randomized. If 'count' is smaller than len(item_list), some items won't appear in the output. If 'count' is equal to len(item_list), all items in item_list will appear in the output. If there are more than one copy of an item in the input, then it will also appear multiple times in the output.</p> <p>Parameters:</p> <ul> <li> <code>item_list</code>             (<code>list</code>)         \u2013          <p>list of items, e.g. [1,2,3,4]</p> </li> <li> <code>count</code>             (<code>int</code>)         \u2013          <p>number of required items in the output; can be bigger than len('item_list'), e.g. 4</p> </li> </ul> <p>Returns:     list of items which are shuffled, e.g. [3,2,1,4]</p> Source code in <code>niceml/utilities/commonutils.py</code> <pre><code>def items_from_shuffled_list(item_list: list, count: int) -&gt; list:\n    \"\"\"\n    Generates a shuffled list of 'item_list', where 'count' is the number of items in that list.\n    The order is randomized. If 'count' is smaller than len(item_list), some items won't appear\n    in the output. If 'count' is equal to len(item_list), all items in item_list will appear in\n    the output. If there are more than one copy of an item in the input, then it\n    will also appear multiple times in the output.\n\n    Args:\n        item_list: list of items, e.g. [1,2,3,4]\n        count: number of required items in the output; can be bigger than len('item_list'), e.g. 4\n    Returns:\n        list of items which are shuffled, e.g. [3,2,1,4]\n    \"\"\"\n    working_item_list = item_list.copy()\n    out_list = []\n    complete_count, residual = divmod(count, len(working_item_list))\n    for _ in range(complete_count):\n        shuffle(working_item_list)\n        out_list += working_item_list\n    if residual &gt; 0:\n        shuffle(working_item_list)\n        out_list += working_item_list[:residual]\n\n    return out_list\n</code></pre>"},{"location":"reference/utilities/commonutils/#niceml.utilities.commonutils.partition_indices","title":"partition_indices","text":"<pre><code>partition_indices(totalsize, numberofpartitions)\n</code></pre>"},{"location":"reference/utilities/commonutils/#niceml.utilities.commonutils.partition_indices--quest-still-used","title":"QUEST: still used?","text":"<p>Splits the length of an iterable (totalsize) into a given number of equal parts and returns the start and end indices of these parts.</p> <p>Parameters:</p> <ul> <li> <code>totalsize</code>             (<code>int</code>)         \u2013          <p>length of the iterable to be partitioned</p> </li> <li> <code>numberofpartitions</code>             (<code>int</code>)         \u2013          <p>number of the partitions generated</p> </li> </ul> <p>Returns:     List of tuples containing the start and end indices for each partition</p> Source code in <code>niceml/utilities/commonutils.py</code> <pre><code>def partition_indices(totalsize: int, numberofpartitions: int) -&gt; List[Tuple[int, int]]:\n    \"\"\"# QUEST: still used?\n    Splits the length of an iterable (totalsize) into a given number of equal parts and\n    returns the start and end indices of these parts.\n\n    Args:\n        totalsize: length of the iterable to be partitioned\n        numberofpartitions: number of the partitions generated\n    Returns:\n        List of tuples containing the start and end indices for each partition\n    \"\"\"\n    chunksize = totalsize // numberofpartitions\n    # How many chunks need an extra 1 added to the size?\n    remainder = totalsize - chunksize * numberofpartitions\n    start_index = 0\n    for partition_idx in range(numberofpartitions):\n        end_index = start_index + chunksize + (partition_idx &lt; remainder)\n        yield start_index, end_index - 1\n        start_index = end_index\n</code></pre>"},{"location":"reference/utilities/commonutils/#niceml.utilities.commonutils.str_to_bool","title":"str_to_bool","text":"<pre><code>str_to_bool(input_value)\n</code></pre> <p>Checks for common str values and interprets them as bool</p> Source code in <code>niceml/utilities/commonutils.py</code> <pre><code>def str_to_bool(input_value: str) -&gt; bool:\n    \"\"\"Checks for common str values and interprets them as bool\"\"\"\n    return input_value.lower() in {\"yes\", \"true\", \"t\", \"1\"}\n</code></pre>"},{"location":"reference/utilities/commonutils/#niceml.utilities.commonutils.to_categorical","title":"to_categorical","text":"<pre><code>to_categorical(input_vector, num_classes)\n</code></pre> <p>1-hot encodes a tensor</p> Source code in <code>niceml/utilities/commonutils.py</code> <pre><code>def to_categorical(input_vector: np.ndarray, num_classes: int):\n    \"\"\"1-hot encodes a tensor\"\"\"\n    return np.eye(num_classes, dtype=\"uint8\")[input_vector]\n</code></pre>"},{"location":"reference/utilities/copyutils/","title":"copyutils","text":""},{"location":"reference/utilities/copyutils/#niceml.utilities.copyutils","title":"copyutils","text":"<p>Module for copying files</p>"},{"location":"reference/utilities/copyutils/#niceml.utilities.copyutils-classes","title":"Classes","text":""},{"location":"reference/utilities/copyutils/#niceml.utilities.copyutils.CopyFileInfo","title":"CopyFileInfo  <code>dataclass</code>","text":"<p>Dataclass which is used to compare an input file with an output file</p>"},{"location":"reference/utilities/copyutils/#niceml.utilities.copyutils.CopyFileInfo-functions","title":"Functions","text":""},{"location":"reference/utilities/copyutils/#niceml.utilities.copyutils.CopyFileInfo.copy_file","title":"copy_file","text":"<pre><code>copy_file()\n</code></pre> <p>Copies the input file to the output location</p> Source code in <code>niceml/utilities/copyutils.py</code> <pre><code>def copy_file(self):\n    \"\"\"Copies the input file to the output location\"\"\"\n    with open_location(self.input_location) as (input_filesystem, input_path):\n        with open_location(self.output_location) as (\n            output_filesystem,\n            output_path,\n        ):\n            output_filesystem.makedirs(dirname(output_path), exist_ok=True)\n            with input_filesystem.open(\n                input_path, \"rb\"\n            ) as fsrc, output_filesystem.open(output_path, \"wb\") as ftgt:\n                ftgt.write(fsrc.read())\n</code></pre>"},{"location":"reference/utilities/copyutils/#niceml.utilities.copyutils.CopyInfo","title":"CopyInfo  <code>dataclass</code>","text":"<p>This class contains the information for copying files between filesystems</p>"},{"location":"reference/utilities/copyutils/#niceml.utilities.copyutils.CopyInfo-functions","title":"Functions","text":""},{"location":"reference/utilities/copyutils/#niceml.utilities.copyutils.CopyInfo.copy_to_filesystem","title":"copy_to_filesystem","text":"<pre><code>copy_to_filesystem(target_filesystem, target_path)\n</code></pre> <p>Copies the files to a target path in the target filesystem</p> Source code in <code>niceml/utilities/copyutils.py</code> <pre><code>def copy_to_filesystem(\n    self, target_filesystem: AbstractFileSystem, target_path: str\n):\n    \"\"\"Copies the files to a target path in the target filesystem\"\"\"\n    with open_location(self.location) as (source_file_system, root_path):\n        for src_file in self.copy_filelist:\n            tgt_file = join_fs_path(\n                target_filesystem, target_path, basename(src_file)\n            )\n            target_filesystem.makedirs(target_path, exist_ok=True)\n            with source_file_system.open(\n                join_fs_path(source_file_system, root_path, src_file), \"rb\"\n            ) as fsrc, target_filesystem.open(tgt_file, \"wb\") as ftgt:\n                ftgt.write(fsrc.read())\n</code></pre>"},{"location":"reference/utilities/copyutils/#niceml.utilities.copyutils-functions","title":"Functions","text":""},{"location":"reference/utilities/copyutils/#niceml.utilities.copyutils.filter_for_required","title":"filter_for_required","text":"<pre><code>filter_for_required(copy_file_list)\n</code></pre> <p>Checks if a copying files from input to output location is required. If a file already exists in the output location and has not changed (same filehash), copying this file is not required. Args:     copy_file_list: list of files to check</p> <p>Returns:</p> <ul> <li> <code>List[CopyFileInfo]</code>         \u2013          <p>List of files that are required to be copy</p> </li> </ul> Source code in <code>niceml/utilities/copyutils.py</code> <pre><code>def filter_for_required(copy_file_list: List[CopyFileInfo]) -&gt; List[CopyFileInfo]:\n    \"\"\"\n    Checks if a copying files from input to output location is required.\n    If a file already exists in the output location and has not changed (same filehash),\n    copying this file is not required.\n    Args:\n        copy_file_list: list of files to check\n\n    Returns:\n        List of files that are required to be copy\n    \"\"\"\n    file_info: CopyFileInfo\n    to_copy_info_list: List[CopyFileInfo] = []\n    for file_info in tqdm(copy_file_list):\n        with open_location(file_info.output_location) as (\n            output_filesystem,\n            output_path,\n        ):\n            if not (\n                output_filesystem.isfile(output_path)\n                and md5_from_file(output_path, output_filesystem) == file_info.checksum\n            ):\n                to_copy_info_list.append(file_info)\n    return to_copy_info_list\n</code></pre>"},{"location":"reference/utilities/copyutils/#niceml.utilities.copyutils.process_copy_files","title":"process_copy_files","text":"<pre><code>process_copy_files(copy_file_list)\n</code></pre> <p>Copies/symlinks all files without any checks from input to output location</p> Source code in <code>niceml/utilities/copyutils.py</code> <pre><code>def process_copy_files(copy_file_list: List[CopyFileInfo]):\n    \"\"\"Copies/symlinks all files without any checks from input to output location\"\"\"\n    file_info: CopyFileInfo\n    for file_info in tqdm(copy_file_list):\n        file_info.copy_file()\n</code></pre>"},{"location":"reference/utilities/encoding/","title":"encoding","text":""},{"location":"reference/utilities/encoding/#niceml.utilities.encoding","title":"encoding","text":"<p>Module for encoding files, data or arrays</p>"},{"location":"reference/utilities/encoding/#niceml.utilities.encoding-functions","title":"Functions","text":""},{"location":"reference/utilities/encoding/#niceml.utilities.encoding.base64_to_bytesio","title":"base64_to_bytesio","text":"<pre><code>base64_to_bytesio(encoded_data)\n</code></pre> <p>Returns a BytesIO stream of the decoded data</p> Source code in <code>niceml/utilities/encoding.py</code> <pre><code>def base64_to_bytesio(encoded_data: Union[bytes, str]) -&gt; BytesIO:\n    \"\"\"Returns a BytesIO stream of the decoded data\"\"\"\n    # can be used with PIL.Image.open to get an image\n    return BytesIO(base64.b64decode(encoded_data))\n</code></pre>"},{"location":"reference/utilities/encoding/#niceml.utilities.encoding.get_base64_from_file","title":"get_base64_from_file","text":"<pre><code>get_base64_from_file(filepath, filesystem=None)\n</code></pre> <p>Returns a file encoded as base64</p> Source code in <code>niceml/utilities/encoding.py</code> <pre><code>def get_base64_from_file(\n    filepath: str, filesystem: Optional[AbstractFileSystem] = None\n) -&gt; bytes:\n    \"\"\"Returns a file encoded as base64\"\"\"\n    if filesystem is None:\n        filesystem = LocalFileSystem()\n\n    with filesystem.open(filepath, \"rb\") as target_file:\n        encoded_string = base64.b64encode(target_file.read())\n\n    return encoded_string\n</code></pre>"},{"location":"reference/utilities/encoding/#niceml.utilities.encoding.numpy_to_base64","title":"numpy_to_base64","text":"<pre><code>numpy_to_base64(array, format='png')\n</code></pre> <p>Stores a numpy array as base 64. Only works with correct format restrictions.</p> Source code in <code>niceml/utilities/encoding.py</code> <pre><code>def numpy_to_base64(\n    array: np.ndarray, format: str = \"png\"\n) -&gt; str:  # pylint: disable=redefined-builtin\n    \"\"\"Stores a numpy array as base 64. Only works with correct format restrictions.\"\"\"\n    pil_img = Image.fromarray(array)\n    buff = BytesIO()\n    pil_img.save(buff, format=format)\n    return base64.b64encode(buff.getvalue()).decode(\"utf-8\")\n</code></pre>"},{"location":"reference/utilities/factoryutils/","title":"factoryutils","text":""},{"location":"reference/utilities/factoryutils/#niceml.utilities.factoryutils","title":"factoryutils","text":"<p>Modul for factory utilities</p>"},{"location":"reference/utilities/factoryutils/#niceml.utilities.factoryutils-classes","title":"Classes","text":""},{"location":"reference/utilities/factoryutils/#niceml.utilities.factoryutils.ImportExceptionError","title":"ImportExceptionError","text":"<p>             Bases: <code>Exception</code></p> <p>Exception if an import is not possible</p>"},{"location":"reference/utilities/factoryutils/#niceml.utilities.factoryutils.InitializationParamsError","title":"InitializationParamsError","text":"<p>             Bases: <code>Exception</code></p> <p>Exception for invalid initialization parameters</p>"},{"location":"reference/utilities/factoryutils/#niceml.utilities.factoryutils.NoValidParameterPathError","title":"NoValidParameterPathError","text":"<p>             Bases: <code>Exception</code></p> <p>Exception if parameter path is not valid</p>"},{"location":"reference/utilities/factoryutils/#niceml.utilities.factoryutils-functions","title":"Functions","text":""},{"location":"reference/utilities/factoryutils/#niceml.utilities.factoryutils.import_function","title":"import_function","text":"<pre><code>import_function(function_name)\n</code></pre> <p>Takes a string as input and returns the function object that is referenced by the string. The string must be in the format of 'module_name.class_name'. The import_module function from Python's built-in importlib module is used to import the module, and then getattr() is used to retrieve an attribute from it (the class).</p> <p>Parameters:</p> <ul> <li> <code>function_name</code>             (<code>str</code>)         \u2013          <p>str: Specify the type of the parameter</p> </li> </ul> <p>Returns:      Function object</p> Source code in <code>niceml/utilities/factoryutils.py</code> <pre><code>def import_function(function_name: str):\n    \"\"\"\n    Takes a string as input and returns the function object that is referenced by the string.\n    The string must be in the format of 'module_name.class_name'. The import_module function\n    from Python's built-in importlib module is used to import the module, and then getattr()\n    is used to retrieve an attribute from it (the class).\n\n    Args:\n        function_name: str: Specify the type of the parameter\n    Returns:\n         Function object\n    \"\"\"\n    type_list = function_name.rsplit(\".\", 1)\n    try:\n        imported_module = import_module(type_list[0])\n    except ModuleNotFoundError as e:\n        raise Exception(f\"Module with name not found: {type_list[0]}\") from e\n    return getattr(imported_module, type_list[1])\n</code></pre>"},{"location":"reference/utilities/factoryutils/#niceml.utilities.factoryutils.init_object","title":"init_object","text":"<pre><code>init_object(input_dict, additional_info=None)\n</code></pre> <p>Imports a class or function dynamically. When <code>type</code> is used the object is initialized with the given <code>params</code> accordingly. Otherwise (with <code>function</code>-keyword), only the imported object is returned.</p> <p>Parameters:</p> <ul> <li> <code>input_dict</code>             (<code>Union[dict, list]</code>)         \u2013          <p>Dict with keywords (type and params) or function.</p> </li> </ul> <p>additional_info: Additional information about to use for initialization.</p> <p>Returns:</p> <ul> <li> <code>Any</code>         \u2013          <p>Initialized or imported object/class/function.</p> </li> </ul> Source code in <code>niceml/utilities/factoryutils.py</code> <pre><code>def init_object(\n    input_dict: Union[dict, list],\n    additional_info: Optional[Union[dict, dataclass]] = None,\n) -&gt; Any:\n    \"\"\"\n    Imports a class or function dynamically.\n    When `type` is used the object is initialized with the given `params` accordingly.\n    Otherwise (with `function`-keyword), only the imported object is returned.\n\n    Args:\n        input_dict: Dict with keywords (type and params) or function.\n    additional_info: Additional information about to use for initialization.\n\n    Returns:\n        Initialized or imported object/class/function.\n    \"\"\"\n    if is_dataclass(additional_info):\n        additional_info = asdict(additional_info)\n\n    if additional_info is None:\n        additional_info = {}\n\n    if isinstance(input_dict, list):\n        return [init_object(x, additional_info) for x in input_dict]\n\n    use_params: bool = False\n    if \"type\" in input_dict:\n        cur_type: str = input_dict[\"type\"]\n        use_params = True\n    elif \"function\" in input_dict:\n        cur_type: str = input_dict[\"function\"]\n    else:\n        raise ImportExceptionError(\"Neither type nor function keyword in param dict!\")\n\n    type_list = cur_type.rsplit(\".\", 1)\n    try:\n        imported_module = import_module(type_list[0])\n    except ModuleNotFoundError as error:\n        raise Exception(f\"Module with name not found: {type_list[0]}\") from error\n    imported_type = getattr(imported_module, type_list[1])\n    if use_params:\n        init_dict = input_dict.get(\"params\", {})\n        try:\n            init_class = imported_type(**init_dict, **additional_info)\n        except TypeError as error:\n            raise InitializationParamsError(\n                f\"Failed to initialize: {cur_type}\"\n            ) from error\n    else:\n        init_class = imported_type\n\n    return init_class\n</code></pre>"},{"location":"reference/utilities/factoryutils/#niceml.utilities.factoryutils.subs_path_and_create_folder","title":"subs_path_and_create_folder","text":"<pre><code>subs_path_and_create_folder(filepath, short_id, run_id)\n</code></pre> <p>Takes a filepath, and replaces the keys 'short_id' and 'run_id' with the corresponding values. It then creates any necessary folders in order to make the path valid.</p> <p>Parameters:</p> <ul> <li> <code>filepath</code>             (<code>str</code>)         \u2013          <p>Pass the filepath to the function</p> </li> <li> <code>short_id</code>             (<code>str</code>)         \u2013          <p>Replace the short_id key in the filepath string</p> </li> <li> <code>run_id</code>             (<code>str</code>)         \u2013          <p>Create a unique folder for each run</p> </li> </ul> <p>Returns:      filepath with replaced short id and run id</p> Source code in <code>niceml/utilities/factoryutils.py</code> <pre><code>def subs_path_and_create_folder(filepath: str, short_id: str, run_id: str) -&gt; str:\n    \"\"\"\n    Takes a filepath, and replaces the keys 'short_id' and 'run_id' with the corresponding\n    values. It then creates any necessary folders in order to make the path valid.\n\n    Args:\n        filepath: Pass the filepath to the function\n        short_id: Replace the short_id key in the filepath string\n        run_id: Create a unique folder for each run\n    Returns:\n         filepath with replaced short id and run id\n    \"\"\"\n    filepath = replace_id_keys(filepath, short_id, run_id)\n    filepath_obj = Path(filepath)\n    filepath_obj.parent.mkdir(parents=True, exist_ok=True)\n    return filepath\n</code></pre>"},{"location":"reference/utilities/gitutils/","title":"gitutils","text":""},{"location":"reference/utilities/gitutils/#niceml.utilities.gitutils","title":"gitutils","text":"<p>Module for git utils</p>"},{"location":"reference/utilities/gitutils/#niceml.utilities.gitutils-classes","title":"Classes","text":""},{"location":"reference/utilities/gitutils/#niceml.utilities.gitutils.NoGitHashAvailableError","title":"NoGitHashAvailableError","text":"<p>             Bases: <code>Exception</code></p> <p>Exception for when no git hash is available</p>"},{"location":"reference/utilities/gitutils/#niceml.utilities.gitutils-functions","title":"Functions","text":""},{"location":"reference/utilities/gitutils/#niceml.utilities.gitutils.get_git_revision_hash","title":"get_git_revision_hash","text":"<pre><code>get_git_revision_hash(path='.')\n</code></pre> <p>Get the git revision hash of the repository located in the path</p> Source code in <code>niceml/utilities/gitutils.py</code> <pre><code>def get_git_revision_hash(path: str = \".\"):\n    \"\"\"Get the git revision hash of the repository located in the path\"\"\"\n    try:\n        git_commit_hash = subprocess.check_output(\n            [\"git\", \"rev-parse\", \"HEAD\"], cwd=path\n        )\n    except Exception as exc:\n        raise NoGitHashAvailableError(\n            f\"Folder seems to be no git repo: {path}\"\n        ) from exc\n\n    return git_commit_hash.decode(\"utf-8\")\n</code></pre>"},{"location":"reference/utilities/gitutils/#niceml.utilities.gitutils.get_git_revision_of_module","title":"get_git_revision_of_module","text":"<pre><code>get_git_revision_of_module(module_name)\n</code></pre> <p>Get the git revision hash of a module</p> Source code in <code>niceml/utilities/gitutils.py</code> <pre><code>def get_git_revision_of_module(module_name: str):\n    \"\"\"Get the git revision hash of a module\"\"\"\n    mod_dir = get_module_dir(module_name)\n    return get_git_revision_hash(mod_dir)\n</code></pre>"},{"location":"reference/utilities/gitutils/#niceml.utilities.gitutils.get_module_dir","title":"get_module_dir","text":"<pre><code>get_module_dir(module_name)\n</code></pre> <p>Get the directory of a module</p> Source code in <code>niceml/utilities/gitutils.py</code> <pre><code>def get_module_dir(module_name: str):\n    \"\"\"Get the directory of a module\"\"\"\n    module = import_module(module_name)\n    return os.path.dirname(module.__file__)\n</code></pre>"},{"location":"reference/utilities/gitutils/#niceml.utilities.gitutils.produce_git_version_yaml","title":"produce_git_version_yaml","text":"<pre><code>produce_git_version_yaml(\n    exp_context, filepath, git_dirs=None, git_modules=None\n)\n</code></pre> <p>Produce a yaml file with the git hashes of the given directories and modules</p> Source code in <code>niceml/utilities/gitutils.py</code> <pre><code>def produce_git_version_yaml(\n    exp_context: ExperimentContext,\n    filepath: str,\n    git_dirs: Union[str, List[str], None] = None,\n    git_modules: Union[str, List[str], None] = None,\n):\n    \"\"\"Produce a yaml file with the git hashes of the given directories and modules\"\"\"\n    if git_modules is None:\n        git_modules = []\n    if git_dirs is None:\n        git_dirs = []\n\n    output_versions = {}\n    for cur_dir in git_dirs:\n        try:\n            output_versions[cur_dir] = get_git_revision_hash(cur_dir)\n        except NoGitHashAvailableError:\n            output_versions[cur_dir] = \"NoVersionAvailable\"\n    for mod in git_modules:\n        try:\n            output_versions[mod] = get_git_revision_of_module(mod)\n        except NoGitHashAvailableError:\n            output_versions[mod] = \"NoVersionAvailable\"\n    exp_context.write_yaml(output_versions, filepath)\n</code></pre>"},{"location":"reference/utilities/hydrautils/","title":"hydrautils","text":""},{"location":"reference/utilities/hydrautils/#niceml.utilities.hydrautils","title":"hydrautils","text":"<p>module for utilities related to hydra</p>"},{"location":"reference/utilities/hydrautils/#niceml.utilities.hydrautils-functions","title":"Functions","text":""},{"location":"reference/utilities/hydrautils/#niceml.utilities.hydrautils.build_import_graph","title":"build_import_graph","text":"<pre><code>build_import_graph(root_file, search_paths=None)\n</code></pre> <p>Builds a directed graph of the import hierarchy of the given root file. Args:      root_file: Path to the yaml-root file of the import hierarchy      search_paths: List of paths to search for imported yaml files Returns:      import_graph: Directed graph of the import hierarchy</p> Source code in <code>niceml/utilities/hydrautils.py</code> <pre><code>def build_import_graph(\n    root_file: str, search_paths: Optional[List[str]] = None\n) -&gt; nx.DiGraph:\n    \"\"\"Builds a directed graph of the import hierarchy of the given root file.\n    Args:\n         root_file: Path to the yaml-root file of the import hierarchy\n         search_paths: List of paths to search for imported yaml files\n    Returns:\n         import_graph: Directed graph of the import hierarchy\n    \"\"\"\n    # Initialize the import graph\n    import_graph = nx.DiGraph()\n    search_paths = search_paths or []\n\n    # Get the root file's directory and load its configuration\n    root_config_path, root_config = find_and_read_file(\n        root_file, search_paths=search_paths, read_func=read_yaml\n    )\n\n    # Add the root file to the import graph\n    import_graph.add_node(root_file)\n    search_paths.append(dirname(root_config_path))\n    # Traverse the import hierarchy recursively\n    import_graph = traverse_import_hierarchy(\n        root_config, root_file, import_graph, search_paths=search_paths\n    )\n    return import_graph\n</code></pre>"},{"location":"reference/utilities/hydrautils/#niceml.utilities.hydrautils.nx_to_mermaid","title":"nx_to_mermaid","text":"<pre><code>nx_to_mermaid(nx_graph)\n</code></pre> <p>Converts a networkx graph to a Mermaid.js graph string.</p> Source code in <code>niceml/utilities/hydrautils.py</code> <pre><code>def nx_to_mermaid(nx_graph: nx.DiGraph):\n    \"\"\"Converts a networkx graph to a Mermaid.js graph string.\"\"\"\n    # Initialize the Mermaid.js graph string\n    mermaid_graph = \"graph LR;\\n\"\n\n    for source, target in nx_graph.edges():\n        source_text = basename(splitext(source)[0])\n        target_text = basename(splitext(target)[0])\n        mermaid_graph += f\"{source}({source_text}) --&gt; {target}({target_text});\\n\"\n\n    return mermaid_graph\n</code></pre>"},{"location":"reference/utilities/hydrautils/#niceml.utilities.hydrautils.parse_defaults_content","title":"parse_defaults_content","text":"<pre><code>parse_defaults_content(entry)\n</code></pre> <p>Parses the content of a defaults entry and returns the corresponding path.</p> Source code in <code>niceml/utilities/hydrautils.py</code> <pre><code>def parse_defaults_content(entry: Union[dict, str]) -&gt; str:\n    \"\"\"Parses the content of a defaults entry and returns the corresponding path.\"\"\"\n    if isinstance(entry, dict):\n        if len(entry) != 1:\n            raise ValueError(\"Only one key allowed in defaults entry\")\n        main_val = list(entry.keys())[0]\n        additional_val = entry[main_val]\n\n    else:\n        main_val = entry\n        additional_val = \"\"\n\n    if \"@\" in main_val:\n        main_val = main_val.split(\"@\")[0]\n\n    if len(additional_val) &gt; 0:\n        return_val = \"/\".join([main_val, additional_val])\n    else:\n        return_val = main_val\n    return return_val\n</code></pre>"},{"location":"reference/utilities/hydrautils/#niceml.utilities.hydrautils.traverse_import_hierarchy","title":"traverse_import_hierarchy","text":"<pre><code>traverse_import_hierarchy(\n    config, config_file, import_graph, search_paths\n)\n</code></pre> <p>Traverses the import hierarchy of the given configuration file and adds the import edges to the import graph.</p> Source code in <code>niceml/utilities/hydrautils.py</code> <pre><code>def traverse_import_hierarchy(\n    config: dict, config_file: str, import_graph: nx.DiGraph, search_paths: List[str]\n):\n    \"\"\"Traverses the import hierarchy of the given configuration file and adds the import edges to the import graph.\"\"\"\n    if \"defaults\" in config:\n        for import_path in config[\"defaults\"]:\n            # Build the absolute path to the imported configuration file\n            import_path = parse_defaults_content(import_path)\n            if import_path == \"_self_\":\n                continue\n            import_file, import_conf = find_and_read_file(\n                import_path, search_paths=search_paths, read_func=read_yaml\n            )\n\n            # Add the imported configuration file to the import graph\n            import_graph.add_node(import_file)\n            import_graph.add_edge(config_file, import_file)\n\n            # Load and traverse the imported configuration file\n            import_config = yaml.safe_load(open(import_file))\n            cur_search_paths = search_paths.copy() + [dirname(import_file)]\n            traverse_import_hierarchy(\n                import_config, import_file, import_graph, search_paths=cur_search_paths\n            )\n    return import_graph\n</code></pre>"},{"location":"reference/utilities/idutils/","title":"idutils","text":""},{"location":"reference/utilities/idutils/#niceml.utilities.idutils","title":"idutils","text":"<p>Module for generating id's</p>"},{"location":"reference/utilities/idutils/#niceml.utilities.idutils-functions","title":"Functions","text":""},{"location":"reference/utilities/idutils/#niceml.utilities.idutils.base_10_to_n","title":"base_10_to_n","text":"<pre><code>base_10_to_n(number, base_chars)\n</code></pre> <p>Convert 'number' to given base with character list Args:     number: Specify the number to be converted     base_chars: characters to convert to Returns:     The base-n representation of a given number</p> Source code in <code>niceml/utilities/idutils.py</code> <pre><code>def base_10_to_n(number: int, base_chars: list) -&gt; str:\n    \"\"\"\n    Convert 'number' to given base with character list\n    Args:\n        number: Specify the number to be converted\n        base_chars: characters to convert to\n    Returns:\n        The base-n representation of a given number\n    \"\"\"\n    base = len(base_chars)\n    if base &lt;= 1:\n        raise ValueError(\"len(base_chars) must be more than 2\")\n    converted_string = \"\"\n    if number == 0:\n        converted_string += base_chars[0]\n    current_number = number\n    while current_number &gt; 0:\n        current_number, mod = divmod(current_number, base)\n        converted_string = base_chars[mod] + converted_string\n    return converted_string\n</code></pre>"},{"location":"reference/utilities/idutils/#niceml.utilities.idutils.generate_short_id","title":"generate_short_id","text":"<pre><code>generate_short_id(run_id, id_len=4)\n</code></pre> <p>Generates an alphanumeric hashed version of an experiments run_id</p> Source code in <code>niceml/utilities/idutils.py</code> <pre><code>def generate_short_id(run_id: str, id_len=4) -&gt; str:\n    \"\"\"Generates an alphanumeric hashed version of an experiments run_id\"\"\"\n    hash_value = hashlib.md5(str([run_id]).encode()).hexdigest()\n    hash_value = int(hash_value, base=16)\n    poss_values = len(ALPHANUMERICLIST) ** id_len\n    hash_value %= poss_values\n    str_value = base_10_to_n(hash_value, ALPHANUMERICLIST)\n    str_value = str_value.rjust(id_len, ALPHANUMERICLIST[0])\n    return str_value\n</code></pre>"},{"location":"reference/utilities/idutils/#niceml.utilities.idutils.id_from_id_list","title":"id_from_id_list","text":"<pre><code>id_from_id_list(id_list, id_len=4)\n</code></pre> <p>Returns a single id from a list of id's</p> Source code in <code>niceml/utilities/idutils.py</code> <pre><code>def id_from_id_list(id_list: list, id_len=4):\n    \"\"\"Returns a single id from a list of id's\"\"\"\n    hash_value = hashlib.md5(str(id_list).encode()).hexdigest()\n    hash_value = int(hash_value, base=16)\n    poss_values = len(ALPHANUMERICLIST) ** id_len\n    hash_value %= poss_values\n    str_value = base_10_to_n(hash_value, ALPHANUMERICLIST)\n    str_value = str_value.rjust(id_len, ALPHANUMERICLIST[0])\n    return str_value\n</code></pre>"},{"location":"reference/utilities/imagegeneration/","title":"imagegeneration","text":""},{"location":"reference/utilities/imagegeneration/#niceml.utilities.imagegeneration","title":"imagegeneration","text":"<p>Module for functions to generate test image dataset</p>"},{"location":"reference/utilities/imagegeneration/#niceml.utilities.imagegeneration-classes","title":"Classes","text":""},{"location":"reference/utilities/imagegeneration/#niceml.utilities.imagegeneration.NumberDataGenerator","title":"NumberDataGenerator  <code>dataclass</code>","text":"<p>Generator of images with numbers for an object detection test dataset</p>"},{"location":"reference/utilities/imagegeneration/#niceml.utilities.imagegeneration.NumberDataGenerator-functions","title":"Functions","text":""},{"location":"reference/utilities/imagegeneration/#niceml.utilities.imagegeneration.NumberDataGenerator.generate_images","title":"generate_images","text":"<pre><code>generate_images()\n</code></pre> <p>Generate images based on a configuration (self). Returns image_location to generated images.</p> Source code in <code>niceml/utilities/imagegeneration.py</code> <pre><code>def generate_images(self) -&gt; dict:\n    \"\"\"Generate images based on a configuration (self).\n    Returns image_location to generated images.\"\"\"\n\n    if len(self.sub_dir) &gt; 0:\n        location = join_location_w_path(self.location, self.sub_dir)\n    else:\n        location = self.location\n\n    _, output_location = generate_test_images(\n        location=location,\n        sample_count=self.sample_count,\n        seed=self.seed,\n        max_number=self.max_number,\n        img_size=self.img_size,\n        font_size_min=self.font_size_min,\n        font_size_max=self.font_size_max,\n        detection_labels=self.detection_labels,\n        rotate=self.rotate,\n    )\n\n    if isinstance(output_location, LocationConfig):\n        output_location = asdict(output_location)\n    return output_location\n</code></pre>"},{"location":"reference/utilities/imagegeneration/#niceml.utilities.imagegeneration-functions","title":"Functions","text":""},{"location":"reference/utilities/imagegeneration/#niceml.utilities.imagegeneration.convert_image_to_df_row","title":"convert_image_to_df_row","text":"<pre><code>convert_image_to_df_row(\n    identifier, label, image, target_size=None\n)\n</code></pre> <p>Takes an image and converts it to a row of data for a pandas DataFrame.</p> <p>Parameters:</p> <ul> <li> <code>identifier</code>             (<code>str</code>)         \u2013          <p>str: Value to identify the image</p> </li> <li> <code>label</code>             (<code>str</code>)         \u2013          <p>str: Target label of the image</p> </li> <li> <code>image</code>             (<code>Union[ndarray, Image]</code>)         \u2013          <p>Union[np.ndarray,ImageType]: Image to convert into a dataframe row</p> </li> <li> <code>target_size</code>             (<code>Optional[Union[Tuple[int, int], ImageSize]]</code>, default:                 <code>None</code> )         \u2013          <p>Optional[Union[Tuple[int, int]: Specify the target size of the image</p> </li> </ul> <p>Returns:     A dictionary representing a dataframe row</p> Source code in <code>niceml/utilities/imagegeneration.py</code> <pre><code>def convert_image_to_df_row(\n    identifier: str,\n    label: str,\n    image: Union[np.ndarray, ImageType],\n    target_size: Optional[Union[Tuple[int, int], ImageSize]] = None,\n) -&gt; dict:\n    \"\"\"\n    Takes an image and converts it to a row of data for a pandas DataFrame.\n\n    Args:\n        identifier: str: Value to identify the image\n        label: str: Target label of the image\n        image: Union[np.ndarray,ImageType]: Image to convert into a dataframe row\n        target_size: Optional[Union[Tuple[int, int]: Specify the target size of the image\n    Returns:\n        A dictionary representing a dataframe row\n    \"\"\"\n\n    df_row = {\"identifier\": identifier, \"label\": int(label)}\n    if isinstance(image, np.ndarray):\n        image = Image.fromarray(image)\n    image = image.convert(mode=\"L\")\n    image = np.asarray(image, dtype=np.uint8)\n\n    if target_size:\n        if isinstance(target_size, ImageSize):\n            target_size = target_size.to_numpy_shape()\n        image = np.resize(image, target_size)\n    else:\n        target_size = image.shape\n\n    for y in range(target_size[0]):\n        for x in range(target_size[1]):\n            df_row[f\"px_{y}_{x}\"] = image[y, x]  # px = pixel\n    return df_row\n</code></pre>"},{"location":"reference/utilities/imagegeneration/#niceml.utilities.imagegeneration.create_objdet_instance_label_from_text_label","title":"create_objdet_instance_label_from_text_label","text":"<pre><code>create_objdet_instance_label_from_text_label(\n    class_name,\n    img_size=None,\n    bounding_box_width=None,\n    bounding_box_height=None,\n    text_layer_position=None,\n    rotation=None,\n)\n</code></pre> <p>Creates an instance of an <code>ObjDetInstanceLabel</code> including bounding box information if all parameters are given. Otherwise, only the class_name is included.</p> <p>Parameters:</p> <ul> <li> <code>class_name</code>             (<code>str</code>)         \u2013          <p>Name of the class to label</p> </li> <li> <code>img_size</code>             (<code>ImageSize</code>, default:                 <code>None</code> )         \u2013          <p>Size of image the label fits to</p> </li> <li> <code>bounding_box_width</code>             (<code>int</code>, default:                 <code>None</code> )         \u2013          <p>Width of bounding box</p> </li> <li> <code>bounding_box_height</code>             (<code>int</code>, default:                 <code>None</code> )         \u2013          <p>Height of bounding box</p> </li> <li> <code>text_layer_position</code>             (<code>Tuple[int, int]</code>, default:                 <code>None</code> )         \u2013          <p>Position of text to be labeled on the image</p> </li> <li> <code>rotation</code>             (<code>int</code>, default:                 <code>None</code> )         \u2013          <p>Rotation of the text</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ObjDetInstanceLabel</code>         \u2013          <p>ObjDetInstanceLabel with class information and,</p> </li> <li> <code>ObjDetInstanceLabel</code>         \u2013          <p>if given,position of the label (bounding box)</p> </li> </ul> Source code in <code>niceml/utilities/imagegeneration.py</code> <pre><code>def create_objdet_instance_label_from_text_label(  # noqa: PLR0913\n    class_name: str,\n    img_size: ImageSize = None,\n    bounding_box_width: int = None,\n    bounding_box_height: int = None,\n    text_layer_position: Tuple[int, int] = None,\n    rotation: int = None,\n) -&gt; ObjDetInstanceLabel:\n    \"\"\"\n    Creates an instance of an `ObjDetInstanceLabel` including bounding box\n    information if all parameters are given. Otherwise, only the class_name is included.\n\n    Args:\n        class_name: Name of the class to label\n        img_size: Size of image the label fits to\n        bounding_box_width: Width of bounding box\n        bounding_box_height: Height of bounding box\n        text_layer_position: Position of text to be labeled on the image\n        rotation: Rotation of the text\n\n    Returns:\n        ObjDetInstanceLabel with class information and,\n        if given,position of the label (bounding box)\n    \"\"\"\n\n    if None in (bounding_box_width, bounding_box_height, img_size, text_layer_position):\n        return ObjDetInstanceLabel(class_name=class_name, bounding_box=None)\n\n    bounding_box = BoundingBox(\n        x_pos=int(text_layer_position[0]),\n        y_pos=int(text_layer_position[1]),\n        width=bounding_box_width,\n        height=bounding_box_height,\n    )\n\n    return ObjDetInstanceLabel(\n        class_name=class_name, bounding_box=bounding_box, rotation=rotation\n    )\n</code></pre>"},{"location":"reference/utilities/imagegeneration/#niceml.utilities.imagegeneration.crop_text_layer_to_text","title":"crop_text_layer_to_text","text":"<pre><code>crop_text_layer_to_text(text_layer)\n</code></pre> <p>Takes in a text layer (image object) and returns the same image, but cropped to only include the number</p> <p>Parameters:</p> <ul> <li> <code>text_layer</code>             (<code>Image</code>)         \u2013          <p>image layer including text and is otherwise transparent (0)</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Image</code>         \u2013          <p>cropped version of text_layer with only the number part of the image object</p> </li> </ul> Source code in <code>niceml/utilities/imagegeneration.py</code> <pre><code>def crop_text_layer_to_text(text_layer: ImageType) -&gt; ImageType:\n    \"\"\"\n    Takes in a text layer (image object) and returns the same image, but cropped to only include\n    the number\n\n    Args:\n        text_layer: image layer including text and is otherwise transparent (0)\n\n    Returns:\n        cropped version of text_layer with only the number part of the image object\n    \"\"\"\n    pixels = text_layer.load()\n    width, height = text_layer.size\n    max_x = max_y = 0\n    min_y = copy(height)\n    min_x = copy(width)\n\n    # Find the corners that bound the number by looking for non-transparent pixels\n    for x_pos in range(width):\n        for y_pos in range(height):\n            curr_pixel = pixels[x_pos, y_pos]\n            if curr_pixel != 0:\n                min_x = min(x_pos, min_x)\n                min_y = min(y_pos, min_y)\n                max_x = max(x_pos, max_x)\n                max_y = max(y_pos, max_y)\n\n    return text_layer.crop((min_x, min_y, max_x, max_y))\n</code></pre>"},{"location":"reference/utilities/imagegeneration/#niceml.utilities.imagegeneration.draw_number_on_image","title":"draw_number_on_image","text":"<pre><code>draw_number_on_image(\n    img,\n    random_generator,\n    max_number,\n    random_font_size,\n    img_size,\n    rotate,\n    mask_img,\n)\n</code></pre> <p>Draws a number on an image, rotates it randomly (if rotate == True) and returns text information (text,text layer, text layer position) Args:     img: image to draw the numbers on     random_generator: Generator of random numbers     max_number: Maximum number of digits that can be generated     random_font_size: Size of numbers in image     img_size: Size of the generated image     rotate: Whether the number should be rotated randomly or not     mask_img: Image with label information</p> <p>Returns:</p> <ul> <li> <code>Image</code>         \u2013          <p>Tuple of 6 parameters: The image, the drawn number, the text_layer, the position of</p> </li> <li> <code>str</code>         \u2013          <p>the number on the image, rotation of the drawn number, mask_img with updated label</p> </li> <li> <code>Image</code>         \u2013          <p>information.</p> </li> </ul> Source code in <code>niceml/utilities/imagegeneration.py</code> <pre><code>def draw_number_on_image(  # noqa: PLR0913\n    img: ImageType,\n    random_generator,\n    max_number: int,\n    random_font_size: int,\n    img_size: ImageSize,\n    rotate: bool,\n    mask_img: ImageType,\n) -&gt; Tuple[ImageType, str, ImageType, Tuple[int, int], int, ImageType]:\n    \"\"\"\n    Draws a number on an image, rotates it randomly (if rotate == True) and\n    returns text information (text,text layer, text layer position)\n    Args:\n        img: image to draw the numbers on\n        random_generator: Generator of random numbers\n        max_number: Maximum number of digits that can be generated\n        random_font_size: Size of numbers in image\n        img_size: Size of the generated image\n        rotate: Whether the number should be rotated randomly or not\n        mask_img: Image with label information\n\n    Returns:\n        Tuple of 6 parameters: The image, the drawn number, the text_layer, the position of\n        the number on the image, rotation of the drawn number, mask_img with updated label\n        information.\n    \"\"\"\n    number = int(random_generator.integers(0, max_number, 1)[0])\n    number_to_draw = str(number)\n\n    text_layer = Image.new(\n        \"L\", (int(random_font_size * 1.4), int(random_font_size * 1.4))\n    )\n\n    draw = ImageDraw.Draw(text_layer)\n    number_position = get_random_position(\n        random_generator=random_generator,\n        font_size=random_font_size,\n        img_size=img_size,\n    )\n    draw.text(\n        xy=(0, 0),\n        text=number_to_draw,\n        fill=255,\n        font=get_rand_font(\n            random_generator=random_generator, font_size=random_font_size\n        ),\n    )\n\n    if rotate:\n        rotation = get_rand_rotation(random_generator=random_generator)\n        text_layer = crop_text_layer_to_text(text_layer.rotate(rotation, expand=True))\n    else:\n        rotation = None\n        text_layer = crop_text_layer_to_text(text_layer)\n\n    img.paste(\n        ImageOps.colorize(\n            text_layer,\n            black=\"black\",\n            white=get_random_color(random_generator=random_generator),\n        ),\n        number_position,\n        text_layer,\n    )\n    text_classidx_img = Image.new(\"L\", text_layer.size, color=number)\n    mask_img.paste(\n        text_classidx_img,\n        number_position,\n        text_layer,\n    )\n\n    return img, number_to_draw, text_layer, number_position, rotation, mask_img\n</code></pre>"},{"location":"reference/utilities/imagegeneration/#niceml.utilities.imagegeneration.generate_number_image","title":"generate_number_image","text":"<pre><code>generate_number_image(\n    random_generator,\n    location=None,\n    max_number=10,\n    img_size=ImageSize(256, 256),\n    rotate=False,\n    font_size_min=80,\n    font_size_max=140,\n    detection_label=False,\n    max_amount=3,\n    save=False,\n)\n</code></pre> <p>Creates a series of generated images with random numbers on them and saves them, if save == True, including the label information (= position of numbers). Images are either a random color or a thumbnail image. Returns a list of created classes and the output_location.</p> <p>Parameters:</p> <ul> <li> <code>random_generator</code>         \u2013          <p>Generator of random numbers</p> </li> <li> <code>location</code>             (<code>Union[dict, LocationConfig]</code>, default:                 <code>None</code> )         \u2013          <p>Output location of the image and its label</p> </li> <li> <code>max_number</code>             (<code>int</code>, default:                 <code>10</code> )         \u2013          <p>Maximum number of digits that can be generated</p> </li> <li> <code>img_size</code>             (<code>ImageSize</code>, default:                 <code>ImageSize(256, 256)</code> )         \u2013          <p>Size of the generated image</p> </li> <li> <code>font_size_min</code>             (<code>int</code>, default:                 <code>80</code> )         \u2013          <p>Minimum font size of the numbers in the image</p> </li> <li> <code>font_size_max</code>             (<code>int</code>, default:                 <code>140</code> )         \u2013          <p>Maximum font size of the numbers in the image</p> </li> <li> <code>detection_label</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Determine if the label should be usable for object detection</p> </li> <li> <code>max_amount</code>             (<code>int</code>, default:                 <code>3</code> )         \u2013          <p>Maximum number of numbers in a single image</p> </li> <li> <code>rotate</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether the drawn numbers should be rotated randomly or not</p> </li> <li> <code>save</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Save the generated images to given output location</p> </li> </ul> <p>Returns:     The generated image, its mask_img and the instance_labels of the numbers</p> Source code in <code>niceml/utilities/imagegeneration.py</code> <pre><code>def generate_number_image(  # noqa: PLR0913\n    random_generator,\n    location: Union[dict, LocationConfig] = None,\n    max_number: int = 10,\n    img_size: ImageSize = ImageSize(256, 256),\n    rotate: bool = False,\n    font_size_min: int = 80,\n    font_size_max: int = 140,\n    detection_label: bool = False,\n    max_amount: int = 3,\n    save: bool = False,\n) -&gt; Tuple[ImageType, ImageType, List[Union[ObjDetInstanceLabel, None]]]:\n    \"\"\"\n    Creates a series of generated images with random numbers on them and saves them,\n    if save == True, including the label information (= position of numbers).\n    Images are either a random color or a thumbnail image.\n    Returns a list of created classes and the output_location.\n\n    Args:\n        random_generator: Generator of random numbers\n        location: Output location of the image and its label\n        max_number: Maximum number of digits that can be generated\n        img_size: Size of the generated image\n        font_size_min: Minimum font size of the numbers in the image\n        font_size_max: Maximum font size of the numbers in the image\n        detection_label: Determine if the label should be usable for object detection\n        max_amount: Maximum number of numbers in a single image\n        rotate: Whether the drawn numbers should be rotated randomly or not\n        save: Save the generated images to given output location\n    Returns:\n        The generated image, its mask_img and the instance_labels of the numbers\n    \"\"\"\n\n    augmentations = alb.Compose(\n        [\n            alb.ShiftScaleRotate(p=0.5),\n            alb.HorizontalFlip(p=0.5),\n            alb.RandomBrightnessContrast(p=0.3),\n            alb.OneOf(\n                [\n                    alb.OpticalDistortion(p=0.3),\n                    alb.GridDistortion(p=0.1),\n                ],\n                p=0.2,\n            ),\n            alb.OneOf(\n                [\n                    alb.CLAHE(clip_limit=2),\n                    alb.Sharpen(),\n                    alb.Emboss(),\n                    alb.RandomBrightnessContrast(),\n                ],\n                p=0.3,\n            ),\n            alb.HueSaturationValue(p=0.3),\n            alb.PiecewiseAffine(scale=0.3, p=0.35),\n        ]\n    )\n\n    instance_labels: List[Union[ObjDetInstanceLabel, None]] = []\n    random_font_size = random_generator.integers(font_size_min, font_size_max, 1)[0]\n    amount_of_numbers_on_image = random_generator.integers(1, max_amount + 1, 1)[0]\n\n    bg_image_paths = [\n        file\n        for file in Path(\n            f\"{Path(__file__).parent.resolve()}/assets/bg_images\"\n        ).iterdir()\n        if file.is_file()\n    ]\n    random_bg = random_generator.integers(0, len(bg_image_paths) - 1, 1)[0]\n    img = Image.open(bg_image_paths[random_bg]).resize(img_size.to_pil_size())\n\n    img_array = np.asarray(img)\n    augmented_img = augmentations(image=img_array)[\"image\"]\n    img = Image.fromarray(augmented_img)\n\n    mask_img = Image.new(\"L\", img.size, color=255)\n    for _ in range(amount_of_numbers_on_image):\n        (\n            img,\n            text,\n            text_layer,\n            text_layer_position,\n            rotation,\n            mask_img,\n        ) = draw_number_on_image(\n            img=img,\n            random_generator=random_generator,\n            max_number=max_number,\n            random_font_size=random_font_size,\n            img_size=img_size,\n            rotate=rotate,\n            mask_img=mask_img,\n        )\n        instance_labels.append(\n            create_objdet_instance_label_from_text_label(\n                **{\n                    \"text_layer_position\": text_layer_position,\n                    \"class_name\": text,\n                    \"img_size\": img_size,\n                    \"bounding_box_width\": text_layer.width,\n                    \"bounding_box_height\": text_layer.height,\n                    \"rotation\": rotation,\n                }\n                if detection_label\n                else {\"class_name\": text}\n            )\n        )\n\n    if save:\n        if not location:\n            raise AttributeError(\n                \"You have to pass a file_path if you want to save the image\"\n            )\n        file_name: str = sha256(img.tobytes()).hexdigest()[:8]\n        with open_location(location) as (cur_fs, root_path):\n            write_image(img, join(root_path, file_name + \".png\"), cur_fs)\n            write_image(mask_img, join(root_path, f\"{file_name}_mask.png\"), cur_fs)\n        if detection_label:\n            label = ObjDetImageLabel(\n                filename=join(f\"{file_name}.json\"),\n                img_size=img_size,\n                labels=instance_labels,\n            )\n\n            save_image_label_as_json(data=label, location=location, name=file_name)\n\n    return img, mask_img, instance_labels\n</code></pre>"},{"location":"reference/utilities/imagegeneration/#niceml.utilities.imagegeneration.generate_test_images","title":"generate_test_images","text":"<pre><code>generate_test_images(\n    location,\n    sample_count,\n    seed=1234,\n    max_number=10,\n    img_size=ImageSize(256, 256),\n    font_size_min=80,\n    font_size_max=140,\n    detection_labels=False,\n    max_amount=3,\n    rotate=False,\n    save=True,\n)\n</code></pre> <p>Wrapper function for 'generate_number_image', which creates a series of generated images with random numbers on them and saves them, if save == True, including the label information (= position of numbers). Returns a list of created classes and the output_location</p> <p>Parameters:</p> <ul> <li> <code>location</code>             (<code>Union[dict, LocationConfig]</code>)         \u2013          <p>Output location of the image and its label</p> </li> <li> <code>sample_count</code>             (<code>int</code>)         \u2013          <p>Number of images to be generated</p> </li> <li> <code>seed</code>             (<code>Optional[int]</code>, default:                 <code>1234</code> )         \u2013          <p>Seed for the random number generator</p> </li> <li> <code>max_number</code>         \u2013          <p>Maximum number of digits that can be generated</p> </li> <li> <code>img_size</code>             (<code>ImageSize</code>, default:                 <code>ImageSize(256, 256)</code> )         \u2013          <p>Size of the generated image</p> </li> <li> <code>font_size_min</code>             (<code>int</code>, default:                 <code>80</code> )         \u2013          <p>Minimum font size of the numbers in the image</p> </li> <li> <code>font_size_max</code>             (<code>int</code>, default:                 <code>140</code> )         \u2013          <p>Maximum font size of the numbers in the image</p> </li> <li> <code>detection_labels</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Determine if the label should be usable for object detection</p> </li> <li> <code>max_amount</code>             (<code>int</code>, default:                 <code>3</code> )         \u2013          <p>Maximum number of numbers in a single image</p> </li> <li> <code>rotate</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Whether the drawn numbers should be rotated randomly or not</p> </li> <li> <code>save</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>Save the generated images to given output location</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tuple[List[str], Union[dict, LocationConfig]]</code>         \u2013          <p>List of label classes and a location configuration</p> </li> </ul> Source code in <code>niceml/utilities/imagegeneration.py</code> <pre><code>def generate_test_images(  # noqa: PLR0913\n    location: Union[dict, LocationConfig],\n    sample_count: int,\n    seed: Optional[int] = 1234,\n    max_number=10,\n    img_size: ImageSize = ImageSize(256, 256),\n    font_size_min: int = 80,\n    font_size_max: int = 140,\n    detection_labels: bool = False,\n    max_amount: int = 3,\n    rotate: bool = False,\n    save: bool = True,\n) -&gt; Tuple[List[str], Union[dict, LocationConfig]]:\n    \"\"\"\n    Wrapper function for 'generate_number_image', which creates a series of generated images\n    with random numbers on them and saves them, if save == True, including the label\n    information (= position of numbers).\n    Returns a list of created classes and the output_location\n\n    Args:\n        location: Output location of the image and its label\n        sample_count: Number of images to be generated\n        seed: Seed for the random number generator\n        max_number: Maximum number of digits that can be generated\n        img_size: Size of the generated image\n        font_size_min: Minimum font size of the numbers in the image\n        font_size_max: Maximum font size of the numbers in the image\n        detection_labels: Determine if the label should be usable for object detection\n        max_amount: Maximum number of numbers in a single image\n        rotate: Whether the drawn numbers should be rotated randomly or not\n        save: Save the generated images to given output location\n\n    Returns:\n        List of label classes and a location configuration\n    \"\"\"\n\n    random_generator = np.random.default_rng(seed=seed)\n    random.seed(seed)  # Setting the seed of `random` is required by albumentation\n    images, _, labels = list(\n        map(\n            list,\n            zip(\n                *[\n                    generate_number_image(\n                        random_generator=random_generator,\n                        max_number=max_number,\n                        img_size=img_size,\n                        font_size_min=font_size_min,\n                        font_size_max=font_size_max,\n                        detection_label=detection_labels,\n                        max_amount=max_amount,\n                        rotate=rotate,\n                        location=location,\n                        save=save,\n                    )\n                    for _ in tqdm(\n                        range(sample_count), desc=\"Generate random number image\"\n                    )\n                ]\n            ),\n        )\n    )\n\n    classes = []\n    for _, labels_of_curr_images in zip(images, labels):\n        classes += [label.class_name for label in labels_of_curr_images]\n\n    return list(set(classes)), location\n</code></pre>"},{"location":"reference/utilities/imagegeneration/#niceml.utilities.imagegeneration.get_rand_font","title":"get_rand_font","text":"<pre><code>get_rand_font(random_generator, font_size=50)\n</code></pre> <p>Returns a randomly selected <code>FreeTypeFont</code> from ten predefined font names</p> Source code in <code>niceml/utilities/imagegeneration.py</code> <pre><code>def get_rand_font(random_generator, font_size: int = 50) -&gt; FreeTypeFont:\n    \"\"\"Returns a randomly selected `FreeTypeFont` from ten predefined font names\"\"\"\n\n    rand_font = random_generator.integers(0, 9, 1)[0]\n    fonts = [\n        \"OpenSans-Regular.ttf\",\n        \"DMMono-Regular.ttf\",\n        \"OxygenMono-Regular.ttf\",\n        \"RobotoMono-Regular.ttf\",\n        \"OpenSans-Regular.ttf\",\n        \"Oswald-Regular.ttf\",\n        \"Ubuntu-Regular.ttf\",\n        \"Rubik-Regular.ttf\",\n        \"Heebo-Regular.ttf\",\n        \"Karla-Regular.ttf\",\n        \"Dosis-Regular.ttf\",\n    ]\n    return get_font(font_name=fonts[rand_font], font_size=font_size)\n</code></pre>"},{"location":"reference/utilities/imagegeneration/#niceml.utilities.imagegeneration.get_rand_rotation","title":"get_rand_rotation","text":"<pre><code>get_rand_rotation(random_generator)\n</code></pre> <p>Returns a random rotation between 10 and 350</p> Source code in <code>niceml/utilities/imagegeneration.py</code> <pre><code>def get_rand_rotation(random_generator) -&gt; int:\n    \"\"\"Returns a random rotation between 10 and 350\"\"\"\n    return int(random_generator.integers(10, 350, 1)[0])\n</code></pre>"},{"location":"reference/utilities/imagegeneration/#niceml.utilities.imagegeneration.get_random_color","title":"get_random_color","text":"<pre><code>get_random_color(random_generator)\n</code></pre> <p>Returns a tuple representing random RGB values</p> Source code in <code>niceml/utilities/imagegeneration.py</code> <pre><code>def get_random_color(random_generator) -&gt; Tuple[int, int, int]:\n    \"\"\"Returns a tuple representing random RGB values\"\"\"\n    return tuple(random_generator.integers(0, 255, 3))\n</code></pre>"},{"location":"reference/utilities/imagegeneration/#niceml.utilities.imagegeneration.get_random_position","title":"get_random_position","text":"<pre><code>get_random_position(\n    random_generator,\n    img_size=ImageSize(256, 256),\n    font_size=None,\n)\n</code></pre> <p>Returns a random x and y coordinate inside an image size with a padding of a given font size</p> Source code in <code>niceml/utilities/imagegeneration.py</code> <pre><code>def get_random_position(\n    random_generator, img_size: ImageSize = ImageSize(256, 256), font_size: int = None\n) -&gt; Tuple[int, int]:\n    \"\"\"Returns a random x and y coordinate inside an image size\n    with a padding of a given font size\"\"\"\n\n    random_x = random_generator.integers(\n        0, img_size.width if font_size is None else (img_size.width - font_size)\n    )\n    random_y = random_generator.integers(\n        0, img_size.height if font_size is None else (img_size.height - font_size)\n    )\n    return random_x, random_y\n</code></pre>"},{"location":"reference/utilities/imagegeneration/#niceml.utilities.imagegeneration.get_scalar_columns_of_tabular_data","title":"get_scalar_columns_of_tabular_data","text":"<pre><code>get_scalar_columns_of_tabular_data(\n    tabular_data_location,\n    tabular_data_file_name=\"train.parq\",\n)\n</code></pre> <p>The get_scalar_columns_of_tabular_data function returns a list of the scalar columns in the tabular data.</p> <p>Parameters:</p> <ul> <li> <code>tabular_data_location</code>             (<code>Union[dict, LocationConfig]</code>)         \u2013          <p>Specify the location of the data</p> </li> <li> <code>tabular_data_file_name</code>             (<code>str</code>, default:                 <code>'train.parq'</code> )         \u2013          <p>Specify the name of the parquet file containing tabular data</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>List[str]</code>         \u2013          <p>A list of the scalar columns in the tabular data</p> </li> </ul> Source code in <code>niceml/utilities/imagegeneration.py</code> <pre><code>def get_scalar_columns_of_tabular_data(\n    tabular_data_location: Union[dict, LocationConfig],\n    tabular_data_file_name: str = \"train.parq\",\n) -&gt; List[str]:\n    \"\"\"\n    The get_scalar_columns_of_tabular_data function returns a list\n    of the scalar columns in the tabular data.\n\n    Args:\n        tabular_data_location: Specify the location of the data\n        tabular_data_file_name: Specify the name of the parquet file containing tabular data\n\n    Returns:\n        A list of the scalar columns in the tabular data\n    \"\"\"\n    with open_location(tabular_data_location) as (tabular_data_fs, tabular_data_root):\n        tabular_data = read_parquet(\n            filepath=join_fs_path(\n                tabular_data_fs, tabular_data_root, tabular_data_file_name\n            )\n        )\n        return [\n            column for column in tabular_data.columns if column.startswith(\"px\")\n        ] + [\"label\"]\n</code></pre>"},{"location":"reference/utilities/imagegeneration/#niceml.utilities.imagegeneration.load_label_from_json","title":"load_label_from_json","text":"<pre><code>load_label_from_json(location, filename)\n</code></pre> <p>Loads an object detection label from a file_path</p> Source code in <code>niceml/utilities/imagegeneration.py</code> <pre><code>def load_label_from_json(\n    location: Union[dict, LocationConfig], filename: str\n) -&gt; ObjDetImageLabel:\n    \"\"\"Loads an object detection label from a file_path\"\"\"\n    with open_location(location) as (cur_fs, root_path):\n        data = read_json(join(root_path, filename), cur_fs)\n        label = ObjDetImageLabel(**data)\n    return label\n</code></pre>"},{"location":"reference/utilities/imagegeneration/#niceml.utilities.imagegeneration.save_image","title":"save_image","text":"<pre><code>save_image(img, name, file_path)\n</code></pre> <p>Saves an image to a file_path and creates folders if not exist</p> Source code in <code>niceml/utilities/imagegeneration.py</code> <pre><code>def save_image(img: ImageType, name: str, file_path: str):\n    \"\"\"Saves an image to a file_path and creates folders if not exist\"\"\"\n    path = Path(f\"{file_path}\")\n    path.mkdir(exist_ok=True, parents=True)\n    img.save(f\"{path}/{name}.png\")\n</code></pre>"},{"location":"reference/utilities/imagegeneration/#niceml.utilities.imagegeneration.save_image_label_as_json","title":"save_image_label_as_json","text":"<pre><code>save_image_label_as_json(data, location, name)\n</code></pre> <p>Saves an ObjDetImageLabel to a file_path and creates folders if not exist</p> Source code in <code>niceml/utilities/imagegeneration.py</code> <pre><code>def save_image_label_as_json(\n    data: ObjDetImageLabel, location: Union[dict, LocationConfig], name: str\n):\n    \"\"\"Saves an ObjDetImageLabel to a file_path and creates folders if not exist\"\"\"\n    with open_location(location) as (cur_fs, root_path):\n        write_json(asdict(data), join(root_path, f\"{name}.json\"), cur_fs)\n</code></pre>"},{"location":"reference/utilities/imageloading/","title":"imageloading","text":""},{"location":"reference/utilities/imageloading/#niceml.utilities.imageloading","title":"imageloading","text":"<p>Module for image loading</p>"},{"location":"reference/utilities/imageloading/#niceml.utilities.imageloading-classes","title":"Classes","text":""},{"location":"reference/utilities/imageloading/#niceml.utilities.imageloading.ImgShapeError","title":"ImgShapeError","text":"<p>             Bases: <code>Exception</code></p> <p>Error when the image has the wrong shape</p>"},{"location":"reference/utilities/imageloading/#niceml.utilities.imageloading-functions","title":"Functions","text":""},{"location":"reference/utilities/imageloading/#niceml.utilities.imageloading.convert_to_3channel_img","title":"convert_to_3channel_img","text":"<pre><code>convert_to_3channel_img(input_img)\n</code></pre> <p>Converts an image (as np.ndarray) to a one with 3 channels</p> <p>Parameters:</p> <ul> <li> <code>input_img</code>             (<code>ndarray</code>)         \u2013          <p>image object as np.ndarray</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>         \u2013          <p>image as np.ndarray with 3 channels</p> </li> </ul> Source code in <code>niceml/utilities/imageloading.py</code> <pre><code>def convert_to_3channel_img(input_img: np.ndarray) -&gt; np.ndarray:  # QUEST: still used?\n    \"\"\"\n    Converts an image (as np.ndarray) to a one with 3 channels\n\n    Args:\n        input_img: image object as np.ndarray\n\n    Returns:\n        image as np.ndarray with 3 channels\n    \"\"\"\n    if len(input_img.shape) not in [2, 3]:\n        raise ImgShapeError(\n            f\"Image cannot be broadcast to a \" f\"3 channel image: {input_img.shape}\"\n        )\n\n    if len(input_img.shape) == 2:\n        return np.concatenate([input_img[:, :, np.newaxis]] * 3, axis=2)\n\n    if input_img.shape[2] == 3:\n        return input_img\n\n    if input_img.shape[2] == 1:\n        return np.concatenate([input_img] * 3, axis=2)\n\n    raise ImgShapeError(\n        f\"Image cannot be broadcast to a \" f\"3 channel image: {input_img.shape}\"\n    )\n</code></pre>"},{"location":"reference/utilities/imageloading/#niceml.utilities.imageloading.load_img_uint8","title":"load_img_uint8","text":"<pre><code>load_img_uint8(\n    image_path,\n    file_system=None,\n    target_image_size=None,\n    interpolation=cv2.INTER_LINEAR,\n)\n</code></pre> <p>Loads an image from arbitrary source ('file_system') and returns an uint8 np.ndarray</p> <p>Parameters:</p> <ul> <li> <code>image_path</code>             (<code>Union[str, LocationConfig]</code>)         \u2013          <p>Path of image file to load</p> </li> <li> <code>file_system</code>             (<code>Optional[AbstractFileSystem]</code>, default:                 <code>None</code> )         \u2013          <p>Allow the function to be used with different file systems; default = local</p> </li> <li> <code>target_image_size</code>             (<code>Optional[ImageSize]</code>, default:                 <code>None</code> )         \u2013          <p>Target size of loaded image</p> </li> <li> <code>interpolation</code>             (<code>int</code>, default:                 <code>INTER_LINEAR</code> )         \u2013          <p>Interpolation of resizing</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>         \u2013          <p>Loaded image object with target size in uint8 format</p> </li> </ul> Source code in <code>niceml/utilities/imageloading.py</code> <pre><code>def load_img_uint8(\n    image_path: Union[str, LocationConfig],\n    file_system: Optional[AbstractFileSystem] = None,\n    target_image_size: Optional[ImageSize] = None,\n    interpolation: int = cv2.INTER_LINEAR,\n) -&gt; np.ndarray:\n    \"\"\"\n    Loads an image from arbitrary source ('file_system') and returns an uint8 np.ndarray\n\n    Args:\n        image_path: Path of image file to load\n        file_system: Allow the function to be used with different file systems; default = local\n        target_image_size: Target size of loaded image\n        interpolation: Interpolation of resizing\n\n    Returns:\n        Loaded image object with target size in uint8 format\n    \"\"\"\n    file_system: AbstractFileSystem = file_system or LocalFileSystem()\n    try:\n        if isinstance(image_path, LocationConfig):\n            image_path = image_path.uri\n        with file_system.open(image_path) as fs_file:\n            image = Image.open(fs_file).copy()\n        np_array = np.array(image)\n        if np_array.dtype == bool:\n            np_array = np_array.astype(np.uint8)\n            np_array *= 255\n    except OSError:\n        with TemporaryDirectory() as tmp_dir:\n            tmp_file = join(tmp_dir, basename(image_path))\n            file_system.get_file(image_path, tmp_file)\n            np_array = cv2.imread(tmp_file)  # pylint: disable=no-member\n    if target_image_size is not None and not target_image_size.np_array_has_same_size(\n        np_array\n    ):\n        np_array = cv2.resize(\n            np_array, target_image_size.to_numpy_shape(), interpolation=interpolation\n        )\n    return np_array\n</code></pre>"},{"location":"reference/utilities/imagesize/","title":"imagesize","text":""},{"location":"reference/utilities/imagesize/#niceml.utilities.imagesize","title":"imagesize","text":"<p>Module for ImageSize</p>"},{"location":"reference/utilities/imagesize/#niceml.utilities.imagesize-classes","title":"Classes","text":""},{"location":"reference/utilities/imagesize/#niceml.utilities.imagesize.ImageSize","title":"ImageSize","text":"<p>Class to represent the size of images</p>"},{"location":"reference/utilities/imagesize/#niceml.utilities.imagesize.ImageSize-functions","title":"Functions","text":""},{"location":"reference/utilities/imagesize/#niceml.utilities.imagesize.ImageSize.__eq__","title":"__eq__","text":"<pre><code>__eq__(other)\n</code></pre> <p>Checks if two ImageSizes are equal</p> Source code in <code>niceml/utilities/imagesize.py</code> <pre><code>def __eq__(self, other: \"ImageSize\"):\n    \"\"\"Checks if two ImageSizes are equal\"\"\"\n    return (\n        other is not None\n        and isinstance(other, ImageSize)\n        and self.width == other.width\n        and self.height == other.height\n    )\n</code></pre>"},{"location":"reference/utilities/imagesize/#niceml.utilities.imagesize.ImageSize.__le__","title":"__le__","text":"<pre><code>__le__(other)\n</code></pre> <p>Compares ImageSizes with the same aspect ratio</p> Source code in <code>niceml/utilities/imagesize.py</code> <pre><code>def __le__(self, other: \"ImageSize\") -&gt; bool:\n    \"\"\"Compares ImageSizes with the same aspect ratio\"\"\"\n    division_factor = self.get_division_factor(other)\n    return division_factor &lt;= IDENTITY_SCALE\n</code></pre>"},{"location":"reference/utilities/imagesize/#niceml.utilities.imagesize.ImageSize.__lt__","title":"__lt__","text":"<pre><code>__lt__(other)\n</code></pre> <p>Compares ImageSizes with the same aspect ratio</p> Source code in <code>niceml/utilities/imagesize.py</code> <pre><code>def __lt__(self, other: \"ImageSize\") -&gt; bool:\n    \"\"\"Compares ImageSizes with the same aspect ratio\"\"\"\n    division_factor = self.get_division_factor(other)\n    return division_factor &lt; IDENTITY_SCALE\n</code></pre>"},{"location":"reference/utilities/imagesize/#niceml.utilities.imagesize.ImageSize.__mul__","title":"__mul__","text":"<pre><code>__mul__(scale)\n</code></pre> <p>Multiplies the ImageSize by a given scale factor</p> Source code in <code>niceml/utilities/imagesize.py</code> <pre><code>def __mul__(self, scale: float) -&gt; \"ImageSize\":\n    \"\"\"Multiplies the ImageSize by a given scale factor\"\"\"\n    return ImageSize(round(self.width * scale), round(self.height * scale))\n</code></pre>"},{"location":"reference/utilities/imagesize/#niceml.utilities.imagesize.ImageSize.__str__","title":"__str__","text":"<pre><code>__str__()\n</code></pre> <p>string with width, height</p> Source code in <code>niceml/utilities/imagesize.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"string with width, height\"\"\"\n    return f\"[{self.width},{self.height}]\"\n</code></pre>"},{"location":"reference/utilities/imagesize/#niceml.utilities.imagesize.ImageSize.__truediv__","title":"__truediv__","text":"<pre><code>__truediv__(divider)\n</code></pre> <p>Divides the ImageSize by a given division factor</p> Source code in <code>niceml/utilities/imagesize.py</code> <pre><code>def __truediv__(self, divider: float) -&gt; \"ImageSize\":\n    \"\"\"Divides the ImageSize by a given division factor\"\"\"\n    return ImageSize(round(self.width / divider), round(self.height / divider))\n</code></pre>"},{"location":"reference/utilities/imagesize/#niceml.utilities.imagesize.ImageSize.create_with_same_aspect_ratio","title":"create_with_same_aspect_ratio","text":"<pre><code>create_with_same_aspect_ratio(*, width=None, height=None)\n</code></pre> <p>Creates an ImageSize with the same aspect ratio given either width or height of the target ImageSize</p> <p>Parameters:</p> <ul> <li> <code>width</code>             (<code>Optional[int]</code>, default:                 <code>None</code> )         \u2013          <p>width of the target ImageSize</p> </li> <li> <code>height</code>             (<code>Optional[int]</code>, default:                 <code>None</code> )         \u2013          <p>height of the target ImageSize</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ImageSize</code>         \u2013          <p>new ImageSize, based on height or width, with the same aspect ratio as the</p> </li> <li> <code>ImageSize</code>         \u2013          <p>original Image Size</p> </li> </ul> Source code in <code>niceml/utilities/imagesize.py</code> <pre><code>def create_with_same_aspect_ratio(  # QUEST: what should be done with both given?\n    self, *, width: Optional[int] = None, height: Optional[int] = None\n) -&gt; \"ImageSize\":\n    \"\"\"\n    Creates an ImageSize with the same aspect ratio given either width or height\n    of the target ImageSize\n\n    Args:\n        width: width of the target ImageSize\n        height: height of the target ImageSize\n\n    Returns:\n        new ImageSize, based on height or width, with the same aspect ratio as the\n        original Image Size\n    \"\"\"\n    if width is None and height is None:\n        raise ValueError(\"Either width or height must be set\")\n    if width is not None and height is not None:\n        cur_image_size = ImageSize(width, height)\n        self.get_division_factor(cur_image_size)\n    if width is not None:\n        cur_image_size = ImageSize(width, round(width * self.height / self.width))\n    else:\n        cur_image_size = ImageSize(round(height * self.width / self.height), height)\n\n    return cur_image_size\n</code></pre>"},{"location":"reference/utilities/imagesize/#niceml.utilities.imagesize.ImageSize.from_numpy_shape","title":"from_numpy_shape  <code>classmethod</code>","text":"<pre><code>from_numpy_shape(shape)\n</code></pre> <p>Creates an ImageSize from a numpy shape</p> Source code in <code>niceml/utilities/imagesize.py</code> <pre><code>@classmethod\ndef from_numpy_shape(cls, shape: Tuple[int, int]) -&gt; \"ImageSize\":\n    \"\"\"Creates an ImageSize from a numpy shape\"\"\"\n    return cls(shape[1], shape[0])\n</code></pre>"},{"location":"reference/utilities/imagesize/#niceml.utilities.imagesize.ImageSize.from_pil_image","title":"from_pil_image  <code>classmethod</code>","text":"<pre><code>from_pil_image(image)\n</code></pre> <p>Creates an ImageSize from a PIL Image</p> Source code in <code>niceml/utilities/imagesize.py</code> <pre><code>@classmethod\ndef from_pil_image(cls, image: Image.Image) -&gt; \"ImageSize\":\n    \"\"\"Creates an ImageSize from a PIL Image\"\"\"\n    return cls(image.width, image.height)\n</code></pre>"},{"location":"reference/utilities/imagesize/#niceml.utilities.imagesize.ImageSize.from_pil_size","title":"from_pil_size  <code>classmethod</code>","text":"<pre><code>from_pil_size(size)\n</code></pre> <p>Creates an ImageSize from a PIL size</p> Source code in <code>niceml/utilities/imagesize.py</code> <pre><code>@classmethod\ndef from_pil_size(cls, size: Tuple[int, int]) -&gt; \"ImageSize\":\n    \"\"\"Creates an ImageSize from a PIL size\"\"\"\n    return cls(size[0], size[1])\n</code></pre>"},{"location":"reference/utilities/imagesize/#niceml.utilities.imagesize.ImageSize.get_division_factor","title":"get_division_factor","text":"<pre><code>get_division_factor(other)\n</code></pre> <p>Calculates the scale factor of two ImageSizes and returns it</p> Source code in <code>niceml/utilities/imagesize.py</code> <pre><code>def get_division_factor(self, other: \"ImageSize\") -&gt; float:\n    \"\"\"Calculates the scale factor of two ImageSizes and returns it\"\"\"\n    scale = self.width / other.width\n    if not isclose(scale, self.height / other.height):\n        raise ImageSizeDivisionError(\n            f\"The ImageSizes have different aspect ratios\"\n            f\"width_ratio: {scale} height_ratio: \"\n            f\"{self.height / other.height}\"\n        )\n    return scale\n</code></pre>"},{"location":"reference/utilities/imagesize/#niceml.utilities.imagesize.ImageSize.np_array_has_same_size","title":"np_array_has_same_size","text":"<pre><code>np_array_has_same_size(np_array)\n</code></pre> <p>Checks if the np_array has the same size as the ImageSize</p> Source code in <code>niceml/utilities/imagesize.py</code> <pre><code>def np_array_has_same_size(self, np_array: np.ndarray) -&gt; bool:\n    \"\"\"Checks if the np_array has the same size as the ImageSize\"\"\"\n    return self.width == np_array.shape[1] and self.height == np_array.shape[0]\n</code></pre>"},{"location":"reference/utilities/imagesize/#niceml.utilities.imagesize.ImageSize.to_numpy_shape","title":"to_numpy_shape","text":"<pre><code>to_numpy_shape()\n</code></pre> <p>tuple with height, width</p> Source code in <code>niceml/utilities/imagesize.py</code> <pre><code>def to_numpy_shape(self) -&gt; Tuple[int, int]:\n    \"\"\"tuple with height, width\"\"\"\n    return self.height, self.width\n</code></pre>"},{"location":"reference/utilities/imagesize/#niceml.utilities.imagesize.ImageSize.to_pil_size","title":"to_pil_size","text":"<pre><code>to_pil_size()\n</code></pre> <p>tuple with width, height</p> Source code in <code>niceml/utilities/imagesize.py</code> <pre><code>def to_pil_size(self) -&gt; Tuple[int, int]:\n    \"\"\"tuple with width, height\"\"\"\n    return self.width, self.height\n</code></pre>"},{"location":"reference/utilities/imagesize/#niceml.utilities.imagesize.ImageSizeDivisionError","title":"ImageSizeDivisionError","text":"<p>             Bases: <code>Exception</code></p> <p>Error for if two ImageSizes have different aspect ratios</p>"},{"location":"reference/utilities/imagesize/#niceml.utilities.imagesize-functions","title":"Functions","text":""},{"location":"reference/utilities/imagesize/#niceml.utilities.imagesize.create_image_size","title":"create_image_size","text":"<pre><code>create_image_size(argument)\n</code></pre> <p>Creates an ImageSize with: - a list of two ints [width, height] - a Tuple of two ints (width, height) - a str of form 'width,height, which will be parsed</p> <p>Parameters:</p> <ul> <li> <code>argument</code>             (<code>Union[str, List[int], Tuple[int, int], dict]</code>)         \u2013          <p>List, Tuple or String containing width and height information</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ImageSize</code>         \u2013          <p>ImageSize with given width and height</p> </li> </ul> Source code in <code>niceml/utilities/imagesize.py</code> <pre><code>def create_image_size(\n    argument: Union[str, List[int], Tuple[int, int], dict]\n) -&gt; ImageSize:\n    \"\"\"\n    Creates an ImageSize with:\n    - a list of two ints [width, height]\n    - a Tuple of two ints (width, height)\n    - a str of form 'width,height, which will be parsed\n\n    Args:\n        argument: List, Tuple or String containing width and height information\n\n    Returns:\n        ImageSize with given width and height\n    \"\"\"\n    if isinstance(argument, str):\n        try:\n            width, height = argument.split(\",\")\n        except ValueError as error:\n            raise Exception(f\"ImageSize couldn't be parsed: {argument}\") from error\n    elif isinstance(argument, dict):\n        width = argument[\"width\"]\n        height = argument[\"height\"]\n    else:\n        width, height = argument\n    return ImageSize(int(width), int(height))\n</code></pre>"},{"location":"reference/utilities/imageutils/","title":"imageutils","text":""},{"location":"reference/utilities/imageutils/#niceml.utilities.imageutils","title":"imageutils","text":"<p>Module for image utilization</p>"},{"location":"reference/utilities/imageutils/#niceml.utilities.imageutils-functions","title":"Functions","text":""},{"location":"reference/utilities/imageutils/#niceml.utilities.imageutils.binarize_multichannel_image","title":"binarize_multichannel_image","text":"<pre><code>binarize_multichannel_image(\n    image_index, image_scores, threshold\n)\n</code></pre> <p>Binarize (0,1) a multichannel image holding prediction information based on a threshold. Returns one binarized image per class and an overall mask with prediction scores above the threshold.</p> <p>Parameters:</p> <ul> <li> <code>image_index</code>             (<code>ndarray</code>)         \u2013          <p>np.ndarray numpy array with the shape (image.height, image.width) filled with the predicted class index of each pixel</p> </li> <li> <code>image_scores</code>             (<code>ndarray</code>)         \u2013          <p>np.ndarray numpy array with the shape (image.height, image.width) filled with a prediction score (0.0-1.0) of each pixel</p> </li> <li> <code>threshold</code>             (<code>float</code>)         \u2013          <p>float threshold to create a mask with a prediction score &gt; threshold</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>binary_multichannel_images</code> (            <code>Dict[str, ndarray]</code> )        \u2013          <p>Dict[str, np.array] Dictionary of binarized images per class</p> </li> <li> <code>scores_mask</code> (            <code>ndarray</code> )        \u2013          <p>np.ndarray mask including information where the prediction is above threshold</p> </li> </ul> Source code in <code>niceml/utilities/imageutils.py</code> <pre><code>def binarize_multichannel_image(\n    image_index: np.ndarray, image_scores: np.ndarray, threshold: float\n) -&gt; Tuple[Dict[str, np.ndarray], np.ndarray]:\n    \"\"\"\n    Binarize (0,1) a multichannel image holding prediction information based on a threshold.\n    Returns one binarized image per class and an overall mask with prediction scores above\n    the threshold.\n\n    Args:\n        image_index: np.ndarray\n            numpy array with the shape (image.height, image.width) filled\n            with the predicted class index of each pixel\n        image_scores: np.ndarray\n            numpy array with the shape (image.height, image.width) filled\n            with a prediction score (0.0-1.0) of each pixel\n        threshold: float\n            threshold to create a mask with a prediction score &gt; threshold\n\n    Returns:\n        binary_multichannel_images: Dict[str, np.array]\n            Dictionary of binarized images per class\n        scores_mask: np.ndarray\n            mask including information where the prediction is above threshold\n    \"\"\"\n    binary_multichannel_images: Dict[str, np.ndarray] = {}\n    scores_mask = cv2.threshold(\n        image_scores,\n        threshold,\n        1,\n        cv2.THRESH_BINARY,\n    )[\n        1\n    ].astype(np.uint8)\n\n    masked_index = image_index * scores_mask\n\n    class_idx_list = np.unique(masked_index)\n\n    for class_idx in class_idx_list:\n        if class_idx &gt; 0:\n            cur_idx_img = np.copy(masked_index)\n            cur_idx_img[masked_index != class_idx] = 0\n            curr_binary_mask = ((cur_idx_img / class_idx) * 255).astype(np.uint8)\n            binary_multichannel_images[str(class_idx)] = curr_binary_mask\n    return binary_multichannel_images, scores_mask\n</code></pre>"},{"location":"reference/utilities/imageutils/#niceml.utilities.imageutils.calc_diff_mask","title":"calc_diff_mask","text":"<pre><code>calc_diff_mask(orig_img, obfuscated_img, min_dist)\n</code></pre> <p>Calculates the difference of an <code>orig_img</code> and an <code>obfuscated_img</code></p> Source code in <code>niceml/utilities/imageutils.py</code> <pre><code>def calc_diff_mask(  # QUEST: still used?\n    orig_img: np.ndarray, obfuscated_img: np.ndarray, min_dist: float\n) -&gt; np.ndarray:\n    \"\"\"Calculates the difference of an `orig_img` and an `obfuscated_img`\"\"\"\n    diff_array = orig_img - obfuscated_img\n    distances = np.linalg.norm(diff_array, axis=-1)\n    mask = (distances &gt; min_dist).astype(float)\n    return mask\n</code></pre>"},{"location":"reference/utilities/imageutils/#niceml.utilities.imageutils.calc_heatmap","title":"calc_heatmap","text":"<pre><code>calc_heatmap(prediction, input_img)\n</code></pre> <p>Creates a heatmap based on a predicted image and an input image</p> Source code in <code>niceml/utilities/imageutils.py</code> <pre><code>def calc_heatmap(\n    prediction: np.ndarray, input_img: np.ndarray\n) -&gt; np.ndarray:  # QUEST: still used?\n    \"\"\"Creates a heatmap based on a predicted image and an input image\"\"\"\n    diff_array = input_img - prediction\n    distances = np.linalg.norm(diff_array, axis=-1).astype(np.uint8)\n    return cv2.applyColorMap(distances, cv2.COLORMAP_JET)\n</code></pre>"},{"location":"reference/utilities/imageutils/#niceml.utilities.imageutils.find_contours_in_binary_image","title":"find_contours_in_binary_image","text":"<pre><code>find_contours_in_binary_image(\n    binary_image, min_area, max_area\n)\n</code></pre> <p>Find the Contours in a binary Image</p> <p>Parameters:</p> <ul> <li> <code>binary_image</code>             (<code>ndarray</code>)         \u2013          <p>image to search for contours on</p> </li> <li> <code>min_area</code>             (<code>int</code>)         \u2013          <p>minimum area of relevant contours</p> </li> <li> <code>max_area</code>             (<code>int</code>)         \u2013          <p>maximum area of relevant contours</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>List</code>         \u2013          <p>Found contours within the relevant area range</p> </li> </ul> Source code in <code>niceml/utilities/imageutils.py</code> <pre><code>def find_contours_in_binary_image(\n    binary_image: np.ndarray, min_area: int, max_area: int\n) -&gt; List:\n    \"\"\"Find the Contours in a binary Image\n\n    Args:\n        binary_image: image to search for contours on\n        min_area: minimum area of relevant contours\n        max_area: maximum area of relevant contours\n\n    Returns:\n        Found contours within the relevant area range\n    \"\"\"\n    contours = findContours(binary_image, RETR_EXTERNAL, CHAIN_APPROX_SIMPLE)[0]\n    return [\n        contour for contour in contours if min_area &lt;= contourArea(contour) &lt;= max_area\n    ]\n</code></pre>"},{"location":"reference/utilities/imageutils/#niceml.utilities.imageutils.get_font","title":"get_font","text":"<pre><code>get_font(font_name, font_size=50)\n</code></pre> <p>Returns a randomly selected <code>FreeTypeFont</code> from ten predefined font names</p> Source code in <code>niceml/utilities/imageutils.py</code> <pre><code>def get_font(font_name: str, font_size: int = 50) -&gt; FreeTypeFont:\n    \"\"\"Returns a randomly selected `FreeTypeFont` from ten predefined font names\"\"\"\n    font_path = f\"{Path(__file__).parent.resolve()}/assets/fonts/{font_name}\"\n    return ImageFont.truetype(font=font_path, size=font_size)\n</code></pre>"},{"location":"reference/utilities/imageutils/#niceml.utilities.imageutils.stich_images","title":"stich_images","text":"<pre><code>stich_images(\n    image_list, horizontal_count, vertical_count, tile_size\n)\n</code></pre> <p>Arranges a list of PIL Images in a grid view with a given tile_size.</p> <p>image_list: List of images to be arranged horizontal_count: Number of images that will be placed horizontally in the stiched image vertical_count: Number of images that will be placed vertically in the stiched image tile_size: Size of each image tile (width, height)</p> <p>Returns:</p> <ul> <li> <code>Image</code>         \u2013          <p>All images stitched together in a grid view as one image</p> </li> </ul> Source code in <code>niceml/utilities/imageutils.py</code> <pre><code>def stich_images(  # QUEST: still used?\n    image_list: List[Image.Image],\n    horizontal_count: int,\n    vertical_count: int,\n    tile_size: Tuple[int, int],\n) -&gt; Image.Image:\n    \"\"\"\n    Arranges a list of PIL Images in a grid view with a given tile_size.\n\n    image_list: List of images to be arranged\n    horizontal_count: Number of images that will be placed horizontally in the stiched image\n    vertical_count: Number of images that will be placed vertically in the stiched image\n    tile_size: Size of each image tile (width, height)\n\n    Returns:\n        All images stitched together in a grid view as one image\n    \"\"\"\n    total_width = horizontal_count * tile_size[0]\n    total_height = vertical_count * tile_size[1]\n    new_image = Image.new(\"RGB\", (total_width, total_height))\n    cur_idx = 0\n    for vertical_position in range(vertical_count):\n        for horizontal_position in range(horizontal_count):\n            if cur_idx &gt;= len(image_list):\n                break\n            cur_img = image_list[cur_idx]\n            new_image.paste(\n                cur_img,\n                box=(\n                    horizontal_position * tile_size[0],\n                    vertical_position * tile_size[1],\n                ),\n            )\n            cur_idx += 1\n\n    return new_image\n</code></pre>"},{"location":"reference/utilities/instancelabeling/","title":"instancelabeling","text":""},{"location":"reference/utilities/instancelabeling/#niceml.utilities.instancelabeling","title":"instancelabeling","text":"<p>Module for InstanceLabel</p>"},{"location":"reference/utilities/instancelabeling/#niceml.utilities.instancelabeling-classes","title":"Classes","text":""},{"location":"reference/utilities/instancelabeling/#niceml.utilities.instancelabeling.InstanceLabel","title":"InstanceLabel","text":"<p>             Bases: <code>ABC</code></p> <p>Abstract class representing an instance of a found object. Additionally, this class is used for visualization purpose</p>"},{"location":"reference/utilities/instancelabeling/#niceml.utilities.instancelabeling.InstanceLabel-functions","title":"Functions","text":""},{"location":"reference/utilities/instancelabeling/#niceml.utilities.instancelabeling.InstanceLabel.calc_iou","title":"calc_iou  <code>abstractmethod</code>","text":"<pre><code>calc_iou(other)\n</code></pre> <p>Calculates the IOU of two given <code>InstanceLabel</code>s</p> <p>Parameters:</p> <ul> <li> <code>other</code>             (<code>InstanceLabel</code>)         \u2013          <p>InstanceLabel to calculate the IOU for</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>         \u2013          <p>Calculated IOU</p> </li> </ul> Source code in <code>niceml/utilities/instancelabeling.py</code> <pre><code>@abstractmethod\ndef calc_iou(self, other: \"InstanceLabel\") -&gt; float:\n    \"\"\"\n    Calculates the IOU of two given `InstanceLabel`s\n\n    Args:\n        other: InstanceLabel to calculate the IOU for\n\n    Returns:\n        Calculated IOU\n    \"\"\"\n</code></pre>"},{"location":"reference/utilities/instancelabeling/#niceml.utilities.instancelabeling.InstanceLabel.scale_label","title":"scale_label  <code>abstractmethod</code>","text":"<pre><code>scale_label(scale_factor)\n</code></pre> <p>Scales an instance label by a given <code>scale_factor</code></p> <p>Parameters:</p> <ul> <li> <code>scale_factor</code>             (<code>float</code>)         \u2013          <p>Factor to scale the instance label by</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>InstanceLabel</code>         \u2013          <p>Scaled instance of this InstanceLabel</p> </li> </ul> Source code in <code>niceml/utilities/instancelabeling.py</code> <pre><code>@abstractmethod\ndef scale_label(self, scale_factor: float) -&gt; \"InstanceLabel\":\n    \"\"\"\n    Scales an instance label by a given `scale_factor`\n\n    Args:\n        scale_factor: Factor to scale the instance label by\n\n    Returns:\n        Scaled instance of this InstanceLabel\n    \"\"\"\n</code></pre>"},{"location":"reference/utilities/instancelabeling/#niceml.utilities.instancelabeling-functions","title":"Functions","text":""},{"location":"reference/utilities/instancelabeling/#niceml.utilities.instancelabeling.get_kind_of_instance_label_match","title":"get_kind_of_instance_label_match","text":"<pre><code>get_kind_of_instance_label_match(\n    pred_label,\n    gt_label,\n    iou,\n    iou_threshold,\n    hide_gt_over_thresh,\n)\n</code></pre> <p>Defines color and activation of <code>pred_label</code> and <code>gt_label</code> based on an <code>iou</code> and an <code>iou_threshold</code>. Red = gt label with no matching prediction label; Blue = prediction label with no matching gt label; Green = prediction label which matched at least one gt label in position and class; Yellow = prediction label which matched at least one gt label in position but not in class.</p> <p>Parameters:</p> <ul> <li> <code>pred_label</code>             (<code>InstanceLabel</code>)         \u2013          <p>Prediction instance label</p> </li> <li> <code>gt_label</code>             (<code>InstanceLabel</code>)         \u2013          <p>Ground truth instance label</p> </li> <li> <code>iou</code>             (<code>float</code>)         \u2013          <p>Iou of <code>pred_label</code> and <code>gt_label</code></p> </li> <li> <code>iou_threshold</code>             (<code>float</code>)         \u2013          <p>Threshold to decide which color and activation should be used for the prediction and ground truth instance labels</p> </li> <li> <code>hide_gt_over_thresh</code>             (<code>bool</code>)         \u2013          <p>Flag to hide the <code>gt_label</code> if the <code>iou</code> is above the <code>iou_threshold</code></p> </li> </ul> <p>Returns:</p> <ul> <li> <code>InstanceLabel</code>         \u2013          <p>Updated <code>pred_label</code> and <code>gt_label</code> including</p> </li> <li> <code>InstanceLabel</code>         \u2013          <p>color and activation for instance label visualization</p> </li> </ul> Source code in <code>niceml/utilities/instancelabeling.py</code> <pre><code>def get_kind_of_instance_label_match(  # QUEST: move to 'instancelabelmatching'?\n    pred_label: InstanceLabel,\n    gt_label: InstanceLabel,\n    iou: float,\n    iou_threshold: float,\n    hide_gt_over_thresh: bool,\n) -&gt; Tuple[InstanceLabel, InstanceLabel]:\n    \"\"\"\n    Defines color and activation of `pred_label` and `gt_label`\n    based on an `iou` and an `iou_threshold`. Red = gt label with no matching prediction label;\n    Blue = prediction label with no matching gt label; Green = prediction label which\n    matched at least one gt label in position and class; Yellow = prediction label\n    which matched at least one gt label in position but not in class.\n\n    Args:\n        pred_label: Prediction instance label\n        gt_label: Ground truth instance label\n        iou: Iou of `pred_label` and `gt_label`\n        iou_threshold: Threshold to decide which color and activation should be\n            used for the prediction and ground truth instance labels\n        hide_gt_over_thresh: Flag to hide the `gt_label` if the `iou` is above the `iou_threshold`\n\n    Returns:\n        Updated `pred_label` and `gt_label` including\n        color and activation for instance label visualization\n    \"\"\"\n\n    if iou &gt;= iou_threshold:\n        # pylint:disable=simplifiable-if-expression\n        if pred_label.color != Color.GREEN:\n            if pred_label.class_index != gt_label.class_index:\n                pred_label.color = Color.YELLOW\n            else:\n                pred_label.color = Color.GREEN\n\n        if not hide_gt_over_thresh:\n            gt_label.active = True\n            gt_label.color = Color.RED\n        else:\n            gt_label.active = False\n\n    else:\n        if pred_label.color not in (Color.GREEN, Color.YELLOW):\n            pred_label.color = Color.BLUE\n\n        if gt_label.active is None or gt_label.active:\n            gt_label.active = True\n            gt_label.color = Color.RED\n\n    pred_label.active = True\n    return pred_label, gt_label\n</code></pre>"},{"location":"reference/utilities/instancelabelmatching/","title":"instancelabelmatching","text":""},{"location":"reference/utilities/instancelabelmatching/#niceml.utilities.instancelabelmatching","title":"instancelabelmatching","text":"<p>Module for instance label matching</p>"},{"location":"reference/utilities/instancelabelmatching/#niceml.utilities.instancelabelmatching-classes","title":"Classes","text":""},{"location":"reference/utilities/instancelabelmatching/#niceml.utilities.instancelabelmatching-functions","title":"Functions","text":""},{"location":"reference/utilities/instancelabelmatching/#niceml.utilities.instancelabelmatching.get_kind_of_label_match","title":"get_kind_of_label_match","text":"<pre><code>get_kind_of_label_match(\n    pred_label_list,\n    gt_label_list,\n    hide_gt_over_thresh=True,\n    iou_threshold=0.5,\n)\n</code></pre> <p>Creates a list of InstanceLabels for prediction labels and ground truth labels. Based on the iou of the prediction label (mask or bbox) and the ground truth label (=gt; mask or bbox), the labels are given a color and are active or not. Red = gt label with no matching prediction label; Blue = prediction label with no matching gt label; Green = prediction label which matched at least one gt label in position and class; Yellow = prediction label which matched at least one gt label in position but not in class.</p> <p>Parameters:</p> <ul> <li> <code>pred_label_list</code>             (<code>List[InstanceLabel]</code>)         \u2013          <p>label list of the prediction labels</p> </li> <li> <code>gt_label_list</code>             (<code>List[InstanceLabel]</code>)         \u2013          <p>label list of the ground truth labels</p> </li> <li> <code>hide_gt_over_thresh</code>             (<code>bool</code>, default:                 <code>True</code> )         \u2013          <p>flag to hide the ground truth labels if the ground truth label have an iou &gt;= <code>iou_threshold</code> with a prediction label</p> </li> <li> <code>iou_threshold</code>             (<code>float</code>, default:                 <code>0.5</code> )         \u2013          <p>threshold to determine kind of match by iou</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tuple[List[InstanceLabel], List[InstanceLabel]]</code>         \u2013          <p>List of InstanceLabel for prediction labels and ground truth labels</p> </li> </ul> Source code in <code>niceml/utilities/instancelabelmatching.py</code> <pre><code>def get_kind_of_label_match(\n    pred_label_list: List[InstanceLabel],\n    gt_label_list: List[InstanceLabel],\n    hide_gt_over_thresh: bool = True,\n    iou_threshold: float = 0.5,\n) -&gt; Tuple[List[InstanceLabel], List[InstanceLabel]]:\n    \"\"\"\n    Creates a list of InstanceLabels for prediction labels and ground truth labels.\n    Based on the iou of the prediction label (mask or bbox) and\n    the ground truth label (=gt; mask or bbox), the labels are given a color and\n    are active or not. Red = gt label with no matching prediction label;\n    Blue = prediction label with no matching gt label; Green = prediction label which\n    matched at least one gt label in position and class; Yellow = prediction label\n    which matched at least one gt label in position but not in class.\n\n    Args:\n        pred_label_list: label list of the prediction labels\n        gt_label_list: label list of the ground truth labels\n        hide_gt_over_thresh: flag to hide the ground truth labels if the ground truth label\n            have an iou &gt;= `iou_threshold` with a prediction label\n        iou_threshold: threshold to determine kind of match by iou\n\n    Returns:\n        List of InstanceLabel for prediction labels and ground truth labels\n    \"\"\"\n\n    if len(pred_label_list) == 0:\n        for gt_label in gt_label_list:\n            gt_label.active = True\n            gt_label.color = Color.RED\n    else:\n        for pred_label in pred_label_list:\n            if len(gt_label_list) == 0:\n                pred_label.color = Color.BLUE\n                pred_label.active = True\n            for gt_label in gt_label_list:\n                iou = pred_label.calc_iou(other=gt_label)\n\n                pred_label, gt_label = get_kind_of_instance_label_match(\n                    pred_label=pred_label,\n                    gt_label=gt_label,\n                    iou=iou,\n                    iou_threshold=iou_threshold,\n                    hide_gt_over_thresh=hide_gt_over_thresh,\n                )\n\n    return pred_label_list, gt_label_list\n</code></pre>"},{"location":"reference/utilities/ioumatrix/","title":"ioumatrix","text":""},{"location":"reference/utilities/ioumatrix/#niceml.utilities.ioumatrix","title":"ioumatrix","text":"<p>Module for iou matrix computation functions</p>"},{"location":"reference/utilities/ioumatrix/#niceml.utilities.ioumatrix-classes","title":"Classes","text":""},{"location":"reference/utilities/ioumatrix/#niceml.utilities.ioumatrix-functions","title":"Functions","text":""},{"location":"reference/utilities/ioumatrix/#niceml.utilities.ioumatrix.compute_iou_matrix","title":"compute_iou_matrix","text":"<pre><code>compute_iou_matrix(anchor_boxes, gt_boxes)\n</code></pre> <p>Computes pairwise IOU matrix for two given sets of boxes</p> <p>Parameters:</p> <ul> <li> <code>anchor_boxes</code>             (<code>ndarray</code>)         \u2013          <p>A tensor with shape <code>(N, 4)</code> representing anchor bounding boxes where each box is of the format <code>[left, top, right, bottom]</code>.</p> </li> <li> <code>gt_boxes</code>             (<code>ndarray</code>)         \u2013          <p>A tensor with shape <code>(M, 4)</code> representing ground truth bounding boxes where each box is of the format <code>[left, top, right, bottom]</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>         \u2013          <p>pairwise IOU matrix with shape <code>(N, M)</code>, where the value at 'i'th row</p> </li> <li> <code>ndarray</code>         \u2013          <p>'j'th column holds the IOU between 'i'th box and 'j'th box from</p> </li> <li> <code>ndarray</code>         \u2013          <p>boxes1 and boxes2 respectively.</p> </li> </ul> Source code in <code>niceml/utilities/ioumatrix.py</code> <pre><code>def compute_iou_matrix(anchor_boxes: np.ndarray, gt_boxes: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Computes pairwise IOU matrix for two given sets of boxes\n\n    Args:\n        anchor_boxes: A tensor with shape `(N, 4)` representing anchor bounding boxes\n            where each box is of the format `[left, top, right, bottom]`.\n        gt_boxes: A tensor with shape `(M, 4)` representing ground truth bounding boxes\n            where each box is of the format `[left, top, right, bottom]`.\n\n    Returns:\n        pairwise IOU matrix with shape `(N, M)`, where the value at 'i'th row\n        'j'th column holds the IOU between 'i'th box and 'j'th box from\n        boxes1 and boxes2 respectively.\n    \"\"\"\n\n    anchor_lefts = anchor_boxes[:, 0][:, np.newaxis]\n    anchor_tops = anchor_boxes[:, 1][:, np.newaxis]\n    anchor_rights = anchor_boxes[:, 2][:, np.newaxis]\n    anchor_bottoms = anchor_boxes[:, 3][:, np.newaxis]\n\n    anchor_areas = (anchor_rights - anchor_lefts) * (anchor_bottoms - anchor_tops)\n\n    gt_lefts = gt_boxes[:, 0][np.newaxis, :]\n    gt_tops = gt_boxes[:, 1][np.newaxis, :]\n    gt_rights = gt_boxes[:, 2][np.newaxis, :]\n    gt_bottoms = gt_boxes[:, 3][np.newaxis, :]\n\n    gt_areas = (gt_rights - gt_lefts) * (gt_bottoms - gt_tops)\n\n    intersect_lefts = np.maximum(anchor_lefts, gt_lefts)\n    intersect_tops = np.maximum(anchor_tops, gt_tops)\n    intersect_rights = np.minimum(anchor_rights, gt_rights)\n    intersect_bottoms = np.minimum(anchor_bottoms, gt_bottoms)\n\n    intersection_widths = np.maximum(0.0, intersect_rights - intersect_lefts)\n    intersection_heights = np.maximum(0.0, intersect_bottoms - intersect_tops)\n\n    intersection_areas = intersection_widths * intersection_heights\n\n    union_areas = anchor_areas + gt_areas - intersection_areas\n    intersection_areas = intersection_areas.astype(float)\n    union_areas = union_areas.astype(float)\n    iou_matrix = np.divide(\n        intersection_areas,\n        union_areas,\n        out=np.zeros(shape=intersection_areas.shape, dtype=float),\n        where=union_areas != 0.0,\n    )\n    return iou_matrix\n</code></pre>"},{"location":"reference/utilities/ioumatrix/#niceml.utilities.ioumatrix.compute_iou_matrix_optimized","title":"compute_iou_matrix_optimized","text":"<pre><code>compute_iou_matrix_optimized(anchor_boxes, gt_boxes)\n</code></pre> <p>Computes pairwise IOU matrix for two given sets of boxes. Computes the same iou matrix as <code>compute_iou_matrix</code> but especially for big matrices this function more efficient and user fewer memory.</p> <p>Parameters:</p> <ul> <li> <code>anchor_boxes</code>             (<code>ndarray</code>)         \u2013          <p>A tensor with shape <code>(N, 4)</code> representing anchor bounding boxes where each box is of the format <code>[left, top, right, bottom]</code>.</p> </li> <li> <code>gt_boxes</code>             (<code>ndarray</code>)         \u2013          <p>A tensor with shape <code>(M, 4)</code> representing ground truth bounding boxes where each box is of the format <code>[left, top, right, bottom]</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Union[csr_matrix, ndarray]</code>         \u2013          <p>pairwise IOU matrix with shape <code>(N, M)</code>, where the value at 'i'th row</p> </li> <li> <code>Union[csr_matrix, ndarray]</code>         \u2013          <p>'j'th column holds the IOU between 'i'th box and 'j'th box from</p> </li> <li> <code>Union[csr_matrix, ndarray]</code>         \u2013          <p>boxes1 and boxes2 respectively.</p> </li> </ul> Source code in <code>niceml/utilities/ioumatrix.py</code> <pre><code>def compute_iou_matrix_optimized(  # pylint: disable=too-many-locals  # QUEST: replace compute_iou_matrix?\n    anchor_boxes: np.ndarray, gt_boxes: np.ndarray\n) -&gt; Union[csr_matrix, np.ndarray]:\n    \"\"\"\n    Computes pairwise IOU matrix for two given sets of boxes.\n    Computes the same iou matrix as `compute_iou_matrix` but especially\n    for big matrices this function more efficient and user fewer memory.\n\n    Args:\n        anchor_boxes: A tensor with shape `(N, 4)` representing anchor bounding boxes\n            where each box is of the format `[left, top, right, bottom]`.\n        gt_boxes: A tensor with shape `(M, 4)` representing ground truth bounding boxes\n            where each box is of the format `[left, top, right, bottom]`.\n\n    Returns:\n        pairwise IOU matrix with shape `(N, M)`, where the value at 'i'th row\n        'j'th column holds the IOU between 'i'th box and 'j'th box from\n        boxes1 and boxes2 respectively.\n    \"\"\"\n    element_count = anchor_boxes.shape[0] * gt_boxes.shape[0]\n    if element_count &lt; 100000:\n        return compute_iou_matrix(anchor_boxes, gt_boxes)\n\n    surrounding_bbox = get_surrounding_bounding_box(anchor_boxes, gt_boxes)\n    box_split_count = get_splitbox_count(element_count)\n    bounding_box_split_list: List[BoundingBox] = split_bounding_boxes(\n        surrounding_bbox, box_split_count, box_split_count\n    )\n    bounding_box_split_array = bbox_list_to_ullr_array(bounding_box_split_list)\n\n    anchor_boxes_iou = compute_iou_matrix(anchor_boxes, bounding_box_split_array)\n    gt_boxes_iou = compute_iou_matrix(gt_boxes, bounding_box_split_array)\n    anchor_indexes = np.argwhere(anchor_boxes_iou &gt; 0)\n    gt_indexes = np.argwhere(gt_boxes_iou &gt; 0)\n\n    value_list = []\n\n    for idx in range(len(bounding_box_split_list)):\n        cur_anchor_indexes = anchor_indexes[anchor_indexes[:, 1] == idx, 0]\n        cur_gt_indexes = gt_indexes[gt_indexes[:, 1] == idx, 0]\n        cur_iou_mat = compute_iou_matrix(\n            anchor_boxes[cur_anchor_indexes, :], gt_boxes[cur_gt_indexes, :]\n        )\n        cur_iou_indexes = np.argwhere(cur_iou_mat &gt; 0)\n        target_iou_values = cur_iou_mat[cur_iou_indexes[:, 0], cur_iou_indexes[:, 1]]\n        target_anchor_indexes = cur_anchor_indexes[cur_iou_indexes[:, 0]]\n        target_gt_indexes = cur_gt_indexes[cur_iou_indexes[:, 1]]\n\n        value_list.append(\n            np.concatenate(\n                [\n                    target_iou_values[np.newaxis, :],\n                    target_anchor_indexes[np.newaxis, :],\n                    target_gt_indexes[np.newaxis, :],\n                ],\n                axis=0,\n            )\n        )\n\n    value_array = np.concatenate(value_list, axis=1)\n\n    value_array = np.unique(value_array, axis=1)\n\n    return csr_matrix(\n        (value_array[0, :], (value_array[1, :], value_array[2, :])),\n        shape=(anchor_boxes.shape[0], gt_boxes.shape[0]),\n    )\n</code></pre>"},{"location":"reference/utilities/ioumatrix/#niceml.utilities.ioumatrix.get_splitbox_count","title":"get_splitbox_count","text":"<pre><code>get_splitbox_count(element_count)\n</code></pre> <p>Returns the number of boxes to split one box into, where the number is at least 2, but not more than 8</p> <p>Parameters:</p> <ul> <li> <code>element_count</code>             (<code>int</code>)         \u2013          <p>Determine the number of elements in a box</p> </li> </ul> <p>Returns:     The number of boxes to split into</p> Source code in <code>niceml/utilities/ioumatrix.py</code> <pre><code>def get_splitbox_count(element_count: int) -&gt; int:\n    \"\"\"\n    Returns the number of boxes to split one box into, where the number is at least 2,\n    but not more than 8\n\n    Args:\n        element_count: Determine the number of elements in a box\n    Returns:\n        The number of boxes to split into\n    \"\"\"\n    target = int(sqrt(element_count) / 300)\n    return max(2, min(8, target))\n</code></pre>"},{"location":"reference/utilities/ioutils/","title":"ioutils","text":""},{"location":"reference/utilities/ioutils/#niceml.utilities.ioutils","title":"ioutils","text":"<p>Module for helper functions for io operations</p>"},{"location":"reference/utilities/ioutils/#niceml.utilities.ioutils-functions","title":"Functions","text":""},{"location":"reference/utilities/ioutils/#niceml.utilities.ioutils.find_and_read_file","title":"find_and_read_file","text":"<pre><code>find_and_read_file(\n    filepath,\n    read_func,\n    search_paths=None,\n    file_system=None,\n    **kwargs\n)\n</code></pre> <p>Tries to find a file in a list of search paths and reads it with given read function</p> <p>Parameters:</p> <ul> <li> <code>filepath</code>             (<code>str</code>)         \u2013          <p>path to file</p> </li> <li> <code>search_paths</code>             (<code>Optional[List[str]]</code>, default:                 <code>None</code> )         \u2013          <p>list of paths to search for file</p> </li> <li> <code>read_func</code>         \u2013          <p>function to read the file</p> </li> <li> <code>file_system</code>             (<code>Optional[AbstractFileSystem]</code>, default:                 <code>None</code> )         \u2013          <p>Allow the function to be used with different file systems; default = local</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Tuple[str, Any]</code>         \u2013          <p>Content of file</p> </li> </ul> Source code in <code>niceml/utilities/ioutils.py</code> <pre><code>def find_and_read_file(\n    filepath: str,\n    read_func,\n    search_paths: Optional[List[str]] = None,\n    file_system: Optional[AbstractFileSystem] = None,\n    **kwargs,\n) -&gt; Tuple[str, Any]:\n    \"\"\"\n    Tries to find a file in a list of search paths and reads it with given read function\n\n    Args:\n        filepath: path to file\n        search_paths: list of paths to search for file\n        read_func: function to read the file\n        file_system: Allow the function to be used with different file systems; default = local\n\n    Returns:\n        Content of file\n    \"\"\"\n    cur_fs: AbstractFileSystem = file_system or LocalFileSystem()\n    search_paths = search_paths or []\n    if cur_fs.exists(filepath):\n        return filepath, read_func(filepath, file_system=cur_fs, **kwargs)\n    for path in search_paths:\n        cur_path = join_fs_path(cur_fs, path, filepath)\n        if cur_fs.exists(cur_path):\n            return cur_path, read_func(cur_path, file_system=cur_fs, **kwargs)\n    raise FileNotFoundError(f\"File not found: {filepath}\")\n</code></pre>"},{"location":"reference/utilities/ioutils/#niceml.utilities.ioutils.list_dir","title":"list_dir","text":"<pre><code>list_dir(\n    path,\n    return_full_path=False,\n    recursive=False,\n    file_system=None,\n    filter_ext=None,\n)\n</code></pre> <p>Returns a list of files in a directory</p> <p>Parameters:</p> <ul> <li> <code>path</code>             (<code>str</code>)         \u2013          <p>path to directory, which should be listed</p> </li> <li> <code>return_full_path</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Returns full filepaths (True) or relative path (False)</p> </li> <li> <code>recursive</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>Determine if the function should look into subfolders</p> </li> <li> <code>file_system</code>             (<code>Optional[AbstractFileSystem]</code>, default:                 <code>None</code> )         \u2013          <p>Allow the function to be used with different file systems; default = local</p> </li> <li> <code>filter_ext</code>             (<code>Optional[List[str]]</code>, default:                 <code>None</code> )         \u2013          <p>List of file extension to filter for; default = all files</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>List[str]</code>         \u2013          <p>A list of files in the specified directory</p> </li> </ul> Source code in <code>niceml/utilities/ioutils.py</code> <pre><code>def list_dir(\n    path: str,\n    return_full_path: bool = False,\n    recursive: bool = False,\n    file_system: Optional[AbstractFileSystem] = None,\n    filter_ext: Optional[List[str]] = None,\n) -&gt; List[str]:\n    \"\"\"\n    Returns a list of files in a directory\n\n    Args:\n        path: path to directory, which should be listed\n        return_full_path: Returns full filepaths (True) or relative path (False)\n        recursive: Determine if the function should look into subfolders\n        file_system: Allow the function to be used with different file systems; default = local\n        filter_ext: List of file extension to filter for; default = all files\n\n    Returns:\n        A list of files in the specified directory\n    \"\"\"\n    cur_fs: AbstractFileSystem = file_system or LocalFileSystem()\n    files: List[str] = [\n        relpath(cur_file, path) for cur_file in list(cur_fs.listdir(path, detail=False))\n    ]\n    if recursive:\n        folders = [\n            cur_folder for cur_folder in files if cur_fs.isdir(join(path, cur_folder))\n        ]\n        for cur_folder in folders:\n            files += [\n                join(cur_folder, cur_file)\n                for cur_file in list_dir(\n                    join(path, cur_folder), False, True, file_system=cur_fs\n                )\n            ]\n\n    if filter_ext is not None:\n        files = [cur_file for cur_file in files if splitext(cur_file)[1] in filter_ext]\n\n    if return_full_path:\n        files = [join(path, cur_file) for cur_file in files]\n\n    return files\n</code></pre>"},{"location":"reference/utilities/ioutils/#niceml.utilities.ioutils.read_csv","title":"read_csv","text":"<pre><code>read_csv(filepath, file_system=None, **kwargs)\n</code></pre> <p>Reads csv with optional AbstractFileSystem given</p> <p>Parameters:</p> <ul> <li> <code>filepath</code>             (<code>str</code>)         \u2013          <p>path to csv file</p> </li> <li> <code>file_system</code>             (<code>Optional[AbstractFileSystem]</code>, default:                 <code>None</code> )         \u2013          <p>Allow the function to be used with different file systems; default = local</p> </li> <li> <code>***kwargs</code>         \u2013          <p>additional arguments for pd.read_csv function</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>         \u2013          <p>dataframe from csv file</p> </li> </ul> Source code in <code>niceml/utilities/ioutils.py</code> <pre><code>def read_csv(\n    filepath: str, file_system: Optional[AbstractFileSystem] = None, **kwargs\n) -&gt; pd.DataFrame:\n    \"\"\"Reads csv with optional AbstractFileSystem given\n\n    Args:\n        filepath: path to csv file\n        file_system: Allow the function to be used with different file systems; default = local\n        ***kwargs: additional arguments for pd.read_csv function\n\n    Returns:\n        dataframe from csv file\"\"\"\n    cur_fs: AbstractFileSystem = file_system or LocalFileSystem()\n    if not cur_fs.exists(filepath):\n        raise FileNotFoundError(f\"CSV not found: {filepath}\")\n    with cur_fs.open(filepath, \"r\", encoding=\"utf-8\") as file:\n        return pd.read_csv(file, **kwargs)\n</code></pre>"},{"location":"reference/utilities/ioutils/#niceml.utilities.ioutils.read_image","title":"read_image","text":"<pre><code>read_image(filepath, file_system=None, **kwargs)\n</code></pre> <p>Reads image with optional AbstractFileSystem given</p> <p>Parameters:</p> <ul> <li> <code>filepath</code>             (<code>str</code>)         \u2013          <p>Path to load the image from</p> </li> <li> <code>file_system</code>             (<code>Optional[AbstractFileSystem]</code>, default:                 <code>None</code> )         \u2013          <p>Allow the function to be used with different file systems; default = local</p> </li> <li> <code>**kwargs</code>         \u2013          <p>additional arguments for Image.open function</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Image</code>         \u2013          <p>loaded image object</p> </li> </ul> Source code in <code>niceml/utilities/ioutils.py</code> <pre><code>def read_image(\n    filepath: str, file_system: Optional[AbstractFileSystem] = None, **kwargs\n) -&gt; Image.Image:\n    \"\"\"Reads image with optional AbstractFileSystem given\n\n    Args:\n        filepath: Path to load the image from\n        file_system: Allow the function to be used with different file systems; default = local\n        **kwargs: additional arguments for Image.open function\n\n    Returns:\n        loaded image object\n    \"\"\"\n    cur_fs: AbstractFileSystem = file_system or LocalFileSystem()\n    if not cur_fs.exists(filepath):\n        raise FileNotFoundError(f\"ImageFile not found: {filepath}\")\n    with file_system.open(filepath, \"rb\") as file:\n        return Image.open(file, **kwargs).copy()\n</code></pre>"},{"location":"reference/utilities/ioutils/#niceml.utilities.ioutils.read_json","title":"read_json","text":"<pre><code>read_json(filepath, file_system=None)\n</code></pre> <p>Reads a json file with optional AbstractFileSystem given</p> <p>Parameters:</p> <ul> <li> <code>filepath</code>             (<code>str</code>)         \u2013          <p>path to json file</p> </li> <li> <code>file_system</code>             (<code>Optional[AbstractFileSystem]</code>, default:                 <code>None</code> )         \u2013          <p>Allow the function to be used with different file systems; default = local</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code>         \u2013          <p>Content of json as dictionary</p> </li> </ul> Source code in <code>niceml/utilities/ioutils.py</code> <pre><code>def read_json(filepath: str, file_system: Optional[AbstractFileSystem] = None) -&gt; dict:\n    \"\"\"\n    Reads a json file with optional AbstractFileSystem given\n\n    Args:\n        filepath: path to json file\n        file_system: Allow the function to be used with different file systems; default = local\n\n    Returns:\n        Content of json as dictionary\n    \"\"\"\n    cur_fs: AbstractFileSystem = file_system or LocalFileSystem()\n    if not cur_fs.exists(filepath):\n        raise FileNotFoundError(f\"Yamlfile not found: {filepath}\")\n    with cur_fs.open(filepath, \"r\", encoding=\"utf-8\") as file:\n        return json.load(file)\n</code></pre>"},{"location":"reference/utilities/ioutils/#niceml.utilities.ioutils.read_parquet","title":"read_parquet","text":"<pre><code>read_parquet(filepath, file_system=None)\n</code></pre> <p>Reads parquet with optional AbstractFileSystem given</p> <p>Parameters:</p> <ul> <li> <code>filepath</code>             (<code>str</code>)         \u2013          <p>path to parquet file</p> </li> <li> <code>file_system</code>             (<code>Optional[AbstractFileSystem]</code>, default:                 <code>None</code> )         \u2013          <p>Allow the function to be used with different file systems; default = local</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataFrame</code>         \u2013          <p>dataframe from parquet file</p> </li> </ul> Source code in <code>niceml/utilities/ioutils.py</code> <pre><code>def read_parquet(\n    filepath: str, file_system: Optional[AbstractFileSystem] = None\n) -&gt; pd.DataFrame:\n    \"\"\"\n    Reads parquet with optional AbstractFileSystem given\n\n    Args:\n        filepath: path to parquet file\n        file_system: Allow the function to be used with different file systems; default = local\n\n    Returns:\n        dataframe from parquet file\n    \"\"\"\n    cur_fs: AbstractFileSystem = file_system or LocalFileSystem()\n    if not cur_fs.exists(filepath):\n        raise FileNotFoundError(f\"Parquetfile not found: {filepath}\")\n    return fastparquet.ParquetFile(filepath, fs=cur_fs).to_pandas()\n</code></pre>"},{"location":"reference/utilities/ioutils/#niceml.utilities.ioutils.read_yaml","title":"read_yaml","text":"<pre><code>read_yaml(filepath, file_system=None)\n</code></pre> <p>Reads a yaml file with optional AbstractFileSystem given</p> <p>Parameters:</p> <ul> <li> <code>filepath</code>             (<code>str</code>)         \u2013          <p>path to yaml file</p> </li> <li> <code>file_system</code>             (<code>Optional[AbstractFileSystem]</code>, default:                 <code>None</code> )         \u2013          <p>Allow the function to be used with different file systems; default = local</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>dict</code>         \u2013          <p>Content of yaml as dictionary</p> </li> </ul> Source code in <code>niceml/utilities/ioutils.py</code> <pre><code>def read_yaml(filepath: str, file_system: Optional[AbstractFileSystem] = None) -&gt; dict:\n    \"\"\"\n    Reads a yaml file with optional AbstractFileSystem given\n\n    Args:\n        filepath: path to yaml file\n        file_system: Allow the function to be used with different file systems; default = local\n\n    Returns:\n        Content of yaml as dictionary\n    \"\"\"\n    cur_fs: AbstractFileSystem = file_system or LocalFileSystem()\n    if not cur_fs.exists(filepath):\n        raise FileNotFoundError(f\"Yamlfile not found: {filepath}\")\n    with cur_fs.open(filepath, \"r\", encoding=\"utf-8\") as file:\n        return yaml.load(file, Loader=yaml.SafeLoader)\n</code></pre>"},{"location":"reference/utilities/ioutils/#niceml.utilities.ioutils.write_csv","title":"write_csv","text":"<pre><code>write_csv(data, filepath, file_system=None, **kwargs)\n</code></pre> <p>Writes dataframe to csv file with optional AbstractFileSystem given</p> <p>Parameters:</p> <ul> <li> <code>data</code>             (<code>DataFrame</code>)         \u2013          <p>Dataframe to write to csv file</p> </li> <li> <code>filepath</code>             (<code>str</code>)         \u2013          <p>Path to save the csv file to</p> </li> <li> <code>file_system</code>             (<code>Optional[AbstractFileSystem]</code>, default:                 <code>None</code> )         \u2013          <p>Allow the function to be used with different file systems; default = local</p> </li> <li> <code>**kwargs</code>         \u2013          <p>additional arguments for data.to_csv function</p> </li> </ul> Source code in <code>niceml/utilities/ioutils.py</code> <pre><code>def write_csv(\n    data: pd.DataFrame,\n    filepath: str,\n    file_system: Optional[AbstractFileSystem] = None,\n    **kwargs,\n):\n    \"\"\"\n    Writes dataframe to csv file with optional AbstractFileSystem given\n\n    Args:\n        data: Dataframe to write to csv file\n        filepath: Path to save the csv file to\n        file_system: Allow the function to be used with different file systems; default = local\n        **kwargs: additional arguments for data.to_csv function\n    \"\"\"\n    cur_fs: AbstractFileSystem = file_system or LocalFileSystem()\n    cur_fs.mkdirs(\n        dirname(filepath),\n        exist_ok=True,\n    )\n    with cur_fs.open(filepath, \"w\", encoding=\"utf-8\") as file:\n        data.to_csv(file, index=False, **kwargs)\n</code></pre>"},{"location":"reference/utilities/ioutils/#niceml.utilities.ioutils.write_image","title":"write_image","text":"<pre><code>write_image(image, filepath, file_system=None, **kwargs)\n</code></pre> <p>Saves image to filepath with optional AbstractFileSystem given</p> <p>Parameters:</p> <ul> <li> <code>image</code>             (<code>Image</code>)         \u2013          <p>Image object</p> </li> <li> <code>filepath</code>             (<code>str</code>)         \u2013          <p>Path to save the image to</p> </li> <li> <code>file_system</code>             (<code>Optional[AbstractFileSystem]</code>, default:                 <code>None</code> )         \u2013          <p>Allow the function to be used with different file systems; default = local</p> </li> <li> <code>**kwargs</code>         \u2013          <p>additional arguments for Image.save function</p> </li> </ul> Source code in <code>niceml/utilities/ioutils.py</code> <pre><code>def write_image(\n    image: Image.Image,\n    filepath: str,\n    file_system: Optional[AbstractFileSystem] = None,\n    **kwargs,\n):\n    \"\"\"\n    Saves image to filepath with optional AbstractFileSystem given\n\n    Args:\n        image: Image object\n        filepath: Path to save the image to\n        file_system: Allow the function to be used with different file systems; default = local\n        **kwargs: additional arguments for Image.save function\n    \"\"\"\n    cur_fs: AbstractFileSystem = file_system or LocalFileSystem()\n    cur_fs.mkdirs(\n        dirname(filepath),\n        exist_ok=True,\n    )\n    with file_system.open(filepath, \"wb\") as file:\n        file_format = filepath.rsplit(\".\")[-1]\n        image.save(file, format=file_format, **kwargs)\n</code></pre>"},{"location":"reference/utilities/ioutils/#niceml.utilities.ioutils.write_json","title":"write_json","text":"<pre><code>write_json(data, filepath, file_system=None, **kwargs)\n</code></pre> <p>Writes dictionary to json with optional AbstractFileSystem given</p> <p>Parameters:</p> <ul> <li> <code>data</code>             (<code>dict</code>)         \u2013          <p>dictionary to be saved as json</p> </li> <li> <code>filepath</code>             (<code>str</code>)         \u2013          <p>path to save the json file to</p> </li> <li> <code>file_system</code>             (<code>Optional[AbstractFileSystem]</code>, default:                 <code>None</code> )         \u2013          <p>Allow the function to be used with different file systems; default = local</p> </li> <li> <code>**kwargs</code>         \u2013          <p>additional arguments for json.dump function</p> </li> </ul> Source code in <code>niceml/utilities/ioutils.py</code> <pre><code>def write_json(\n    data: dict,\n    filepath: str,\n    file_system: Optional[AbstractFileSystem] = None,\n    **kwargs,\n):\n    \"\"\"\n    Writes dictionary to json with optional AbstractFileSystem given\n\n    Args:\n        data: dictionary to be saved as json\n        filepath: path to save the json file to\n        file_system: Allow the function to be used with different file systems; default = local\n        **kwargs: additional arguments for json.dump function\n    \"\"\"\n    cur_fs: AbstractFileSystem = file_system or LocalFileSystem()\n    cur_fs.mkdirs(\n        dirname(filepath),\n        exist_ok=True,\n    )\n    with cur_fs.open(filepath, \"w\", encoding=\"utf-8\") as file:\n        json.dump(data, file, **kwargs)\n</code></pre>"},{"location":"reference/utilities/ioutils/#niceml.utilities.ioutils.write_parquet","title":"write_parquet","text":"<pre><code>write_parquet(\n    dataframe,\n    filepath,\n    compression=\"gzip\",\n    file_system=None,\n    **kwargs\n)\n</code></pre> <p>Writes dataframe to parquet file with optional AbstractFileSystem given</p> <p>Parameters:</p> <ul> <li> <code>dataframe</code>             (<code>DataFrame</code>)         \u2013          <p>Dataframe to write to parquet file</p> </li> <li> <code>filepath</code>             (<code>str</code>)         \u2013          <p>Path to save the parquet file to</p> </li> <li> <code>compression</code>             (<code>Optional[str]</code>, default:                 <code>'gzip'</code> )         \u2013          <p>Compression method</p> </li> <li> <code>file_system</code>             (<code>Optional[AbstractFileSystem]</code>, default:                 <code>None</code> )         \u2013          <p>Allow the function to be used with different file systems; default = local</p> </li> <li> <code>**kwargs</code>         \u2013          <p>additional arguments for fastparquet.write function</p> </li> </ul> Source code in <code>niceml/utilities/ioutils.py</code> <pre><code>def write_parquet(\n    dataframe: pd.DataFrame,\n    filepath: str,\n    compression: Optional[str] = \"gzip\",\n    file_system: Optional[AbstractFileSystem] = None,\n    **kwargs,\n):\n    \"\"\"\n    Writes dataframe to parquet file with optional AbstractFileSystem given\n\n    Args:\n        dataframe: Dataframe to write to parquet file\n        filepath: Path to save the parquet file to\n        compression: Compression method\n        file_system: Allow the function to be used with different file systems; default = local\n        **kwargs: additional arguments for fastparquet.write function\n    \"\"\"\n    cur_fs: AbstractFileSystem = file_system or LocalFileSystem()\n    cur_fs.mkdirs(\n        dirname(filepath),\n        exist_ok=True,\n    )\n    fastparquet.write(\n        filepath,\n        dataframe,\n        open_with=cur_fs.open,\n        compression=compression,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/utilities/ioutils/#niceml.utilities.ioutils.write_yaml","title":"write_yaml","text":"<pre><code>write_yaml(data, filepath, file_system=None, **kwargs)\n</code></pre> <p>Writes dictionary to yaml with optional AbstractFileSystem given</p> <p>Parameters:</p> <ul> <li> <code>data</code>             (<code>dict</code>)         \u2013          <p>dictionary to be saved as yaml</p> </li> <li> <code>filepath</code>             (<code>str</code>)         \u2013          <p>path to save the yaml file to</p> </li> <li> <code>file_system</code>             (<code>Optional[AbstractFileSystem]</code>, default:                 <code>None</code> )         \u2013          <p>Allow the function to be used with different file systems; default = local</p> </li> <li> <code>**kwargs</code>         \u2013          <p>additional arguments for yaml.dump function</p> </li> </ul> Source code in <code>niceml/utilities/ioutils.py</code> <pre><code>def write_yaml(\n    data: dict,\n    filepath: str,\n    file_system: Optional[AbstractFileSystem] = None,\n    **kwargs,\n):\n    \"\"\"\n    Writes dictionary to yaml with optional AbstractFileSystem given\n\n    Args:\n        data: dictionary to be saved as yaml\n        filepath: path to save the yaml file to\n        file_system: Allow the function to be used with different file systems; default = local\n        **kwargs: additional arguments for yaml.dump function\n    \"\"\"\n    cur_fs: AbstractFileSystem = file_system or LocalFileSystem()\n    cur_fs.mkdirs(\n        dirname(filepath),\n        exist_ok=True,\n    )\n    with cur_fs.open(filepath, \"w\", encoding=\"utf-8\") as file:\n        yaml.dump(data, file, Dumper=yaml.SafeDumper, **kwargs)\n</code></pre>"},{"location":"reference/utilities/logutils/","title":"logutils","text":""},{"location":"reference/utilities/logutils/#niceml.utilities.logutils","title":"logutils","text":"<p>Module for utils for logging</p>"},{"location":"reference/utilities/logutils/#niceml.utilities.logutils-functions","title":"Functions","text":""},{"location":"reference/utilities/logutils/#niceml.utilities.logutils.get_logstr_from_dict","title":"get_logstr_from_dict","text":"<pre><code>get_logstr_from_dict(log_dict)\n</code></pre> <p>Combines a dict to a single str</p> Source code in <code>niceml/utilities/logutils.py</code> <pre><code>def get_logstr_from_dict(log_dict: dict):\n    \"\"\"Combines a dict to a single str\"\"\"\n    str_list: List[str] = [f\"{key}: {value}\" for key, value in log_dict.items()]\n    ret_str: str = \"\\n\".join(str_list)\n    return ret_str\n</code></pre>"},{"location":"reference/utilities/matchingresult/","title":"matchingresult","text":""},{"location":"reference/utilities/matchingresult/#niceml.utilities.matchingresult","title":"matchingresult","text":"<p>Module for abstract MatchingResult class</p>"},{"location":"reference/utilities/matchingresult/#niceml.utilities.matchingresult-classes","title":"Classes","text":""},{"location":"reference/utilities/matchingresult/#niceml.utilities.matchingresult.MatchingResult","title":"MatchingResult","text":"<p>             Bases: <code>ABC</code></p> <p>Abstract class to calculate precision (per class) and recall (per class) based on <code>true_pos</code>, <code>false_pos</code> and <code>false_neg</code> instance labels</p> <p>Parameters:</p> <ul> <li> <code>true_pos</code>         \u2013          <p>true_positives = List of correctly predicted instance labels (prediction = ground truth)</p> </li> <li> <code>false_pos</code>         \u2013          <p>false_positives = List of instance labels that were found too much (prediction, but no ground truth)</p> </li> <li> <code>false_neg</code>         \u2013          <p>false_negatives = List of instance labels that were not found correctly (ground truth, but no prediction)</p> </li> </ul>"},{"location":"reference/utilities/matchingresult/#niceml.utilities.matchingresult.MatchingResult-functions","title":"Functions","text":""},{"location":"reference/utilities/matchingresult/#niceml.utilities.matchingresult.MatchingResult.__add__","title":"__add__","text":"<pre><code>__add__(other)\n</code></pre> <p>Adds two MatchingResult objects</p> Source code in <code>niceml/utilities/matchingresult.py</code> <pre><code>def __add__(self, other: \"MatchingResult\") -&gt; \"MatchingResult\":\n    \"\"\"Adds two MatchingResult objects\"\"\"\n    return MatchingResult(\n        true_pos=self.true_pos + other.true_pos,\n        false_pos=self.false_pos + other.false_pos,\n        false_neg=self.false_neg + other.false_neg,\n    )\n</code></pre>"},{"location":"reference/utilities/matchingresult/#niceml.utilities.matchingresult.MatchingResult.calculate_per_class_precision","title":"calculate_per_class_precision","text":"<pre><code>calculate_per_class_precision(target_classes=None)\n</code></pre> <p>Calculates the precision per class</p> Source code in <code>niceml/utilities/matchingresult.py</code> <pre><code>def calculate_per_class_precision(\n    self, target_classes: Optional[Set[str]] = None\n) -&gt; dict:\n    \"\"\"Calculates the precision per class\"\"\"\n    cls_precision_dict = {}\n    try:\n        if target_classes is None:\n            class_names = self.get_containing_class_names()\n        else:\n            class_names = target_classes\n\n        for class_name in class_names:\n            true_pos = [\n                label for label in self.true_pos if label.class_name == class_name\n            ]\n            false_pos = [\n                label for label in self.false_pos if label.class_name == class_name\n            ]\n            if (len(true_pos) + len(false_pos)) != 0:\n                cls_precision_dict[class_name] = len(true_pos) / (\n                    len(true_pos) + len(false_pos)\n                )\n            else:\n                cls_precision_dict[class_name] = 0.0\n\n        return cls_precision_dict\n\n    except AttributeError as error:\n        # pylint: disable=broad-exception-raised\n        raise Exception(\n            f\"{error} - label should contain ObjDetInstanceLabel and BoundingBox\"\n        ) from error\n</code></pre>"},{"location":"reference/utilities/matchingresult/#niceml.utilities.matchingresult.MatchingResult.calculate_per_class_recall","title":"calculate_per_class_recall","text":"<pre><code>calculate_per_class_recall(target_classes=None)\n</code></pre> <p>Calculates the recall per target class</p> Source code in <code>niceml/utilities/matchingresult.py</code> <pre><code>def calculate_per_class_recall(\n    self, target_classes: Optional[List[str]] = None\n) -&gt; dict:\n    \"\"\"Calculates the recall per target class\"\"\"\n    cls_recall_dict = {}\n    try:\n        if target_classes is None:\n            class_names = self.get_containing_class_names()\n        else:\n            class_names = set(target_classes)\n\n        for class_name in class_names:\n            true_pos = [\n                label for label in self.true_pos if label.class_name == class_name\n            ]\n            false_neg = [\n                label for label in self.false_neg if label.class_name == class_name\n            ]\n            if len(true_pos) + len(false_neg) != 0:\n                cls_recall_dict[class_name] = len(true_pos) / (\n                    len(true_pos) + len(false_neg)\n                )\n            else:\n                cls_recall_dict[class_name] = 0.0\n\n        return cls_recall_dict\n\n    except AttributeError as error:\n        raise Exception(  # pylint: disable=broad-except\n            f\"{error} - label should contain ObjDetInstanceLabel and BoundingBox\"\n        ) from error\n</code></pre>"},{"location":"reference/utilities/matchingresult/#niceml.utilities.matchingresult.MatchingResult.calculate_precision","title":"calculate_precision","text":"<pre><code>calculate_precision()\n</code></pre> <p>Calculates the precision</p> Source code in <code>niceml/utilities/matchingresult.py</code> <pre><code>def calculate_precision(self) -&gt; float:\n    \"\"\"Calculates the precision\"\"\"\n    if len(self.true_pos) == 0:\n        return 0.0\n    return len(self.true_pos) / (len(self.true_pos) + len(self.false_pos))\n</code></pre>"},{"location":"reference/utilities/matchingresult/#niceml.utilities.matchingresult.MatchingResult.calculate_recall","title":"calculate_recall","text":"<pre><code>calculate_recall()\n</code></pre> <p>Calculates the recall</p> Source code in <code>niceml/utilities/matchingresult.py</code> <pre><code>def calculate_recall(self) -&gt; float:\n    \"\"\"Calculates the recall\"\"\"\n    if len(self.true_pos) == 0:\n        return 0.0\n    return len(self.true_pos) / (len(self.true_pos) + len(self.false_neg))\n</code></pre>"},{"location":"reference/utilities/matchingresult/#niceml.utilities.matchingresult.MatchingResult.get_containing_class_names","title":"get_containing_class_names","text":"<pre><code>get_containing_class_names()\n</code></pre> <p>Returns all class names of the true positives, false positives and false negatives</p> Source code in <code>niceml/utilities/matchingresult.py</code> <pre><code>def get_containing_class_names(self) -&gt; Set[str]:\n    \"\"\"Returns all class names of the true positives, false positives and false negatives\"\"\"\n    return {\n        label.class_name\n        for label in self.true_pos + self.false_pos + self.false_neg\n    }\n</code></pre>"},{"location":"reference/utilities/matchingresult/#niceml.utilities.matchingresult-functions","title":"Functions","text":""},{"location":"reference/utilities/matchingresult/#niceml.utilities.matchingresult.match_classification_prediction_and_gt","title":"match_classification_prediction_and_gt","text":"<pre><code>match_classification_prediction_and_gt(\n    pred_labels, gt_labels, matching_iou=0.5\n)\n</code></pre> <p>Matches region and class of predictions to ground truth labels and checks if the ground truth label could be found by minimum one prediction. Not matching ground truth labels are counted as false negative. Not matching predictions are counted as false positives. The sum of false negative and true positive is the amount of ground truth labels</p> <p>Parameters:</p> <ul> <li> <code>pred_labels</code>             (<code>List[InstanceLabel]</code>)         \u2013          <p>prediction labels (bounding box or mask)</p> </li> <li> <code>gt_labels</code>             (<code>List[InstanceLabel]</code>)         \u2013          <p>ground truth labels (bounding box or mask)</p> </li> <li> <code>matching_iou</code>             (<code>float</code>, default:                 <code>0.5</code> )         \u2013          <p>Minimum iou for region matching</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>MatchingResult</code>         \u2013          <p>MatchingResult with true_pos, false_pos and false_neg</p> </li> </ul> Source code in <code>niceml/utilities/matchingresult.py</code> <pre><code>def match_classification_prediction_and_gt(\n    pred_labels: List[InstanceLabel],\n    gt_labels: List[InstanceLabel],\n    matching_iou: float = 0.5,\n) -&gt; MatchingResult:\n    \"\"\"\n    Matches region and class of predictions to ground truth labels and checks\n    if the ground truth label could be found by minimum one prediction.\n    Not matching ground truth labels are counted as false negative.\n    Not matching predictions are counted as false positives.\n    The sum of false negative and true positive is the amount\n    of ground truth labels\n\n    Args:\n        pred_labels: prediction labels (bounding box or mask)\n        gt_labels:  ground truth labels (bounding box or mask)\n        matching_iou: Minimum iou for region matching\n\n    Returns:\n        MatchingResult with true_pos, false_pos and false_neg\n    \"\"\"\n\n    matched_pred_labels: Set[int] = set()\n    classification_true_pos_list: List[InstanceLabel] = []\n    classification_false_pos_list: List[InstanceLabel] = []\n    classification_false_neg_list: List[InstanceLabel] = []\n\n    for cur_gt_label in gt_labels:\n        cur_gt_true_pos = False\n        for pred_idx, cur_pred_label in enumerate(pred_labels):\n            cur_iou = cur_gt_label.calc_iou(cur_pred_label)\n\n            if (\n                cur_iou &gt; matching_iou\n                and cur_pred_label.class_name == cur_gt_label.class_name\n            ):\n                matched_pred_labels.add(pred_idx)\n                cur_gt_true_pos = True\n\n        if cur_gt_true_pos:\n            classification_true_pos_list.append(cur_gt_label)\n        else:\n            classification_false_neg_list.append(cur_gt_label)\n\n    missed_pred_label_idxes = [\n        index for index in range(len(pred_labels)) if index not in matched_pred_labels\n    ]\n    for index in missed_pred_label_idxes:\n        cur_pred_label = pred_labels[index]\n        classification_false_pos_list.append(cur_pred_label)\n\n    return MatchingResult(\n        true_pos=classification_true_pos_list,\n        false_pos=classification_false_pos_list,\n        false_neg=classification_false_neg_list,\n    )\n</code></pre>"},{"location":"reference/utilities/matchingresult/#niceml.utilities.matchingresult.match_detection_prediction_and_gt","title":"match_detection_prediction_and_gt","text":"<pre><code>match_detection_prediction_and_gt(\n    pred_labels, gt_labels, matching_iou=0.5\n)\n</code></pre> <p>Matches regions of predictions to ground truth label regions and checks if the ground truth label could be found by minimum one prediction. Not matching ground truth labels are counted as false negative. Not matching predictions are counted as false positives. The sum of false negative and true positive is the amount of ground truth labels</p> <p>Parameters:</p> <ul> <li> <code>pred_labels</code>             (<code>List[InstanceLabel]</code>)         \u2013          <p>prediction labels (bounding box or mask)</p> </li> <li> <code>gt_labels</code>             (<code>List[InstanceLabel]</code>)         \u2013          <p>ground truth labels (bounding box or mask)</p> </li> <li> <code>matching_iou</code>             (<code>float</code>, default:                 <code>0.5</code> )         \u2013          <p>Minimum iou for region matching</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>MatchingResult</code>         \u2013          <p>MatchingResult with true_pos, false_pos and false_neg</p> </li> </ul> Source code in <code>niceml/utilities/matchingresult.py</code> <pre><code>def match_detection_prediction_and_gt(\n    pred_labels: List[InstanceLabel],\n    gt_labels: List[InstanceLabel],\n    matching_iou: float = 0.5,\n) -&gt; MatchingResult:\n    \"\"\"\n    Matches regions of predictions to ground truth label regions and checks\n    if the ground truth label could be found by minimum one prediction.\n    Not matching ground truth labels are counted as false negative.\n    Not matching predictions are counted as false positives.\n    The sum of false negative and true positive is the amount\n    of ground truth labels\n\n    Args:\n        pred_labels: prediction labels (bounding box or mask)\n        gt_labels:  ground truth labels (bounding box or mask)\n        matching_iou: Minimum iou for region matching\n\n    Returns:\n        MatchingResult with true_pos, false_pos and false_neg\n    \"\"\"\n\n    matched_pred_labels: Set[int] = set()\n    classification_true_pos_list: List[InstanceLabel] = []\n    classification_false_pos_list: List[InstanceLabel] = []\n    classification_false_neg_list: List[InstanceLabel] = []\n\n    for cur_gt_label in gt_labels:\n        cur_gt_true_pos = False\n        for pred_idx, cur_pred_label in enumerate(pred_labels):\n            cur_iou = cur_gt_label.calc_iou(cur_pred_label)\n\n            if cur_iou &gt; matching_iou:\n                matched_pred_labels.add(pred_idx)\n                cur_gt_true_pos = True\n\n        if cur_gt_true_pos:\n            classification_true_pos_list.append(cur_gt_label)\n        else:\n            classification_false_neg_list.append(cur_gt_label)\n\n    missed_pred_label_idxes = [\n        index for index in range(len(pred_labels)) if index not in matched_pred_labels\n    ]\n    for index in missed_pred_label_idxes:\n        cur_pred_label = pred_labels[index]\n        classification_false_pos_list.append(cur_pred_label)\n\n    return MatchingResult(\n        true_pos=classification_true_pos_list,\n        false_pos=classification_false_pos_list,\n        false_neg=classification_false_neg_list,\n    )\n</code></pre>"},{"location":"reference/utilities/omegaconfutils/","title":"omegaconfutils","text":""},{"location":"reference/utilities/omegaconfutils/#niceml.utilities.omegaconfutils","title":"omegaconfutils","text":"<p>Module for all Omegaconf utils</p>"},{"location":"reference/utilities/omegaconfutils/#niceml.utilities.omegaconfutils-classes","title":"Classes","text":""},{"location":"reference/utilities/omegaconfutils/#niceml.utilities.omegaconfutils.StringSepResolver","title":"StringSepResolver","text":"<pre><code>StringSepResolver(seperator=',', cast_type=None)\n</code></pre> <p>OmegaConf resolver which extracts values from a string using the seperator</p> <p>Parameters:</p> <ul> <li> <code>seperator</code>             (<code>str</code>, default:                 <code>','</code> )         \u2013          <p>Used to split the input str</p> </li> <li> <code>cast_type</code>         \u2013          <p>Optional; If given it is used to convert the value to a given type</p> </li> </ul> Source code in <code>niceml/utilities/omegaconfutils.py</code> <pre><code>def __init__(self, seperator: str = \",\", cast_type=None):\n    self.seperator = seperator\n    self.cast_type = cast_type\n</code></pre>"},{"location":"reference/utilities/omegaconfutils/#niceml.utilities.omegaconfutils.StringSepResolver-functions","title":"Functions","text":""},{"location":"reference/utilities/omegaconfutils/#niceml.utilities.omegaconfutils.StringSepResolver.__call__","title":"__call__","text":"<pre><code>__call__(incoming_str, index)\n</code></pre> <p>Extracts a value from 'incoming_str' by index Args:     incoming_str: str with target information (e.g. '124,264')     index: target index (e.g. 1 -&gt; 264)</p> Source code in <code>niceml/utilities/omegaconfutils.py</code> <pre><code>def __call__(self, incoming_str: str, index: int):\n    \"\"\"\n    Extracts a value from 'incoming_str' by index\n    Args:\n        incoming_str: str with target information (e.g. '124,264')\n        index: target index (e.g. 1 -&gt; 264)\n    \"\"\"\n    index = int(index)\n    res = incoming_str.split(sep=self.seperator)[index]\n    if self.cast_type is not None:\n        res = self.cast_type(res)\n    return res\n</code></pre>"},{"location":"reference/utilities/omegaconfutils/#niceml.utilities.omegaconfutils.TrueDivResolver","title":"TrueDivResolver","text":"<p>OmegaConf resolver which divides two values and returns an int</p>"},{"location":"reference/utilities/omegaconfutils/#niceml.utilities.omegaconfutils.TypeCastResolver","title":"TypeCastResolver","text":"<pre><code>TypeCastResolver(cast_type)\n</code></pre> <p>Converts a string to a given type</p> Source code in <code>niceml/utilities/omegaconfutils.py</code> <pre><code>def __init__(self, cast_type):\n    self.cast_type = cast_type\n</code></pre>"},{"location":"reference/utilities/omegaconfutils/#niceml.utilities.omegaconfutils-functions","title":"Functions","text":""},{"location":"reference/utilities/omegaconfutils/#niceml.utilities.omegaconfutils.register_niceml_resolvers","title":"register_niceml_resolvers","text":"<pre><code>register_niceml_resolvers()\n</code></pre> <p>register all niceml OmegaConf resolvers</p> Source code in <code>niceml/utilities/omegaconfutils.py</code> <pre><code>def register_niceml_resolvers():\n    \"\"\"register all niceml OmegaConf resolvers\"\"\"\n    # If this function is called twice, the Resolvers are already registered.\n    # In this case, the upcoming ValueError is ignored.\n    with contextlib.suppress(ValueError):\n        OmegaConf.register_new_resolver(\n            \"niceml.extract_int\", StringSepResolver(cast_type=int)\n        )\n        OmegaConf.register_new_resolver(\n            \"niceml.extract_float\", StringSepResolver(cast_type=float)\n        )\n        OmegaConf.register_new_resolver(\"niceml.extract_raw\", StringSepResolver())\n        OmegaConf.register_new_resolver(\"niceml.to_int\", TypeCastResolver(int))\n        OmegaConf.register_new_resolver(\"niceml.to_float\", TypeCastResolver(float))\n        OmegaConf.register_new_resolver(\"niceml.to_bool\", TypeCastResolver(str_to_bool))\n        OmegaConf.register_new_resolver(\"niceml.true_div\", TrueDivResolver())\n</code></pre>"},{"location":"reference/utilities/pytestutils/","title":"pytestutils","text":""},{"location":"reference/utilities/pytestutils/#niceml.utilities.pytestutils","title":"pytestutils","text":""},{"location":"reference/utilities/pytestutils/#niceml.utilities.pytestutils-classes","title":"Classes","text":""},{"location":"reference/utilities/pytestutils/#niceml.utilities.pytestutils.ExptestPytestError","title":"ExptestPytestError","text":"<p>             Bases: <code>Exception</code></p> <p>Custom exception for error reporting.</p>"},{"location":"reference/utilities/pytestutils/#niceml.utilities.pytestutils.ExptestPytestWrapper","title":"ExptestPytestWrapper","text":"<pre><code>ExptestPytestWrapper(\n    name, parent, exp_test, target_path, index\n)\n</code></pre> <p>             Bases: <code>Item</code></p> Source code in <code>niceml/utilities/pytestutils.py</code> <pre><code>def __init__(\n    self, name, parent, exp_test: ExperimentTest, target_path: str, index: int\n):\n    super().__init__(name, parent)\n    self.exp_test = exp_test\n    self.target_path = target_path\n    self.index = index\n</code></pre>"},{"location":"reference/utilities/pytestutils/#niceml.utilities.pytestutils.ExptestPytestWrapper-functions","title":"Functions","text":""},{"location":"reference/utilities/pytestutils/#niceml.utilities.pytestutils.ExptestPytestWrapper.repr_failure","title":"repr_failure","text":"<pre><code>repr_failure(excinfo, style=None)\n</code></pre> <p>Called when self.runtest() raises an exception.</p> Source code in <code>niceml/utilities/pytestutils.py</code> <pre><code>def repr_failure(\n    self,\n    excinfo,\n    style=None,\n):\n    \"\"\"Called when self.runtest() raises an exception.\"\"\"\n    if isinstance(excinfo.value, ExptestPytestError):\n        exp_test_result: ExpTestResult\n        _, exp_test_result = excinfo.value.args\n        return str(exp_test_result)\n</code></pre>"},{"location":"reference/utilities/readwritelock/","title":"readwritelock","text":""},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock","title":"readwritelock","text":"<p>Module for Read/Write lock for fsspec filesystems</p>"},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock-classes","title":"Classes","text":""},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock.FileLock","title":"FileLock","text":"<pre><code>FileLock(retry_time=10, timeout=172800, is_acquired=False)\n</code></pre> <p>             Bases: <code>ABC</code></p> <p>Abstract base class for file locks.</p> <p>Initialize FileLock</p> Source code in <code>niceml/utilities/readwritelock.py</code> <pre><code>def __init__(\n    self, retry_time: float = 10, timeout: float = 172800, is_acquired: bool = False\n):\n    \"\"\"Initialize FileLock\"\"\"\n    self.retry_time = retry_time\n    self.timeout = timeout\n    self.is_acquired: bool = is_acquired\n</code></pre>"},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock.FileLock-functions","title":"Functions","text":""},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock.FileLock.__enter__","title":"__enter__","text":"<pre><code>__enter__()\n</code></pre> <p>context manager enter method</p> Source code in <code>niceml/utilities/readwritelock.py</code> <pre><code>def __enter__(self):\n    \"\"\"context manager enter method\"\"\"\n    self.acquire()\n    return self\n</code></pre>"},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock.FileLock.__eq__","title":"__eq__","text":"<pre><code>__eq__(other)\n</code></pre> <p>Compares two file locks</p> Source code in <code>niceml/utilities/readwritelock.py</code> <pre><code>def __eq__(self, other: \"FileLock\"):\n    \"\"\"Compares two file locks\"\"\"\n    return (\n        self.retry_time == other.retry_time\n        and self.timeout == other.timeout\n        and self.is_acquired == other.is_acquired\n    )\n</code></pre>"},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock.FileLock.__exit__","title":"__exit__","text":"<pre><code>__exit__(exc_type, exc_value, traceback)\n</code></pre> <p>context manager exit method</p> Source code in <code>niceml/utilities/readwritelock.py</code> <pre><code>def __exit__(self, exc_type, exc_value, traceback):\n    \"\"\"context manager exit method\"\"\"\n    self.release()\n</code></pre>"},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock.FileLock.acquire","title":"acquire  <code>abstractmethod</code>","text":"<pre><code>acquire()\n</code></pre> <p>Acquire the lock</p> Source code in <code>niceml/utilities/readwritelock.py</code> <pre><code>@abstractmethod\ndef acquire(self):\n    \"\"\"Acquire the lock\"\"\"\n</code></pre>"},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock.FileLock.force_delete","title":"force_delete  <code>abstractmethod</code>","text":"<pre><code>force_delete()\n</code></pre> <p>Force delete the lock</p> Source code in <code>niceml/utilities/readwritelock.py</code> <pre><code>@abstractmethod\ndef force_delete(self):\n    \"\"\"Force delete the lock\"\"\"\n</code></pre>"},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock.FileLock.is_acquirable","title":"is_acquirable  <code>abstractmethod</code>","text":"<pre><code>is_acquirable()\n</code></pre> <p>Checks if lock file does not exist</p> Source code in <code>niceml/utilities/readwritelock.py</code> <pre><code>@abstractmethod\ndef is_acquirable(self) -&gt; bool:\n    \"\"\"Checks if lock file does not exist\"\"\"\n</code></pre>"},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock.FileLock.release","title":"release  <code>abstractmethod</code>","text":"<pre><code>release()\n</code></pre> <p>Release the lock</p> Source code in <code>niceml/utilities/readwritelock.py</code> <pre><code>@abstractmethod\ndef release(self):\n    \"\"\"Release the lock\"\"\"\n</code></pre>"},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock.ReadLock","title":"ReadLock","text":"<pre><code>ReadLock(\n    path_config,\n    retry_time=10,\n    retry_await_time=0,\n    timeout=172800,\n    write_lock_name=\"write.lock\",\n    read_lock_name=\"read.lock\",\n    is_acquired=False,\n)\n</code></pre> <p>             Bases: <code>FileLock</code></p> <p>Read lock for fsspec filesystems.</p> <p>Initialize ReadLock</p> Source code in <code>niceml/utilities/readwritelock.py</code> <pre><code>def __init__(  # noqa: PLR0913\n    self,\n    path_config: Union[LocationConfig, Dict[str, Any]],\n    retry_time: float = 10,\n    retry_await_time=0,\n    timeout: float = 172800,\n    write_lock_name: str = \"write.lock\",\n    read_lock_name: str = \"read.lock\",\n    is_acquired: bool = False,\n):\n    \"\"\"Initialize ReadLock\"\"\"\n    if write_lock_name == read_lock_name:\n        raise ValueError(\"write_lock_name and read_lock_name must be different\")\n    super().__init__(retry_time, timeout, is_acquired)\n    self.path_config = path_config\n    self.write_lock_name = write_lock_name\n    self.read_lock_name = read_lock_name\n    self.retry_await_time = retry_await_time\n</code></pre>"},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock.ReadLock-functions","title":"Functions","text":""},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock.ReadLock.__eq__","title":"__eq__","text":"<pre><code>__eq__(other)\n</code></pre> <p>Compares two file locks</p> Source code in <code>niceml/utilities/readwritelock.py</code> <pre><code>def __eq__(self, other: \"ReadLock\"):\n    \"\"\"Compares two file locks\"\"\"\n    return (\n        isinstance(other, ReadLock)\n        and self.retry_time == other.retry_time\n        and self.timeout == other.timeout\n        and self.is_acquired == other.is_acquired\n        and self.path_config == other.path_config\n        and self.write_lock_name == other.write_lock_name\n        and self.read_lock_name == other.read_lock_name\n        and self.retry_await_time == other.retry_await_time\n    )\n</code></pre>"},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock.ReadLock.acquire","title":"acquire","text":"<pre><code>acquire()\n</code></pre> <p>Acquire the lock</p> Source code in <code>niceml/utilities/readwritelock.py</code> <pre><code>def acquire(self):\n    \"\"\"Acquire the lock\"\"\"\n    if self.is_acquired:\n        return\n    with open_location(self.path_config) as (cur_fs, root_path):\n        start_time = time.monotonic()\n        read_lock_path = join_fs_path(cur_fs, root_path, self.read_lock_name)\n        while True:\n            write_lock_path = join_fs_path(cur_fs, root_path, self.write_lock_name)\n            cur_fs.mkdirs(root_path, exist_ok=True)\n            if is_lock_file_acquirable(write_lock_path, cur_fs):\n                break\n            if time.monotonic() - start_time &gt; self.timeout:\n                raise TimeoutError(\n                    f\"Timeout while waiting for write lock release \"\n                    f\"'{write_lock_path}' to acquire read lock at \"\n                    f\"'{read_lock_path}'\"\n                )\n            logging.info(\n                f\"Waiting for write lock release {self.retry_await_time} \"\n                f\"seconds, to acquire read lock.\"\n            )\n            time.sleep(self.retry_time)\n            self.retry_await_time += self.retry_time\n        increase_lock_file_usage(read_lock_path, cur_fs)\n        self.is_acquired = True\n</code></pre>"},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock.ReadLock.force_delete","title":"force_delete","text":"<pre><code>force_delete()\n</code></pre> <p>Force delete the lock</p> Source code in <code>niceml/utilities/readwritelock.py</code> <pre><code>def force_delete(self):\n    \"\"\"Force delete the lock\"\"\"\n    self.is_acquired = False\n    with open_location(self.path_config) as (cur_fs, root_path):\n        read_lock_path = join_fs_path(cur_fs, root_path, self.read_lock_name)\n        release_lock_file(read_lock_path, cur_fs)\n</code></pre>"},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock.ReadLock.is_acquirable","title":"is_acquirable","text":"<pre><code>is_acquirable()\n</code></pre> <p>Checks if lock file does not exist</p> Source code in <code>niceml/utilities/readwritelock.py</code> <pre><code>def is_acquirable(self) -&gt; bool:\n    \"\"\"Checks if lock file does not exist\"\"\"\n    with open_location(self.path_config) as (cur_fs, root_path):\n        lock_path = join_fs_path(cur_fs, root_path, self.read_lock_name)\n        lock_is_acquirable = is_lock_file_acquirable(lock_path, cur_fs)\n    return lock_is_acquirable\n</code></pre>"},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock.ReadLock.release","title":"release","text":"<pre><code>release()\n</code></pre> <p>Release the lock</p> Source code in <code>niceml/utilities/readwritelock.py</code> <pre><code>def release(self):\n    \"\"\"Release the lock\"\"\"\n    if self.is_acquired:\n        with open_location(self.path_config) as (cur_fs, root_path):\n            read_lock_path = join_fs_path(cur_fs, root_path, self.read_lock_name)\n            decrease_lock_file_usage(read_lock_path, cur_fs)\n            self.is_acquired = False\n</code></pre>"},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock.WriteLock","title":"WriteLock","text":"<pre><code>WriteLock(\n    path_config,\n    retry_time=10,\n    retry_await_time=0,\n    timeout=172800,\n    write_lock_name=\"write.lock\",\n    read_lock_name=\"read.lock\",\n    is_acquired=False,\n)\n</code></pre> <p>             Bases: <code>FileLock</code></p> <p>Write lock for fsspec filesystems.</p> <p>Initialize WriteLock</p> Source code in <code>niceml/utilities/readwritelock.py</code> <pre><code>def __init__(  # noqa: PLR0913\n    self,\n    path_config: Union[LocationConfig, Dict[str, Any]],\n    retry_time: float = 10,\n    retry_await_time: int = 0,\n    timeout: float = 172800,\n    write_lock_name: str = \"write.lock\",\n    read_lock_name: str = \"read.lock\",\n    is_acquired: bool = False,\n):\n    \"\"\"Initialize WriteLock\"\"\"\n    if write_lock_name == read_lock_name:\n        raise ValueError(\"write_lock_name and read_lock_name must be different\")\n    super().__init__(retry_time, timeout, is_acquired)\n    self.path_config = path_config\n    self.write_lock_name = write_lock_name\n    self.read_lock_name = read_lock_name\n    self.retry_await_time = retry_await_time\n</code></pre>"},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock.WriteLock-functions","title":"Functions","text":""},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock.WriteLock.__eq__","title":"__eq__","text":"<pre><code>__eq__(other)\n</code></pre> <p>Compares two file locks</p> Source code in <code>niceml/utilities/readwritelock.py</code> <pre><code>def __eq__(self, other: \"WriteLock\"):\n    \"\"\"Compares two file locks\"\"\"\n    return (\n        isinstance(other, WriteLock)\n        and self.retry_time == other.retry_time\n        and self.timeout == other.timeout\n        and self.is_acquired == other.is_acquired\n        and self.path_config == other.path_config\n        and self.write_lock_name == other.write_lock_name\n        and self.read_lock_name == other.read_lock_name\n        and self.retry_await_time == other.retry_await_time\n    )\n</code></pre>"},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock.WriteLock.acquire","title":"acquire","text":"<pre><code>acquire()\n</code></pre> <p>Acquire the lock</p> Source code in <code>niceml/utilities/readwritelock.py</code> <pre><code>def acquire(self):\n    \"\"\"Acquire the lock\"\"\"\n    if self.is_acquired:\n        return\n    with open_location(self.path_config) as (cur_fs, root_path):\n        start_time = time.monotonic()\n        cur_fs.mkdirs(root_path, exist_ok=True)\n        while True:  # Acquire Write Lock\n            write_lock_path = join_fs_path(cur_fs, root_path, self.write_lock_name)\n            if is_lock_file_acquirable(write_lock_path, cur_fs):\n                acquire_lock_file(write_lock_path, cur_fs)\n                self.is_acquired = True\n                break\n            if time.monotonic() - start_time &gt; self.timeout:\n                raise TimeoutError(\n                    f\"Timeout while waiting for write lock release at\"\n                    f\" '{write_lock_path}'\"\n                )\n            logging.info(\n                f\"Waiting for write lock release {self.retry_await_time} seconds\"\n            )\n            time.sleep(self.retry_time)\n            self.retry_await_time += self.retry_time\n        self.retry_await_time = 0\n        while True:  # Check if Read Lock is acquired\n            read_lock_path = join_fs_path(cur_fs, root_path, self.read_lock_name)\n            if is_lock_file_acquirable(read_lock_path, cur_fs):\n                break\n            if time.monotonic() - start_time &gt; self.timeout:\n                self.release()\n                raise TimeoutError(\n                    f\"Timeout while waiting for read lock release at\"\n                    f\" '{read_lock_path}'\"\n                )\n            logging.info(\n                f\"Waiting for read lock release {self.retry_await_time} seconds\"\n            )\n            time.sleep(self.retry_time)\n            self.retry_await_time += self.retry_time\n</code></pre>"},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock.WriteLock.force_delete","title":"force_delete","text":"<pre><code>force_delete()\n</code></pre> <p>Force delete the lock</p> Source code in <code>niceml/utilities/readwritelock.py</code> <pre><code>def force_delete(self):\n    \"\"\"Force delete the lock\"\"\"\n    self.is_acquired = False\n    with open_location(self.path_config) as (cur_fs, root_path):\n        write_lock_path = join_fs_path(cur_fs, root_path, self.write_lock_name)\n        release_lock_file(write_lock_path, cur_fs)\n</code></pre>"},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock.WriteLock.is_acquirable","title":"is_acquirable","text":"<pre><code>is_acquirable()\n</code></pre> <p>Checks if lock file does not exist</p> Source code in <code>niceml/utilities/readwritelock.py</code> <pre><code>def is_acquirable(self) -&gt; bool:\n    \"\"\"Checks if lock file does not exist\"\"\"\n    with open_location(self.path_config) as (cur_fs, root_path):\n        lock_path = join_fs_path(cur_fs, root_path, self.write_lock_name)\n        lock_is_acquirable = is_lock_file_acquirable(lock_path, cur_fs)\n    return lock_is_acquirable\n</code></pre>"},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock.WriteLock.release","title":"release","text":"<pre><code>release()\n</code></pre> <p>Release the lock</p> Source code in <code>niceml/utilities/readwritelock.py</code> <pre><code>def release(self):\n    \"\"\"Release the lock\"\"\"\n    if self.is_acquired:\n        with open_location(self.path_config) as (cur_fs, root_path):\n            write_lock_path = join_fs_path(cur_fs, root_path, self.write_lock_name)\n            release_lock_file(write_lock_path, cur_fs)\n            self.is_acquired = False\n</code></pre>"},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock-functions","title":"Functions","text":""},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock.acquire_lock_file","title":"acquire_lock_file","text":"<pre><code>acquire_lock_file(lock_file_path, file_system=None)\n</code></pre> <p>Acquire the lock file.</p> Source code in <code>niceml/utilities/readwritelock.py</code> <pre><code>def acquire_lock_file(\n    lock_file_path: str, file_system: Optional[AbstractFileSystem] = None\n) -&gt; None:\n    \"\"\"Acquire the lock file.\"\"\"\n    file_system = file_system or LocalFileSystem()\n    if not is_lock_file_acquirable(lock_file_path, file_system):\n        raise RuntimeError(f\"Lock file {lock_file_path} is not available.\")\n    file_system.touch(lock_file_path)\n</code></pre>"},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock.decrease_lock_file_usage","title":"decrease_lock_file_usage","text":"<pre><code>decrease_lock_file_usage(lock_file_path, file_system=None)\n</code></pre> <p>Decrease the lock file usage.</p> Source code in <code>niceml/utilities/readwritelock.py</code> <pre><code>def decrease_lock_file_usage(\n    lock_file_path: str, file_system: Optional[AbstractFileSystem] = None\n) -&gt; None:\n    \"\"\"Decrease the lock file usage.\"\"\"\n    file_system = file_system or LocalFileSystem()\n    if not file_system.exists(lock_file_path):\n        current_usage: int = 0\n    else:\n        with file_system.open(lock_file_path, \"r\") as file:\n            current_usage = int(file.read())\n    if current_usage &gt; 1:\n        with file_system.open(lock_file_path, \"w\") as file:\n            file.write(str(current_usage - 1))\n    else:\n        release_lock_file(lock_file_path, file_system)\n</code></pre>"},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock.increase_lock_file_usage","title":"increase_lock_file_usage","text":"<pre><code>increase_lock_file_usage(lock_file_path, file_system=None)\n</code></pre> <p>Increase the lock file usage.</p> Source code in <code>niceml/utilities/readwritelock.py</code> <pre><code>def increase_lock_file_usage(\n    lock_file_path: str, file_system: Optional[AbstractFileSystem] = None\n) -&gt; None:\n    \"\"\"Increase the lock file usage.\"\"\"\n    file_system = file_system or LocalFileSystem()\n    if not file_system.exists(lock_file_path):\n        current_usage: int = 0\n    else:\n        with file_system.open(lock_file_path, \"r\") as file:\n            current_usage = int(file.read())\n    with file_system.open(lock_file_path, \"w\") as file:\n        file.write(str(current_usage + 1))\n</code></pre>"},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock.is_lock_file_acquirable","title":"is_lock_file_acquirable","text":"<pre><code>is_lock_file_acquirable(lock_file_path, file_system=None)\n</code></pre> <p>Check if the lock file is available. The lock file is available if it does not exist at lock_file_path.</p> Source code in <code>niceml/utilities/readwritelock.py</code> <pre><code>def is_lock_file_acquirable(\n    lock_file_path: str, file_system: Optional[AbstractFileSystem] = None\n) -&gt; bool:\n    \"\"\"Check if the lock file is available.\n    The lock file is available if it does not exist at lock_file_path.\"\"\"\n    file_system = file_system or LocalFileSystem()\n    if file_system.exists(lock_file_path):\n        return False\n    return True\n</code></pre>"},{"location":"reference/utilities/readwritelock/#niceml.utilities.readwritelock.release_lock_file","title":"release_lock_file","text":"<pre><code>release_lock_file(lock_file_path, file_system=None)\n</code></pre> <p>Release the lock file.</p> Source code in <code>niceml/utilities/readwritelock.py</code> <pre><code>def release_lock_file(\n    lock_file_path: str, file_system: Optional[AbstractFileSystem] = None\n) -&gt; None:\n    \"\"\"Release the lock file.\"\"\"\n    file_system = file_system or LocalFileSystem()\n    if not file_system.exists(lock_file_path):\n        logger = logging.getLogger(__name__)\n        logger.warning(f\"Lock file {lock_file_path} does not exist.\")\n    else:\n        file_system.rm(lock_file_path)\n</code></pre>"},{"location":"reference/utilities/regexutils/","title":"regexutils","text":""},{"location":"reference/utilities/regexutils/#niceml.utilities.regexutils","title":"regexutils","text":"<p>Module for regular expression utilities</p>"},{"location":"reference/utilities/regexutils/#niceml.utilities.regexutils-functions","title":"Functions","text":""},{"location":"reference/utilities/regexutils/#niceml.utilities.regexutils.check_exp_name","title":"check_exp_name","text":"<pre><code>check_exp_name(exp_name)\n</code></pre> <p>Checks if an experiment name matches a pattern (EXP_NAME_PATTERN) Args:     exp_name: experiment name to check</p> <p>Returns:</p> <ul> <li> <code>bool</code>         \u2013          <p>True if <code>exp_name</code> matches the pattern</p> </li> </ul> Source code in <code>niceml/utilities/regexutils.py</code> <pre><code>def check_exp_name(exp_name: str) -&gt; bool:\n    \"\"\"\n    Checks if an experiment name matches a pattern (EXP_NAME_PATTERN)\n    Args:\n        exp_name: experiment name to check\n\n    Returns:\n        True if `exp_name` matches the pattern\n    \"\"\"\n    pattern = re.compile(EXP_NAME_PATTERN)\n    return bool(pattern.match(exp_name))\n</code></pre>"},{"location":"reference/utilities/splitutils/","title":"splitutils","text":""},{"location":"reference/utilities/splitutils/#niceml.utilities.splitutils","title":"splitutils","text":"<p>Module for utils which are used for split data</p>"},{"location":"reference/utilities/splitutils/#niceml.utilities.splitutils-classes","title":"Classes","text":""},{"location":"reference/utilities/splitutils/#niceml.utilities.splitutils.DataSetInfo","title":"DataSetInfo  <code>dataclass</code>","text":"<p>Dataclass which represents a data set info including a set name (e.g. test) and a probability to split the dataset</p>"},{"location":"reference/utilities/splitutils/#niceml.utilities.splitutils.DataSetInfo-functions","title":"Functions","text":""},{"location":"reference/utilities/splitutils/#niceml.utilities.splitutils.DataSetInfo.to_tuple","title":"to_tuple","text":"<pre><code>to_tuple()\n</code></pre> <p>Returns a tuple with shape (set_name,probability)</p> Source code in <code>niceml/utilities/splitutils.py</code> <pre><code>def to_tuple(self) -&gt; Tuple[str, float]:\n    \"\"\"Returns a tuple with shape (set_name,probability)\"\"\"\n    return self.set_name, self.probability\n</code></pre>"},{"location":"reference/utilities/splitutils/#niceml.utilities.splitutils-functions","title":"Functions","text":""},{"location":"reference/utilities/splitutils/#niceml.utilities.splitutils.clear_folder","title":"clear_folder","text":"<pre><code>clear_folder(location)\n</code></pre> <p>Deletes every file or folder inside a given location</p> Source code in <code>niceml/utilities/splitutils.py</code> <pre><code>def clear_folder(location: Union[dict, LocationConfig]):\n    \"\"\"Deletes every file or folder inside a given location\"\"\"\n    with open_location(location) as (target_fs, path):\n        if target_fs.exists(path):\n            try:\n                target_fs.rm(path, recursive=True)\n            except Exception as error:\n                print(f\"Failed to delete {path}. Reason: {error}\")\n</code></pre>"},{"location":"reference/utilities/splitutils/#niceml.utilities.splitutils.create_copy_files_container","title":"create_copy_files_container","text":"<pre><code>create_copy_files_container(\n    folder_list,\n    input_location,\n    recursive,\n    dataset_info_list,\n    delimiter_maxsplit,\n    name_delimiter,\n    output_location,\n)\n</code></pre> <p>Creates a list of CopyFileInfo objects. The CopyFileInfo object contains the input and output locations for each file, as well as the checksum of that file. This function also takes in a list of DataSetInfo objects, which contain information about how many files should be copied into each set (train/validation/test). It then uses this information to randomly assign files into sets based on their probability.</p> <p>Parameters:</p> <ul> <li> <code>folder_list</code>             (<code>List[str]</code>)         \u2013          <p>Folders to copy from</p> </li> <li> <code>input_location</code>             (<code>Union[dict, LocationConfig]</code>)         \u2013          <p>Location of the input data (path) with corresponding LocationConfig</p> </li> <li> <code>recursive</code>             (<code>bool</code>)         \u2013          <p>Indicate whether to recursively search for files in the input_location</p> </li> <li> <code>dataset_info_list</code>             (<code>List[DataSetInfo]</code>)         \u2013          <p>Determine the name and probability of each dataset</p> </li> <li> <code>delimiter_maxsplit</code>             (<code>int</code>)         \u2013          <p>Maxsplit to split the file name into a set and an identifier</p> </li> <li> <code>name_delimiter</code>             (<code>str</code>)         \u2013          <p>Delimiter to split the file name into a set and an identifier</p> </li> <li> <code>output_location</code>             (<code>Union[dict, LocationConfig]</code>)         \u2013          <p>Location of the output files (path) with corresponding LocationConfig</p> </li> </ul> <p>Returns:      A list of CopyFileInfo objects with input and output location and the files checksum</p> Source code in <code>niceml/utilities/splitutils.py</code> <pre><code>def create_copy_files_container(\n    folder_list: List[str],\n    input_location: Union[dict, LocationConfig],\n    recursive: bool,\n    dataset_info_list: List[DataSetInfo],\n    delimiter_maxsplit: int,\n    name_delimiter: str,\n    output_location: Union[dict, LocationConfig],\n) -&gt; List[CopyFileInfo]:\n    \"\"\"\n    Creates a list of CopyFileInfo objects.\n    The CopyFileInfo object contains the input and output locations for\n    each file, as well as the checksum of that file.\n    This function also takes in a list of DataSetInfo objects, which contain\n    information about how many files should be copied into each set (train/validation/test).\n    It then uses this information to randomly assign files into sets based on their probability.\n\n    Args:\n        folder_list: Folders to copy from\n        input_location: Location of the input data (path) with corresponding LocationConfig\n        recursive: Indicate whether to recursively search for files in the input_location\n        dataset_info_list: Determine the name and probability of each dataset\n        delimiter_maxsplit: Maxsplit to split the file name into a set and an identifier\n        name_delimiter:  Delimiter to split the file name into a set and an identifier\n        output_location: Location of the output files (path) with corresponding LocationConfig\n    Returns:\n         A list of CopyFileInfo objects with input and output location and the files checksum\n    \"\"\"\n    set_list, prob_list = generate_set_and_prob_list(dataset_info_list)\n    copy_list: List[CopyFileInfo] = []\n    with open_location(input_location) as (input_fs, input_path):\n        for input_folder in folder_list:\n            files: List[str] = [\n                x\n                for x in list_dir(\n                    join(input_path, input_folder),\n                    recursive=recursive,\n                    file_system=input_fs,\n                )\n                if input_fs.isfile(join(input_path, input_folder, x))\n            ]\n            for file in files:\n                cur_basename = basename(splitext(file)[0])\n                if delimiter_maxsplit &gt; 0 and name_delimiter in cur_basename:\n                    cur_basename = cur_basename.rsplit(\n                        name_delimiter, maxsplit=delimiter_maxsplit\n                    )[0]\n                identifier = \"\".join(\n                    [char for char in cur_basename if char in ALPHANUMERICLIST]\n                )\n                cur_seed = int(identifier, base=len(ALPHANUMERICLIST)) % (2**32 - 1)\n                rng = np.random.default_rng(seed=cur_seed)\n                drawn_set = rng.choice(set_list, 1, p=prob_list)[0]\n                output_file = join(drawn_set, file)\n                input_file_path = join(input_folder, file)\n                checksum = md5_from_file(\n                    join(input_path, input_file_path), file_system=input_fs\n                )\n                file_input_location = join_location_w_path(\n                    input_location, input_file_path\n                )\n                file_output_location = join_location_w_path(\n                    output_location, output_file\n                )\n                copy_list.append(\n                    CopyFileInfo(file_input_location, file_output_location, checksum)\n                )\n    return copy_list\n</code></pre>"},{"location":"reference/utilities/splitutils/#niceml.utilities.splitutils.generate_set_and_prob_list","title":"generate_set_and_prob_list","text":"<pre><code>generate_set_and_prob_list(set_info_list)\n</code></pre> Takes a list of DataSetInfo objects and returns two lists <ol> <li>List of Names of each set in the order they appear in the input list.</li> <li>Corresponding list containing each set's probability, also in order.</li> </ol> <p>Parameters:</p> <ul> <li> <code>set_info_list</code>             (<code>List[DataSetInfo]</code>)         \u2013          <p>List of DataSetInfo objects</p> </li> </ul> <p>Returns:     A list of names (str) and a list of probabilities (float)</p> Source code in <code>niceml/utilities/splitutils.py</code> <pre><code>def generate_set_and_prob_list(\n    set_info_list: List[DataSetInfo],\n) -&gt; Tuple[List[str], List[float]]:\n    \"\"\"\n    Takes a list of DataSetInfo objects and returns two lists:\n        1. List of Names of each set in the order they appear in the input list.\n        2. Corresponding list containing each set's probability, also in order.\n\n    Args:\n        set_info_list: List of DataSetInfo objects\n    Returns:\n        A list of names (str) and a list of probabilities (float)\n    \"\"\"\n    tmp_list: List[Tuple[str, float]] = [dsf.to_tuple() for dsf in set_info_list]\n    names, probs = zip(*tmp_list)\n    return list(names), list(probs)\n</code></pre>"},{"location":"reference/utilities/splitutils/#niceml.utilities.splitutils.init_dataset_info","title":"init_dataset_info","text":"<pre><code>init_dataset_info(info)\n</code></pre> <p>Returns a DataSetInfo for the given information</p> <p>Parameters:</p> <ul> <li> <code>info</code>             (<code>str</code>)         \u2013          <p>string with the format [set_name,probability], e.g. 'test,0.1'</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>DataSetInfo</code>         \u2013          <p>DataSetInfo object with set and probability information</p> </li> </ul> Source code in <code>niceml/utilities/splitutils.py</code> <pre><code>def init_dataset_info(info: str) -&gt; DataSetInfo:\n    \"\"\"\n    Returns a DataSetInfo for the given information\n\n    Args:\n        info: string with the format [set_name,probability], e.g. 'test,0.1'\n\n    Returns:\n        DataSetInfo object with set and probability information\n    \"\"\"\n    set_name, prob = info.split(\",\")\n    prob = float(prob)\n    return DataSetInfo(set_name=set_name, probability=prob)\n</code></pre>"},{"location":"reference/utilities/thumbnailshower/","title":"thumbnailshower","text":""},{"location":"reference/utilities/thumbnailshower/#niceml.utilities.thumbnailshower","title":"thumbnailshower","text":"<p>Module for ImageThumbnailShower</p>"},{"location":"reference/utilities/thumbnailshower/#niceml.utilities.thumbnailshower-classes","title":"Classes","text":""},{"location":"reference/utilities/thumbnailshower/#niceml.utilities.thumbnailshower.ImageThumbnailShower","title":"ImageThumbnailShower","text":"<pre><code>ImageThumbnailShower(col_count, selectable=True)\n</code></pre> <p>Class to show image thumbnails in a gridview in streamlit</p> Source code in <code>niceml/utilities/thumbnailshower.py</code> <pre><code>def __init__(self, col_count: int, selectable: bool = True):\n    self.col_count = col_count\n    self.selectable = selectable\n</code></pre>"},{"location":"reference/utilities/thumbnailshower/#niceml.utilities.thumbnailshower.ImageThumbnailShower-functions","title":"Functions","text":""},{"location":"reference/utilities/thumbnailshower/#niceml.utilities.thumbnailshower.ImageThumbnailShower.show_thumbnails","title":"show_thumbnails","text":"<pre><code>show_thumbnails(image_list, image_ids)\n</code></pre> <p>Shows image thumbnails in a gridview component in streamlit</p> <p>Parameters:</p> <ul> <li> <code>image_list</code>             (<code>List[Union[ndarray, Image]]</code>)         \u2013          <p>List of images to show</p> </li> <li> <code>image_ids</code>             (<code>List[str]</code>)         \u2013          <p>Ids of the images to show</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Optional[int]</code>         \u2013          <p>Index of image when an id is selected in the component</p> </li> </ul> Source code in <code>niceml/utilities/thumbnailshower.py</code> <pre><code>def show_thumbnails(\n    self, image_list: List[Union[np.ndarray, Image.Image]], image_ids: List[str]\n) -&gt; Optional[int]:\n    \"\"\"Shows image thumbnails in a gridview component in streamlit\n\n    Args:\n        image_list: List of images to show\n        image_ids: Ids of the images to show\n\n    Returns:\n        Index of image when an id is selected in the component\n    \"\"\"\n    columns = st.columns(self.col_count)\n    selection_idx: Optional[int] = None\n    for idx, image in enumerate(image_list):\n        cur_col = columns[idx % self.col_count]\n        cur_id = image_ids[idx]\n        caption = None if self.selectable else cur_id\n        cur_col.image(image, use_column_width=True, caption=caption)\n        if self.selectable and cur_col.button(cur_id):\n            selection_idx = idx\n    return selection_idx\n</code></pre>"},{"location":"reference/utilities/timeutils/","title":"timeutils","text":""},{"location":"reference/utilities/timeutils/#niceml.utilities.timeutils","title":"timeutils","text":"<p>Module for time related utilities</p>"},{"location":"reference/utilities/timeutils/#niceml.utilities.timeutils-functions","title":"Functions","text":""},{"location":"reference/utilities/timeutils/#niceml.utilities.timeutils.generate_timestamp","title":"generate_timestamp","text":"<pre><code>generate_timestamp()\n</code></pre> <p>Generates the timestamp to be used by versioning</p> <p>Returns:</p> <ul> <li> <code>str</code>         \u2013          <p>String representation of the current timestamp</p> </li> </ul> Source code in <code>niceml/utilities/timeutils.py</code> <pre><code>def generate_timestamp() -&gt; str:\n    \"\"\"Generates the timestamp to be used by versioning\n\n    Returns:\n        String representation of the current timestamp\n    \"\"\"\n    current_ts = datetime.now()\n    fmt = (\n        \"{d.year:04d}-{d.month:02d}-{d.day:02d}T{d.hour:02d}\"\n        \".{d.minute:02d}.{d.second:02d}.{ms:03d}Z\"\n    )\n    return fmt.format(d=current_ts, ms=current_ts.microsecond // 1000)\n</code></pre>"},{"location":"reference/utilities/userselection/","title":"userselection","text":""},{"location":"reference/utilities/userselection/#niceml.utilities.userselection","title":"userselection","text":"<p>Module for user selection dashboard component</p>"},{"location":"reference/utilities/userselection/#niceml.utilities.userselection-classes","title":"Classes","text":""},{"location":"reference/utilities/userselection/#niceml.utilities.userselection-functions","title":"Functions","text":""},{"location":"reference/utilities/userselection/#niceml.utilities.userselection.get_user_selection","title":"get_user_selection","text":"<pre><code>get_user_selection(\n    selection_info,\n    component_key=None,\n    class_label=\"Class\",\n    prob_label=\"Probability\",\n    data_identifier_options=None,\n    data_identifier_label=\"Data identifier\",\n    data_identifier_hint=None,\n)\n</code></pre> <p>Returns the users dashboard selection for specific values from a SelectionInfo. It creates the UI elements for selecting a class and probability value. It also allows users to select data points by their identifier (e.g., text).</p> <p>Parameters:</p> <ul> <li> <code>selection_info</code>             (<code>SelectionInfo</code>)         \u2013          <p>Information about the classes, min/max probability values and identifiers in the dataset</p> </li> <li> <code>component_key</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>Key to uniquely identify and update the component</p> </li> <li> <code>class_label</code>             (<code>str</code>, default:                 <code>'Class'</code> )         \u2013          <p>Label of the select box</p> </li> <li> <code>prob_label</code>             (<code>str</code>, default:                 <code>'Probability'</code> )         \u2013          <p>Label for the probability slider</p> </li> <li> <code>data_identifier_options</code>             (<code>Optional[List[str]]</code>, default:                 <code>None</code> )         \u2013          <p>List of data identifiers</p> </li> <li> <code>data_identifier_label</code>             (<code>str</code>, default:                 <code>'Data identifier'</code> )         \u2013          <p>Label of the data identifier input</p> </li> <li> <code>data_identifier_hint</code>             (<code>Optional[str]</code>, default:                 <code>None</code> )         \u2013          <p>Hint provided to the user for selection of 'data_identifier_options'</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Selection</code>         \u2013          <p>Selection object with user selection</p> </li> </ul> Source code in <code>niceml/utilities/userselection.py</code> <pre><code>def get_user_selection(\n    selection_info: SelectionInfo,\n    component_key: Optional[str] = None,\n    class_label: str = \"Class\",\n    prob_label: str = \"Probability\",\n    data_identifier_options: Optional[List[str]] = None,\n    data_identifier_label: str = \"Data identifier\",\n    data_identifier_hint: Optional[str] = None,\n) -&gt; Selection:\n    \"\"\"\n    Returns the users dashboard selection for specific values from a SelectionInfo.\n    It creates the UI elements for selecting a class and probability value. It also\n    allows users to select data points by their identifier (e.g., text).\n\n    Args:\n        selection_info: Information about the classes, min/max probability values and\n            identifiers in the dataset\n        component_key: Key to uniquely identify and update the component\n        class_label: Label of the select box\n        prob_label: Label for the probability slider\n        data_identifier_options: List of data identifiers\n        data_identifier_label: Label of the data identifier input\n        data_identifier_hint: Hint provided to the user for selection of 'data_identifier_options'\n\n    Returns:\n        Selection object with user selection\n    \"\"\"\n    container = st.container()\n    sel_identifiers: Optional[List[str]] = None\n    if data_identifier_options is not None and len(data_identifier_options) &gt; 0:\n        col_1, col_2, col_3 = container.columns(spec=3)\n        sel_identifiers = col_3.multiselect(\n            label=data_identifier_label,\n            help=data_identifier_hint or \"ID to select a specific data point\",\n            key=f\"{component_key}_text_input\",\n            options=data_identifier_options or [],\n        )\n        sel_class = col_1.selectbox(\n            label=class_label,\n            options=selection_info.class_set,\n            key=f\"{component_key}_select_box\",\n        )\n        col_2.markdown(\n            \"&lt;div style='display: flex;align-items: center; justify-content:center; \"\n            \"height:72px; width:100%;'&gt;or&lt;/div&gt;\",\n            unsafe_allow_html=True,\n        )\n    else:\n        sel_class = container.selectbox(\n            class_label,\n            selection_info.class_set,\n            key=f\"{component_key}_select_box\",\n        )\n\n    prob_val = st.slider(\n        prob_label,\n        selection_info.min_prob_value,\n        selection_info.max_prob_value,\n        selection_info.min_prob_value,\n        key=f\"{component_key}_slider\",\n    )\n    return Selection(\n        class_name=sel_class, prob_value=prob_val, identifiers=sel_identifiers or []\n    )\n</code></pre>"},{"location":"reference/utilities/boundingboxes/__init__/","title":"boundingboxes","text":""},{"location":"reference/utilities/boundingboxes/__init__/#niceml.utilities.boundingboxes","title":"boundingboxes","text":""},{"location":"reference/utilities/boundingboxes/bboxconversion/","title":"bboxconversion","text":""},{"location":"reference/utilities/boundingboxes/bboxconversion/#niceml.utilities.boundingboxes.bboxconversion","title":"bboxconversion","text":"<p>Module for bounding box conversion functions</p>"},{"location":"reference/utilities/boundingboxes/bboxconversion/#niceml.utilities.boundingboxes.bboxconversion-classes","title":"Classes","text":""},{"location":"reference/utilities/boundingboxes/bboxconversion/#niceml.utilities.boundingboxes.bboxconversion-functions","title":"Functions","text":""},{"location":"reference/utilities/boundingboxes/bboxconversion/#niceml.utilities.boundingboxes.bboxconversion.bbox_list_to_ullr_array","title":"bbox_list_to_ullr_array","text":"<pre><code>bbox_list_to_ullr_array(bbox_list)\n</code></pre> <p>Converts a list of bounding boxes to a numpy array with (left, top, right, bottom)</p> Source code in <code>niceml/utilities/boundingboxes/bboxconversion.py</code> <pre><code>def bbox_list_to_ullr_array(bbox_list: List[BoundingBox]) -&gt; np.ndarray:\n    \"\"\"Converts a list of bounding boxes to a numpy array with (left, top, right, bottom)\"\"\"\n    ullr_list = [bbox.get_absolute_ullr() for bbox in bbox_list]\n    return np.array(ullr_list)\n</code></pre>"},{"location":"reference/utilities/boundingboxes/bboxconversion/#niceml.utilities.boundingboxes.bboxconversion.bounding_box_from_absolute_cxcywh","title":"bounding_box_from_absolute_cxcywh","text":"<pre><code>bounding_box_from_absolute_cxcywh(\n    cx_pixel, cy_pixel, width_pixel, height_pixel\n)\n</code></pre> <p>Returns a bounding box from absolute center coordinates [x,y,width,height] in pixels</p> Source code in <code>niceml/utilities/boundingboxes/bboxconversion.py</code> <pre><code>def bounding_box_from_absolute_cxcywh(\n    cx_pixel: float,\n    cy_pixel: float,\n    width_pixel: float,\n    height_pixel: float,\n) -&gt; BoundingBox:\n    \"\"\"Returns a bounding box from absolute center coordinates [x,y,width,height] in pixels\"\"\"\n    left = cx_pixel - width_pixel / 2\n    top = cy_pixel - height_pixel / 2\n    return BoundingBox(left, top, width_pixel, height_pixel)\n</code></pre>"},{"location":"reference/utilities/boundingboxes/bboxconversion/#niceml.utilities.boundingboxes.bboxconversion.compute_target_gt_array","title":"compute_target_gt_array","text":"<pre><code>compute_target_gt_array(\n    anchor_boxes,\n    gt_boxes,\n    iou_matrix,\n    box_variances,\n    class_index_array,\n    num_classes,\n    match_iou=0.5,\n    ignore_iou=0.4,\n)\n</code></pre> <p>Computes the np.array which is used as a target for the net training</p> <p>Parameters:</p> <ul> <li> <code>anchor_boxes</code>             (<code>ndarray</code>)         \u2013          <p>n x 4 array with anchors in ullr format</p> </li> <li> <code>gt_boxes</code>             (<code>ndarray</code>)         \u2013          <p>m x 4 array with gt boxes in ullr format</p> </li> <li> <code>iou_matrix</code>             (<code>ndarray</code>)         \u2013          <p>n x m matrix with corresponding iou values</p> </li> <li> <code>box_variances</code>             (<code>ndarray</code>)         \u2013          <p>array with 4 values for scaling</p> </li> <li> <code>class_index_array</code>             (<code>ndarray</code>)         \u2013          <p>array with length m with gt class indices</p> </li> <li> <code>num_classes</code>             (<code>int</code>)         \u2013          <p>number of classes as int</p> </li> <li> <code>match_iou</code>             (<code>float</code>, default:                 <code>0.5</code> )         \u2013          <p>float value between zero and one to define when two bounding boxes are matching</p> </li> <li> <code>ignore_iou</code>             (<code>float</code>, default:                 <code>0.4</code> )         \u2013          <p>bounding boxes with an iou between ignore_iou and match_iou are ignored</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>         \u2013          <p>Returns a vector with length 4 + 1 + num_classes.</p> </li> <li> <code>ndarray</code>         \u2013          <p>The first four digits are the encoded bounding box coordinates,</p> </li> <li> <code>ndarray</code>         \u2013          <p>then comes the mask value (POSITIVE,NEGATIVE,IGNORE) and finally</p> </li> <li> <code>ndarray</code>         \u2013          <p>a target class list representing the corresponding class label of the bounding box.</p> </li> </ul> Source code in <code>niceml/utilities/boundingboxes/bboxconversion.py</code> <pre><code>def compute_target_gt_array(  # pylint: disable=too-many-arguments,too-many-locals\n    anchor_boxes: np.ndarray,\n    gt_boxes: np.ndarray,\n    iou_matrix: np.ndarray,\n    box_variances: np.ndarray,\n    class_index_array: np.ndarray,\n    num_classes: int,\n    match_iou: float = 0.5,\n    ignore_iou: float = 0.4,\n) -&gt; np.ndarray:\n    \"\"\"\n    Computes the np.array which is used as a target for the net training\n\n    Args:\n        anchor_boxes: n x 4 array with anchors in ullr format\n        gt_boxes: m x 4 array with gt boxes in ullr format\n        iou_matrix: n x m matrix with corresponding iou values\n        box_variances: array with 4 values for scaling\n        class_index_array: array with length m with gt class indices\n        num_classes: number of classes as int\n        match_iou: float value between zero and one to define when\n            two bounding boxes are matching\n        ignore_iou: bounding boxes with an iou between ignore_iou and match_iou are ignored\n\n    Returns:\n        Returns a vector with length 4 + 1 + num_classes.\n        The first four digits are the encoded bounding box coordinates,\n        then comes the mask value (POSITIVE,NEGATIVE,IGNORE) and finally\n        a target class list representing the corresponding class label of the bounding box.\n\n    \"\"\"\n    anchor_gt_indexes = np.argmax(iou_matrix, axis=1)\n    iou_maxes = np.max(iou_matrix, axis=1)\n\n    mask_array = np.zeros((anchor_boxes.shape[0],))\n    positive_targets = iou_maxes &gt;= match_iou\n    negative_targets = iou_maxes &lt;= ignore_iou\n\n    ignore_targets = np.logical_not(np.logical_or(positive_targets, negative_targets))\n    mask_array[positive_targets] = POSITIVE_MASK_VALUE\n    mask_array[negative_targets] = NEGATIVE_MASK_VALUE\n    mask_array[ignore_targets] = IGNORE_MASK_VALUE\n\n    target_class_array = class_index_array[anchor_gt_indexes]\n    # to one hot encoding\n    target_class_array = np.eye(num_classes)[target_class_array, :]\n    target_class_array[negative_targets, :] = 0.0\n    target_class_array[ignore_targets, :] = 0.0\n\n    anchor_boxes_xywh = convert_to_xywh(anchor_boxes)\n    gt_boxes_xywh = convert_to_xywh(gt_boxes)\n    anchor_gt_targets = gt_boxes_xywh[anchor_gt_indexes, :]\n    encoded_boxes = encode_boxes(anchor_boxes_xywh, anchor_gt_targets, box_variances)\n    return np.concatenate(\n        (encoded_boxes, mask_array[:, np.newaxis], target_class_array), axis=1\n    )\n</code></pre>"},{"location":"reference/utilities/boundingboxes/bboxconversion/#niceml.utilities.boundingboxes.bboxconversion.convert_to_ullr","title":"convert_to_ullr","text":"<pre><code>convert_to_ullr(boxes)\n</code></pre> <p>Changes the box format from [x, y, width, height] to corner coordinates [xmin, ymin, xmax, ymax]</p> <p>Parameters:</p> <ul> <li> <code>boxes</code>             (<code>ndarray</code>)         \u2013          <p>A tensor of rank 2 or higher with a shape of <code>( num_boxes, 4)</code> representing bounding boxes where each box is of the format <code>[x, y, width, height]</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li>         \u2013          <p>converted boxes with shape same as that of boxes.</p> </li> </ul> Source code in <code>niceml/utilities/boundingboxes/bboxconversion.py</code> <pre><code>def convert_to_ullr(boxes: np.ndarray):\n    \"\"\"Changes the box format from [x, y, width, height] to corner coordinates [xmin, ymin, xmax, ymax]\n\n    Args:\n        boxes: A tensor of rank 2 or higher with a shape of `( num_boxes, 4)`\n            representing bounding boxes where each box is of the format\n            `[x, y, width, height]`.\n\n    Returns:\n        converted boxes with shape same as that of boxes.\n    \"\"\"\n    return np.concatenate(\n        [boxes[:, :2], boxes[:, :2] + boxes[:, 2:4], boxes[:, 4:]], axis=1\n    )\n</code></pre>"},{"location":"reference/utilities/boundingboxes/bboxconversion/#niceml.utilities.boundingboxes.bboxconversion.convert_to_xywh","title":"convert_to_xywh","text":"<pre><code>convert_to_xywh(boxes)\n</code></pre> <p>Changes the box format from the format [left, top, right, bottom] to [upper left x, upper left y, width and height].</p> <p>Parameters:</p> <ul> <li> <code>boxes</code>             (<code>ndarray</code>)         \u2013          <p>A tensor of rank 2 or higher with a shape of <code>(num_boxes, 4)</code> representing bounding boxes where each box is of the format <code>[left, top, right, bottom]</code>.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>         \u2013          <p>Converted bounding boxes with shape same as that of boxes.</p> </li> </ul> Source code in <code>niceml/utilities/boundingboxes/bboxconversion.py</code> <pre><code>def convert_to_xywh(boxes: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Changes the box format from the format [left, top, right, bottom] to [upper left x,\n    upper left y, width and height].\n\n    Args:\n        boxes: A tensor of rank 2 or higher with a shape of `(num_boxes, 4)` representing\n            bounding boxes where each box is of the format `[left, top, right, bottom]`.\n\n    Returns:\n        Converted bounding boxes with shape same as that of boxes.\n    \"\"\"\n    xys = boxes[:, :2]\n    widths = boxes[:, 2] - boxes[:, 0]\n    heights = boxes[:, 3] - boxes[:, 1]\n\n    return np.concatenate(\n        [xys, widths[:, np.newaxis], heights[:, np.newaxis], boxes[:, 4:]], axis=1\n    )\n</code></pre>"},{"location":"reference/utilities/boundingboxes/bboxconversion/#niceml.utilities.boundingboxes.bboxconversion.dict_to_bounding_box","title":"dict_to_bounding_box","text":"<pre><code>dict_to_bounding_box(data)\n</code></pre> <p>Creates an BoundingBox from a dict</p> Source code in <code>niceml/utilities/boundingboxes/bboxconversion.py</code> <pre><code>def dict_to_bounding_box(data) -&gt; Union[BoundingBox, None]:\n    \"\"\"Creates an BoundingBox from a dict\"\"\"\n    if data is None:\n        return None\n    return data if isinstance(data, BoundingBox) else BoundingBox(**data)\n</code></pre>"},{"location":"reference/utilities/boundingboxes/bboxconversion/#niceml.utilities.boundingboxes.bboxconversion.shift_bbox_by_percentage","title":"shift_bbox_by_percentage","text":"<pre><code>shift_bbox_by_percentage(\n    bbox_coords, percentage, axis, direction\n)\n</code></pre> <p>Shifts a bounding box to a direction by a given percentage of the bounding box Args:     bbox_coords: Bounding box coordinates to be shifted     percentage: Percentage of the bounding box to shift by     axis: Perform shift on y-axis [0], on x-axis [1] or on both [0,1]     direction: Shift direction;</p> <pre><code>    UP if direction == 0 and axis == 0;\n    DOWN if direction == 1 and axis == 0;\n    LEFT if direction == 0 and axis == 1;\n    RIGHT if direction == 1 and axis == 1;\n\n    If axis is a list (0,1) the direction has to be a list too.\n    In this case the first position of the direction list is on x\n    and the second position is the shift at y.\n</code></pre> <p>Returns:</p> <ul> <li>         \u2013          <p>Shifted bounding box</p> </li> </ul> Source code in <code>niceml/utilities/boundingboxes/bboxconversion.py</code> <pre><code>def shift_bbox_by_percentage(\n    bbox_coords: Tuple[float, float, float, float],\n    percentage: float,\n    axis: Union[List[int], int],\n    direction: Union[List[int], int],\n):\n    \"\"\"\n    Shifts a bounding box to a direction by a given percentage of the bounding box\n    Args:\n        bbox_coords: Bounding box coordinates to be shifted\n        percentage: Percentage of the bounding box to shift by\n        axis: Perform shift on y-axis [0], on x-axis [1] or on both [0,1]\n        direction: Shift direction;\n\n            UP if direction == 0 and axis == 0;\n            DOWN if direction == 1 and axis == 0;\n            LEFT if direction == 0 and axis == 1;\n            RIGHT if direction == 1 and axis == 1;\n\n            If axis is a list (0,1) the direction has to be a list too.\n            In this case the first position of the direction list is on x\n            and the second position is the shift at y.\n\n    Returns:\n        Shifted bounding box\n    \"\"\"\n    shifted_bbox = BoundingBox(*bbox_coords)\n    if isinstance(axis, int):\n        if isinstance(direction, list):\n            raise ValueError(\n                f\"If only a single axis is passed ({axis}), the direction has to be an int too.\"\n            )\n        if axis == 0:\n            shifted_bbox = shift_y_axis(\n                bbox=shifted_bbox, direction=direction, percentage=percentage\n            )\n        else:\n            shifted_bbox = shift_x_axis(\n                bbox=shifted_bbox, direction=direction, percentage=percentage\n            )\n    else:\n        shifted_bbox = shift_y_axis(\n            bbox=shifted_bbox, direction=direction[0], percentage=percentage\n        )\n        shifted_bbox = shift_x_axis(\n            bbox=shifted_bbox, direction=direction[1], percentage=percentage\n        )\n    return shifted_bbox\n</code></pre>"},{"location":"reference/utilities/boundingboxes/bboxconversion/#niceml.utilities.boundingboxes.bboxconversion.shift_x_axis","title":"shift_x_axis","text":"<pre><code>shift_x_axis(bbox, direction, percentage)\n</code></pre> <p>Shifts a bounding box on x-axis in a specified direction by percentage of that bounding box.</p> <p>Parameters:</p> <ul> <li> <code>bbox</code>             (<code>BoundingBox</code>)         \u2013          <p>bounding box to be shifted</p> </li> <li> <code>direction</code>             (<code>int</code>)         \u2013          <p>the direction of the shift (0 = up, 1 = down)</p> </li> <li> <code>percentage</code>             (<code>float</code>)         \u2013          <p>Percentage of the bounding box to shift by</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>BoundingBox</code>         \u2013          <p>Shifted bounding box</p> </li> </ul> Source code in <code>niceml/utilities/boundingboxes/bboxconversion.py</code> <pre><code>def shift_x_axis(bbox: BoundingBox, direction: int, percentage: float) -&gt; BoundingBox:\n    \"\"\"\n    Shifts a bounding box on x-axis in a specified direction by percentage of that bounding box.\n\n    Args:\n        bbox: bounding box to be shifted\n        direction: the direction of the shift (0 = up, 1 = down)\n        percentage: Percentage of the bounding box to shift by\n\n    Returns:\n        Shifted bounding box\n    \"\"\"\n\n    if direction == 0:\n        bbox.x_pos = int(bbox.x_pos * (1 - percentage))\n    else:\n        bbox.x_pos = int(bbox.x_pos * (1 + percentage))\n    return bbox\n</code></pre>"},{"location":"reference/utilities/boundingboxes/bboxconversion/#niceml.utilities.boundingboxes.bboxconversion.shift_y_axis","title":"shift_y_axis","text":"<pre><code>shift_y_axis(bbox, direction, percentage)\n</code></pre> <p>Shifts a bounding box on the y-axis in a specified direction by percentage of that bounding box.</p> <p>Parameters:</p> <ul> <li> <code>bbox</code>             (<code>BoundingBox</code>)         \u2013          <p>bounding box to be shifted</p> </li> <li> <code>direction</code>             (<code>int</code>)         \u2013          <p>the direction of the shift (0 = left, 1 = right)</p> </li> <li> <code>percentage</code>             (<code>float</code>)         \u2013          <p>Percentage of the bounding box to shift by</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>BoundingBox</code>         \u2013          <p>Shifted bounding box</p> </li> </ul> Source code in <code>niceml/utilities/boundingboxes/bboxconversion.py</code> <pre><code>def shift_y_axis(bbox: BoundingBox, direction: int, percentage: float) -&gt; BoundingBox:\n    \"\"\"\n    Shifts a bounding box on the y-axis in a specified direction by percentage of that bounding box.\n\n    Args:\n        bbox: bounding box to be shifted\n        direction: the direction of the shift (0 = left, 1 = right)\n        percentage: Percentage of the bounding box to shift by\n\n    Returns:\n        Shifted bounding box\n    \"\"\"\n\n    if direction == 0:\n        bbox.y_pos = int(bbox.y_pos * (1 - percentage))\n    else:\n        bbox.y_pos = int(bbox.y_pos * (1 + percentage))\n\n    return bbox\n</code></pre>"},{"location":"reference/utilities/boundingboxes/bboxconversion/#niceml.utilities.boundingboxes.bboxconversion.to_relative_bbox_values","title":"to_relative_bbox_values","text":"<pre><code>to_relative_bbox_values(values, img_size)\n</code></pre> <p>Converts absolute image coordinates to relative image coordinates based on image size</p> Source code in <code>niceml/utilities/boundingboxes/bboxconversion.py</code> <pre><code>def to_relative_bbox_values(\n    values: Tuple[int, int, int, int], img_size: ImageSize\n) -&gt; Tuple[float, float, float, float]:\n    \"\"\"Converts absolute image coordinates to relative image coordinates based on image size\"\"\"\n    img_size_list = [img_size.width, img_size.height]\n\n    # noinspection PyTypeChecker\n    return tuple(\n        float(value / img_size_list[idx % 2])\n        for value, idx in zip(\n            values,\n            range(4),\n        )\n    )\n</code></pre>"},{"location":"reference/utilities/boundingboxes/bboxdrawing/","title":"bboxdrawing","text":""},{"location":"reference/utilities/boundingboxes/bboxdrawing/#niceml.utilities.boundingboxes.bboxdrawing","title":"bboxdrawing","text":"<p>Module for BoundingBoxes / ObjDetInstanceLabels draw functions</p>"},{"location":"reference/utilities/boundingboxes/bboxdrawing/#niceml.utilities.boundingboxes.bboxdrawing-classes","title":"Classes","text":""},{"location":"reference/utilities/boundingboxes/bboxdrawing/#niceml.utilities.boundingboxes.bboxdrawing-functions","title":"Functions","text":""},{"location":"reference/utilities/boundingboxes/bboxdrawing/#niceml.utilities.boundingboxes.bboxdrawing.draw_bounding_box_on_image","title":"draw_bounding_box_on_image","text":"<pre><code>draw_bounding_box_on_image(\n    label, image, font_color=Color.BLACK\n)\n</code></pre> <p>Draws a bounding box on an image</p> <p>Parameters:</p> <ul> <li> <code>label</code>             (<code>ObjDetInstanceLabel</code>)         \u2013          <p>ObjDetInstanceLabel (bounding box) to draw on the 'image'</p> </li> <li> <code>image</code>             (<code>Image</code>)         \u2013          <p>image to draw the bounding boxes on</p> </li> <li> <code>font_color</code>         \u2013          <p>font color of the bounding box</p> </li> </ul> <p>Returns:</p> <ul> <li>         \u2013          <p>image with the bounding box</p> </li> </ul> Source code in <code>niceml/utilities/boundingboxes/bboxdrawing.py</code> <pre><code>def draw_bounding_box_on_image(\n    label: ObjDetInstanceLabel,\n    image: ImageType,\n    font_color=Color.BLACK,\n):\n    \"\"\"\n    Draws a bounding box on an image\n\n    Args:\n        label: ObjDetInstanceLabel (bounding box) to draw on the 'image'\n        image: image to draw the bounding boxes on\n        font_color: font color of the bounding box\n\n    Returns:\n        image with the bounding box\n    \"\"\"\n\n    if label.color == Color.BLUE:\n        font_color = Color.WHITE\n\n    draw = ImageDraw.Draw(image)\n\n    line_width = int(\n        (image.width if image.width &gt;= image.height else image.height) * 0.003\n    )\n    font_size = int(\n        (image.width if image.width &gt;= image.height else image.height) * 0.015\n    )\n\n    font = get_font(\"OpenSans-Regular.ttf\", font_size=font_size)\n\n    text = f\"{label.class_name}: {label.score:.2f}\" if label.score else label.class_name\n    (left, top, right, bottom) = font.getbbox(text)\n    text_width = right - left\n    text_height = bottom - top\n    x_1, y_1, x_2, y_2 = label.bounding_box.get_absolute_ullr()\n    draw.rectangle(\n        (x_1 - line_width, y_1 - line_width, x_2 + line_width, y_2 + line_width),\n        outline=label.color,\n        width=line_width,\n    )\n    draw.rectangle(\n        (\n            x_1 - line_width,\n            y_1 - (font_size + line_width),\n            x_1 + text_width + line_width,\n            y_1 - (font_size + line_width) + text_height,\n        ),\n        fill=label.color,\n    )\n\n    draw.text(\n        (x_1 - line_width, y_1 - (font_size + line_width)),\n        text=text,\n        fill=font_color,\n        font=font,\n    )\n\n    return image\n</code></pre>"},{"location":"reference/utilities/boundingboxes/bboxdrawing/#niceml.utilities.boundingboxes.bboxdrawing.draw_labels_on_image","title":"draw_labels_on_image","text":"<pre><code>draw_labels_on_image(\n    image,\n    pred_bbox_label_list,\n    gt_bbox_label_list,\n    hide_gt=False,\n    hide_gt_over_thresh=False,\n    iou_threshold=0.5,\n)\n</code></pre> <p>Draws multiple bounding boxes of ObjDetInstanceLabels on an image</p> <p>Parameters:</p> <ul> <li> <code>image</code>             (<code>Image</code>)         \u2013          <p>image to draw the bounding boxes on</p> </li> <li> <code>pred_bbox_label_list</code>             (<code>List[ObjDetInstanceLabel]</code>)         \u2013          <p>prediction bounding box label information list</p> </li> <li> <code>gt_bbox_label_list</code>             (<code>List[ObjDetInstanceLabel]</code>)         \u2013          <p>ground truth bounding box label information list</p> </li> <li> <code>hide_gt</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>flag to hide the gt labels</p> </li> <li> <code>hide_gt_over_thresh</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>flag to hide the gt labels for the predicted bounding boxes with an iou &gt;= iou_threshold</p> </li> <li> <code>iou_threshold</code>             (<code>float</code>, default:                 <code>0.5</code> )         \u2013          <p>iou threshold for label matching</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Image</code>         \u2013          <p>image with predicted and ground truth bounding boxes</p> </li> </ul> Source code in <code>niceml/utilities/boundingboxes/bboxdrawing.py</code> <pre><code>def draw_labels_on_image(  # noqa: PLR0913\n    image: ImageType,\n    pred_bbox_label_list: List[ObjDetInstanceLabel],\n    gt_bbox_label_list: List[ObjDetInstanceLabel],\n    hide_gt: bool = False,\n    hide_gt_over_thresh: bool = False,\n    iou_threshold: float = 0.5,\n) -&gt; ImageType:\n    \"\"\"\n    Draws multiple bounding boxes of ObjDetInstanceLabels on an image\n\n    Args:\n        image: image to draw the bounding boxes on\n        pred_bbox_label_list: prediction bounding box label information list\n        gt_bbox_label_list: ground truth bounding box label information list\n        hide_gt: flag to hide the gt labels\n        hide_gt_over_thresh: flag to hide the gt labels for the\n            predicted bounding boxes with an iou &gt;= iou_threshold\n        iou_threshold: iou threshold for label matching\n\n    Returns:\n        image with predicted and ground truth bounding boxes\n    \"\"\"\n    pred_bbox_visu_label_list: List[ObjDetInstanceLabel]\n    gt_bbox_visu_label_list: List[ObjDetInstanceLabel]\n    pred_bbox_visu_label_list, gt_bbox_visu_label_list = get_kind_of_label_match(\n        pred_label_list=pred_bbox_label_list,\n        gt_label_list=gt_bbox_label_list,\n        hide_gt_over_thresh=hide_gt_over_thresh,\n        iou_threshold=iou_threshold,\n    )\n\n    for pred_label in pred_bbox_visu_label_list:\n        if pred_label.active:\n            image = draw_bounding_box_on_image(image=image, label=pred_label)\n\n    if not hide_gt:\n        for gt_label in gt_bbox_visu_label_list:\n            if gt_label.active:\n                image = draw_bounding_box_on_image(image=image, label=gt_label)\n    return image\n</code></pre>"},{"location":"reference/utilities/boundingboxes/bboxencoding/","title":"bboxencoding","text":""},{"location":"reference/utilities/boundingboxes/bboxencoding/#niceml.utilities.boundingboxes.bboxencoding","title":"bboxencoding","text":"<p>Module for functions regarding bounding box encoding</p>"},{"location":"reference/utilities/boundingboxes/bboxencoding/#niceml.utilities.boundingboxes.bboxencoding-functions","title":"Functions","text":""},{"location":"reference/utilities/boundingboxes/bboxencoding/#niceml.utilities.boundingboxes.bboxencoding.decode_boxes","title":"decode_boxes","text":"<pre><code>decode_boxes(\n    anchor_boxes_xywh, encoded_array_xywh, box_variances\n)\n</code></pre> <p>Decodes the incoming array to target boxes</p> <p>Parameters:</p> <ul> <li> <code>anchor_boxes_xywh</code>             (<code>ndarray</code>)         \u2013          <p>Anchor boxes in x,y,width,height format</p> </li> <li> <code>encoded_array_xywh</code>             (<code>ndarray</code>)         \u2013          <p>Encoded boxes in x,y,width,height format</p> </li> <li> <code>box_variances</code>             (<code>ndarray</code>)         \u2013          <p>Box variance to scale by</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>         \u2013          <p>The decoded boxes x,y,width,height format</p> </li> </ul> Source code in <code>niceml/utilities/boundingboxes/bboxencoding.py</code> <pre><code>def decode_boxes(\n    anchor_boxes_xywh: np.ndarray,\n    encoded_array_xywh: np.ndarray,\n    box_variances: np.ndarray,\n) -&gt; np.ndarray:\n    \"\"\"\n    Decodes the incoming array to target boxes\n\n    Args:\n        anchor_boxes_xywh: Anchor boxes in x,y,width,height format\n        encoded_array_xywh: Encoded boxes in x,y,width,height format\n        box_variances: Box variance to scale by\n\n    Returns:\n        The decoded boxes x,y,width,height format\n    \"\"\"\n    x_pos = (\n        encoded_array_xywh[:, 0] * box_variances[0] * anchor_boxes_xywh[:, 2]\n    ) + anchor_boxes_xywh[:, 0]\n    y_pos = (\n        encoded_array_xywh[:, 1] * box_variances[1] * anchor_boxes_xywh[:, 3]\n    ) + anchor_boxes_xywh[:, 1]\n    width = (\n        np.exp(encoded_array_xywh[:, 2] * box_variances[2]) * anchor_boxes_xywh[:, 2]\n    )\n    height = (\n        np.exp(encoded_array_xywh[:, 3] * box_variances[3]) * anchor_boxes_xywh[:, 3]\n    )\n\n    return np.concatenate(\n        (\n            x_pos[:, np.newaxis],\n            y_pos[:, np.newaxis],\n            width[:, np.newaxis],\n            height[:, np.newaxis],\n        ),\n        axis=1,\n    )\n</code></pre>"},{"location":"reference/utilities/boundingboxes/bboxencoding/#niceml.utilities.boundingboxes.bboxencoding.encode_boxes","title":"encode_boxes","text":"<pre><code>encode_boxes(\n    anchor_boxes_xywh, gt_boxes_xywh, box_variances\n)\n</code></pre> <p>Encodes the anchor boxes to a numpy array</p> <p>Parameters:</p> <ul> <li> <code>anchor_boxes_xywh</code>             (<code>ndarray</code>)         \u2013          <p>Anchor boxes in x,y,width,height format</p> </li> <li> <code>gt_boxes_xywh</code>             (<code>ndarray</code>)         \u2013          <p>Ground truth boxes in x,y,width,height format</p> </li> <li> <code>box_variances</code>             (<code>ndarray</code>)         \u2013          <p>Box variance to scale by</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>         \u2013          <p>A scaled and encoded box as a numpy array of shape (num_anchors, 4)</p> </li> </ul> Source code in <code>niceml/utilities/boundingboxes/bboxencoding.py</code> <pre><code>def encode_boxes(\n    anchor_boxes_xywh: np.ndarray, gt_boxes_xywh: np.ndarray, box_variances: np.ndarray\n) -&gt; np.ndarray:\n    \"\"\"\n    Encodes the anchor boxes to a numpy array\n\n    Args:\n        anchor_boxes_xywh: Anchor boxes in x,y,width,height format\n        gt_boxes_xywh: Ground truth boxes in x,y,width,height format\n        box_variances: Box variance to scale by\n\n    Returns:\n        A scaled and encoded box as a numpy array of shape (num_anchors, 4)\n    \"\"\"\n    enc0 = (gt_boxes_xywh[:, 0] - anchor_boxes_xywh[:, 0]) / anchor_boxes_xywh[:, 2]\n    enc1 = (gt_boxes_xywh[:, 1] - anchor_boxes_xywh[:, 1]) / anchor_boxes_xywh[:, 3]\n    enc2 = np.where(\n        gt_boxes_xywh[:, 2] / anchor_boxes_xywh[:, 2] &gt; 0,\n        np.log(gt_boxes_xywh[:, 2] / anchor_boxes_xywh[:, 2]),\n        0,\n    )\n    enc3 = np.where(\n        gt_boxes_xywh[:, 3] / anchor_boxes_xywh[:, 3] &gt; 0,\n        np.log(gt_boxes_xywh[:, 3] / anchor_boxes_xywh[:, 3]),\n        0,\n    )\n    encoded_array = np.concatenate(\n        (\n            enc0[:, np.newaxis],\n            enc1[:, np.newaxis],\n            enc2[:, np.newaxis],\n            enc3[:, np.newaxis],\n        ),\n        axis=1,\n    )\n    encoded_array = encoded_array / box_variances\n\n    return encoded_array\n</code></pre>"},{"location":"reference/utilities/boundingboxes/bboxlabeling/","title":"bboxlabeling","text":""},{"location":"reference/utilities/boundingboxes/bboxlabeling/#niceml.utilities.boundingboxes.bboxlabeling","title":"bboxlabeling","text":"<p>Module for ObjDetInstanceLabel</p>"},{"location":"reference/utilities/boundingboxes/bboxlabeling/#niceml.utilities.boundingboxes.bboxlabeling-classes","title":"Classes","text":""},{"location":"reference/utilities/boundingboxes/bboxlabeling/#niceml.utilities.boundingboxes.bboxlabeling.ObjDetImageLabel","title":"ObjDetImageLabel","text":"<p>Labels of all ObjDetInstanceLabels on an image file</p>"},{"location":"reference/utilities/boundingboxes/bboxlabeling/#niceml.utilities.boundingboxes.bboxlabeling.ObjDetInstanceLabel","title":"ObjDetInstanceLabel","text":"<p>             Bases: <code>InstanceLabel</code></p> <p>Label information for one specific bounding box and its prediction score</p>"},{"location":"reference/utilities/boundingboxes/bboxlabeling/#niceml.utilities.boundingboxes.bboxlabeling.ObjDetInstanceLabel-functions","title":"Functions","text":""},{"location":"reference/utilities/boundingboxes/bboxlabeling/#niceml.utilities.boundingboxes.bboxlabeling.ObjDetInstanceLabel.calc_iou","title":"calc_iou","text":"<pre><code>calc_iou(other)\n</code></pre> <p>Calculates the IOU of two given <code>ObjDetInstanceLabel</code>s bounding boxes</p> <p>Parameters:</p> <ul> <li> <code>other</code>             (<code>ObjDetInstanceLabel</code>)         \u2013          <p>ObjDetInstanceLabel to calculate the IOU for</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>         \u2013          <p>Calculated IOU</p> </li> </ul> Source code in <code>niceml/utilities/boundingboxes/bboxlabeling.py</code> <pre><code>def calc_iou(self, other: \"ObjDetInstanceLabel\") -&gt; float:\n    \"\"\"\n    Calculates the IOU of two given `ObjDetInstanceLabel`s bounding boxes\n\n    Args:\n        other: ObjDetInstanceLabel to calculate the IOU for\n\n    Returns:\n        Calculated IOU\n    \"\"\"\n    return self.bounding_box.calc_iou(  # pylint: disable=no-member\n        other=other.bounding_box\n    )\n</code></pre>"},{"location":"reference/utilities/boundingboxes/bboxlabeling/#niceml.utilities.boundingboxes.bboxlabeling.ObjDetInstanceLabel.scale_label","title":"scale_label","text":"<pre><code>scale_label(scale_factor)\n</code></pre> <p>Scales an ObjDetInstanceLabel by a given <code>scale_factor</code></p> <p>Parameters:</p> <ul> <li> <code>scale_factor</code>             (<code>float</code>)         \u2013          <p>Factor to scale the ObjDetInstanceLabel by</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ObjDetInstanceLabel</code>         \u2013          <p>Scaled instance of this ObjDetInstanceLabel</p> </li> </ul> Source code in <code>niceml/utilities/boundingboxes/bboxlabeling.py</code> <pre><code>def scale_label(self, scale_factor: float) -&gt; \"ObjDetInstanceLabel\":\n    \"\"\"\n    Scales an ObjDetInstanceLabel by a given `scale_factor`\n\n    Args:\n        scale_factor: Factor to scale the ObjDetInstanceLabel by\n\n    Returns:\n        Scaled instance of this ObjDetInstanceLabel\"\"\"\n    return ObjDetInstanceLabel(\n        class_name=self.class_name,\n        class_index=self.class_index,\n        color=self.color,\n        active=self.active,\n        bounding_box=self.bounding_box.scale(scale_factor),\n        score=self.score,\n        rotation=self.rotation,\n    )\n</code></pre>"},{"location":"reference/utilities/boundingboxes/bboxlabeling/#niceml.utilities.boundingboxes.bboxlabeling.ObjDetInstanceLabel.to_content_list","title":"to_content_list","text":"<pre><code>to_content_list()\n</code></pre> <p>Creates a list with the contents of the ObjDetInstanceLabel in the following order: 1. all bounding boxes (separately), 2. class name, 3. class index, 4. prediction score, 5. rotation</p> Source code in <code>niceml/utilities/boundingboxes/bboxlabeling.py</code> <pre><code>def to_content_list(self) -&gt; list:\n    \"\"\"\n    Creates a list with the contents of the ObjDetInstanceLabel in the following order:\n    1. all bounding boxes (separately),\n    2. class name,\n    3. class index,\n    4. prediction score,\n    5. rotation\n    \"\"\"\n    content_list = list(  # pylint: disable=no-member\n        self.bounding_box.get_absolute_ullr()\n    )\n    content_list += [self.class_name, self.class_index, self.score, self.rotation]\n    return content_list\n</code></pre>"},{"location":"reference/utilities/boundingboxes/bboxlabeling/#niceml.utilities.boundingboxes.bboxlabeling-functions","title":"Functions","text":""},{"location":"reference/utilities/boundingboxes/bboxlabeling/#niceml.utilities.boundingboxes.bboxlabeling.dict_to_objdet_instance_label","title":"dict_to_objdet_instance_label","text":"<pre><code>dict_to_objdet_instance_label(data)\n</code></pre> <p>Converts a list of dicts to a list of ObjDetInstanceLabels</p> Source code in <code>niceml/utilities/boundingboxes/bboxlabeling.py</code> <pre><code>def dict_to_objdet_instance_label(\n    data: List[Union[dict, ObjDetInstanceLabel]]\n) -&gt; List[ObjDetInstanceLabel]:\n    \"\"\"Converts a list of dicts to a list of ObjDetInstanceLabels\"\"\"\n    converted_data: List[ObjDetInstanceLabel] = []\n    for entry in data:\n        if isinstance(entry, dict):\n            converted_data.append(ObjDetInstanceLabel(**entry))\n        else:\n            converted_data.append(entry)\n    return converted_data\n</code></pre>"},{"location":"reference/utilities/boundingboxes/bboxlabeling/#niceml.utilities.boundingboxes.bboxlabeling.obj_instance_factory_from_content_list","title":"obj_instance_factory_from_content_list","text":"<pre><code>obj_instance_factory_from_content_list(content_list)\n</code></pre> <p>Creates an ObjDetInstanceLabel from a list of values. Correct order of 'content_list' required: idx 0-3: ullr coordinates, idx 4: class_name, idx 5: class_idx, idx 6: prediction score, idx 7: rotation</p> Source code in <code>niceml/utilities/boundingboxes/bboxlabeling.py</code> <pre><code>def obj_instance_factory_from_content_list(\n    content_list: list,\n) -&gt; ObjDetInstanceLabel:\n    \"\"\"Creates an ObjDetInstanceLabel from a list of values.\n    Correct order of 'content_list' required:\n    idx 0-3: ullr coordinates,\n    idx 4: class_name,\n    idx 5: class_idx,\n    idx 6: prediction score,\n    idx 7: rotation\"\"\"\n    bbox = bounding_box_from_ullr(*content_list[:4])\n    class_name: str = content_list[4]\n    class_index: Optional[int] = content_list[5]\n    score: Optional[float] = content_list[6]\n    rotation: int = content_list[7]\n    return ObjDetInstanceLabel(\n        class_name=class_name,\n        bounding_box=bbox,\n        class_index=class_index,\n        score=score,\n        rotation=rotation,\n    )\n</code></pre>"},{"location":"reference/utilities/boundingboxes/boundingbox/","title":"boundingbox","text":""},{"location":"reference/utilities/boundingboxes/boundingbox/#niceml.utilities.boundingboxes.boundingbox","title":"boundingbox","text":"<p>Module for BoundingBox and corresponding methods</p>"},{"location":"reference/utilities/boundingboxes/boundingbox/#niceml.utilities.boundingboxes.boundingbox-classes","title":"Classes","text":""},{"location":"reference/utilities/boundingboxes/boundingbox/#niceml.utilities.boundingboxes.boundingbox.BoundingBox","title":"BoundingBox","text":"<p>Class to represent a bounding box and its methods</p>"},{"location":"reference/utilities/boundingboxes/boundingbox/#niceml.utilities.boundingboxes.boundingbox.BoundingBox-functions","title":"Functions","text":""},{"location":"reference/utilities/boundingboxes/boundingbox/#niceml.utilities.boundingboxes.boundingbox.BoundingBox.__eq__","title":"__eq__","text":"<pre><code>__eq__(other)\n</code></pre> <p>Checks if two BoundingBoxes are the (nearly) same</p> Source code in <code>niceml/utilities/boundingboxes/boundingbox.py</code> <pre><code>def __eq__(self, other: \"BoundingBox\"):\n    \"\"\"Checks if two BoundingBoxes are the (nearly) same\"\"\"\n    if isinstance(other, BoundingBox):\n        return (\n            isclose(self.x_pos, other.x_pos)\n            and isclose(self.y_pos, other.y_pos)\n            and isclose(self.width, other.width)\n            and isclose(self.height, other.height)\n        )\n\n    return False\n</code></pre>"},{"location":"reference/utilities/boundingboxes/boundingbox/#niceml.utilities.boundingboxes.boundingbox.BoundingBox.__repr__","title":"__repr__","text":"<pre><code>__repr__()\n</code></pre> <p>Returns BoundingBox parameters as string</p> Source code in <code>niceml/utilities/boundingboxes/boundingbox.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Returns BoundingBox parameters as string\"\"\"\n    return (\n        f\"BBox(x:{self.x_pos:0.2f} y:{self.y_pos:0.2f} \"\n        f\"w:{self.width:0.2f} h:{self.height:0.2f})\"\n    )\n</code></pre>"},{"location":"reference/utilities/boundingboxes/boundingbox/#niceml.utilities.boundingboxes.boundingbox.BoundingBox.calc_iou","title":"calc_iou","text":"<pre><code>calc_iou(other)\n</code></pre> <p>Calculates the iou between the two bounding boxes</p> Source code in <code>niceml/utilities/boundingboxes/boundingbox.py</code> <pre><code>def calc_iou(self, other: \"BoundingBox\") -&gt; float:\n    \"\"\"Calculates the iou between the two bounding boxes\"\"\"\n    if not isinstance(other, BoundingBox):\n        raise TypeError(f\"other is not type BoundingBox but {type(other)}\")\n\n    try:\n        inter_area: float = self.get_intersection(other).get_absolute_area()\n        # Calculates the Union area by using Formula: Union(A,B) = A + B - Inter(A,B)\n        union_area = (\n            self.get_absolute_area() + other.get_absolute_area() - inter_area\n        )\n        return inter_area / union_area\n    except AttributeError:\n        return 0\n</code></pre>"},{"location":"reference/utilities/boundingboxes/boundingbox/#niceml.utilities.boundingboxes.boundingbox.BoundingBox.decode","title":"decode","text":"<pre><code>decode(predicted_values, box_variance)\n</code></pre> <p>Decodes the predicted net values to a bounding box</p> Source code in <code>niceml/utilities/boundingboxes/boundingbox.py</code> <pre><code>def decode(\n    self,\n    predicted_values: List[float],\n    box_variance: List[float],\n) -&gt; \"BoundingBox\":\n    \"\"\"Decodes the predicted net values to a bounding box\"\"\"\n    x_pos = (predicted_values[0] * box_variance[0] * self.width) + self.x_pos\n    y_pos = (predicted_values[1] * box_variance[1] * self.height) + self.y_pos\n    width = exp(predicted_values[2] * box_variance[2]) * self.width\n    height = exp(predicted_values[3] * box_variance[3]) * self.height\n\n    return BoundingBox(x_pos=x_pos, y_pos=y_pos, width=width, height=height)\n</code></pre>"},{"location":"reference/utilities/boundingboxes/boundingbox/#niceml.utilities.boundingboxes.boundingbox.BoundingBox.do_intersect","title":"do_intersect","text":"<pre><code>do_intersect(other)\n</code></pre> <p>Checks whether two bounding boxes do intersect</p> Source code in <code>niceml/utilities/boundingboxes/boundingbox.py</code> <pre><code>def do_intersect(self, other: \"BoundingBox\") -&gt; bool:\n    \"\"\"Checks whether two bounding boxes do intersect\"\"\"\n    b1_left, b1_top, b1_right, b1_bottom = self.get_absolute_ullr()\n    b2_left, b2_top, b2_right, b2_bottom = other.get_absolute_ullr()\n    return not (\n        b2_left &gt; b1_right\n        or b2_right &lt; b1_left\n        or b2_top &gt; b1_bottom\n        or b2_bottom &lt; b1_top\n    )\n</code></pre>"},{"location":"reference/utilities/boundingboxes/boundingbox/#niceml.utilities.boundingboxes.boundingbox.BoundingBox.encode","title":"encode","text":"<pre><code>encode(gt_bbox, box_variance)\n</code></pre> <p>Encodes the anchor(self) with a ground truth box to net targets</p> Source code in <code>niceml/utilities/boundingboxes/boundingbox.py</code> <pre><code>def encode(\n    self,\n    gt_bbox: \"BoundingBox\",\n    box_variance: List[float],\n) -&gt; List[float]:\n    \"\"\"Encodes the anchor(self) with a ground truth box to net targets\"\"\"\n    # QUEST: better docstring?\n    if not isinstance(gt_bbox, BoundingBox):\n        raise TypeError(f\"other is not type BoundingBox but {type(gt_bbox)}\")\n\n    x_pos = (gt_bbox.x_pos - self.x_pos) / self.width\n    y_pos = (gt_bbox.y_pos - self.y_pos) / self.height\n    width = log(gt_bbox.width / self.width)\n    height = log(gt_bbox.height / self.height)\n    x_pos /= box_variance[0]\n    y_pos /= box_variance[1]\n    width /= box_variance[2]\n    height /= box_variance[3]\n\n    return [x_pos, y_pos, width, height]\n</code></pre>"},{"location":"reference/utilities/boundingboxes/boundingbox/#niceml.utilities.boundingboxes.boundingbox.BoundingBox.get_absolute_area","title":"get_absolute_area","text":"<pre><code>get_absolute_area()\n</code></pre> <p>Returns bounding box area (= width * height)</p> Source code in <code>niceml/utilities/boundingboxes/boundingbox.py</code> <pre><code>def get_absolute_area(self) -&gt; float:\n    \"\"\"Returns bounding box area (= width * height)\"\"\"\n    return self.width * self.height\n</code></pre>"},{"location":"reference/utilities/boundingboxes/boundingbox/#niceml.utilities.boundingboxes.boundingbox.BoundingBox.get_absolute_ullr","title":"get_absolute_ullr","text":"<pre><code>get_absolute_ullr(convert_to_int=False)\n</code></pre> <p>Returns a tuple of upper-left and lower-right coordinates (x_upper_left, y_upper_left, x_lower_right, y_lower_right) as float or int values</p> Source code in <code>niceml/utilities/boundingboxes/boundingbox.py</code> <pre><code>def get_absolute_ullr(\n    self, convert_to_int: bool = False\n) -&gt; Union[Tuple[float, float, float, float], Tuple[int, int, int, int]]:\n    \"\"\"Returns a tuple of upper-left and lower-right coordinates (x_upper_left,\n    y_upper_left, x_lower_right, y_lower_right) as float or int values\"\"\"\n    if convert_to_int:\n        return (\n            int(self.x_pos),\n            int(self.y_pos),\n            int(self.x_pos + self.width),\n            int(self.y_pos + self.height),\n        )\n\n    return (\n        self.x_pos,\n        self.y_pos,\n        self.x_pos + self.width,\n        self.y_pos + self.height,\n    )\n</code></pre>"},{"location":"reference/utilities/boundingboxes/boundingbox/#niceml.utilities.boundingboxes.boundingbox.BoundingBox.get_absolute_xywh","title":"get_absolute_xywh","text":"<pre><code>get_absolute_xywh(convert_to_int=False)\n</code></pre> <p>Returns a tuple in pixel coords: (x, y, w, h) as float or int values</p> Source code in <code>niceml/utilities/boundingboxes/boundingbox.py</code> <pre><code>def get_absolute_xywh(\n    self, convert_to_int: bool = False\n) -&gt; Union[Tuple[float, float, float, float], Tuple[int, int, int, int]]:\n    \"\"\"Returns a tuple in pixel coords: (x, y, w, h) as float or int values\"\"\"\n    if convert_to_int:\n        return int(self.x_pos), int(self.y_pos), int(self.width), int(self.height)\n    return self.x_pos, self.y_pos, self.width, self.height\n</code></pre>"},{"location":"reference/utilities/boundingboxes/boundingbox/#niceml.utilities.boundingboxes.boundingbox.BoundingBox.get_intersection","title":"get_intersection","text":"<pre><code>get_intersection(other)\n</code></pre> <p>Calculates the intersection bounding box</p> Source code in <code>niceml/utilities/boundingboxes/boundingbox.py</code> <pre><code>def get_intersection(self, other: \"BoundingBox\") -&gt; Optional[\"BoundingBox\"]:\n    \"\"\"Calculates the intersection bounding box\"\"\"\n    if not self.do_intersect(other):\n        return None\n    b1_left, b1_top, b1_right, b1_bottom = self.get_absolute_ullr()\n    b2_left, b2_top, b2_right, b2_bottom = other.get_absolute_ullr()\n\n    intersect_left = max(b1_left, b2_left)\n    intersect_top = max(b1_top, b2_top)\n    intersect_bottom = min(b1_bottom, b2_bottom)\n    intersect_right = min(b1_right, b2_right)\n\n    return bounding_box_from_ullr(\n        intersect_left, intersect_top, intersect_right, intersect_bottom\n    )\n</code></pre>"},{"location":"reference/utilities/boundingboxes/boundingbox/#niceml.utilities.boundingboxes.boundingbox.BoundingBox.get_relative_area","title":"get_relative_area","text":"<pre><code>get_relative_area(image_size)\n</code></pre> <p>Returns the absolute bounding box area in pixels</p> Source code in <code>niceml/utilities/boundingboxes/boundingbox.py</code> <pre><code>def get_relative_area(self, image_size: ImageSize) -&gt; float:\n    \"\"\"Returns the absolute bounding box area in pixels\"\"\"\n    return self.get_absolute_area() / (image_size.width * image_size.height)\n</code></pre>"},{"location":"reference/utilities/boundingboxes/boundingbox/#niceml.utilities.boundingboxes.boundingbox.BoundingBox.get_relative_ullr","title":"get_relative_ullr","text":"<pre><code>get_relative_ullr(img_size)\n</code></pre> <p>Returns a tuple with relative upper-left and lower-right coordinates (x_ul,y_ul,x_lr,y_lr)</p> Source code in <code>niceml/utilities/boundingboxes/boundingbox.py</code> <pre><code>def get_relative_ullr(\n    self, img_size: ImageSize\n) -&gt; Tuple[float, float, float, float]:\n    \"\"\"Returns a tuple with relative upper-left and lower-right coordinates\n    (x_ul,y_ul,x_lr,y_lr)\"\"\"\n    return get_scaled_values(self.get_absolute_ullr(), img_size)\n</code></pre>"},{"location":"reference/utilities/boundingboxes/boundingbox/#niceml.utilities.boundingboxes.boundingbox.BoundingBox.get_relative_xywh","title":"get_relative_xywh","text":"<pre><code>get_relative_xywh(img_size)\n</code></pre> <p>Returns a tuple with relative coordinates (x,y,width,height)</p> Source code in <code>niceml/utilities/boundingboxes/boundingbox.py</code> <pre><code>def get_relative_xywh(\n    self, img_size: ImageSize\n) -&gt; Tuple[float, float, float, float]:\n    \"\"\"Returns a tuple with relative coordinates (x,y,width,height)\"\"\"\n    return get_scaled_values(self.get_absolute_xywh(), img_size)\n</code></pre>"},{"location":"reference/utilities/boundingboxes/boundingbox/#niceml.utilities.boundingboxes.boundingbox.BoundingBox.scale","title":"scale","text":"<pre><code>scale(scale)\n</code></pre> <p>Scales a bounding box (x_pos, y_pos, width, height) by a given scale factor.</p> <p>scale: Args:     scale: Factor to scale the bounding box by</p> <p>Returns:</p> <ul> <li> <code>BoundingBox</code>         \u2013          <p>Scaled BoundingBox</p> </li> </ul> Source code in <code>niceml/utilities/boundingboxes/boundingbox.py</code> <pre><code>def scale(self, scale: float) -&gt; \"BoundingBox\":\n    \"\"\"\n    Scales a bounding box (x_pos, y_pos, width, height) by a given scale factor.\n\n    scale:\n    Args:\n        scale: Factor to scale the bounding box by\n\n    Returns:\n        Scaled BoundingBox\n    \"\"\"\n    x_pos = round(self.x_pos * scale)\n    y_pos = round(self.y_pos * scale)\n    width = round(self.width * scale)\n    height = round(self.height * scale)\n\n    return BoundingBox(x_pos, y_pos, width, height)\n</code></pre>"},{"location":"reference/utilities/boundingboxes/boundingbox/#niceml.utilities.boundingboxes.boundingbox.BoundingBox.shift","title":"shift","text":"<pre><code>shift(axis, shift_by, direction)\n</code></pre> <p>Shifts a bounding box on a given axis by <code>shift_by</code></p> <p>Parameters:</p> <ul> <li> <code>axis</code>             (<code>int</code>)         \u2013          <p>Axis on which to be shifted (0: X-Axis, 1: Y-Axis).</p> </li> <li> <code>shift_by</code>             (<code>int</code>)         \u2013          <p>Shift value in pixels</p> </li> <li> <code>direction</code>             (<code>int</code>)         \u2013          <p>Direction to be shifted (0: left if axis is 0, up if axis is 1; 1: right if axis is 0, down if axis is 1)</p> </li> </ul> Source code in <code>niceml/utilities/boundingboxes/boundingbox.py</code> <pre><code>def shift(self, axis: int, shift_by: int, direction: int):\n    \"\"\"\n    Shifts a bounding box on a given axis by `shift_by`\n\n    Args:\n        axis: Axis on which to be shifted (0: X-Axis, 1: Y-Axis).\n        shift_by: Shift value in pixels\n        direction: Direction to be shifted (0: left if axis is 0,\n            up if axis is 1; 1: right if axis is 0, down if axis is 1)\n    \"\"\"\n\n    if axis == 0:\n        if direction == 0:\n            self.x_pos -= shift_by\n        else:\n            self.x_pos += shift_by\n    elif direction == 0:\n        self.y_pos -= shift_by\n    else:\n        self.y_pos += shift_by\n</code></pre>"},{"location":"reference/utilities/boundingboxes/boundingbox/#niceml.utilities.boundingboxes.boundingbox-functions","title":"Functions","text":""},{"location":"reference/utilities/boundingboxes/boundingbox/#niceml.utilities.boundingboxes.boundingbox.bounding_box_from_ullr","title":"bounding_box_from_ullr","text":"<pre><code>bounding_box_from_ullr(left, top, right, bottom)\n</code></pre> <p>Returns a bounding box from given ullr coordinates</p> Source code in <code>niceml/utilities/boundingboxes/boundingbox.py</code> <pre><code>def bounding_box_from_ullr(\n    left: float, top: float, right: float, bottom: float\n) -&gt; BoundingBox:\n    \"\"\"Returns a bounding box from given ullr coordinates\"\"\"\n    return BoundingBox(left, top, right - left, bottom - top)\n</code></pre>"},{"location":"reference/utilities/boundingboxes/boundingbox/#niceml.utilities.boundingboxes.boundingbox.get_bounding_box_attributes","title":"get_bounding_box_attributes","text":"<pre><code>get_bounding_box_attributes()\n</code></pre> <p>Returns a list with the names of the attributes of the bounding box class</p> <p>Returns:</p> <ul> <li> <code>List[str]</code>         \u2013          <p>List of strings with the names of the BoundingBox attributes</p> </li> </ul> Source code in <code>niceml/utilities/boundingboxes/boundingbox.py</code> <pre><code>def get_bounding_box_attributes() -&gt; List[str]:\n    \"\"\"\n    Returns a list with the names of the attributes of the bounding box class\n\n    Returns:\n        List of strings with the names of the BoundingBox attributes\n    \"\"\"\n    # pylint: disable=not-an-iterable\n    return [field.name for field in fields(BoundingBox)]\n</code></pre>"},{"location":"reference/utilities/boundingboxes/boundingbox/#niceml.utilities.boundingboxes.boundingbox.get_scaled_values","title":"get_scaled_values","text":"<pre><code>get_scaled_values(values, image_size)\n</code></pre> <p>Scales the values with the image size from pixel to relative</p> Source code in <code>niceml/utilities/boundingboxes/boundingbox.py</code> <pre><code>def get_scaled_values(\n    values: tuple, image_size: ImageSize\n) -&gt; Tuple[float, float, float, float]:\n    \"\"\"Scales the values with the image size from pixel to relative\"\"\"\n    img_size_list = [image_size.width, image_size.height]\n\n    # noinspection PyTypeChecker\n    return tuple(\n        value / img_size_list[idx % 2]\n        for value, idx in zip(\n            values,\n            range(4),\n        )\n    )\n</code></pre>"},{"location":"reference/utilities/boundingboxes/boundingbox/#niceml.utilities.boundingboxes.boundingbox.get_surrounding_bounding_box","title":"get_surrounding_bounding_box","text":"<pre><code>get_surrounding_bounding_box(*bbox_arrays)\n</code></pre> <p>Finds the surrounding bounding box from the given bounding box arrays which are in ullr format. The surrounding bounding box is defined as the smallest possible rectangle that contains all the inputted boxes.</p> <p>Parameters:</p> <ul> <li> <code>bbox_arrays</code>             (<code>ndarray</code>, default:                 <code>()</code> )         \u2013          <p>Variable number of bounding box arrays</p> </li> </ul> <p>Returns:     BoundingBox that surrounds all of the given bounding boxes</p> Source code in <code>niceml/utilities/boundingboxes/boundingbox.py</code> <pre><code>def get_surrounding_bounding_box(*bbox_arrays: np.ndarray) -&gt; BoundingBox:\n    \"\"\"\n    Finds the surrounding bounding box from the given bounding box arrays which are in ullr format.\n    The surrounding bounding box is defined as the smallest possible rectangle that contains all\n    the inputted boxes.\n\n    Args:\n        bbox_arrays: Variable number of bounding box arrays\n    Returns:\n        BoundingBox that surrounds all of the given bounding boxes\n    \"\"\"\n    coordinates = []\n    for bbox_ar in bbox_arrays:\n        x_min = np.min(bbox_ar[:, 0])\n        y_min = np.min(bbox_ar[:, 1])\n        x_max = np.max(bbox_ar[:, 2])\n        y_max = np.max(bbox_ar[:, 3])\n\n        coordinates.append([x_min, y_min, x_max, y_max])\n\n    coordinates_array = np.array(coordinates)\n\n    x_min = np.min(coordinates_array[:, 0])\n    y_min = np.min(coordinates_array[:, 1])\n    x_max = np.max(coordinates_array[:, 2])\n    y_max = np.max(coordinates_array[:, 3])\n\n    return bounding_box_from_ullr(x_min, y_min, x_max, y_max)\n</code></pre>"},{"location":"reference/utilities/boundingboxes/boundingbox/#niceml.utilities.boundingboxes.boundingbox.split_bounding_boxes","title":"split_bounding_boxes","text":"<pre><code>split_bounding_boxes(bounding_box, x_boxes, y_boxes)\n</code></pre> <p>Splits the bounding_box in smaller boxes covering the same area</p> <p>Parameters:</p> <ul> <li> <code>bounding_box</code>             (<code>BoundingBox</code>)         \u2013          <p>BoundingBox to be split</p> </li> <li> <code>x_boxes</code>             (<code>int</code>)         \u2013          <p>Number of boxes to split the bounding box into along the x-axis</p> </li> <li> <code>y_boxes</code>             (<code>int</code>)         \u2013          <p>Number of boxes to split the bounding box into along the y-axis</p> </li> </ul> <p>Returns:     A list of bounding boxes</p> Source code in <code>niceml/utilities/boundingboxes/boundingbox.py</code> <pre><code>def split_bounding_boxes(\n    bounding_box: BoundingBox, x_boxes: int, y_boxes: int\n) -&gt; List[BoundingBox]:\n    \"\"\"\n    Splits the bounding_box in smaller boxes covering the same area\n\n    Args:\n        bounding_box: BoundingBox to be split\n        x_boxes: Number of boxes to split the bounding box into along the x-axis\n        y_boxes: Number of boxes to split the bounding box into along the y-axis\n    Returns:\n        A list of bounding boxes\n    \"\"\"\n    assert x_boxes &gt;= 1 and y_boxes &gt;= 1\n    new_width: float = bounding_box.width / x_boxes\n    new_height: float = bounding_box.height / y_boxes\n    bbox_list: List[BoundingBox] = []\n    for x_idx in range(x_boxes):\n        for y_idx in range(y_boxes):\n            bbox = BoundingBox(\n                bounding_box.x_pos + x_idx * new_width,\n                bounding_box.y_pos + y_idx * new_height,\n                new_width,\n                new_height,\n            )\n            bbox_list.append(bbox)\n    return bbox_list\n</code></pre>"},{"location":"reference/utilities/boundingboxes/filtering/__init__/","title":"filtering","text":""},{"location":"reference/utilities/boundingboxes/filtering/__init__/#niceml.utilities.boundingboxes.filtering","title":"filtering","text":""},{"location":"reference/utilities/boundingboxes/filtering/nmsfilter/","title":"nmsfilter","text":""},{"location":"reference/utilities/boundingboxes/filtering/nmsfilter/#niceml.utilities.boundingboxes.filtering.nmsfilter","title":"nmsfilter","text":"<p>Module for NmsFilter</p>"},{"location":"reference/utilities/boundingboxes/filtering/nmsfilter/#niceml.utilities.boundingboxes.filtering.nmsfilter-classes","title":"Classes","text":""},{"location":"reference/utilities/boundingboxes/filtering/nmsfilter/#niceml.utilities.boundingboxes.filtering.nmsfilter.NmsFilter","title":"NmsFilter","text":"<p>             Bases: <code>PredictionFilter</code></p> <p>Applies non-maximum suppression (nms) filtering to predictions</p>"},{"location":"reference/utilities/boundingboxes/filtering/nmsfilter/#niceml.utilities.boundingboxes.filtering.nmsfilter-functions","title":"Functions","text":""},{"location":"reference/utilities/boundingboxes/filtering/nmsfilter/#niceml.utilities.boundingboxes.filtering.nmsfilter.non_maximum_suppression","title":"non_maximum_suppression","text":"<pre><code>non_maximum_suppression(\n    prediction_array_xywh,\n    iou_threshold,\n    coordinates_count,\n    class_count,\n    score_threshold=0.5,\n)\n</code></pre> <p>Filters the box predictions to get the most relevant boxes according to given parameters Args:     prediction_array_xywh: Array of prediction boxes in format [x,y,width,height]     iou_threshold: IOU threshold for boxes to keep     coordinates_count: Number of coordinates in prediction array     class_count: Number of classes in prediction array     score_threshold: Prediction score threshold for predictions to keep</p> <p>Returns:</p> <ul> <li> <code>ndarray</code>         \u2013          <p>Array of prediction boxes to keep</p> </li> </ul> Source code in <code>niceml/utilities/boundingboxes/filtering/nmsfilter.py</code> <pre><code>def non_maximum_suppression(  # pylint: disable=too-many-locals\n    prediction_array_xywh: np.ndarray,\n    iou_threshold: float,\n    coordinates_count: int,\n    class_count: int,\n    score_threshold: float = 0.5,\n) -&gt; np.ndarray:\n    \"\"\"\n    Filters the box predictions to get the most relevant boxes according to given parameters\n    Args:\n        prediction_array_xywh: Array of prediction boxes in format [x,y,width,height]\n        iou_threshold: IOU threshold for boxes to keep\n        coordinates_count: Number of coordinates in prediction array\n        class_count: Number of classes in prediction array\n        score_threshold: Prediction score threshold for predictions to keep\n\n    Returns:\n        Array of prediction boxes to keep\n    \"\"\"\n    prediction_array_ullr = convert_to_ullr(prediction_array_xywh)\n\n    max_class_array = np.argmax(\n        prediction_array_ullr[:, coordinates_count : coordinates_count + class_count],\n        axis=1,\n    )\n    max_score = np.max(\n        prediction_array_ullr[:, coordinates_count : coordinates_count + class_count],\n        axis=1,\n    )\n\n    prediction_array_ullr = prediction_array_ullr[max_score &gt; score_threshold, :]\n    max_class_array = max_class_array[max_score &gt; score_threshold]\n    max_score = max_score[max_score &gt; score_threshold]\n\n    sorted_scores_idxes = max_score.argsort()[::-1]\n    prediction_array_ullr = prediction_array_ullr[sorted_scores_idxes]\n    max_class_array = max_class_array[sorted_scores_idxes]\n\n    out_bboxes: List[np.ndarray] = []\n    for cur_class in range(class_count):\n        cur_class_idxes = max_class_array == cur_class\n        class_prediction_array_ullr = prediction_array_ullr[cur_class_idxes]\n\n        if len(class_prediction_array_ullr) == 0:\n            continue\n        iou_mat = compute_iou_matrix(\n            class_prediction_array_ullr, class_prediction_array_ullr\n        )\n        used_box_idxes = set()\n        for cur_row_idx in range(iou_mat.shape[0]):\n            if cur_row_idx in used_box_idxes:\n                continue\n\n            cur_cluster_idxes = np.argwhere(iou_mat[cur_row_idx, :] &gt; iou_threshold)[\n                :, 0\n            ].tolist()\n            used_box_idxes.update(cur_cluster_idxes)\n            out_bboxes.append(\n                class_prediction_array_ullr[cur_row_idx, :][np.newaxis, :]\n            )\n\n    if len(out_bboxes) == 0:\n        return np.empty(shape=(0, prediction_array_ullr.shape[1]))\n    out_bbox_array_ullr = np.concatenate(out_bboxes, axis=0)\n    return convert_to_xywh(out_bbox_array_ullr)\n</code></pre>"},{"location":"reference/utilities/boundingboxes/filtering/predictionfilter/","title":"predictionfilter","text":""},{"location":"reference/utilities/boundingboxes/filtering/predictionfilter/#niceml.utilities.boundingboxes.filtering.predictionfilter","title":"predictionfilter","text":"<p>Module for PredictionFilter</p>"},{"location":"reference/utilities/boundingboxes/filtering/predictionfilter/#niceml.utilities.boundingboxes.filtering.predictionfilter-classes","title":"Classes","text":""},{"location":"reference/utilities/boundingboxes/filtering/predictionfilter/#niceml.utilities.boundingboxes.filtering.predictionfilter.PredictionFilter","title":"PredictionFilter","text":"<p>             Bases: <code>ABC</code></p> <p>Class to filter predictions</p>"},{"location":"reference/utilities/boundingboxes/filtering/predictionfilter/#niceml.utilities.boundingboxes.filtering.predictionfilter.PredictionFilter-functions","title":"Functions","text":""},{"location":"reference/utilities/boundingboxes/filtering/predictionfilter/#niceml.utilities.boundingboxes.filtering.predictionfilter.PredictionFilter.filter","title":"filter  <code>abstractmethod</code>","text":"<pre><code>filter(prediction_array_xywh)\n</code></pre> <p>Filters prediction arrays with corresponding class predictions Args:     prediction_array_xywh: input predictions (n x (4 + num_classes))</p> <p>Returns:</p> <ul> <li> <code>prediction_array_xywh</code> (            <code>ndarray</code> )        \u2013          <p>Filtered predictions (m x (4 + num_classes))</p> </li> </ul> Source code in <code>niceml/utilities/boundingboxes/filtering/predictionfilter.py</code> <pre><code>@abstractmethod\ndef filter(self, prediction_array_xywh: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Filters prediction arrays with corresponding class predictions\n    Args:\n        prediction_array_xywh: input predictions (n x (4 + num_classes))\n\n    Returns:\n        prediction_array_xywh: Filtered predictions (m x (4 + num_classes))\n    \"\"\"\n</code></pre>"},{"location":"reference/utilities/boundingboxes/filtering/predictionfilter/#niceml.utilities.boundingboxes.filtering.predictionfilter.PredictionFilter.initialize","title":"initialize","text":"<pre><code>initialize(data_description)\n</code></pre> <p>Initialization method for the prediction filter Args:     data_description: <code>DataDescription</code> that can be used for initialization</p> Source code in <code>niceml/utilities/boundingboxes/filtering/predictionfilter.py</code> <pre><code>def initialize(\n    self,\n    data_description: Union[\n        OutputObjDetDataDescription, OutputImageDataDescription\n    ],\n):\n    \"\"\"\n    Initialization method for the prediction filter\n    Args:\n        data_description: `DataDescription` that can be used for initialization\n    \"\"\"\n    if isinstance(data_description, OutputObjDetDataDescription):\n        self.output_class_count = data_description.get_output_class_count()\n    elif isinstance(data_description, OutputImageDataDescription):\n        self.output_class_count = data_description.get_output_channel_count()\n    else:\n        raise TypeError(\n            f\"Object of class {type(data_description)} \"\n            f\"is not instance of class: {OutputObjDetDataDescription} \"\n            f\"or {OutputImageDataDescription}\"\n        )\n</code></pre>"},{"location":"reference/utilities/boundingboxes/filtering/predictionfilter/#niceml.utilities.boundingboxes.filtering.predictionfilter.PredictionFilter.to_dict","title":"to_dict","text":"<pre><code>to_dict()\n</code></pre> <p>Creates a representation of itself as a dict</p> Source code in <code>niceml/utilities/boundingboxes/filtering/predictionfilter.py</code> <pre><code>def to_dict(self) -&gt; dict:\n    \"\"\"Creates a representation of itself as a dict\"\"\"\n    filter_dict = asdict(self)\n    filter_dict[\"pred_type\"] = type(self).__name__\n    return filter_dict\n</code></pre>"},{"location":"reference/utilities/boundingboxes/filtering/predictionfilter/#niceml.utilities.boundingboxes.filtering.predictionfilter-functions","title":"Functions","text":""},{"location":"reference/utilities/boundingboxes/filtering/predictionfilter/#niceml.utilities.boundingboxes.filtering.predictionfilter.get_filter_attributes","title":"get_filter_attributes","text":"<pre><code>get_filter_attributes(filter_class, ignore_attributes=None)\n</code></pre> <p>Iterates the attributes of <code>filter_class</code> and returns it. Returns:     list of the attributes of <code>filter_class</code> as a dict with <code>name</code> and <code>default</code> as keys</p> Source code in <code>niceml/utilities/boundingboxes/filtering/predictionfilter.py</code> <pre><code>def get_filter_attributes(  # QUEST: still used?\n    filter_class: Type[PredictionFilter], ignore_attributes: Optional[List[str]] = None\n):\n    \"\"\"\n    Iterates the attributes of `filter_class` and returns it.\n    Returns:\n        list of the attributes of `filter_class` as a dict with `name` and `default` as keys\n    \"\"\"\n    # pylint: disable=not-an-iterable\n    ignore_attributes = ignore_attributes or []\n    filter_attributes = []\n\n    for field in fields(filter_class):\n        if field.name not in ignore_attributes:\n            filter_attribute = {\"name\": field.name, \"default\": 0.0, \"step\": None}\n\n            if field.name in [\"score_threshold\", \"iou_threshold\"]:\n                filter_attribute[\"default\"] = 0.5\n\n            if field.type == Union[int, None]:\n                filter_attribute[\"step\"] = 1\n                filter_attribute[\"default\"] = (\n                    200 if field.name == \"max_output_count\" else 0\n                )\n            filter_attributes.append(filter_attribute)\n    return filter_attributes\n</code></pre>"},{"location":"reference/utilities/boundingboxes/filtering/predictionfiltertype/","title":"predictionfiltertype","text":""},{"location":"reference/utilities/boundingboxes/filtering/predictionfiltertype/#niceml.utilities.boundingboxes.filtering.predictionfiltertype","title":"predictionfiltertype","text":"<p>Module for PredictionFilterType</p>"},{"location":"reference/utilities/boundingboxes/filtering/predictionfiltertype/#niceml.utilities.boundingboxes.filtering.predictionfiltertype-classes","title":"Classes","text":""},{"location":"reference/utilities/boundingboxes/filtering/predictionfiltertype/#niceml.utilities.boundingboxes.filtering.predictionfiltertype.PredictionFilterTypes","title":"PredictionFilterTypes","text":"<p>             Bases: <code>str</code>, <code>Enum</code></p> <p>Enum for the types of prediction filters.</p>"},{"location":"reference/utilities/boundingboxes/filtering/thresholdfilter/","title":"thresholdfilter","text":""},{"location":"reference/utilities/boundingboxes/filtering/thresholdfilter/#niceml.utilities.boundingboxes.filtering.thresholdfilter","title":"thresholdfilter","text":"<p>Module for ThresholdFilter</p>"},{"location":"reference/utilities/boundingboxes/filtering/thresholdfilter/#niceml.utilities.boundingboxes.filtering.thresholdfilter-classes","title":"Classes","text":""},{"location":"reference/utilities/boundingboxes/filtering/thresholdfilter/#niceml.utilities.boundingboxes.filtering.thresholdfilter.ThresholdFilter","title":"ThresholdFilter","text":"<p>             Bases: <code>PredictionFilter</code></p> <p>Removes all predictions lower than score_threshold</p>"},{"location":"reference/utilities/boundingboxes/filtering/thresholdfilter/#niceml.utilities.boundingboxes.filtering.thresholdfilter.ThresholdFilter-functions","title":"Functions","text":""},{"location":"reference/utilities/boundingboxes/filtering/thresholdfilter/#niceml.utilities.boundingboxes.filtering.thresholdfilter.ThresholdFilter.filter","title":"filter","text":"<pre><code>filter(prediction_array_xywh)\n</code></pre> <p>Filters the prediction in array according to given filter conditions Args:     prediction_array_xywh: prediction array in format [y,x,width,height]</p> <p>Returns:</p> <ul> <li> <code>ndarray</code>         \u2013          <p>filtered prediction array</p> </li> </ul> Source code in <code>niceml/utilities/boundingboxes/filtering/thresholdfilter.py</code> <pre><code>def filter(self, prediction_array_xywh: np.ndarray) -&gt; np.ndarray:\n    \"\"\"\n    Filters the prediction in array according to given filter conditions\n    Args:\n        prediction_array_xywh: prediction array in format [y,x,width,height]\n\n    Returns:\n        filtered prediction array\n    \"\"\"\n    scores = prediction_array_xywh[\n        :, self.coordinates_count : self.coordinates_count + self.output_class_count\n    ]\n    max_vals = np.max(scores, axis=1)\n    filtered_array = prediction_array_xywh[max_vals &gt;= self.score_threshold, :]\n    if (\n        self.max_output_count is None\n        or filtered_array.shape[0] &lt;= self.max_output_count\n    ):\n        return filtered_array\n    max_vals = max_vals[max_vals &gt;= self.score_threshold]\n    sorted_scores_idxes = max_vals.argsort()[::-1][: self.max_output_count]\n    return filtered_array[sorted_scores_idxes, :]\n</code></pre>"},{"location":"reference/utilities/boundingboxes/filtering/unifiedboxfilter/","title":"unifiedboxfilter","text":""},{"location":"reference/utilities/boundingboxes/filtering/unifiedboxfilter/#niceml.utilities.boundingboxes.filtering.unifiedboxfilter","title":"unifiedboxfilter","text":"<p>Module for UnifiedBoxFilter</p>"},{"location":"reference/utilities/boundingboxes/filtering/unifiedboxfilter/#niceml.utilities.boundingboxes.filtering.unifiedboxfilter-classes","title":"Classes","text":""},{"location":"reference/utilities/boundingboxes/filtering/unifiedboxfilter/#niceml.utilities.boundingboxes.filtering.unifiedboxfilter.UnifiedBoxFilter","title":"UnifiedBoxFilter","text":"<p>             Bases: <code>PredictionFilter</code></p> <p>Combines overlapping bounding boxes with the same class to one unified box with combined border coordinates.</p>"},{"location":"reference/utilities/boundingboxes/filtering/unifiedboxfilter/#niceml.utilities.boundingboxes.filtering.unifiedboxfilter.UnifiedBoxFilter-functions","title":"Functions","text":""},{"location":"reference/utilities/boundingboxes/filtering/unifiedboxfilter/#niceml.utilities.boundingboxes.filtering.unifiedboxfilter.UnifiedBoxFilter.filter","title":"filter","text":"<pre><code>filter(prediction_array_xywh)\n</code></pre> <p>Filters bounding boxes of prediction array according to given filter conditions Args:     prediction_array_xywh: prediction array in format [y,x,width,height]</p> <p>Returns:</p> <ul> <li> <code>ndarray</code>         \u2013          <p>filtered prediction array</p> </li> </ul> Source code in <code>niceml/utilities/boundingboxes/filtering/unifiedboxfilter.py</code> <pre><code>def filter(  # pylint: disable=too-many-locals\n    self, prediction_array_xywh: np.ndarray\n) -&gt; np.ndarray:\n    \"\"\"\n    Filters bounding boxes of prediction array according to given filter conditions\n    Args:\n        prediction_array_xywh: prediction array in format [y,x,width,height]\n\n    Returns:\n        filtered prediction array\n    \"\"\"\n    prediction_array_ullr = convert_to_ullr(prediction_array_xywh)\n\n    max_class_array = np.argmax(\n        prediction_array_ullr[\n            :, self.box_coordinates : self.box_coordinates + self.output_class_count\n        ],\n        axis=1,\n    )\n    max_score = np.max(\n        prediction_array_ullr[\n            :, self.box_coordinates : self.box_coordinates + self.output_class_count\n        ],\n        axis=1,\n    )\n\n    prediction_array_ullr = prediction_array_ullr[\n        max_score &gt; self.score_threshold, :\n    ]\n    max_class_array = max_class_array[max_score &gt; self.score_threshold]\n    max_score = max_score[max_score &gt; self.score_threshold]\n\n    sorted_scores_idxes = max_score.argsort()[::-1]\n    prediction_array_ullr = prediction_array_ullr[sorted_scores_idxes]\n    max_class_array = max_class_array[sorted_scores_idxes]\n\n    out_bboxes: List[np.ndarray] = []\n    for cur_class in range(self.output_class_count):\n        cur_class_idxes = max_class_array == cur_class\n        class_prediction_array_ullr = prediction_array_ullr[cur_class_idxes]\n\n        if len(class_prediction_array_ullr) == 0:\n            continue\n        iou_mat = compute_iou_matrix(\n            class_prediction_array_ullr, class_prediction_array_ullr\n        )\n        used_box_idxes = set()\n        for cur_row_idx in range(iou_mat.shape[0]):\n            if cur_row_idx in used_box_idxes:\n                continue\n\n            cur_cluster_idxes = np.argwhere(\n                iou_mat[cur_row_idx, :] &gt; self.iou_threshold\n            )[:, 0].tolist()\n            used_box_idxes.update(cur_cluster_idxes)\n\n            cur_cluster_prediction_array = class_prediction_array_ullr[\n                cur_cluster_idxes, :\n            ]\n\n            ul_corners = np.min(cur_cluster_prediction_array[:, :2], axis=0)\n            lr_corners = np.max(cur_cluster_prediction_array[:, 2:4], axis=0)\n            predictions = np.max(\n                cur_cluster_prediction_array[\n                    :,\n                    self.box_coordinates : self.box_coordinates\n                    + self.output_class_count,\n                ],\n                axis=0,\n            )\n            additional_info = class_prediction_array_ullr[\n                cur_row_idx, self.box_coordinates + self.output_class_count :\n            ]\n            cur_cluster_bbox = np.concatenate(\n                [ul_corners, lr_corners, predictions, additional_info]\n            )\n            out_bboxes.append(cur_cluster_bbox[np.newaxis, :])\n    if len(out_bboxes) == 0:\n        return np.empty(shape=(0, prediction_array_ullr.shape[1]))\n    out_bbox_array_ullr = np.concatenate(out_bboxes, axis=0)\n    return convert_to_xywh(out_bbox_array_ullr)\n</code></pre>"},{"location":"reference/utilities/boundingboxes/filtering/unifiedboxfilter/#niceml.utilities.boundingboxes.filtering.unifiedboxfilter-functions","title":"Functions","text":""},{"location":"reference/utilities/filtering/__init__/","title":"filtering","text":""},{"location":"reference/utilities/filtering/__init__/#niceml.utilities.filtering","title":"filtering","text":""},{"location":"reference/utilities/filtering/probabilityclassselector/","title":"probabilityclassselector","text":""},{"location":"reference/utilities/filtering/probabilityclassselector/#niceml.utilities.filtering.probabilityclassselector","title":"probabilityclassselector","text":"<p>Module for probability selection</p>"},{"location":"reference/utilities/filtering/probabilityclassselector/#niceml.utilities.filtering.probabilityclassselector-classes","title":"Classes","text":""},{"location":"reference/utilities/filtering/probabilityclassselector/#niceml.utilities.filtering.probabilityclassselector.ProbabilityClassSelector","title":"ProbabilityClassSelector","text":"<pre><code>ProbabilityClassSelector(\n    data, class_col, prob_col, min_delta=0.1\n)\n</code></pre> <p>Selection class for a specific dataframe which selects based on a class column and a prediction column</p> <p>Parameters:</p> <ul> <li> <code>data</code>             (<code>DataFrame</code>)         \u2013          <p>Includes the data to investigate</p> </li> <li> <code>class_col</code>             (<code>str</code>)         \u2013          <p>column name containing the classes</p> </li> <li> <code>prob_col</code>             (<code>str</code>)         \u2013          <p>column name containing the prediction probabilities</p> </li> <li> <code>min_delta</code>             (<code>float</code>, default:                 <code>0.1</code> )         \u2013          <p>The minimum difference between minimum and maximum probability; default 0.1</p> </li> </ul> Source code in <code>niceml/utilities/filtering/probabilityclassselector.py</code> <pre><code>def __init__(\n    self,\n    data: pd.DataFrame,\n    class_col: str,\n    prob_col: str,\n    min_delta: float = 0.1,\n):\n    self.data = data\n    self.class_col = class_col\n    self.prob_col = prob_col\n    self.min_delta = min_delta\n</code></pre>"},{"location":"reference/utilities/filtering/probabilityclassselector/#niceml.utilities.filtering.probabilityclassselector.ProbabilityClassSelector-functions","title":"Functions","text":""},{"location":"reference/utilities/filtering/probabilityclassselector/#niceml.utilities.filtering.probabilityclassselector.ProbabilityClassSelector.get_selected_data","title":"get_selected_data","text":"<pre><code>get_selected_data(selection)\n</code></pre> <p>Filter and sort the data due to the selection</p> Source code in <code>niceml/utilities/filtering/probabilityclassselector.py</code> <pre><code>def get_selected_data(self, selection: Selection):\n    \"\"\"Filter and sort the data due to the selection\"\"\"\n    selected_data: pd.DataFrame = self.data[\n        self.data[self.class_col] == selection.class_name\n    ]\n    selected_data = selected_data.sort_values(by=[self.prob_col])\n    selected_data = selected_data[\n        selected_data[self.prob_col] &gt;= selection.prob_value\n    ]\n    return selected_data\n</code></pre>"},{"location":"reference/utilities/filtering/probabilityclassselector/#niceml.utilities.filtering.probabilityclassselector.ProbabilityClassSelector.get_selection_info","title":"get_selection_info","text":"<pre><code>get_selection_info()\n</code></pre> <p>Returns info about the possible selections</p> Source code in <code>niceml/utilities/filtering/probabilityclassselector.py</code> <pre><code>def get_selection_info(self) -&gt; SelectionInfo:\n    \"\"\"Returns info about the possible selections\"\"\"\n    class_list = list(self.data[self.class_col].unique())\n    min_prob = float(self.data[self.prob_col].min())\n    max_prob = float(self.data[self.prob_col].max())\n    if max_prob - min_prob &lt; self.min_delta:\n        max_prob = min_prob + self.min_delta\n    return SelectionInfo(class_list, min_prob, max_prob)\n</code></pre>"},{"location":"reference/utilities/filtering/probabilityclassselector/#niceml.utilities.filtering.probabilityclassselector.Selection","title":"Selection  <code>dataclass</code>","text":"<p>Specific selection with regard to SelectionInfo</p>"},{"location":"reference/utilities/filtering/probabilityclassselector/#niceml.utilities.filtering.probabilityclassselector.SelectionInfo","title":"SelectionInfo  <code>dataclass</code>","text":"<p>What classes and probability range is included in data</p>"},{"location":"reference/utilities/fsspec/__init__/","title":"fsspec","text":""},{"location":"reference/utilities/fsspec/__init__/#niceml.utilities.fsspec","title":"fsspec","text":""},{"location":"reference/utilities/fsspec/locationutils/","title":"locationutils","text":""},{"location":"reference/utilities/fsspec/locationutils/#niceml.utilities.fsspec.locationutils","title":"locationutils","text":"<p>Module to access description for a remote storage location</p>"},{"location":"reference/utilities/fsspec/locationutils/#niceml.utilities.fsspec.locationutils-classes","title":"Classes","text":""},{"location":"reference/utilities/fsspec/locationutils/#niceml.utilities.fsspec.locationutils.LocationConfig","title":"LocationConfig","text":"<p>Access description for a remote storage location. The description is targeted at fsspec_.</p>"},{"location":"reference/utilities/fsspec/locationutils/#niceml.utilities.fsspec.locationutils.LocationConfig-functions","title":"Functions","text":""},{"location":"reference/utilities/fsspec/locationutils/#niceml.utilities.fsspec.locationutils.LocationConfig.__str__","title":"__str__","text":"<pre><code>__str__()\n</code></pre> <p>Returns string representation without credential values</p> Source code in <code>niceml/utilities/fsspec/locationutils.py</code> <pre><code>def __str__(self) -&gt; str:\n    \"\"\"Returns string representation without credential values\"\"\"\n    info = asdict(self)\n    info[\"credentials\"] = list(info[\"credentials\"])\n    return str(info)\n</code></pre>"},{"location":"reference/utilities/fsspec/locationutils/#niceml.utilities.fsspec.locationutils-functions","title":"Functions","text":""},{"location":"reference/utilities/fsspec/locationutils/#niceml.utilities.fsspec.locationutils.get_location_uri","title":"get_location_uri","text":"<pre><code>get_location_uri(location)\n</code></pre> <p>Returns the URI of a LocationConfig.</p> Source code in <code>niceml/utilities/fsspec/locationutils.py</code> <pre><code>def get_location_uri(location: Union[LocationConfig, dict]) -&gt; str:\n    \"\"\"Returns the URI of a LocationConfig.\"\"\"\n    parsed_config = (\n        location\n        if isinstance(location, LocationConfig)\n        else cattr.structure(location, LocationConfig)\n    )\n    return parsed_config.uri\n</code></pre>"},{"location":"reference/utilities/fsspec/locationutils/#niceml.utilities.fsspec.locationutils.join_fs_path","title":"join_fs_path","text":"<pre><code>join_fs_path(file_system, *paths)\n</code></pre> <p>Returns joined given paths with the fsspec specific path seperator</p> Source code in <code>niceml/utilities/fsspec/locationutils.py</code> <pre><code>def join_fs_path(file_system: AbstractFileSystem, *paths: str) -&gt; str:\n    \"\"\"Returns joined given paths with the fsspec specific path seperator\"\"\"\n    paths = [path for path in paths if len(path) &gt; 0]\n    return file_system.sep.join(paths)\n</code></pre>"},{"location":"reference/utilities/fsspec/locationutils/#niceml.utilities.fsspec.locationutils.join_location_w_path","title":"join_location_w_path","text":"<pre><code>join_location_w_path(location, path)\n</code></pre> <p>Returns joined LocationConfig with one or more path objects</p> Source code in <code>niceml/utilities/fsspec/locationutils.py</code> <pre><code>def join_location_w_path(\n    location: Union[LocationConfig, dict], path: Union[List[str], str]\n) -&gt; LocationConfig:\n    \"\"\"Returns joined LocationConfig with one or more path objects\"\"\"\n    parsed_config = (\n        location\n        if isinstance(location, LocationConfig)\n        else cattr.structure(location, LocationConfig)\n    )\n    copied_config = deepcopy(parsed_config)\n    # TODO: check how to get the correct separator from the filesystem\n    if isinstance(path, list):\n        for path_obj in path:\n            copied_config.uri = join(copied_config.uri, path_obj)\n    else:\n        copied_config.uri = join(copied_config.uri, path)\n    return copied_config\n</code></pre>"},{"location":"reference/utilities/fsspec/locationutils/#niceml.utilities.fsspec.locationutils.open_location","title":"open_location","text":"<pre><code>open_location(config)\n</code></pre> <p>Creates a filesystem and path from configuration as a single context manager. The filesystem is \"closed\" (i.e. open connections are closed) when the context is left.</p> Source code in <code>niceml/utilities/fsspec/locationutils.py</code> <pre><code>@contextmanager\ndef open_location(config: Union[LocationConfig, Dict[str, Any]]) -&gt; Iterator[FSPath]:\n    \"\"\"\n    Creates a filesystem and path from configuration as a single context manager.\n    The filesystem is \"closed\" (i.e. open connections are closed) when the context is left.\n    \"\"\"\n    parsed_config = (\n        config\n        if isinstance(config, LocationConfig)\n        else cattr.structure(config, LocationConfig)\n    )\n    credentials = deepcopy(parsed_config.credentials)\n    fs_args = deepcopy(parsed_config.fs_args)\n    filesystem, path = url_to_fs(parsed_config.uri, **credentials, **fs_args)\n    try:\n        yield filesystem, path\n    finally:\n        del filesystem\n</code></pre>"},{"location":"reference/utilities/masks/__init__/","title":"masks","text":""},{"location":"reference/utilities/masks/__init__/#niceml.utilities.masks","title":"masks","text":""},{"location":"reference/utilities/masks/maskdownscale/","title":"maskdownscale","text":""},{"location":"reference/utilities/masks/maskdownscale/#niceml.utilities.masks.maskdownscale","title":"maskdownscale","text":"<p>Module to wrap cython maskdownscale</p>"},{"location":"reference/utilities/masks/maskdownscale/#niceml.utilities.masks.maskdownscale-functions","title":"Functions","text":""},{"location":"reference/utilities/masks/maskdownscale/#niceml.utilities.masks.maskdownscale.get_downscaled_masked_histogram","title":"get_downscaled_masked_histogram","text":"<pre><code>get_downscaled_masked_histogram(\n    mask_image, num_classes, default_value, ds_factor\n)\n</code></pre> <p>Calculates a simple histogram for the downscaled mask image Args:     mask_image: image to downscale     num_classes: number of classes included in image     default_value: background value of the image     ds_factor: downscale factor</p> <p>Returns:</p> <ul> <li> <code>ndarray</code>         \u2013          <p>Masked histogram</p> </li> </ul> Source code in <code>niceml/utilities/masks/maskdownscale.py</code> <pre><code>def get_downscaled_masked_histogram(\n    mask_image: np.ndarray, num_classes: int, default_value: int, ds_factor: int\n) -&gt; np.ndarray:\n    \"\"\"\n    Calculates a simple histogram for the downscaled mask image\n    Args:\n        mask_image: image to downscale\n        num_classes: number of classes included in image\n        default_value: background value of the image\n        ds_factor: downscale factor\n\n    Returns:\n        Masked histogram\n    \"\"\"\n    img_shape = mask_image.shape\n    hist_shape = (\n        int(img_shape[0] // ds_factor),\n        int(img_shape[1] // ds_factor),\n        num_classes,\n    )\n    mask_hist = np.zeros(hist_shape, int)\n    mask_image = mask_image.astype(np.uint8)\n    try:\n        mask_hist = cy_mask_downscale(mask_image, mask_hist, default_value, ds_factor)\n    except IndexError as excep:\n        max_mask_img = np.max(mask_image[mask_image != default_value])\n        raise IndexError(\n            f\"MaskImage contains {max_mask_img} but \"\n            f\"highest allowed value is: {num_classes - 1}\"\n        ) from excep\n    return mask_hist\n</code></pre>"},{"location":"reference/utilities/semseg/__init__/","title":"semseg","text":""},{"location":"reference/utilities/semseg/__init__/#niceml.utilities.semseg","title":"semseg","text":""},{"location":"reference/utilities/semseg/semsegdrawing/","title":"semsegdrawing","text":""},{"location":"reference/utilities/semseg/semsegdrawing/#niceml.utilities.semseg.semsegdrawing","title":"semsegdrawing","text":"<p>Module for error mask (SemSegInstanceLabel) draw functions</p>"},{"location":"reference/utilities/semseg/semsegdrawing/#niceml.utilities.semseg.semsegdrawing-classes","title":"Classes","text":""},{"location":"reference/utilities/semseg/semsegdrawing/#niceml.utilities.semseg.semsegdrawing-functions","title":"Functions","text":""},{"location":"reference/utilities/semseg/semsegdrawing/#niceml.utilities.semseg.semsegdrawing.draw_error_mask_on_image","title":"draw_error_mask_on_image","text":"<pre><code>draw_error_mask_on_image(label, image)\n</code></pre> <p>Draws an error mask of a SemSegInstanceLabel on an image</p> <p>Parameters:</p> <ul> <li> <code>label</code>             (<code>SemSegInstanceLabel</code>)         \u2013          <p>label (error mask) to draw on the image</p> </li> <li> <code>image</code>             (<code>Image</code>)         \u2013          <p>image to draw the error masks on</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Image</code>         \u2013          <p>image with the error mask</p> </li> </ul> Source code in <code>niceml/utilities/semseg/semsegdrawing.py</code> <pre><code>def draw_error_mask_on_image(\n    label: SemSegInstanceLabel,\n    image: ImageType,\n) -&gt; ImageType:\n    \"\"\"\n    Draws an error mask of a SemSegInstanceLabel on an image\n\n    Args:\n        label: label (error mask) to draw on the image\n        image: image to draw the error masks on\n\n    Returns:\n        image with the error mask\n    \"\"\"\n\n    color_image = Image.new(\"RGB\", image.size, label.color)\n    mask_input = label.mask\n    mask_input[mask_input == 255] = 100\n    mask = Image.fromarray(mask_input)\n    mask = mask.convert(\"L\")\n    image = Image.composite(color_image, image, mask)\n    return image\n</code></pre>"},{"location":"reference/utilities/semseg/semsegdrawing/#niceml.utilities.semseg.semsegdrawing.draw_labels_on_image","title":"draw_labels_on_image","text":"<pre><code>draw_labels_on_image(\n    image,\n    pred_error_mask_label_list,\n    gt_error_mask_label_list,\n    hide_gt=False,\n)\n</code></pre> <p>Draws multiple prediction and ground truth error mask labels (SemSegInstanceLabel) on an image</p> <p>Parameters:</p> <ul> <li> <code>image</code>             (<code>Image</code>)         \u2013          <p>image to draw the error masks on</p> </li> <li> <code>pred_error_mask_label_list</code>             (<code>List[SemSegInstanceLabel]</code>)         \u2013          <p>list of prediction error mask labels</p> </li> <li> <code>gt_error_mask_label_list</code>             (<code>List[SemSegInstanceLabel]</code>)         \u2013          <p>list of ground truth error mask labels</p> </li> <li> <code>hide_gt</code>             (<code>bool</code>, default:                 <code>False</code> )         \u2013          <p>flag to hide the gt labels</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Image</code>         \u2013          <p>Image with predicted and ground truth error masks</p> </li> </ul> Source code in <code>niceml/utilities/semseg/semsegdrawing.py</code> <pre><code>def draw_labels_on_image(  # pylint: disable=too-many-arguments\n    image: ImageType,\n    pred_error_mask_label_list: List[SemSegInstanceLabel],\n    gt_error_mask_label_list: List[SemSegInstanceLabel],\n    hide_gt: bool = False,\n) -&gt; ImageType:\n    \"\"\"\n\n    Draws multiple prediction and ground truth error mask labels\n    (SemSegInstanceLabel) on an image\n\n    Args:\n        image: image to draw the error masks on\n        pred_error_mask_label_list: list of prediction error mask labels\n        gt_error_mask_label_list: list of ground truth error mask labels\n        hide_gt: flag to hide the gt labels\n\n    Returns:\n        Image with predicted and ground truth error masks\n    \"\"\"\n\n    for pred_label in pred_error_mask_label_list:\n        if pred_label.active:\n            image = draw_error_mask_on_image(image=image, label=pred_label)\n\n    if not hide_gt:\n        for gt_label in gt_error_mask_label_list:\n            if gt_label.active:\n                image = draw_error_mask_on_image(image=image, label=gt_label)\n    return image\n</code></pre>"},{"location":"reference/utilities/semseg/semseginstancelabeling/","title":"semseginstancelabeling","text":""},{"location":"reference/utilities/semseg/semseginstancelabeling/#niceml.utilities.semseg.semseginstancelabeling","title":"semseginstancelabeling","text":"<p>Module for SemSegInstanceLabel</p>"},{"location":"reference/utilities/semseg/semseginstancelabeling/#niceml.utilities.semseg.semseginstancelabeling-classes","title":"Classes","text":""},{"location":"reference/utilities/semseg/semseginstancelabeling/#niceml.utilities.semseg.semseginstancelabeling.SemSegInstanceLabel","title":"SemSegInstanceLabel","text":"<p>             Bases: <code>InstanceLabel</code></p> <p><code>InstanceLabel</code> for one SemSeg error mask instance (prediction or ground truth).</p>"},{"location":"reference/utilities/semseg/semseginstancelabeling/#niceml.utilities.semseg.semseginstancelabeling.SemSegInstanceLabel-functions","title":"Functions","text":""},{"location":"reference/utilities/semseg/semseginstancelabeling/#niceml.utilities.semseg.semseginstancelabeling.SemSegInstanceLabel.calc_iou","title":"calc_iou","text":"<pre><code>calc_iou(other)\n</code></pre> <p>Calculates the IOU of the masks of two <code>SemSegInstanceLabel</code>s</p> <p>Parameters:</p> <ul> <li> <code>other</code>             (<code>SemSegInstanceLabel</code>)         \u2013          <p>Second SemSegInstanceLabel to calculate the IOU with</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>float</code>         \u2013          <p>Calculated IOU</p> </li> </ul> Source code in <code>niceml/utilities/semseg/semseginstancelabeling.py</code> <pre><code>def calc_iou(self, other: \"SemSegInstanceLabel\") -&gt; float:\n    \"\"\"\n    Calculates the IOU of the masks of two `SemSegInstanceLabel`s\n\n    Args:\n        other: Second SemSegInstanceLabel to calculate the IOU with\n\n    Returns:\n        Calculated IOU\n    \"\"\"\n\n    intersection = np.logical_and(self.mask, other.mask)\n    union = np.logical_or(self.mask, other.mask)\n\n    return np.sum(intersection) / np.sum(union)\n</code></pre>"},{"location":"reference/utilities/semseg/semseginstancelabeling/#niceml.utilities.semseg.semseginstancelabeling.SemSegInstanceLabel.scale_label","title":"scale_label","text":"<pre><code>scale_label(scale_factor)\n</code></pre> <p>Scales an SemSegInstanceLabel by a given <code>scale_factor</code></p> <p>Parameters:</p> <ul> <li> <code>scale_factor</code>             (<code>float</code>)         \u2013          <p>Factor to scale the SemSegInstanceLabel by</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>SemSegInstanceLabel</code>         \u2013          <p>Scaled instance of this SemSegInstanceLabel</p> </li> </ul> Source code in <code>niceml/utilities/semseg/semseginstancelabeling.py</code> <pre><code>def scale_label(self, scale_factor: float) -&gt; \"SemSegInstanceLabel\":\n    \"\"\"\n    Scales an SemSegInstanceLabel by a given `scale_factor`\n\n    Args:\n        scale_factor: Factor to scale the SemSegInstanceLabel by\n\n    Returns:\n        Scaled instance of this SemSegInstanceLabel\n    \"\"\"\n    scaled_mask = cv2.resize(  # pylint: disable = no-member\n        self.mask,\n        dsize=None,\n        fx=scale_factor,\n        fy=scale_factor,\n        interpolation=cv2.INTER_NEAREST,  # pylint: disable = no-member,\n    )\n    return SemSegInstanceLabel(\n        class_name=self.class_name,\n        class_index=self.class_index,\n        color=self.color,\n        active=self.active,\n        mask=scaled_mask,\n    )\n</code></pre>"}]}